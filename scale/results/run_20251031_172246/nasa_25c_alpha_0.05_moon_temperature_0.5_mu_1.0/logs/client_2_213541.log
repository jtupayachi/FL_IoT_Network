[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c06bd50-2911-442a-9d4d-9e0367a8aee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ef5433-980f-47f9-a527-20a1d6026e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e451a553-0752-4655-8d09-e7b08c82370f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6d2183-59c5-4cd1-a6f3-bd8f71a4c3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e7efa0-26c0-4232-91f7-be02e9c26e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e8b5a0-db15-44df-9012-f303a9ca3c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134c0942-8c49-49d8-8171-5b45cf036e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b71b52c-2e2e-4f74-b4ae-b837215c2d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d16629-8fe8-4fab-94c9-49c7c8881c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348a1018-e691-470f-8520-3477a9ca9a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2adbb22d-637a-45d7-8ee3-d88649d5a028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2e1b5d-13e0-4f74-b4bb-77b0f13a9e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9863afe6-44ee-4a1b-bb17-8cdcd94b822d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3a011c-3632-4b09-a1b2-bf11b69d381c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842c8641-2493-4c80-ab8f-f3655244af75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4065cf7c-40e2-47c7-9c9b-526e3e4c7758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dac673-2734-4c09-8fee-810e33a4908d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c402415-071c-4634-8cca-030488b58966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 649e6341-c48f-4ab6-92ef-a9f7d16e9a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3418ec95-c49b-4e2c-8d9a-1673361a0e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644de606-2a88-466c-acf0-eadfcd1dd4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd73b96-ff33-434e-a5c6-e10fe4cbafc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06545fb9-c29e-4391-aa15-f7f9859b7023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74a0fad-b004-4cc3-8027-24bc16f91e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbbbd57c-7b96-4458-b9b7-3bd5c6ee0e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4f91c8-e764-4a24-8407-a216267ea9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0601476f-d260-46dd-bc3f-8119910c3c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2897899e-1950-4386-8fb6-073974b0730c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e070dcb5-71fd-4389-a8d0-0cb7f81921d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09550cd0-3d83-454d-ae03-efaadd29c245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154b6544-a7bb-4ad8-a194-6a3a0d21e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edacf80f-7438-4919-af49-dc52ae54669d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d5180e5-73a8-4e2a-90bb-4d686648354d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb01133-d286-47e0-955e-b6893f1d7c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a2ca6a-b0a2-43cb-b355-da23490162e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa9d41d-182a-44dc-b841-c3ed43b58acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17a4bec-e12a-4dc5-b574-4faaf89883b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5e7ff5-4dbb-452f-b821-c315e3edd923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c47fd5-2783-4d97-9b66-1b1bc909e251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41fe3299-2647-46bf-ae10-e7486a114fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb25af3-770e-4acd-bead-2d237dfeacd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fa33c2-e525-4d5b-90bc-b706aa51af8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bf130e-0617-4a5a-8140-157e5fabb477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c640bf-430c-41fb-abdd-bfda494bab0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8ea677-524b-482a-b548-dcf26412e03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d27ba1-fd3e-47f0-b098-499ea1ba8e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e62577-4023-434f-af55-c520110de92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7d11e6-3863-49e4-b7e4-a6cb5f7c83fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc472ab9-1c9f-44e3-aa08-fc014ed2650a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195d845b-b9f3-41eb-95ec-e76b973508f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c190c5b0-b7e4-4305-90db-0d1459008253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0ee7bf-8c66-4fc1-b4e3-35d443bee0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2821d687-ce4a-404d-9bc6-164094c2da2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f87f6ee-01ec-4941-b577-1281154ca65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aca7249-21cb-42eb-8e8f-04f0cae8c1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 253da90b-cdab-4c9b-bafb-867a3268fbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc26f912-cfd6-43c6-a6ef-ee3d465c5cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29f5dc1-d295-40dc-a3e5-eafd788afe2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b6f33e-008d-4332-8f84-e7cd9f2be511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6511d5f5-8f05-4daf-87f0-f11157462fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb0278e-7901-48ac-9b4c-fc29c631e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1d6159-c85a-4533-987f-534acc486bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083b3b7e-e054-4abf-9981-5ce2c53703a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d88c03-dd31-46f2-b7f3-51a33c681686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95224d0-3feb-4162-929f-151676b1825a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c631ccc3-9040-4dac-be97-8b90e4169f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cb94a4-abe6-415d-a255-f5b8ad6b05b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c382fc53-deb9-452a-a7b6-05965046f00b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c880e0-8985-4990-81f3-4e31ba775aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9159434-e8f9-4ffe-ae0a-8e294e91b4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d5e8d1-6040-41a4-8b29-9c09a90e01aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0078f8a7-02e4-462b-b466-0aa96fa9d475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68abd83a-b344-4ed4-a21a-a487470465d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c1b05b-1ce0-4791-ac20-20be96fb2819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6bd863-8a32-433c-aa07-1a1d783d6803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7d1719-809e-4a7e-8548-120349dba6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc88374-e3b6-4d5b-8351-320a96967f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200ffc97-712c-411a-8dde-47e7002da886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89db83e7-1110-4496-a29a-404cb85f69ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e4141a-ad5f-497e-958e-5d66d77edaa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfaf5e99-5e8d-45ee-901f-089812b29df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85fcdfd-66de-4c4d-9f73-bf4ae0bfa9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f45424f5-5c58-4c8b-bb1b-93e64ba451bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb43884-4903-4bd1-a1d6-a71334b08000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c39b264-16b0-4a42-927c-63d7763f2afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23de1e89-b151-43c2-b299-5782629e7c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49119df6-32f2-4c17-9327-b2c540399fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d163f23a-eeb3-4dd3-98c1-cc8e2bede7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3862bc8-7ca9-4723-8b7a-b402699098ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badcbe0c-98cd-466e-8381-81ca4f822717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea31971-5412-4be7-9b5d-5d7314e8324e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7694befb-1f26-4f37-97e7-0d04a492c785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1df173-e09c-4b7d-9691-442fcb55ecfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27bdeba-e1f4-4a95-8c26-d3ea0fb5a897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ee9708-50c5-4d77-b9d9-9e0a74d5e6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cbbdec-e6cb-4ef3-92c6-b9f704547c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e3b19d-0c46-4776-96ae-dff4de961571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b59e785-21f5-4bef-bb3a-c5efff145d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3c154b-c7d6-40f1-b07a-e48d83c23ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af5e691-a05b-41f4-952e-990827a0119e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c033d52-b22f-490e-b452-104ac4cc5d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba39fa15-08c0-4558-8246-8df5d9b69ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713573ce-7fca-4fd8-b612-5032f65ae349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119947d1-cc25-4fb3-b179-775c93c9ec92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce332e8e-bb3e-42f5-8b13-85b774af0a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb2870f-d96e-4144-9ba4-06a57b484a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61db9c2a-fd2f-4324-88e2-828c717e6304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2411fce-981a-48da-bb11-8185b742413f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e9af98-c715-429a-a69f-d45884224f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e232a4-36e9-4272-87ed-7a7148c5ea26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30da9e2-04ac-42ac-9b3f-67f453ad2e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90dbb111-2b2a-4ca0-97de-cfc13193ccac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be4b20ae-c2eb-45e7-9e1b-19b21375fc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45230489-b970-4cb3-90eb-c0042c6182d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 605c77bc-ede3-4e81-be47-f571fbedade8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d69500-1719-4d12-9c3f-ca3a285339b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25bdea5d-5975-4af6-9436-1b53cf885b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71017826-988b-44be-b007-0b04cdacf9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca111588-d82d-48e6-8092-22a9d583b922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef88d7f-bd13-4207-8466-0718ebaaa86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c3c1ca-c7f5-4cbd-9e58-e31b036fb257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e479e82b-e233-4cf6-b344-a045558dfd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6628f1dc-5629-45ac-b488-8c8d5c2e825e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7e09c1-37a8-4f81-b10d-25435f1999f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2aadac-1a50-4d43-8a0a-057f3d23f88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c839a8-d8d9-4fcb-9a08-f8f966281d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19ac755-d016-4e56-85d4-3efaa1bc629a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071517ed-52f0-4d22-8447-22d43dd37db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38574299-162f-4bd0-b285-22901258e0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9192b0a1-aac3-43af-a96f-646356dbb9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56ebe84-5f97-47b5-b795-926cea2dbcd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01250186-2643-4a80-bf06-17ce5ef8f163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36d76beb-8e6b-473d-a3c3-924cf62218cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5af948-587d-445b-be99-873e1a2f2347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30990493-6c5c-4266-bc84-ada778ed07cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72e36c7-7bc7-4cb2-a053-7145a0c650f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba8ce93-58db-4163-a12c-43193583a58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1382b7d1-6a61-42dd-85dc-dccbe9361b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f661a49c-80a1-4564-8ed3-895a78a27f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baef6b55-72b6-4322-a8b5-766333595cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53685119-7f00-4357-991c-ab5390ad2416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 991b873a-03d7-4625-8674-25045b8a76a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa03f8a2-c5f2-438f-9089-e7d90f5d8362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7224fe92-ba8e-4c3e-940d-27093d150143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b8c0b9-a9fd-479e-9237-2d63f2aa15a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923d22ff-5542-4cad-9fa0-bc32c5b18117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e13e539-d888-4dfb-8eb4-2d52549de85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a69e31b7-c8ff-4c6a-ad3e-b8fb3af1c41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0391d2e9-8382-414b-a2ea-8715f13ba033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9d774e2-dad0-4868-9548-23c4897286e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d676fea5-72b0-4abf-8c0b-45210e542895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c260d60b-5741-4196-b23b-7d0338aaea2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b777423-89fc-4c02-8fe8-5cafc5302d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3399bdc5-60af-43f9-97fc-ef505084be1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2aee0cd-52ce-413c-aa0b-b5fb9c4cda55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad880db-43c5-43a4-87a2-cf39827f47cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a4289e4-ce5c-4189-83f7-e6488eb61fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcffe612-6368-4e0b-b01e-4c39cadaa2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31199b21-b2eb-472e-970d-9f96df1440d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf2d5ac-f532-4426-a272-ec8c23568c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f631e3fa-10a4-4c48-98ef-d2e3af620854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e732c05-cafc-4486-b5b5-18e652807b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad6e16a-e617-4a64-9ae7-702d8d9182cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf3e24d7-0db6-4015-9f39-ab6304f953b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937fa1ee-81bf-465e-87cd-04815d93fad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fe975f-22cb-4a51-8a52-e5eeabc13a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01750b7-8e7c-422a-8a36-ba904519a152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab234af-f931-4176-8f2b-1fecfc38155d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de750944-7808-4c5f-8d6a-18b7fce7340e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7cbb01-aaa3-4309-8b88-5a21b0b58c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe3a962-0e69-43dd-b1df-aba707f46051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be71894c-3959-4fc6-b4ad-52efd9331825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c468885-aeb9-4dc4-bc39-070b195c6e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf55a7e9-605b-465e-bae6-ae92c2b68c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fd1760-926e-4967-9e44-0ec3fa6c3569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e80a22-9b66-42a7-9771-a218ef7e1834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05cccec-a450-4723-a6f6-9920ff045c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34a3b99-8e4b-4b4d-8e1f-b8c48c699355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11dc2a1b-6211-4dd9-9aba-a5af3ba9c7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0dcbf3a-d87d-40f2-97b0-a5edd595583b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8647e25a-ed9c-460c-97eb-c4dc997c7c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05561b08-4e66-49a1-82b6-94b107e4796d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be101d5b-f9d3-4212-9c33-97d4454e5b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d033a8c-7789-4c34-bb29-476759852312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249116e1-645f-44dc-8812-c652571436b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9d786d-4320-46e1-bf88-ca6f91d820c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e77300-563e-43e2-96ee-b8f8dad4ac25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8f3b7d-6a0e-4217-b220-0e7e5e0b2b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f6c52e-c123-44f8-bf71-fcf3b341c028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667633ad-f4e2-4bc9-a1f0-e0198c1ae15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215c28bd-2774-4a77-a895-f747634e06bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd8c719-fd3a-4499-8659-407e88abed83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dedbfbac-eb90-40c0-9031-4521c3b9ca60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d885d65-afb2-49dd-b42e-e3cac46dd0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1177537-0ec3-450b-8a3e-f21a80c59fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f5a04a-1c43-44f8-9558-653bff09f2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51ca10e-d56a-4798-8609-2aad668925e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ba61a7-80e4-44b3-8ee2-ce32cbd7873c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be69d691-4522-4711-8fb6-86c106d1be3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8684425c-103a-404b-aed4-2975767a42cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f73d686-3d79-4741-b54d-b70f0394c8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74330f14-858b-4903-9ea7-5bb757061127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84fd2f16-94af-487e-a119-1a725c2dcefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b2bacb-6f20-4da7-9486-8284e0ed544e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7311d678-0544-4fb5-b7b6-0fc6c011bd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfef250-3b96-4a8b-bf04-cdaff444f74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34e0d5d-8cdb-4d3b-9ed6-4aa6d3d3e591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61656588-1c49-4c1e-840a-d633b51cd01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fefd8b6-9546-4436-b700-3bafab9b6477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02be1c83-8452-4c0f-95e9-ec83dd36d04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83b50d6-dbc5-4f8c-9463-7f259993804d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a078c5d5-634c-40f6-8e8e-f2c6c8b0028e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db68498-f853-48ef-9d3a-ee78633ac664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7300e1-06fc-49cc-8295-4a86c76f3e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417da2d9-c488-442d-8d55-9cf641edf23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8928c55-53ee-40b0-b20d-8585bb9ee459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07b8be5-c50a-486e-9402-38a9405ce887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97e2c41-8fe7-40cb-9b0d-6424b91394fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30fdc73a-7745-41bc-956c-f155ca0f3466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d65473-f254-4c50-a78a-f49605e5461d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3dd193-c0fa-42b4-a069-81ec66b16a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2146c5a1-e0fa-4261-bece-e56b2894c52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b531fe-8451-42b4-a1c7-877452904c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7098a823-730e-47fe-b532-3d1b3b79226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 343f988e-c950-4e5a-aeb3-12102b988c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13971ba-9a2c-4716-b80c-4924eaadbd89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77a71af-b48c-4b36-a64e-2b0628bbbe8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90aef96-5c24-4045-b99c-509fdbcc7fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d34aaa-fc6d-489d-85e9-8aac01354c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456cdc9a-4576-4b49-a7c3-db5109ad06b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e13d5bb-d9fd-4ec9-9163-307cd2e5f815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a662e0-423c-4ff5-b156-3fbe0d070b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1f5de7d-ccb0-4a36-9e35-48e2d22f1fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c0d8b0-2783-4849-83da-f8c61f621b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1431660c-7a04-41b6-af07-885e47f530b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e389c9-fffc-437e-9f85-179fa17da5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee5e92c-02a8-46bd-93aa-c0fe68c2d9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9556e8e-32db-4c35-8230-4cdb29b4c935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2feae012-dedd-4212-b7cf-137aa197cb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38753b02-c8b8-446b-8eee-a94f33e6892c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49929895-e210-432c-ae47-b8e1a5ab55c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b667d3f5-3194-4f6a-84b0-b55d1fcc23bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4081b1cb-6fc5-4620-a8d1-4b832ce96386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1e633b-ae20-464d-a982-f64f5cd1a183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d91078-0a17-41f2-93ec-f5608d5df61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e52feb-263a-47e9-90d0-592a3a0f7072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4ec771-652d-403a-b4fe-97b164c723d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2cabbb-871d-421d-a3ba-72f2586306a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da96884-448d-4bf9-b55f-bc2345befcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023a2605-b623-49de-ab26-539ce9e6a035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5421e86d-5eec-4c4b-92e6-ad49c49a514c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1ecae0-3035-4a6c-a044-70eea34994a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57cf069-0aa4-4062-875c-5d7b15697f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555d1800-d304-4d4e-95a9-71680a4a9cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee44f9c-fc68-466e-8583-dbcc4d24c86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9a7962-c6da-49cb-8a07-0f72cd3e8649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372bc7e7-268e-400c-a425-42533b059ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40489788-0ced-4a61-8569-da3e7ef1bb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c42899f-0f98-4529-a649-0af0257265a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9614afce-a04a-4635-b19b-ebab95e58a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb86a4bc-ccdd-4504-a13f-67d5dd6a8403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e034d87c-8874-49d0-a652-27fdf363f47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fef0b99-c893-4c8b-bdeb-28d19c347b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e03d592-1f82-430a-baf6-9d92a195df3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab38c52c-528a-429b-929f-e2de90e4969c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d372db-058d-4e53-9602-1d15fa5ff124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87700dbe-cd67-426f-ae6e-900b87e48ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7016a4e8-41d3-4934-8ae8-1d55620efc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ae9a92-9415-4121-89bb-1fd8e21c0caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d43026-d69f-4669-9550-6a03e1d1efc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d859b164-b227-427d-8c27-b1531e717f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0cb22df-61db-4bbe-ae26-8bb05ca35c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a4e130-9b05-4eef-a586-cf97adb13d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a6398f-0725-496b-aa9d-2d4bcd0ee2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1edd5110-3386-4ddc-a6f6-5aed717378b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714a1023-5696-4178-982e-8dcc381a6fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6457c134-5642-46a6-8c8b-dd33f5edd6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f38eaf-2360-4b48-bbcd-9189cc5544d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f87286c-bed1-4f2c-a291-78e543fe1f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3916a23c-b1db-4f0a-9695-7071c6fdba31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028516d2-b712-48c2-81b2-45936038bfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8acb9f2-f4b4-49e2-812a-392a577202a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a97fb19-9893-4c59-9585-243044a158a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c421c5-24ab-45bc-b90a-f844f97a6b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392aca2d-e549-4098-b1ba-1914bd05795b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f2459a-1e9d-4cc9-b540-37ee2fdf0b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cbaf539-4a67-4b85-a961-c526baa2717c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2811467-ac27-4b7a-b178-391ceca46090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23cc22f-4b5b-4dcc-b0b9-377aaf09d405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb5f18b-b74d-4a9e-9cac-1a7d18d48b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d128b6c3-f036-4239-ac87-8c175631f30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92952850-2c62-4673-94ad-8caa2c219616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6001f037-9a72-42d2-82b9-4578344bf78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae884c9-d574-4ce3-8f1c-dc34e6008f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf43a8ce-4c93-449e-8d82-3a3ddfefabf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec462ab0-25fb-4a51-ad08-1220a4302dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0084e58-8ebc-44e7-bd80-154603608d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c3c97c8-10c5-4599-a680-891c64532818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23d4a03-a84e-461a-a487-a57c38123eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23fac5fe-4e19-4fd4-b659-6fd1a43c4304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5166cd43-5681-4f98-8c17-3cf60604ada4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf2ce23-0a5b-4ab6-855b-f7abbbca2492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997b86d7-9d0b-4fd6-87bc-46e5226a7ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae610f6c-eca7-41c7-94ad-ede6a65e4388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa6b9d0e-5609-4bd3-96d5-bfde2124347a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e274335-0777-4084-82df-2206ddcf9948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a802d5-fe68-4ad5-9ab5-cd80730cf882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e66e59-98b8-40df-b39a-b305fc8331e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef7aa08-aa55-445a-baee-9f2126de660a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ddb15d4-eb90-4dcf-9760-fd081e661dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 952d7a87-6890-495c-aba9-6f9373a65188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e60071c-2d83-49d4-ae8a-be3efa5e760a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb33ef0-fd52-4af1-a22f-ad08cb926531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43cf16f7-e8a9-4a9a-9f99-613c702fe8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4a9417-0b61-4d3f-82ec-aaea210a8deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c7bd46-bfba-4e6a-a7f1-b2ff7608d5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc8e65d5-644c-46fb-ac27-7e3b7a12e72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1187a1bc-cec0-456a-8aeb-e3e46b95d6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746e4460-a829-49c6-8263-19e06581f716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b9dc9d-357b-412c-8bc6-c6847afd5a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903d0c73-f7cc-41b3-9eaa-f8a2bc825bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b02a1ba-f6ed-4761-a248-9daeae9a032b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a80f86-6f0b-4573-91b4-7dbf9382712f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41a6955-5a95-4f37-850a-7da71b2e137f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e573fa95-0586-4392-bfd7-e92e59cc9f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95320877-37c7-4f83-b54b-055f9b63d322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cded9112-2265-4b15-8a12-1cb621496ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f0971a-33a5-4410-83d5-1287638eeb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0459fa-811a-4376-8eaf-26ea5864b0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2e7425-40f6-4591-8c24-1b88c959f509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec748a6-121f-4464-8691-b08d0885bfa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cad44cc-8e91-4c1e-add6-3ee0f483bce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05087ac-5b3e-4add-a3bc-d054432c3413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1e7844-6423-472a-991b-e6557a5aa27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a89b9e-50e6-4a0b-9284-a083e608ddb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46ffcaf-e482-48fa-b502-442ea6cc8180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc7031c-f8f6-452c-999c-a6cc14eafb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e88e408-083d-4bcc-b591-d599db2a4b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b037bd00-6108-472e-8d1c-5b42124c597d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb80f14-1846-4194-a208-3ce88cc8b195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4517d941-0e49-42dd-939f-3f758eb38ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc6351b-23eb-40e2-9b44-d02cbf34fc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c86f80-b9b8-4fd4-a01e-4e76023e911b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349c13cb-777f-4575-977a-30cee26ea6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0828945d-f0f8-4f3d-84f1-f51821bac043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad72cd0-8732-4d3a-89c8-9c6525c663c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9537bc00-a031-4280-9258-1c61f5e332e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080f4c9e-5294-4f9a-abc6-c310e403ca32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e185f685-f906-46f3-9863-19e8295213a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a89178-b101-4b74-a762-8017951f32b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db15c06-db03-4251-90b8-3f20f6852f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8256f4bf-eb90-421a-a791-e099c7f45fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf021319-b138-4b6c-99a8-bcfe4811f331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1c8a5c-8121-48db-a33a-0e22777720c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd40fdeb-e9ce-4c7f-b75e-2c369b2ee42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121d6bd6-41a6-4a0b-a362-6da1f2322df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9061b09b-e81d-4b6b-aa4a-3acba3b5e832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2acfbbf0-e4f9-4e91-916e-f6e326579146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5007ef-25f9-4269-b3ca-51fe6bbfe8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cdc15d2-7581-4be8-9f32-a9380fb3559d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5d01523-82ea-4e4f-82f1-257e3b2523d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48e9459-c417-4b29-bbc7-71096c87e3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8748c2c-abbe-4eb3-9a35-9214b4a17e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb12bb5-87bb-4372-b50f-7459c5f98efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f439f17-45d6-4459-bc01-e058c687cea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d620f62-a50b-4ed4-ae2d-df8e35696a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ad557f-8972-459b-b2d2-89474c8e2e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a4205f-d68a-48da-8a00-0087e7dace88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a926103-1d4f-4748-8c3e-8e6868c17b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25896a07-d2f2-48b4-8e9a-698addfb85ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc300e8-a4b6-4ef1-841e-4f224b9afb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c591f1-70d4-48a9-8a24-694efedf784e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 266cf246-4c05-487e-8abd-9502a2ceddf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e6b5fa-7938-49a9-9fa7-7d977a9f331d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d2c02cc-345f-499f-9654-d8ce4f78ec1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c7ad0d-00ff-4653-8353-63fe354475e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 845f0683-0eb9-4a92-8cae-40b9a70184e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6babf22f-aa56-47d8-9d8e-e4c3a86aa52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab6b59d-4ce4-4ffd-b642-c3f95c48a8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f686a03-6b3d-4da9-a658-d6625c8bbd89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ce70cd-f04d-413b-916a-dfc2f98c2abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ae33bd-fa31-4c36-adf9-76e4ada794d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464f6f16-9870-46cd-8efc-569937e71abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe8a271-5c0e-4019-adbc-0e3d056c840d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6f4dd2-fdec-4ad2-b895-fe2328422838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2576d7f4-ddc3-42c9-9d00-20ac690f7b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9afb468-b7bd-4bd5-83f1-8b19ba378a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4e65cb-da71-405a-b242-636be7bb6d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f47e415c-e287-47e5-8991-edbd5e60a2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6911a5db-2ea1-4970-abaa-dbffe50ce088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb44caed-c91c-4703-8a17-a51c30bff75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016b7bb3-7f73-47c4-8f69-966390e587bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ff21bb-1500-4b3e-ae32-775a18ac962d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0327298-075e-4f74-bb26-65e7ca35c762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919c5d02-648f-4679-9c8f-0e40c964ea3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b1d70b-69f1-4b04-97c1-52ca1c8fbf69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681a638c-61f8-4dc9-8499-e9805b36c905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2112b2a7-41b3-4bc2-b071-61c974c9d09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae719788-f847-4963-b563-a447ab3c07d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45a7a3c-850a-44d1-a34b-053e67f4c7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3629203-af95-4ed6-b0a7-5782815e078e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13cfefe2-0024-4423-a548-3ad853f7b899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc219a4-a28e-44e8-a23e-310b89dfb5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ed4230-b3f7-4f8d-9ee6-09a9b9cc655d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282f0598-f478-44ac-8f29-04014afb6fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babf3538-7b20-435f-854a-233d23c03e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66dd1ef3-eaee-4c1e-81db-f7c1ed09f5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697af243-3a0d-477f-84e3-75141f4fe58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed834aff-cfb0-4587-a8ff-7b0baafad519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabcceb5-9889-41c6-99f1-18d2b0804f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff604d3-5f99-4db7-91c0-0821db7ddd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53cf1984-e461-4ae7-b5bb-7207e25f8615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9337c961-2d8f-4488-acad-ce1a6b08807e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb989cb-9fea-40ae-b37e-4fc938b08ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b97cc2b-2474-494e-94e1-83ce9963ed70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a26fef12-05bf-4ff6-a353-ef23afed1c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1c9717-00b4-44b2-992c-be1418784174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32792e8b-6602-48ff-a920-82d2d34d7b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b720f61-42df-4f9d-b560-a51058e32f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5226ad8c-418c-48ed-b7d0-ab1939a207a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052817fc-f6b4-4293-a143-125084913db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39fe601-7abf-4ebc-9d2b-c477139db336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692ac9f7-5427-4a6f-9f73-36d59507f3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b9f53f7-2a60-403a-a787-917bf2465a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1b0270-d50d-4f7c-b5a6-739ec69ba478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998e39d3-ef31-4765-9413-69046361067f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d52c65-c74a-4270-b08f-91e626604274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6686d6-d52c-4e31-8460-a1bd56d08862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edefc199-94d9-4a0c-9c6b-397df27e9730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a62b4d-7bfa-4301-aff2-a7027b876237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1e3633-a19e-4db1-8919-a3ce4fa31938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6bbde6-4f0c-4b4b-824e-e871f63de618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc7e1e82-eb27-4e14-9318-0152b50a217b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83542ee3-5bdb-4d7a-bf24-444eb58cd93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69aa89b-83e8-4b6e-90cb-b9b51b346915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e353663-2316-4eba-a9ca-9a4a3505dca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7e4dba-e38a-4fab-8180-87874cc9cc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12c9d3b-136a-46f7-a646-0204e702c739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4145d4-e97d-440e-9818-7ec89de0d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1aa6cb-2667-4bd4-ac03-481b3a07e7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98cda06-afeb-4d30-92dd-5a21a0a2aca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f23462-e428-4e3c-a587-80a7f3fdbedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ba6423-ebef-4d3a-aa5f-4cfdeca7d922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce9ed29-c8c4-4a5f-b37d-0643ebaf336c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9c8a79-2582-43ff-acb8-d5942be90eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ad6344-6370-48bd-8f71-31fa2919e63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134db842-f294-4a5a-b393-ea4a6ee3e963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f9cc1f-66c5-4abd-bffc-3577ef904c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e938046-6a0d-4da8-bf24-e8aef20eba10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a699f0f-6d90-4886-a10c-1f6dfab1c88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0654a57-5262-4bd3-ae1b-1656777d1b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ec3ba7-ddd6-41be-a5b6-4ee8087be1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21b1fec-819c-46b3-9164-ebbe60cdce2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8995224e-b29f-4610-8d48-3859fd453118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39f4dd88-0641-4b23-9d17-a558f3b5f678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d34386e-1a24-472f-9fd7-74c26fde60e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a87f99-7457-46df-9f19-0ba9136997a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d9ab78-fc5b-410d-872f-0a80e7d76324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e255b85-37ae-4283-beb5-e7ebf6b7c580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f3c40c-bc28-48b3-90f3-ef73b65563b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8773a072-5d3a-43ab-8d7f-606af3df062f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063eab3f-effc-45b4-84fc-5fb0c79c30ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6786ec21-599d-4012-ba87-900fbbeec8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e11107-5fa8-49d6-878c-b814cfc8f8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb04a0e-6547-47a7-963c-9c5c33a77f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e3d8ce-0c2f-4e24-bb05-eca3cc1c0358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86322330-4692-439a-b22f-0c2107a2f0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e423fb-7d1e-4830-b718-dd08fe192960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a437b9f1-dbb2-4cc1-863e-a9b3f976d3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49809a1c-545f-4f9c-af08-70a646829270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4ab91a-2948-4f44-a049-de7107efe880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0c1c49-02f8-4ea4-a7c0-b5353478aafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cac52a-d888-41ef-900e-785df6f6a512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d1e828-0902-418f-9d68-985c32ae653d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cff050a-4a91-49c3-8ce5-541c91a40ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172b74d8-1ed0-477b-bc3d-a949c75365b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f337361-2fdd-4ab4-a9ce-9f9ad320d251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1c7704-03e1-4fd3-8122-629d8e937680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883d7642-d1bc-427c-9bee-83953db0f217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df8992e-aa9d-42cc-90f3-8b20664cb51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b03a32cc-2100-44cc-a557-d024c6299107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75eaf436-2086-4366-acfb-502eaf087b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c78901-3a65-46b8-ae6a-e87913637ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdd6fe1-0a01-42de-a64a-7489e210ac9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4a6092-0320-4b97-bdcb-9110195f980c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9a6379-de99-48de-89c0-65815b2bf7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb77ad1-2a31-4303-8d91-55da5957b6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9294e35f-3dfa-4497-b908-a3296335110f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10209381-0ed5-4755-bff5-34bfd90e792e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5082a8-ba67-458b-b28e-885cb3213b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f01f8db-b618-4240-9a88-c45a9f6da4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd188dfa-6725-4a48-b224-d16902b3fd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297b0139-f8f2-41dd-9eb2-365bb9d76192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86157bd-7281-40fd-aee2-9347c875b613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 767f5d80-ba2f-4c1f-bbd2-a182eae531ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a48b7a-5168-47b5-aba8-5b465a3121a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa462b1b-e201-4967-b40d-d0de9d23af46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b091c4-644b-498b-b0bd-bfa9b66ed0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263a663a-eef9-4001-93d5-d1518d0f7134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78fc68f-5df7-4428-afb7-5fe235acc612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da33124-958b-4afa-8b1c-952386bacea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5ce073-bf6f-4576-b891-12a209b631a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c68edb8-34ca-406d-9457-6f49a9ea0f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a746c0-ab7e-463e-8998-4b8f514ffbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3232026c-59c8-4706-a7eb-c927845ec35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee10139a-d48b-44a2-80b6-ec5c8899fad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9319d8a8-d6ed-4fd4-9add-cafdec4b052c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5914b1-ec05-47da-83a2-826db50712d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40427e77-545e-4404-ba36-e21d1fa594a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2b9bb0-1759-4716-81c9-6c434e05365a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80aeed5-8419-4298-b284-f645f6c894f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840cadfd-de79-4700-b052-0d7358699e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e992c4b-3c69-4fc2-b2cd-4a321850913a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5957fbf6-f1c3-462e-8480-e42e9c13ceae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d7d760-fb8a-4203-aa78-3d3d3e60a7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b122e0b8-6de9-44bf-845c-3ce2c67a5043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8c7e03-3ad6-49ec-9e72-3c815ea48a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2481ca82-9310-4989-8e20-17de38258366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f71e23e-9922-4700-bc9e-f93ccc615639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e11a19-76bb-4656-8b1a-15110af05f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4375600-167a-4bfd-a9f6-4d2338c5ed27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3cf59f-0b39-4ca9-9a81-2d4dd37a31d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7e0654-0b66-4990-91b1-b07b5d92dd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39334a6-4163-4f72-8584-08017126d2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e872c651-0a1b-4e51-9c19-14b1967880ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922cf606-76d9-47b5-a9f9-68487edbe2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1527b7-8c86-4941-a10d-c8e85e0cd787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d766d2-f65c-42c3-a24f-900b75064c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc69ee5e-7643-4e59-b412-a4a4ed54ab05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dc6b59-3cf0-4dcd-b4d9-7dc8673ff487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0c105b-963a-4e28-bd43-0c117cf52c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5505aa37-bce0-409c-9aeb-7f670674d982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3584c957-cd45-4c38-b98b-c2daee5746e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ac05ac7-a7ae-424e-b80f-b96228508f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a62080-004f-4e43-8cae-23d6970a9f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff93e1e9-e4b6-43c8-a238-a84102fcc651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00721822-7dbd-4f01-a554-38a394b896c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4635db-2ac8-44e5-b244-d12fb5b1a328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f092dcb-a3f1-40d5-a631-02e1a5cef9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c29fc262-8563-404b-828b-7578d42573dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85a12f82-1037-46ea-9adf-c751ddc7f5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022ef914-bcfc-4151-8976-740725a2f8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c448c7-b157-4707-8e55-eb06e4985708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d68cd8-0606-49d4-b3f3-96e8c7179c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb0e7c4-1f88-48e6-b712-3b6ded9b0e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086ae7a0-5d52-4576-b0f8-7b5422ef05e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f096f8-b365-4639-8608-774a08587de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79876ca8-067b-43a9-abbc-4ff1d7c4ee6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ee0a54-c242-4a5d-8f4e-2370e390ecee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c20b2a15-ecef-4b30-a81d-3c2cef8da93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519de839-f9f3-44c8-9754-d38756799296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5be24e-cc54-4954-ba59-4a948682c288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d3e613-dd7e-4def-a005-fcba2385b847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad553e2-a6ab-4f9b-921a-3e5b7941997b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a7c04e-9020-4c55-8480-178b6b65d676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7595679a-6994-4b56-ad97-b6244467eaa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c97b84a-c10e-48f0-b88c-7e6c70cba8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f927296-43df-4ebe-a099-5f927caef8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99eba9c-c7b4-4834-9b72-cf545edc5fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23909cc3-3133-4b6e-9939-d3820f1c21a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16897346-a260-43a1-841d-0f8243281138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1db741c-cd91-4c9f-9a7b-8f7a060f42cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5418a3-6ef3-4894-b90e-4412e9d86ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc958a95-233c-477b-8b71-8944421a7d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228e4533-bfd2-49b7-af47-342e3634cb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824582f4-833c-4f01-8560-06f9acaf3500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c34e9a-3d70-487a-b85b-5876db06d4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd27751-bb78-4072-bd2a-d1f315f6bd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3ca328-1da7-457c-ad89-21da5db76eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b77caa2-2d96-46db-8f40-a78c9c036a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c98b5d6-633f-4776-9641-68df22f9324f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5fcfded-6110-4e01-8a4c-bf67b15b458e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdf2b8e-d78c-4be3-abeb-75118d7d7bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe5ac2f-cc86-40f6-b48f-a4a0c7fce449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90848aba-3dc7-436d-8c77-84c74f64bb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6504bd96-a81e-45da-9805-ddfcfd6e58d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8cb132-c50b-484f-b68f-e6063c79cc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd51e28-1dc4-4758-9873-b7ab4d2b8c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b05ed2-1ed8-4874-81a1-efedd8c245a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ac4a37-7440-4e55-8ed4-fff6dbbdbb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42161ad0-3e97-441b-a5d7-c6cc7a9eed71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf33d410-7be9-4b7e-b70b-be30841d297a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d76136-5628-4d31-8db8-d3babf4d85d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a21b0af-ab66-4566-bf06-215b6b1226bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d59ff5-6239-4b31-ba24-8bc426d95519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b04a10-d9d0-4c95-9622-2eedd302d56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456b0c01-c714-4b20-aa61-75f26176f6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44dbe65a-ab99-405b-b51a-ba2c733965ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c8299e-b864-424a-a210-d981c9f56b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4527da24-160a-463f-8a86-ddfd5d36365e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0e77b2-3939-4e65-825a-ed735fc69de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59ce67b-3b3e-4b3a-ba16-6e72b391d02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1c612d-99d1-4f72-ac9a-76cd42189105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d22f6b0-9941-406a-90f6-1dc9ed5afb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e45c34-fb6a-4279-9895-2b2104111393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3d6b45-c480-455e-8ad8-f832bbfba359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac377dab-473c-4249-a4a5-5fe658086580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab3ef8f-811c-46d0-9753-d931b8ef24f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5d3680-d6c8-4db3-b711-abe91d682fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4152cd6e-2b52-4525-811a-4d00ec9502f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee89fc9-2d91-4846-a722-d5a7a77f6bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3647200-204a-4489-bd65-c3b09e385781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8031ea-1240-41f4-9190-6faa29183918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21366ef9-0a05-4a35-b82f-2cc874d9c2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecfdf02-f730-4453-b9df-7ff946c240d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ae36052-ac19-4cae-bc0c-02b3d8b5ee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351830ec-f63d-41b5-b280-3f48a16c8f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39a4573-89bb-4bc8-9f16-4be0a77b21eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1278923a-6f39-488f-9f98-8d0381a01b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04420d5d-de29-4b44-814f-ac3889b23b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e51dea6-fd7b-4a3f-bf36-60599632cf02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ae103b-0b6b-49f8-a416-fa25a59e7ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602001c4-0836-4354-9310-5fff5e00855f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59077842-70c1-4ac9-bb7e-6daab3759e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4236ee-93c8-4488-846d-6fbc485862d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c5efec-eb02-4663-a6ba-c3612c2220dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca45e942-3362-4eb0-a8b5-116440699a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63d99b2-e7cf-4c35-81ff-f44055e20073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3abb2cc6-b270-4456-857c-705d6096a217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b19f8e-3a5f-45c0-a211-d545b6562808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91616deb-b12a-452f-8ed8-08de3924516a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941d063e-83b5-4f39-8b12-ed2291b2b784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09322b6b-4c0d-4a11-8b02-4c0631f8a157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6eccfbc-5817-4723-bc94-d2a2b524cf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd333e4-209b-41b8-a7ed-bd242d4aedcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4001c8-b917-4130-900a-c25022018a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9115340-a563-4592-ad20-a4477ca4e977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef9ce02-0a3d-4dff-9089-948cbc638e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588163ec-3c6e-4b53-8dfc-93bcc82354c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616f912f-2b5e-4aa9-9cbb-582da445ceaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b84fe0-b620-4dad-8900-87506e44ef86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbd7a4e7-23c1-4c66-b527-5ca435ec0044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d787f99-891a-43ab-bece-a1a1334e7a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666a0ddb-bb70-47bf-9a33-d709363217e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e1cd86-44da-4ed6-af4d-f389d6367a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06105c1f-7956-4cee-987e-448283d1b536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8ce8fe-6966-46eb-9a09-9a3de935e434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b06628c-8d0e-4298-9caf-34813a3a21e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc39b8ba-3f05-40f3-bf9d-d941244487f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90fd743c-15f3-43bd-8f89-0dc0cb7e1560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2960d18-65dd-4ec1-9c24-99e7ab96f1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac76d14-814f-40c3-8199-a302fff166ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecb3212-f12e-42d0-8b79-7bbc4ac43c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c50092b-bcde-4541-8fd6-55e3e68f0cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df6d256-b004-4a8f-811d-2eae2eff909a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2936d2ac-d54b-405a-964a-f68a16123158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa31be30-9f72-4ee6-af62-d5745d1332da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5259d60-6b9f-4ee0-8268-db1e4b1feffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e2ee99-39ee-4c7a-a7c8-1303316b8c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51f795da-800a-4e35-8111-56c73207004e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1729b9-05df-4bb6-ab49-66cb40a0035b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddcb24d-60b7-43d6-90e1-4e872875db21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff173b5d-d8bd-49f3-b38c-319e0b765a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075d7ed7-52c2-474e-8a5a-6c693bc56d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d054a155-50da-4737-8b6b-507efd75f204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bca8578-69fb-4ec1-a68b-14331e990acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22bfc1f-942e-4a4b-a29d-f063e3a10095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec37adfd-2832-4254-bab8-5388a2c096e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f15b5f0-ca7c-444a-8b79-b07a0c497749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8825509c-4f2c-4fb3-b0e0-682332adb93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1a63f3-274a-4eb2-8ab5-b71e9e94bc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf57ce58-8e24-42c0-be00-0cbb4968d060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e22a7c9-c95c-4e8a-8ac6-93bb0ff26f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47bc65f2-bc74-4e92-abb3-237ae22d3ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105463da-51ef-4357-a85c-3ad2036b8129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed33aa99-0cc6-40db-8528-51ef74a08b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa6c58d2-3fc3-4e02-929b-352c8d6e486c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54403b9-e6c5-4fba-86e1-953e95654113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404142cd-2d21-49ea-9e58-35845f6dc350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8535c9a-490b-4859-90dd-4a9a91a1ca25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af9dbb4-0c9a-4159-b958-4131244b91a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0c7eb2-1a54-43da-ba7c-c423dbf75d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330a3455-33a6-4233-b27c-ee62f4bbda5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f387fba3-ced7-4273-8996-42e772e2f7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba4ddcdc-2704-4c13-9935-4f60ffd74298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf3c5ad-4da6-4c45-9f20-ca69ebd30263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d81e89-5f2d-4308-a02c-389223f3895e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bc463b-c1e1-40ef-96fd-ab659bbe2851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45cf6049-3f23-4908-828d-acf8aed992fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fcba1c-931d-408c-8b72-9893961dda95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba9e9c0-11e2-48f9-befa-9af1b9554cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8af1ad9-101c-4b45-a542-5c4cbc8575a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f916c5e3-a9f1-4409-8a1a-c572ad26fad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26531e4a-6f4d-4f2b-aeae-a3ce66f77a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a877718-eb56-4b02-92f7-7321e02906de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0db453-913d-41d1-8944-85bd47fd3ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d2a075-0c49-4125-80c5-39ff6c2bb7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa29bfb2-d2b0-4ed6-a8e9-e0beeb8f5943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e2c89c-e33e-4a70-8c8e-be5d8d7e933c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a210e1f-7889-4ef9-a954-cd8fd3f38d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42d58b6-5502-434f-9742-d7e1df51f5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a1d971-69ce-482a-ae2d-a9a521b8d6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01971351-145f-4c73-aead-e71c3aa2c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623a99aa-9d25-49cb-9798-63f5e8777bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8967cb1-7c9b-4bca-ae0a-8a48fe29dcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633927f6-1fef-4abf-86f1-443785edd2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6163fad4-2cbd-4b1a-a118-071dcae6a0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af4c23c-1506-4894-9ecb-97c0220fa7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526da0d3-0489-491a-b17d-a034d39d7c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2523ec-0de0-456e-a9b2-b73a7ef5307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1d8ca1-99b9-428c-b0c4-20a9e55b45bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e3ef3c-8ebc-445b-9216-47c52a1d6354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c871ccc-2e5a-4cf3-9e8b-7ecb1f729987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf674e7-aa28-4850-84a9-52ee1054308b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1092457c-5278-4bdb-9497-3819dcf6b4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc16266-db7c-470c-b9c8-a2ed3d17805e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc142d8-99b1-4784-b30a-acaa862453e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961aa99c-9429-4740-8ebd-6452cf7dc318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad4d383-035e-4fcb-991a-64b463da0f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ef0e83-16a8-4040-b4b6-e9e40279d389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ab0035-afa7-4e85-869a-57c19e64b5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d85150-93ba-4f9d-ba51-1ec78bf5484a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e67cfeb-6d9d-440b-ae6e-cd9e62e15aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c9a429-383a-437c-9e2c-8bdf3d722565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e2c623-2be4-44ce-8b34-935284121650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7951ad-4cf7-48c4-8c56-14fae52c8d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf1bed4-0146-4d34-ade6-2d376b01c406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77c95a7-61dd-428b-af89-19be3db39214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b3a368-27c2-4e2b-a269-51f207f9c346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29494d1-c31f-482d-9d2c-16d772c73ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99aede11-415f-4195-8fef-a8ca58aa8b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1fa99a5-90a3-44f5-b790-e1f3a64d55d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abbe47f8-50e2-421e-b0f5-36bcada2a853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88976bba-9662-44bd-8317-85d1fd80a047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7702c420-b8dc-4df4-ae1d-8d5111960549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ec4528-b1c0-4a01-86ff-64fdd29dba45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1f21c0-aec9-44f5-9ee3-655a26a2845c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02af14ef-7402-4e67-9681-2af33e5eefae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb313195-7aa8-479a-84ab-15f60c1f350e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(5055, 24), y=(5055,)
   Test:  X=(1264, 24), y=(1264,)

⚠️  Limiting training data: 5055 → 800 samples
⚠️  Limiting test data: 1264 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0852, RMSE: 0.2920, MAE: 0.2523, R²: -0.0150

============================================================
🔄 Round 4 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0816 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0830, val=0.0775 (↓), lr=0.001000
   • Epoch   3/100: train=0.0809, val=0.0772, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0800, val=0.0770 (↓), lr=0.001000
   • Epoch   5/100: train=0.0800, val=0.0766, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0788, val=0.0758, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0759, val=0.0756, patience=6/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 4 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0483
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0379
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2513, R²: -0.0024

============================================================
🔄 Round 6 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0802, val=0.0778 (↓), lr=0.000250
   • Epoch   3/100: train=0.0797, val=0.0780, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0795, val=0.0779, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0794, val=0.0777, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0789, val=0.0770, patience=1/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0786, val=0.0767, patience=11/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 6 Summary - Client client_2
   Epochs: 25/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0191
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0150
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2514, R²: -0.0034

============================================================
🔄 Round 9 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0802 (↓), lr=0.000031
   • Epoch   2/100: train=0.0797, val=0.0797, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0796, val=0.0795 (↓), lr=0.000031
   • Epoch   4/100: train=0.0795, val=0.0793, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0795, val=0.0793, patience=2/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0793, val=0.0790, patience=8/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0792, val=0.0788, patience=8/15, lr=0.000008
   📉 Epoch 24: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 9 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0079
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0120
============================================================


============================================================
🔄 Round 10 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0832 (↓), lr=0.000004
   • Epoch   2/100: train=0.0790, val=0.0831, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0789, val=0.0831, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0788, val=0.0830, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0786, val=0.0829, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 10 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0030
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0033
============================================================


============================================================
🔄 Round 11 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 11 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0011
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0155
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2514, R²: -0.0031

============================================================
🔄 Round 18 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 18 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0071
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0078
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2516, R²: -0.0045

============================================================
🔄 Round 19 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 19 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0026
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0284
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0044

📊 Round 19 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0044

============================================================
🔄 Round 23 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 23 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0029
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0068
============================================================


============================================================
🔄 Round 24 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 24 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0069
============================================================


============================================================
🔄 Round 25 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 25 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0044
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0439
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0043

============================================================
🔄 Round 30 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 30 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0049
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0047
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0043

📊 Round 30 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0042

============================================================
🔄 Round 33 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 33 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0014
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0009
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0042

📊 Round 33 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0042

📊 Round 33 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0042

📊 Round 33 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0042

============================================================
🔄 Round 39 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 39 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0023
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0005
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0041

============================================================
🔄 Round 41 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 41 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0009
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0220
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2516, R²: -0.0041

============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0066
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0058
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0041

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0041

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0041

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0041

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0040

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0040

📊 Round 43 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0011
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0265
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0040

📊 Round 51 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 53 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 53 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0046
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0531
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 56 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 56 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0051
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0068
============================================================


============================================================
🔄 Round 59 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 59 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0015
   Val:   Loss=0.0684, RMSE=0.2616, R²=-0.0042
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 63 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 63 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0039
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0016
============================================================


============================================================
🔄 Round 64 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 64 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0035
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0027
============================================================


============================================================
🔄 Round 66 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 66 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0085
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0174
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 68 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 68 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0075
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0055
============================================================


============================================================
🔄 Round 70 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 70 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0103
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 75 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 75 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0020
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0043
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 77 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 77 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0018
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0059
============================================================


============================================================
🔄 Round 78 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 78 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0052
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0074
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 79 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 79 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0099
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0071
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 80 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 80 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0069
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0093
============================================================


============================================================
🔄 Round 81 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 81 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0027
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0044
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 82 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 82 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0017
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0079
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

📊 Round 82 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 85 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 85 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0042
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0068
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 87 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 87 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0057
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0115
============================================================


============================================================
🔄 Round 89 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 89 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0029
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0011
============================================================


============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0064
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0116
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0104
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0068
============================================================


============================================================
🔄 Round 97 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 97 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0024
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0038
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 100 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 100 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0047
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0057
============================================================


============================================================
🔄 Round 102 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 102 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0015
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0344
============================================================


============================================================
🔄 Round 103 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 103 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0016
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0075
============================================================


============================================================
🔄 Round 105 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 105 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0080
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0121
============================================================


============================================================
🔄 Round 107 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 107 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0010
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0134
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 107 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 112 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 112 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0015
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0110
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 112 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 112 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 118 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 118 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0089
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0142
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 118 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 120 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 120 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0051
   Val:   Loss=0.0781, RMSE=0.2796, R²=-0.0050
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 120 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 124 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 124 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0102
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0139
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 128 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 128 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0028
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0075
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 129 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 129 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0053
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0045
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 130 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 130 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0029
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0353
============================================================


============================================================
🔄 Round 131 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 131 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0090
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0106
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 131 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 133 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 133 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0051
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0050
============================================================


============================================================
🔄 Round 134 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 134 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0022
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0055
============================================================


============================================================
🔄 Round 136 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 136 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0021
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0399
============================================================


============================================================
🔄 Round 137 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 137 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0010
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0138
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 137 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 137 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 144 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 144 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0028
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0453
============================================================


============================================================
🔄 Round 145 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 145 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0005
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0204
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 145 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 145 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 145 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 154 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 154 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0005
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0279
============================================================


============================================================
🔄 Round 155 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 155 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0052
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0013
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 158 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 158 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0023
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0055
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 160 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 160 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0092
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 162 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 162 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0026
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0043
============================================================


============================================================
🔄 Round 163 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 163 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0023
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0053
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 165 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 165 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0032
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0685
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 166 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 166 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0012
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0222
============================================================


============================================================
🔄 Round 167 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 167 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0060
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0054
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 171 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 171 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0001
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0345
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 171 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 171 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 177 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 177 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0063
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0057
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 182 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 182 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0087
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0087
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 182 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 185 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 185 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0024
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0463
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 185 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 185 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0074
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0114
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 191 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 197 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 197 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0004
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0332
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 197 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0002
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0182
============================================================


============================================================
🔄 Round 203 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 203 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0040
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0017
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 203 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 203 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 209 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 209 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0030
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0057
============================================================


============================================================
🔄 Round 210 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 210 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0005
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0252
============================================================


============================================================
🔄 Round 211 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 211 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0071
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0052
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 212 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 212 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0048
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0021
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 214 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 214 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0019
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0093
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 217 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 217 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0007
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0323
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 219 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 219 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0006
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0232
============================================================


============================================================
🔄 Round 220 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 220 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0046
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0010
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 223 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 223 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0015
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0582
============================================================


============================================================
🔄 Round 224 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 224 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0050
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0022
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 225 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 225 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0020
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0092
============================================================


============================================================
🔄 Round 227 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 227 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0039
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0023
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 228 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 228 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0139
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0026
============================================================


============================================================
🔄 Round 229 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 229 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0025
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0065
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 229 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 233 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 233 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0081
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0096
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 233 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 233 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 245 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 245 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0037
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0028
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 246 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 246 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0018
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0136
============================================================


============================================================
🔄 Round 247 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 247 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0032
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0046
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 249 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 249 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0018
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0406
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 249 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 256 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 256 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0057
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0042
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 256 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 259 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 259 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0030
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0058
============================================================


============================================================
🔄 Round 262 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 262 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0097
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0157
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 265 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 265 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0072
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0003
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 266 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 266 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0030
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0058
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 269 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 269 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0051
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0020
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 269 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 272 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 272 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0000
============================================================


============================================================
🔄 Round 273 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 273 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0024
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0091
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 276 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 276 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0019
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0130
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 278 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 278 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0004
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0180
============================================================


============================================================
🔄 Round 281 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 281 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0073
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0039
============================================================


============================================================
🔄 Round 282 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 282 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0055
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0036
============================================================


============================================================
🔄 Round 283 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 283 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0019
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0120
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 283 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 283 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 287 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 287 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0021
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0096
============================================================


============================================================
🔄 Round 289 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 289 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0010
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0307
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 290 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 290 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0023
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0162
============================================================


============================================================
🔄 Round 291 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 291 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0035
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0073
============================================================


============================================================
🔄 Round 292 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 292 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0054
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0025
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 292 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 292 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 296 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 296 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0073
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0063
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 297 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 297 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0042
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0014
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 297 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 297 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 303 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 303 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0095
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0060
============================================================


============================================================
🔄 Round 304 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 304 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0101
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0037
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 304 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 316 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 316 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0111
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0023
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 316 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 316 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 320 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 320 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0031
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0058
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 320 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 320 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 324 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 324 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0199
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 324 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 328 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 328 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0027
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0081
============================================================


============================================================
🔄 Round 329 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 329 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0022
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0208
============================================================


============================================================
🔄 Round 330 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 330 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0025
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0436
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 330 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 330 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 334 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 334 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0086
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 336 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 336 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0028
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0078
============================================================


============================================================
🔄 Round 337 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 337 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0046
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0007
============================================================


============================================================
🔄 Round 338 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 338 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0046
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0005
============================================================


============================================================
🔄 Round 339 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 339 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0042
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0018
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 342 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 342 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0025
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0117
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 342 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 348 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 348 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0007
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0325
============================================================


============================================================
🔄 Round 349 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 349 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0015
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0236
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 349 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 351 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 351 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0021
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0193
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 354 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 354 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0002
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0217
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 354 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 358 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 358 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0039
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0030
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 358 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 361 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0667 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 361 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0106
   Val:   Loss=0.0667, RMSE=0.2582, R²=0.0170
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 361 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 361 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 361 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 369 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 369 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0042
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0018
============================================================


============================================================
🔄 Round 371 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 371 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0097
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0067
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 371 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 371 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 376 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 376 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0046
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0006
============================================================


============================================================
🔄 Round 377 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 377 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0029
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0074
============================================================


============================================================
🔄 Round 378 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 378 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0069
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0057
============================================================


============================================================
🔄 Round 380 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 380 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0037
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0508
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 383 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 383 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0066
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0012
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 383 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

📊 Round 383 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 386 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 386 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0141
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0026
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 387 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 387 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0011
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0460
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 392 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 392 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0014
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0146
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 393 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 393 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0004
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0268
============================================================


============================================================
🔄 Round 397 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 397 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0045
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0006
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 398 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 398 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0062
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0058
============================================================


============================================================
🔄 Round 399 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 399 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0011
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0158
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 399 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 399 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 406 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 406 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0092
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0131
============================================================


============================================================
🔄 Round 407 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 407 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0187
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 409 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 409 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0083
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0010
============================================================


============================================================
🔄 Round 411 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 411 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0028
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0064
============================================================


============================================================
🔄 Round 413 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 413 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0120
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0080
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 414 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 414 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0119
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 416 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 416 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0029
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0062
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 416 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 420 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 420 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0109
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0161
============================================================


============================================================
🔄 Round 421 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 421 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0099
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0040
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 421 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 424 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 424 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=-0.0035
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0039
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 428 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 428 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0077
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0007
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 429 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 429 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0009
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0192
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 430 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 430 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0036
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0037
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 432 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 432 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0011
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0137
============================================================


============================================================
🔄 Round 433 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 433 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0014
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0407
============================================================


============================================================
🔄 Round 437 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 437 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0031
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0071
============================================================


============================================================
🔄 Round 439 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 439 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0302
============================================================


============================================================
🔄 Round 440 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 440 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0043
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0016
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 446 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 446 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0058
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0012
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 446 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 452 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 452 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0031
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0066
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 452 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 456 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 456 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0050
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0000
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 456 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 456 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 456 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 464 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 464 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0023
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0097
============================================================


============================================================
🔄 Round 466 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 466 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0065
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0014
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 467 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 467 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0135
   Val:   Loss=0.0680, RMSE=0.2607, R²=-0.0043
============================================================


============================================================
🔄 Round 468 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 468 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0015
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0135
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 469 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 469 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0053
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0001
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 469 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 472 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 472 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0038
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0038
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 475 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 475 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0065
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0035
============================================================


============================================================
🔄 Round 476 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 476 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0031
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0127
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 482 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 482 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0011
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0251
============================================================


============================================================
🔄 Round 484 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 484 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0066
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0001
============================================================


============================================================
🔄 Round 485 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 485 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0010
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0277
============================================================


============================================================
🔄 Round 486 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 486 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0055
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0029
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 486 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 488 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 488 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0351
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 490 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 490 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0133
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0046
============================================================


============================================================
🔄 Round 492 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 492 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0075
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0004
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 492 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 497 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 497 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0005
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0190
============================================================


============================================================
🔄 Round 498 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 498 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0075
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0046
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 501 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 501 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0009
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0186
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 501 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 501 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 504 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 504 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0033
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0135
============================================================


============================================================
🔄 Round 505 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 505 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0006
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0319
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 505 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 508 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 508 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0040
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0068
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 509 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 509 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0081
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0085
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 509 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 511 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 511 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0128
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0150
============================================================


============================================================
🔄 Round 512 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 512 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0027
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0086
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 513 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 513 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0008
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0182
============================================================


============================================================
🔄 Round 516 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 516 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0027
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0097
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 517 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 517 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0028
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0074
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 517 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 522 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 522 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0027
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0084
============================================================


============================================================
🔄 Round 523 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 523 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0069
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0039
============================================================


============================================================
🔄 Round 526 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 526 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0007
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0374
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 526 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 526 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 532 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 532 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0005
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0308
============================================================


============================================================
🔄 Round 533 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 533 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0009
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0154
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 533 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 536 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 536 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0002
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0187
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 536 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 536 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 536 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 541 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 541 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0061
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0028
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 541 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 543 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 543 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0031
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0069
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 543 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 546 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 546 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0097
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0080
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 548 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 548 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0024
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0431
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 552 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 552 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0063
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0044
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 552 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 555 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 555 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0062
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0031
============================================================


============================================================
🔄 Round 556 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 556 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0005
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0212
============================================================


============================================================
🔄 Round 557 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 557 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0005
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0251
============================================================


============================================================
🔄 Round 559 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 559 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0089
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0104
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 562 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 562 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0092
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0083
============================================================


============================================================
🔄 Round 564 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 564 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0095
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0025
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 564 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 567 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 567 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0044
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0057
============================================================


============================================================
🔄 Round 569 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 569 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0214
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 570 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 570 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0059
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0034
============================================================


============================================================
🔄 Round 572 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 572 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0014
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0138
============================================================


============================================================
🔄 Round 574 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 574 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0083
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0072
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 579 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 579 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0107
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0016
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 583 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 583 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0059
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0015
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 583 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 583 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 590 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 590 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0049
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0004
============================================================


============================================================
🔄 Round 591 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 591 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0031
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0079
============================================================


============================================================
🔄 Round 592 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 592 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0036
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0057
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 592 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 596 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 596 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0063
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0028
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 600 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 600 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0118
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0058
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 601 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 601 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0004
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0238
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 603 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 603 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0081
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0043
============================================================


============================================================
🔄 Round 604 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 604 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0055
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0021
============================================================


============================================================
🔄 Round 606 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 606 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0319
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 608 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 608 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0019
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0127
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 609 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 609 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0073
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0084
============================================================


============================================================
🔄 Round 612 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 612 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0003
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0239
============================================================


============================================================
🔄 Round 616 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 616 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0045
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0059
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 616 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 616 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 620 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 620 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0047
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0011
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 620 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 624 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 624 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0042
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0023
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 625 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 625 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0068
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0050
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 625 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 629 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 629 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0064
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0036
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 630 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 630 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0036
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0052
============================================================


============================================================
🔄 Round 633 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 633 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0153
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 636 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 636 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0115
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0128
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 639 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 639 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0435
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 639 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 639 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 643 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 643 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0027
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0138
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 644 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 644 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0004
   Val:   Loss=0.0731, RMSE=0.2705, R²=-0.0302
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0036

📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 658 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 658 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0043
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0023
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 662 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 662 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0051
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0001
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 664 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 664 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0395
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 664 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 667 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0642 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0642, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0642, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0642, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0642, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0642)

============================================================
📊 Round 667 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0072
   Val:   Loss=0.0642, RMSE=0.2534, R²=0.0008
============================================================


============================================================
🔄 Round 668 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 668 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0069
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0021
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 670 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 670 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0018
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0149
============================================================


============================================================
🔄 Round 674 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 674 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0026
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0132
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 675 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 675 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0019
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0137
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 676 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 676 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0024
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0092
============================================================


============================================================
🔄 Round 683 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 683 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0100
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0105
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 684 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 684 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0194
============================================================


============================================================
🔄 Round 685 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 685 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0027
   Val:   Loss=0.0721, RMSE=0.2684, R²=-0.0215
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 685 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 688 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 688 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0049
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0003
============================================================


============================================================
🔄 Round 689 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 689 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0133
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 690 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 690 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0010
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0195
============================================================


============================================================
🔄 Round 695 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 695 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0019
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0136
============================================================


============================================================
🔄 Round 696 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 696 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0049
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0003
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 697 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 697 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0090
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0027
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 697 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 702 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 702 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0021
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0138
============================================================


============================================================
🔄 Round 703 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 703 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0277
============================================================


============================================================
🔄 Round 704 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 704 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0061
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0040
============================================================


============================================================
🔄 Round 705 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 705 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0110
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0069
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 709 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 709 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0899
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 710 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 710 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0085
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0074
============================================================


============================================================
🔄 Round 712 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 712 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0063
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0029
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 712 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 716 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 716 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0029
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0078
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 719 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 719 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0047
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0020
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 719 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 719 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 722 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 722 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0016
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0505
============================================================


============================================================
🔄 Round 723 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 723 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0007
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0225
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 723 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 726 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 726 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0010
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0310
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 726 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 729 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 729 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0005
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0335
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 734 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 734 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0038
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0052
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 734 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 738 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 738 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0099
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0032
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 738 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 741 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 741 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0045
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0033
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 741 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 741 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 752 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 752 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0060
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0040
============================================================


============================================================
🔄 Round 753 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 753 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0038
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0043
============================================================


============================================================
🔄 Round 754 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 754 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0065
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0019
============================================================


============================================================
🔄 Round 755 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 755 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0301
============================================================


============================================================
🔄 Round 756 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 756 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0086
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0052
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 756 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 759 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 759 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0012
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0374
============================================================


============================================================
🔄 Round 760 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 760 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0038
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0060
============================================================


============================================================
🔄 Round 761 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 761 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0071
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0090
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 762 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 762 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0021
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0126
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 763 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 763 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0086
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0041
============================================================


============================================================
🔄 Round 764 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 764 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0014
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0192
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 766 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 766 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0050
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0005
============================================================


============================================================
🔄 Round 768 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 768 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0077
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0074
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 768 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 773 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 773 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0047
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0012
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 774 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 774 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0014
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0150
============================================================


============================================================
🔄 Round 775 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 775 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0013
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0266
============================================================


============================================================
🔄 Round 776 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 776 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0017
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0348
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 776 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 778 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 778 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0192
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 778 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 781 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 781 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0092
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0021
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 783 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 783 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0044
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0023
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 785 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 785 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0049
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0004
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 787 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 787 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0006
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0297
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 787 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 787 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 793 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 793 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0038
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0651
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 793 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 796 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 796 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0056
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0005
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 796 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 801 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 801 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0034
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0061
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 806 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 806 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0065
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0001
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 806 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 814 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 814 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0717, RMSE=0.2679, R²=-0.0157
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 815 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 815 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0051
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0059
============================================================


============================================================
🔄 Round 816 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 816 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0038
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0047
============================================================


📊 Round 816 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 816 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 816 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 816 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 828 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 828 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0016
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0222
============================================================


============================================================
🔄 Round 829 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 829 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0019
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0135
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 830 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 830 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0078
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0039
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 832 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 832 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0085
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0016
============================================================


============================================================
🔄 Round 834 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 834 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0032
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0109
============================================================


============================================================
🔄 Round 835 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 835 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0058
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0005
============================================================


============================================================
🔄 Round 841 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 841 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0087
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0051
============================================================


📊 Round 841 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 841 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 846 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 846 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0007
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0314
============================================================


============================================================
🔄 Round 847 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 847 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0049
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0009
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 848 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 848 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0005
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0398
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 849 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 849 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0020
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0117
============================================================


============================================================
🔄 Round 852 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 852 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0108
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0022
============================================================


============================================================
🔄 Round 853 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 853 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0114
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0110
============================================================


📊 Round 853 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 855 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 855 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0031
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0090
============================================================


📊 Round 855 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 856 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 856 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0057
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0017
============================================================


============================================================
🔄 Round 857 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 857 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0025
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0120
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 858 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 858 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0080
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0008
============================================================


============================================================
🔄 Round 860 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 860 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0004
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0228
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

📊 Round 860 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 863 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 863 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0036
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0059
============================================================


============================================================
🔄 Round 864 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 864 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0063
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0020
============================================================


📊 Round 864 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 866 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 866 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0030
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0090
============================================================


============================================================
🔄 Round 867 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 867 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0040
============================================================


============================================================
🔄 Round 869 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 869 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0004
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0190
============================================================


============================================================
🔄 Round 871 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 871 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0104
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0000
============================================================


📊 Round 871 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 875 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 875 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0016
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0284
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 878 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 878 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0047
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0019
============================================================


============================================================
🔄 Round 879 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 879 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0063
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0037
============================================================


============================================================
🔄 Round 881 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 881 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0077
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0038
============================================================


📊 Round 881 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 882 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 882 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0117
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0133
============================================================


============================================================
🔄 Round 886 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 886 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0071
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0073
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2514, R²: -0.0037

============================================================
🔄 Round 889 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 889 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0022
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0774
============================================================


============================================================
🔄 Round 890 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 890 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0026
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0105
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 891 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 891 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0001
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0217
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 893 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 893 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0059
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0022
============================================================


📊 Round 893 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 896 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 896 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0047
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0031
============================================================


📊 Round 896 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 896 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 899 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 899 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0040
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0047
============================================================


============================================================
🔄 Round 900 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 900 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0071
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0031
============================================================


📊 Round 900 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 901 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 901 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0080
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0083
============================================================


============================================================
🔄 Round 903 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 903 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0127
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0108
============================================================


============================================================
🔄 Round 904 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 904 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0127
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0035
============================================================


============================================================
🔄 Round 907 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 907 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0073
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0077
============================================================


📊 Round 907 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 908 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 908 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0219
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

📊 Round 908 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 912 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 912 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0056
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0003
============================================================


============================================================
🔄 Round 913 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 913 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0153
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0012
============================================================


📊 Round 913 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 914 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 914 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0128
============================================================


============================================================
🔄 Round 918 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 918 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0029
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0090
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 920 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 920 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0009
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0305
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 922 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 922 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0068
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0053
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 923 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 923 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0017
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0456
============================================================


============================================================
🔄 Round 925 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 925 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0018
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0135
============================================================


📊 Round 925 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 927 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 927 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0056
   Val:   Loss=0.0720, RMSE=0.2682, R²=-0.0019
============================================================


📊 Round 927 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 933 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 933 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0012
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0153
============================================================


============================================================
🔄 Round 934 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 934 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0029
   Val:   Loss=0.0681, RMSE=0.2610, R²=-0.0105
============================================================


============================================================
🔄 Round 937 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 937 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0050
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0008
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 939 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 939 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0054
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0014
============================================================


📊 Round 939 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 942 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 942 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0011
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0165
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 945 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 945 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0068
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0065
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 948 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 948 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0040
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0069
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
