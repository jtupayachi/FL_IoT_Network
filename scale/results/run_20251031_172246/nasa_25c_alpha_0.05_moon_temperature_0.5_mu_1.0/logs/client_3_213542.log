[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ff7978-5c42-49ec-b247-c979f8b5d408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ee1999-e8d6-4ce3-aa2f-3e86b21c28b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b3e3a6-b1fb-4f50-ad87-17d268f6caad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea23889c-e022-46fd-9f44-9625ac3bb955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a31d00a-321a-4204-8669-2c0ce1f609bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb9e33e-80a6-4bb5-8d46-1d148bda6c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c03685f-6700-4502-bb26-e031b1fbb650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e38f2b8-561f-4205-8cbe-8ce57096c3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ff6f0e-f7e7-4b39-b7d4-b8eea7912bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b207e8-147c-4609-bf7b-9a48c74e36eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4dad8f-c63e-4228-8a54-2f7558ec7e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea9d14c-273e-4836-95ee-2e219d47da66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6f3a54-a339-4571-98d2-931fee19e96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c516e2d-33b8-4ce5-afeb-0e5b170a9e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f14d6151-a630-4be9-900e-101c41d04ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e0e4905-50fd-46e3-b8b0-6c4f3cf0f3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec4d6e9b-1d9d-4797-8751-24eff2186fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e358e144-e827-487d-9030-589a6d624069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c986bc-1f9e-4276-8272-671d413ea751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 021afe22-a3db-462b-b6cd-7efb90c636b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85de487a-bc22-4ca8-8577-3d2b30997a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 436059e8-9c6f-4ae9-906e-85b0ceb185e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d131ff67-6fa2-46bf-9507-936a4fe4b299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad32c768-e395-40b4-b839-a0a8cd34161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32fce86d-4c77-45dc-a6b3-dcb06297133f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62576838-f403-4809-8c24-df4b234b5602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db2428c-e1a4-4d9f-bcfb-f84e529e24fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea216e5-2bca-4447-9a3f-78d4650b790d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dba381d-40ee-46aa-b0b5-4809dca0e5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f95ffa7-57e3-44ad-b8e1-fc70c013bcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e93b71-afd8-465b-9f32-d51a14bb48a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad09fac-6a8b-4fb3-9075-96e1660db029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57139d9-7262-4978-bfd3-9518c6d28cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7d7ac1-0e17-43a1-b513-b3ac3a1bbc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bbdddd6-5bc1-42d0-8952-94e223beeb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b5e81b-a803-4155-9a35-a79646ef9b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b846c0-d51d-4b8a-8f12-359016e82476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82472b69-2bd7-4986-a27a-4b5f039256bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aedb5b6-40e8-41d2-a4a6-178853a748cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1d7bb0-dfb6-4fff-8e66-f2d2803c0c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be38fec-633c-4438-a63b-9b23feb54617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33e54ca5-def5-42d1-bea1-4c8c06d19d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f3380b-080e-484e-930a-bfd83b56697d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 902eb2fe-6920-41f3-b2e3-c4359c4bc39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb833a92-61a2-4b69-a6a4-be1792403a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1307c6-35c9-44d0-85f2-9b033feaa18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80b22bf-6976-4244-a8a4-b5520adf7a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66365a74-457a-4f8c-98d1-8c840d488575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e36d58e-2079-43bc-ae49-e240d294a357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c38c0f-1ef9-4bfd-be1e-6941651433b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b776a80-b5cb-4fc4-9aa7-27899682a67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712c0b26-94f0-4148-8464-79cb563f0b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578988e5-73a1-4b92-86df-2942c14025b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5db4165-1c13-410c-9d6f-49984eed7463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74e252b-7cb4-481b-9bea-b887b32dbb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85f2fb8-fdde-4539-9192-20bd8fa6e14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977fe659-9d9e-4b31-ae23-b8dc34692244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21418daa-692a-44c2-955b-ef15c5a67237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8392fa-1799-4f80-b2a2-40cc9d972629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5508277-e50d-40b5-a15b-2d42933ed132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98dd2781-77c2-4231-b104-07ae27922c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677daf83-292b-49f9-a50b-36a996dc5517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 337bf04b-b1cf-42bb-936f-510ef40579ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44eb08e4-e08a-482d-ac56-918c1013f555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a0c2e9-4405-4e9c-8b11-e8fe23ac6b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d7c581-fb45-4b1c-90e0-2aa0271cff2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d9463a-78eb-42c3-81f4-d804f1158785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728a8f10-e6a8-4a2c-9ed9-0e0d5becf1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e9b280d-be87-4c5e-8f2a-01d4f76c17ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993e026b-90ea-4ac3-9191-fab61e5614e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b900f748-21f6-4e11-b158-8401b5d9b6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f889999d-1679-4e98-afe9-1d89e5ed4c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1368d08e-60ae-49c0-946a-51475c7bc8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce79f00c-f4d5-42c2-a600-3ec474df8d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd61d8d-8880-40a3-bbff-9eecbf56e6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1ad474-f23e-4bdb-8510-a804527a59ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b2e477-97e0-4971-8897-3784c9a5faa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d02c93-6b06-4a38-8a47-66c67f266043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f137d0d4-a110-4f8a-bebe-aeb6a68826cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884fa619-3159-4088-8e85-0771817223cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d382cbf-9178-4b01-9509-98c3093a7669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da348f8-b9cf-4f55-91ec-c31760b37fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f84f3f-0409-4386-a356-f7c51ce1a98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f677a39-230e-4e26-b9b2-679e773be9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7276d752-1cf8-4c00-b2a5-4bdcd1895235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece474fd-3728-4084-88a0-a5d432617505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8082004b-557b-4ddf-9503-13c0a2aaf8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a628660-2b65-4cae-8eed-282a88511c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54de315c-e363-4cd7-ac67-2aed7fccfacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c97b55f-b44e-4030-af03-2ab37524d796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b65f69d-6503-4944-9b6f-382da3c0a1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0835d866-35a9-40b4-92b4-22f8d6486b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2cdb79e-1d14-409c-9372-563c47404a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a68ebb3-647e-4445-acd8-9f061913d4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56820ed8-0900-456f-b20e-ed223d9b1825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fb2f12-fd04-45f5-ac3a-4abe6cd96a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac146d4-4b3b-498b-8fda-8cbc3cdfbc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb781f08-38df-42cd-a672-3982a777d436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6292731-7021-42d9-b86b-42f12e0ce465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163ebbca-fd01-46e2-b6f2-bfffa618437f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23903c17-53a0-4c67-9cb7-1598819f0c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edac92f2-79cd-456c-a3e0-0d16fe146c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700dcfd2-5379-4600-abd7-4e5eaa833f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d95698f-c128-4c83-ab9a-fade5ac95806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cad5162a-7dd7-4260-b6c8-df83588039a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6fb1d3-7eae-4d4d-b3e5-7debf7147087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62b6b07-e162-4a33-a251-194e5ebce32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4afaafe-976a-4a6e-a931-24909e5f378c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d214a48-cd94-4f04-8ede-d2f4775377b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59bbdfc-8507-4f31-a7f6-3aff0cff3270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c4f7cf-bb6e-4187-9a15-94687f36c370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de192ed7-daa5-4c78-9305-be75be2958a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78227d86-a520-4984-8607-13a4ec2f9001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8b194f-146b-4f96-a937-e467a9a266fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f344064-71b1-46a2-9ae9-c09b6de17ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7acd70-cb35-4349-a490-c93d75a3852f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016aee48-2e34-4e66-b911-b32c73ead3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2db01df-1647-420d-b8c3-f6bcc72d3d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72f5937-86b8-45f6-b7c3-30ada3b7243c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a50a008-f444-45f2-9058-690a8afa0f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0223cc6-3818-4917-8d87-5aaea7e2bfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db80229-b9c5-4725-a86f-908d3c9c082d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c43044-6e1c-4992-a2f0-bba78c5deabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6788f2-52f5-4123-b980-16879a223c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4284e262-6898-4497-b153-92db4e11c72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1737a5-5fca-4067-848b-63667e193d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3894c1a0-e74f-4356-ab07-ea84272e3dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d453135c-3eae-4606-b694-3942e05a2d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a4bd8f5-90d7-4def-abd6-9794d8f127c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a30d0b8a-0632-4799-8098-ecbe5447af54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce75e4b7-06f0-41b3-98d2-8567219b2b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e9fde4-63c1-420c-a87d-db06336c279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277b1209-46e7-4d72-8ea9-88ea23f62383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309c92a1-e6fa-43b9-82e0-7ce6045e012f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549055bc-7207-4345-853a-d4de2e38d1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546701a0-2f91-4f02-aceb-2a76322fa272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce01913c-fe80-4532-852b-610ed077e232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f8bbdb-305e-4c4d-86ea-e4a6cd6faa5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54cbf534-95b2-4e09-9ebb-3b24bd116784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1774a62f-fadd-452e-8c86-164970d85182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35071883-7175-43a1-99a0-26e01f1be494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cbaa0c-baf9-4e16-b751-f2272ae80f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238faa7b-04c4-487e-82d0-02f05650e7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df24f03-5981-42e9-9ddc-57e5c551cc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa93f51c-be13-43de-9d9a-d7c8c459602d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf91cf3b-4599-4f9a-a8af-1081d84368ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bbf715f-01a1-478f-a2d0-5a1ddd619154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09de601-585c-4ccf-9f37-dc1b0c0a2e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac08113a-ec0c-444a-9f27-9352654a2f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c02737e-68df-4efa-b64a-ac4696a538d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 273cc928-d6bd-489c-9ef0-1a6709621db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02c0bdd-9950-4527-9bcd-df3d1ebfaa2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4799d04-7208-41c6-b16e-e9c205f20d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ecc703e-78fb-421c-882e-ce46eb577555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78e5bb2-74c4-4ae2-bed7-682a659692e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3da620e-0016-4bb1-b9cb-2e893c1f4377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf90730-3857-4aa9-87a6-f4875269d93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a4719a-93f4-474b-87d2-8aeabbe5574e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bbbba39-88a9-410a-872d-4f8b17830125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005c2958-5f40-45a3-827f-715fbfccff0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71174e3d-e2ba-4545-849b-87522c1f31a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181ed268-e85c-4c5d-aa1a-4b803acb0e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658ec218-c61b-403e-95fb-ad4681ad6944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b771859-b957-42b4-9f06-dc9747688125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d947db-0a34-45cc-96b0-3b6245cdb81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c4c291-db7e-4304-8df7-d574906e766f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c473ea-e238-4843-b30c-867d917dfe6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e462710-84f0-4789-8b2b-6edb1bcfe102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9412b1-eb5e-4ba1-a896-8f12c22c085f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a283b43f-c6dd-4ae8-8d8f-9d032529e16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca83f11-23a3-4950-a1bc-0da54efbb12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc69c809-6b12-499d-ba35-e01ac62d14b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb570c2-c4f8-44eb-a9eb-6bad1b4532b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efba4f9-6d32-4793-b210-96e73556a480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba9926a-816c-4117-a180-17d415b0ef25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ef7a50-44bd-44a4-bbc7-ec6d79f703b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5770c8b-8c97-4918-a8a3-2ee7f9ab8829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5e181b-0548-41a5-ab54-582e08961f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4eeb497-3a55-49e9-8463-0ffada6444b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e748de81-df4a-4ae4-8729-ab4bf8ab9326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d0e6ee-7b6a-40cb-b5ad-3b037fea8f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a840db7-d90b-47ed-8adb-863d3486e741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e35452-4f10-46fc-a704-aad8ec764bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b4c61f-e793-4074-9103-6998a207cacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a47ebd0-2838-416f-94e0-a2648fa96ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a5828c-0bbb-430f-a1ea-6ba635283567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05ff9de-0222-48e3-8404-26a35b06db3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a68a0bd-9fff-446e-927e-5cab7f97a30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6b5a49-613b-4946-9bcb-842709b23557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf9a1bba-ffb1-4d14-998e-f5012f15a483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85171de-a1a8-4cff-917f-8b00f47a539b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20e10dab-11a5-49a6-92de-df594843c869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f99bed31-6ddb-4020-977a-30665d6bd4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1add209f-d4bf-4363-8966-04c7b530d0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98969097-8f76-4803-86f9-8390173f97d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19046ee2-fca1-4fc2-a7c1-6f8adabc1fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4cea49c-d32d-4866-82ca-5598c23b2430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840fea16-3883-4358-a6de-84eab8d99485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd12fe5-4eb8-43a1-9651-9d7462073df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8e4951-a52d-47ec-ac44-2d00d21131dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad87009-7745-4574-8f46-7700ccd439db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bcf719d-e102-4d94-bc76-aef3fcfc1a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ca677d-84e9-4d30-bc6e-aca97a476742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3973d836-aed5-4760-927e-82c14cae5cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8f8d87-a3de-4db0-898f-8af9811ba6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8746bc8-d50e-4d74-b496-7efd293f53a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab956f3-8014-4fc4-94f9-1ce23b671325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81428087-2fbe-42fe-8c10-34cb80ccab18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525baf05-26fb-4ea5-8e6a-9d987add386c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4af2bb-4603-483c-b0ed-f6f778f5de17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a6bf84-85a3-4da4-acb2-58664767d511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96dc672-bf3a-4db8-805a-7b370a2a23ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3864e9c-462e-4536-89bb-5bf43544c12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99fed46e-0e5c-472f-9187-4dce3ce99d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11df5a6d-ee46-41a0-9461-7f6c8dcc3d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d451232-8cbf-48d3-9206-beec0e9ad10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2a185b-2d33-4560-b479-378ea989c330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ceb99c-1b10-4a9f-9590-5e7528dd86ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d450c851-7656-42a4-972a-236508460c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c4039a-1559-49e6-becb-efb90ab879a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048b05e1-ddf1-4465-823c-1b9f12223ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f909a648-c754-428e-a2c3-b393ed205137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3356107f-409d-4b4f-8e7b-ec26f8912ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acbe0222-4a29-45df-b2c8-ffce698032ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec55bac-1181-4154-b56c-07f384af8bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda007e7-b7da-412b-9a6b-2f4c746da458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fec4aa3-48ad-48e9-bf5f-ed3d3502de44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67960a4-fc48-4997-90f6-c0806a607d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cadabce5-b3ae-4307-90be-490f7d122e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ffce7f-b8eb-4077-bfc4-4c7af7518a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a97f9a-4502-44e4-803b-6a5c21b25be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37a8b4f-0f6d-4538-af67-6ec6596c81fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada98910-ef00-43cf-8f9b-4185eb94d1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee29c7d-e792-4d85-bc7e-6ef30285bcca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de741be-8716-452b-8068-4a7e8dc9f949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0cdbd0a-ee5a-48d7-88fa-9da8e2df70af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b53949-1206-4299-b443-3087575bc709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13b76e6-5441-49ca-b063-66f6e9b59aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495ebbf6-9d69-4484-bea0-5d978a5c1ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c454d4d4-91cf-4764-85d8-5a8a2bf11db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0515a4fc-cb74-4a31-8e5a-0e38f2ae8f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65a1052-d49e-4cef-8bac-76a797bfab1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf62cee2-eaf6-435f-8aaa-da549fe2d765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61561a63-b511-4a94-855d-496a932637a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad1d570-870f-4f56-a4b5-9e3a2e0ff564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a805508c-3d85-4184-a5e9-0ad7f3f25f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84ffa9c-3535-4585-a9bc-13802f829aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f019280-8743-4af9-a11d-0f45a1e6e6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56fc2e6-b5fe-47c3-b2c8-12793c34e0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5848790c-3f89-4de6-a08c-322b713272e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff65ceaf-b508-4f73-b3ef-8f98a7ecf609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16356655-d7b5-4998-92d8-25da066b36f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbc8b2e-f42a-4eae-a203-abafdfc38acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79417f62-a9c7-4778-b71a-263c8c9845d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb95dfde-d951-4e5f-af43-143c4abf9556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9085e7b9-2d8e-4b05-88c2-2ee4e51820a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26747a6-471d-4b1e-8f25-eae81e11562c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80c8822-9dd6-4d3f-a21c-638306e69a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f496b2-57c6-462f-8eb2-a71f5521546c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf43f9f-68e8-49c7-8245-9530ae1fa9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9082fdb-fbde-4123-b541-640c6efdb7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf5db4a-6695-49a2-a53c-236de0e7847e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604c31c8-e781-47f7-9ada-4a058869d073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6275ed87-6347-4875-be52-169ad9945c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c82d3e3-088d-4873-b452-fa3f839d5a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 649251ba-9a58-473d-a3e4-6b2546093b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58ab0b1-50cc-486d-8a11-188dd67d2237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad21edb-01bb-4b97-b27f-52983b212332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be56af9d-b01b-45f1-87eb-297abe2a1c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5748267-ae6b-4a4b-abe8-1337946214d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a5431b-f829-4a42-ac85-bacc1edd9625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04231b40-b07b-4415-b2c8-e94c297d9fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d71389-b45d-4012-a698-cd19a3824ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a8ce19-d919-4443-b745-424ee7ff324a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e660531-8c24-442e-ac9e-44adf1b24f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d04259-39b3-487c-83bb-2e7b6f0b3d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c789a4-a6e2-4399-9a31-d8244f97ef6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9525c2-575d-4403-b3df-958ba82731bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9445f0af-91a1-4b8e-ab82-24a82d67f285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4103124-f7ab-4b68-a803-259063e95580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfafe125-2c29-4c49-bdf9-cc6593beae5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2972f5db-e2aa-47b6-a4ea-d9044ce8ec01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16835341-59ab-4ff7-b91b-e06bc30a3ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7ebc16-f754-48da-9562-95a307595298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557c0017-2191-44bb-a096-c1435c98e218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac0ee26-c44d-439f-80d6-9eceba252a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a330ec9-5da8-4b0f-baa5-25548e035b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da86c7b-2ec7-43ed-9ed9-a2e93b45cad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668ac40e-bead-4696-a5ae-4ccd4cd3ca9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7635d9-0fae-486c-bfc3-06b412c36800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96ba848-85b9-45c3-9aa5-3b9f0cf10a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6cea5a-8f12-4d76-b3ab-78b898b5f77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1958f24-c19e-46a7-8cf6-e6055ef8eb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7811cb1f-2372-4e74-8589-ecc70bfd4cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69bcfbf1-c769-49f1-9d94-52e2a2f01228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d0478f-46fe-412d-8371-0e2b9a9c95c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c7c9a2-ed1c-46d5-8473-093dc059244d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de59896-7e75-46b5-b45b-ffc664a5c1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9371e8c5-f5d8-485f-be5a-03d9ae1cd8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31bd5e51-5633-4c88-a5ab-daf63bcbe6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79dc2b1-e8ba-4705-9a09-3e7693244d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdcbcab3-f2b3-45f3-9f98-32368cbf7086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d6225d-2d1b-4657-a6f5-b21a8b886b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223d6b2e-5863-4a60-ad8d-c5cb11904bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cefb875-b5a9-4f34-8143-106bafcb9dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652f9853-a97d-4063-9384-288dda54d250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd2a2f7-f911-42df-ad18-bc344a7b3708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0f9398-0f28-4298-84cb-6f339f5f5e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78fe5aa-4413-4b02-be03-e4986fe636e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eb59587-963a-45b8-941c-e7d82f66cf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422c6a39-5630-4f8d-8540-d367ac090d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53d72b1-0ffb-41ec-9b55-dc0920db2464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955361b0-54d1-4d9d-ab96-b8e2dc401a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0fe9e4c-85d2-44ff-8d61-e074babb59e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d60388d-2ac8-4b7b-a61f-1b2974237ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bece241b-94bf-4f42-889d-72b9f23b9f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67891721-ff7a-48e7-8a94-69a67a88134d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00e1932-8b7c-4470-9785-e1d0f68df20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce3ff22-a141-4a75-935a-5ef3de54dba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b155223-e889-43d5-b574-8cc2c11fd4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020423f3-1570-4daf-8d42-30359497badd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db51252-8363-49d1-8c8d-aae914190fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171dd3a3-485b-47ca-bd4e-e04b1e773fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ab9b0b-dbae-4370-adb4-8f1b4b9d2308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b7e9fc-3e04-4dab-bc6b-13fe96640d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fd20b6-c019-4da6-8bee-9e14fc72fd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a87d54-271c-493c-9d06-8df0767ccdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a606a11-a44f-4d51-9131-1de6c6f36e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc15d02-5a03-437d-8784-08a2a7ff2afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61014521-b570-4384-8c92-9f2a58cbf83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b75630e-16f8-4943-aebf-aff58a29f0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61aebbd-f9a9-4d95-b04f-ae66c04d99a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d626d247-f773-4f7e-b796-916adb91a5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4ecfc9-e111-4d13-b420-e1a20f91d13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a7781d-af28-4e36-af41-d27011050c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e42e797-7bb7-4f76-bfb0-f68053885fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2c5eb9-ecae-407e-95c8-4032eddb0714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2795a6d-628d-4a2b-9f2b-9927be8cb760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c37c835-3121-4b0e-903c-b79aee757e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d3737d-59e2-4601-8bc0-2f8a48eeb0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d5a4da-0125-4b3b-a8e8-88fbf1d8a0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0853dfec-3ab9-4821-92d3-ba23f7f2881c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957569b8-5946-469e-b246-92eb6850793d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 711cf85d-fa84-48c1-8ff0-0f1d7757f784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef965134-05cc-40c3-bd8f-c9c86c25dab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a4c0ce-464f-4c44-a3ca-c3bd3273d035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d36a51f-64cd-4229-ad11-f6b47f9c4691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154659db-ea3b-45e8-b83d-dec885129065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42ff48b-d1d0-470e-bfd5-c0ccc756fcf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fccea11-a4d3-4d9b-9c45-d59fe76d3451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33a915d-7191-4d29-9c09-29915ca3a5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e09ff4-e8ed-465f-a70a-45d1b20f68d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1be36f-ffe2-43a5-87dc-ab61a7e9ee78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09e9dd0-a64f-4f76-8187-b657400527ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f29a4ce-0a4b-4345-8501-bcd4289e17f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0675c1f9-99ec-4a6d-8366-e9c567479c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2dc300a-530f-4b6b-8678-5f904c0ea574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6acb2e23-55d0-40e4-af81-c6eae12136e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75691c8-72dc-4010-b1bb-bb416972ea5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f43d62-ff2b-41d6-a0e8-bc0a1209932d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f536ac-a12a-4c8f-aab4-51065f8a4265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5aa77e1-836c-4df3-abd3-e3fdb9aad3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8d62a9-8851-4485-a9a6-3e716c8018d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a4f344-51fe-4343-b4ce-b32a5bffc417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab762a1-48d7-45aa-b545-88b162bdcbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8738d265-494e-4a5d-bd5f-56547605bfcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05af9d30-981e-4927-8d46-b88747d6721b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88356c1-55be-4aae-b237-0f2267b724d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5afee2-2be7-4cd4-ba2e-df03da908dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aec6034-d407-45cf-97d6-f4fffede7bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60814949-dcb1-42b9-b4ab-a59626b5e929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229774e6-9dc3-40bd-966a-bfd520137f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5a1ddc-785f-4825-897c-f6a3f27ae606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b674be-0ddb-4983-a283-2df6d51d65e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58a743f-fd52-46f4-8361-c04123cbb6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05dc106f-66df-4283-95ef-6593e0118efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009a83bd-466e-4832-828a-dd7689e38858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f52ef9-a327-4971-8d1f-de743da597a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7537bdac-63e2-4ad3-89d1-b710e602079a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83272a65-b69f-4cf7-8f5f-20233d2bd278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8b440e-0ceb-4108-98b2-da56abdb0f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ca8f7c-9ffb-4f87-851e-ad49142d39a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9d787f-dff0-47af-83a1-f1c9e2e59069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead5d0fe-236a-4de5-bbb9-d4609d134d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a50db6f6-d301-4582-9f08-ce84cef9717f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ea180a-1784-4e37-9a09-84783cc6fc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e018d553-b1f8-4294-8812-82f5aa10c0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5c41b7-3b01-4a35-9230-180b186f411e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4476638c-a20b-4d1e-aaf2-4c3c3b14d980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af3f30c4-804d-4209-8f4a-eaae63982ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3df3c91-b652-4447-8dca-6f6ce43f337c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612f30c0-a652-40de-81da-817c7f58dd57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98334abb-907e-420c-98ef-ff3fc9b98347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0e954d-2086-4586-9cb5-8b94ed9bbed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f2ca43-7245-4dd5-8a9c-24424fdaa8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe2cc64f-95c7-44fe-b845-fe94f09ff61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fee416a-c56c-4fb4-9384-3e846a2ba114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8280f04-3c61-4eb2-8a91-280569219a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73556411-9c8a-4809-98a3-d37e1a9dc649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bc3207-69b9-49ef-8e63-a8b21d8cb832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df643339-53a0-4156-8271-700eeb5b726b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e251cdb1-f15c-4a7d-9adb-d14dbcb44099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475d9a84-d6f2-47a0-b25d-84e2a670d317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216a1012-0ad2-4683-9095-b7ee3166713d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef427a58-f40a-4aab-ac4b-32b8ff184bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9189f9-8077-4723-b1c4-7730da2a1c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef17b67-413d-4510-aca8-81ffbc462ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f823a694-9921-4215-a7c7-f6e0742dfb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 169cfa0b-aa73-4237-825f-da2936204182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05729b56-1783-48f3-8521-7e05cc010316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33539b09-c8b0-4db6-ab63-c4d064ee05f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eaa0f03-530d-47d3-907b-9b5a0520e4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16b6a08-0316-4a68-a43c-4437ab6551b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ed08c6-de00-4c00-aad6-4959304364ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e125f074-1e1a-412e-8ab0-f2c392ee04aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc3cd10-cbaf-4bea-ab07-51c731add845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a24cbe-1ede-4574-a3dc-b9575d3f74bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13ad0d6-c788-4bef-a49b-e0582687b264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ba5d4b-d084-4a13-9037-2543fb08a46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04fc285f-7f62-41ce-999e-3443f1f69f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01f6f2c-99f8-41c8-a5bf-6ac57be59cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c62c9e9-42fb-4f0b-8937-81416646f9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae63709e-6594-494c-95a5-ddcc87f31863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be8c8ec-c295-486b-821b-de72531d9ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ddd3972-dc8e-4cb4-a2b9-c814915f35fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d8bc442-e574-4495-a23f-88a2cfa76ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f7c6487-b4f0-495a-8a2c-947ac4f751b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5fa7228-50bb-4282-8092-c160d9614a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb632553-dd54-48f3-a242-958830a419f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f1c1b1-2d83-4b8c-ac1f-1119cdadfcf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df55b884-79b9-4c29-8a63-51eae2836041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1a5e07-04d3-41bd-89c5-db5a5ee6840b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56446e8c-1ffd-4335-bc91-4161b6d6d62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34fe3158-26a9-4b46-9bdf-7c290787f6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9323e9-7458-4cdd-855f-3d7b271c2660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea3b2c5-8e07-4437-b167-d4077b9d1891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe39d5ce-eb46-4291-b295-58e164abad27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cc6d43-ebb2-4d6e-b66f-5847e833fac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2f774d-1976-434b-bfff-d3d638be79ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab4290f-a2db-4130-954b-ca1ffd70b9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a865429-d367-489c-90ba-7230ebb96186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121a34c4-6c5c-4541-afca-9927d8c56e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310defb2-3b55-4afb-960d-d8d8b261838f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d42240-3bb7-4b29-aa5d-448208502826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ac1346-f9df-42e4-a41c-ac0be3100edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b28266a-766a-4743-a506-c8c83142b511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891d97ad-2f90-46d4-b5e9-237c8af20ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8311316-f730-488c-bd89-db1c9835d856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2e69bc-3bd4-46c7-a0ca-27996cf8fb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16c9ce5-d5c6-420c-956b-2ded047175ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 167bf708-8cf4-4fed-8f33-868e3b819845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3454e5a4-bb95-49f9-a5bc-db53fc7cff0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b7a4a8-497b-4c3c-bdb5-5191a486041f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88635fa8-5d92-48df-a445-4c84c5ab98a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f525b4d-c838-4f2b-8670-cc7365e214a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71467f8-47b9-4103-86b3-a6d0b45562a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07055c57-51e6-4332-a3ff-6ab3f4666409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe7040f-08a7-468f-813a-7889b020a6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa774ff-cb18-48e7-804d-770b7451852b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a7f569-c240-4b41-b21f-7ebf6eebb677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40fa2d7-138b-4cd4-93dc-505f03a5891f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5218324b-7bde-4b58-a9b2-21a5cc19f004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c96768b-9c66-476f-beb1-c0d4830ec6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2dd7fd-692b-4d28-8ca5-734038fbb984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a768c59-4444-4d6b-aca8-92d8b5a16f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e579d24d-73ca-43d5-83a2-60695ac19e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d186f0-6111-4287-bf2e-c01f47bfd3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ae5b40-9d19-4679-b3bf-e998319b1d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059b52fd-1fbd-4e5a-bf08-fdc98a4816b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f21858-1286-4a25-b379-a61a550eec07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c443d4-ea6a-40b2-a532-7749f437675e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7058ebb6-f6ab-4196-9bcc-76b6c816d05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0896ab12-5012-4a85-ba47-b2796f70e957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc5f3f9-5cd7-45b2-a739-999df45d7848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1e1679-d81a-46ff-96aa-347f85a4e4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3be078c-ecb5-4688-b978-03b1df6d581d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11d54ad-2465-45f9-b586-189db79f1055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8ac7ab-a1e6-470c-96f3-6432f793982a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4445ef3-b762-4edb-a0a2-317dd028bcdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd07092-ab30-4952-9462-f3950808d8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fcd4422-2d90-4840-b61a-8cd0f613058b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aad5dd7-3016-4291-a380-f688ff057006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66bf1614-493a-4f5d-9373-033d7fb22002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aafa183-973d-492a-9f19-4e2b22dc0d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf9a590-89ec-4f62-9713-35d14bf9a46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3942548e-cda8-4989-8322-d1c63edb48c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39176e1e-2a57-4a8c-8dc5-68b19b7db709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915f3125-cb5d-4b33-927b-b6d67d1e5c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3674d12-f099-4798-8d7a-32f09a5e74c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48b84db-d416-4034-b2f8-06a932372f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1147e48c-4d1c-4748-9602-3ce2bf6f0111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a85fb1d-54e8-42a9-8c46-ea52dcc3a38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d03d4ee-bd50-4643-b734-340e6cccc7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fa467d-bf39-4ed1-9df6-6ff08d0afa68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c611c4-d639-44e8-83d3-2fc953e3d877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6422e9-b1f6-48b3-8789-3d7787bab0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcfd8e10-8ae0-4dee-81f1-97695653f254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d148473-09cb-4b3c-8e9d-60a825846609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 893e30db-814f-48df-a2f9-a6f52aa2c31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f246e69-ab68-4175-a506-a5c8750880c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b516f48-e490-4e58-a8df-362be1ba872a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffdf786-5a29-4d40-a46b-30626367699d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0fc4ad-97c9-4ef6-999c-b57f7bda3140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e732b7ef-6852-49fc-9688-db46d03ea6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd54e143-7965-433a-ac41-12e078fc6b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d379349-ee48-4e5f-8bb9-cc30fdbc5570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4578f017-b54d-45f8-b24f-ca6b00007f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a36068-48c4-4d04-8612-3c8db1add3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90859794-07b5-4ef2-963c-4c398ddb49ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f3ae70c-106b-4efc-8ea0-502e6c5ac68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda0fb30-b3f0-41b4-b072-37b3bf1c537f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47c5945-c726-45bb-a0a2-e91cb3dcb088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239d8742-0f0a-4326-8f5f-42749ea0da21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee17801b-bf61-4ac2-a12f-8fe1fbcc708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c6f97a-72fb-4044-96be-b9b49a893658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c052218-da00-4e87-8595-9ede22428948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c2d2b5-d859-4b1a-bfcb-7f7090c0f6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8374db5b-fa3a-4716-a377-02d5d4b68024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6de60e-5db9-408e-8d00-4be3185b3a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05913662-5b9a-4160-b3bc-14cc85e5540d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce00c0c-c528-4a9b-af61-1c7d0258146b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b42440e-da4b-43b3-82e5-9104290097ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa6c9817-036c-47ac-b37e-2a7ec4165f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25448d64-b9ad-4264-ad06-272bbff360e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2592fd2-0f18-4e25-b68e-0c836591151d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a4b29b-8d41-4392-98c8-4f16476da2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7457d65f-a4f9-4280-b415-21edd8914341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8858cb5-d517-48ad-93e6-3b58997f2e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc243a3-100d-4148-8487-e22b975a91f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf5367f-91f5-4d52-b184-102b9efeb07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cb3bae-cffb-4188-a382-da72afbc1a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2734ea-1d21-43e3-abf4-25956af5da94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecd9643-3e01-4c03-8cd0-ca65febc9441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3068f642-6818-47b4-bc93-83b129169100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361cf9fb-08bb-4b90-95e4-1138569c1773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dbcd96c-2704-4f80-b299-31bfeb61921d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d904c7c-910a-4be0-9976-829c64539b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfc0ffe-63ea-434e-a845-7a09e96f9a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab736c46-6358-46da-81b7-279237142c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1fc744-bb3f-47d4-b27c-ff3e4f2503e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e9acc5-9f7c-462d-826c-a9bcc1c35fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c22091-673f-4b69-8c6d-9592222d23e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f52e38-3c47-451a-ac8f-9361f7619c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9fb055-1c80-440e-949d-d0c421946de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976c9638-2778-489e-af13-f20b83d0dc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 295666e4-e160-4744-9771-7130c0fcbc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b38ea7-3887-4ad2-bf98-59f11f864f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b089b3-90a4-4b5d-a37a-24768220b682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33e2fa74-fd9c-476b-945f-94639907ef6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a253feb7-510b-447c-9313-ae9d161adf45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0500e9-3eeb-4b69-b770-82466551a293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a6d60d-cb9a-469c-bd94-e2dec62afcb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc2235d-665d-4f78-908d-ae7ac83e93dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6dc2f26-3dac-4d4f-b9b9-920d3ec1e706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01b23d3-2446-4baa-adf7-831746d76720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774b76c9-649a-439a-8e1f-f3567eef9155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7e3d0f-d702-4c63-bf9b-040535bf5609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e4c0ee-c01b-4ad9-8680-d135cf3b37cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44870cc-99b3-41e0-9313-93be66e69b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29607963-09cd-4893-99bc-61a4d948b788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a0b3fd-af96-425b-b46a-1c797019ca87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bddb61e-93f4-4fd7-9193-f7ded086dee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1923c91-3eb3-41dd-8bc8-18becac3b580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808d2110-abf6-483e-9059-c8ab17879284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc67999a-fc8e-4b1e-8331-44961915d589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a8104d-3da8-4a78-a40c-5cf6e5c72b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633d1a9b-fc5d-4515-a723-01b6c3bdb673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d371deb-f02c-4ed5-a375-e980e2098c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed3f7459-d4b7-4941-a631-4a57f5fb444a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8ea3ac-7353-4c83-8553-49ea516cf585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7a9c56-232d-44fa-9799-81a08d3471ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1a8786-6b44-4d28-9819-ca0797857d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46dd5acb-46d8-4405-8676-c1853da7e173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fce94b2-b9c2-49ef-875c-09dd58fc32b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb973f9a-c2ac-4a55-91dd-e12604445665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1474de-4b51-4d2b-90b7-9bd33cda58c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03913123-5a8f-4fad-bfd3-a02212f75ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac4256b-7ca9-488d-a7a1-67c5bd46cf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c39640-3dff-45b0-8a66-56aef13c3040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c491aac1-b973-45a1-8e8b-8d2f5d4d4a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 985fc36a-b29d-463a-9cc0-4a50367b74f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1198db8-234c-453e-ab94-97604746b1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67cd442-b5ad-4546-9aeb-c7c331df08ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd1e1b5-7a56-49a2-8798-2a2741308036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba87057-a22f-435d-8ca9-1f9d5c11b45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc030f9a-9505-4f4a-925c-504b170af75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5f0427-33dc-45ba-906c-3193e6b5bb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7246877-6435-47ef-a6ac-bc417f2a1748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3a3d70-bfd9-46ad-bcaa-646c95d8b740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1468c2-f3da-4e40-81ab-2bcb7c02d59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1597f65b-ab0a-4894-8bab-d022f38bc6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9c35bb-9f2a-4c6b-87e1-342508620640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 945483f5-5147-48b1-97b0-ef53acd3a802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c012a1a-b68a-4e38-9a97-df285c8f7f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78dd3b8b-99f3-4dea-b772-04b82a21eb5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ac08dc-9273-4efb-988f-c407b6742ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c80295a-a79b-4d44-9444-29da1758f7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7808252d-e161-4444-bafc-da25e68ed8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf79fc2-64cd-4913-afa2-d7949fb47035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e57ef6b-145f-405a-969c-b42ded0aa6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4600b49a-2ec2-4a40-a0da-26817e5c6977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5676745a-399d-4550-b476-e3835dcfee24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcb3bd24-4ccd-43e3-8203-6b739147e4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41c450a-5b47-43ce-8cd3-6cf1d6931502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a985de74-a130-4b29-b9d3-942d61050a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0475bac3-960d-4d38-9a41-a66dea82187f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7eba776-1b1b-4f53-8f3d-3c716351b65e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88dccb6c-a6d2-4653-a5fd-16fac7a15506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9867a538-746c-47bc-b79c-9d5c232be724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0777e435-f532-4b6e-bea7-259254849f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b562a2-4437-4cde-8ebd-d24da5c38d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1b3562-5a3b-43c0-9165-01cd0f4c10d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81db387-3f22-4832-abc4-a0225377593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ae50ab-32e0-47f2-9e37-2f1072736a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8c036b-73b3-4257-bae4-5cf519e0df82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0aece2c-f39e-4940-b635-507176ee1057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d41214-5dec-4adb-87e1-bed9fb88a6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650f691d-e4ef-4c1b-b634-27a948263a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b430713a-b603-4ee6-b01d-630702b3bc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c416f452-4a14-4289-a10f-e40f08ca5a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ab4658-7642-49f4-8724-bfb57cc1f448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddc3328-3f91-4742-87e4-9699f7156c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afee6056-e03c-4864-93d0-c9fc5b297947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09bd57b4-8694-4a29-986a-e5ed7ad9d94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6cf5429-874d-4894-9dc7-9944699cc18c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d987f7-572e-4eb2-9874-5600f365b6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483c96bc-b51d-412a-a1aa-09ccae73dfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7199363-653a-4c03-99e3-55d332c25612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7273224-194b-495c-8201-593983afa699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bd1a71-7bde-451e-b9cf-cd7495d23b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea1a66b-29e1-482e-b817-964d2056cd7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f3736a7-dd05-4410-a597-b5410ef4fe05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4b1397-0161-4628-a95f-e3f165a185a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6568463a-6184-4054-8887-7ab379a158d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66622f19-b2c0-4b47-9627-cc3cf43e11a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56246dcd-cf76-4b5a-9588-1e9a829328bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec731c3a-dc94-4cc0-af35-788ab4dde6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d9dd7c-def2-4eac-9e67-b1d6acfcb5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd304f23-8df8-45ef-a2da-dae0c02414f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02baafef-51fb-4a41-9d48-7e61c0408334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6abec80-76dc-438d-97ed-f2822f813ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6843d18-841f-49db-9644-41a57de405cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e7f9a9-08c5-45c3-8f2f-955205c14ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c2f7ff-4a8e-4c74-a294-f59755dd59f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a18bd271-2530-41cc-be9a-5560eab31f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1004242-f203-4036-ae18-c3b1f8d34538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fcc6f62-fea8-465f-a82d-3bce8f145178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffadc98-fa74-4954-9cb9-733228a1f947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6bbaa69-b6d0-4ee3-a655-3d4b00687659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca31f6f5-3817-4953-b958-938c9ea26587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ab314f-9a0a-4ce6-abfc-3e3e60b8be0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc96058-3664-4aba-b481-278c6117f849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1965994a-b9a8-45b7-b436-f5b6d1cca769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7371848a-ec56-4d0f-8470-cc473764f034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4149e5ae-b29e-4418-9057-b234f42bde87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67744f1-b1a4-4c18-b3fa-0a642f3344a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7801a63b-8f40-46ab-982e-b15983b99f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e38bda-fa39-4776-865a-fcd3ee717039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06693ca5-4d90-486a-9428-37714377b578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5725e32-3294-4c23-a2f2-81d6c1ad6044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b234ece2-e588-4760-85df-0c9766ae861f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5836f4f-a13f-4211-b573-adf7bb21cf3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c4601e-6c28-46f6-a5f5-88b4eba93a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9e1536-c6b1-492c-a935-3e7e6f1eda6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb1fe3d-16f5-419f-84f1-1fac43631e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5013a423-8b37-4ea7-b9eb-3bab5a962c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d054de-9110-4e14-bb78-e6ea45122979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebc6c17-460f-4178-85e0-34571e190a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9723735a-869f-4ce9-ad40-d389f65f755e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd67b00-94ce-455f-836b-2df525639f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1768c6cd-13e3-4794-a397-691f87baff61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82be385f-bdf6-4c8e-a821-6901dc2f2524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb77be05-34ee-42a4-becf-1bcb6b3f9397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac9f648-972f-4c92-ad39-b69aec85483b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc79fbd1-a152-43e8-a4da-91ab8750a674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13579b10-3be7-47bb-b26e-d4b2ffedf463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5863c3e8-1de5-4f04-9026-73c115bf64d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8b4a45-a337-4ab5-a7e1-f530f6b9521b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9029be-2597-4e06-81e8-6c71a89b7d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4910d91c-8152-4af1-a5f6-1a2226ea058e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a42fae5-850e-4b4f-80ef-c062cef3c83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38a4537-79d5-4e54-9723-c841573486af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8cbc0b-a84d-4021-9aca-b0fd46e9acb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c471232-a372-4593-bd51-6128c544bd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0771dcf4-7602-447b-8ff6-2707e78cfdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ef8a56-1ce9-4273-9d31-eb4a536d89a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff9631a-86b4-4eea-a540-bd9f519cd5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 760fefa0-2529-4c36-a921-77dc66d35aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb2c271-1f2f-43ed-a84e-9822ecd704b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ad0405-75cb-4752-8cf5-f0e91aa41e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1cdad8-040a-4071-bd31-e6e75823a7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e1ce8a-f820-447e-a6f4-e4cb8d4e5adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9600cc-823d-4b9e-b5f8-9fb3414c5b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6055c67-48b9-483c-8b0a-13ffb9584079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f51ef6f-ed49-479f-b20d-7b0b21328d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c2c35a-bc22-4d8a-84df-49085bd8dce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5e661a-f016-414d-9cce-a085684e1b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e8e75c-e0c8-4599-b2b5-b31c3f7ac99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9117ce-b23a-45f6-9a78-db7e519aef04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48eb3f78-7f9f-4317-a786-e1884b37abc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146598eb-f1f3-43ad-8443-37d6769f0c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d24d39-b4c5-4120-88e8-435fedee56dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8bd4890-005a-43bd-bc02-9eba95193c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507c0db8-63ee-4ded-8e25-d5344969b17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad8b06a-75b3-417b-a25e-16eb4f46a26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53058aa-6c30-4daa-a58f-5f8bfcbca1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9811f6ae-b4f3-4df0-b8da-53de67c012af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5109a485-dce8-48e1-8eee-72f98ba34493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45237448-8598-407f-8276-e6d9a4065153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c82d1830-e102-4a94-a60e-95e06dee153f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7933032c-2d4b-4720-a79c-40dbff85d8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe8dc57e-ce3d-4e0f-9cc6-f05c0a3ea830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e18fa15-4549-47d1-8eb5-7549a2ae6397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ba3676-c69f-4c58-a6d3-d9bdbe50e158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41e8441c-8649-435f-a777-b65cecaf4d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff174af-de37-4d09-b997-20cbaa567abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25028c8-43f2-4d71-a80c-29aa6655d1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752e7a82-444f-485a-af30-126164e16651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45cac05-b985-4f84-908d-232648a0c5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb996dd-92d5-47e0-b073-548877a33b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03038342-c3ad-4e09-a2d7-6542795fc64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17565a86-92d4-4013-8c6e-855daca30f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9882675e-3435-4e50-ae4c-44f5044c8ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb51f404-681a-49a9-9820-a873f57323b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f247fe39-1cbe-4784-b0e1-f52f4f13cbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cdde112-061f-49b5-b991-5c511e63687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089a2f62-bb9c-478c-906e-cd66520b0d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5bde4ad-1d80-4c47-98c9-6eb59b06e2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbcfe71-d919-46ef-a6ec-1c314c53b1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598d4d1a-62dc-47ff-ae9e-4fa387147ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e4fe64-e9d4-4b03-8cde-9eb97ab166ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b5a3f6-a0d4-4f82-861d-0dafed43f988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661ea762-1294-467d-a186-cfbd22c1d193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2df426-d038-4159-bc6d-f08380887246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ecc2d2f-db94-4eba-83c0-5fe6fcae30aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4268cce-e540-4f8d-b6d5-397ab902b473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 560f1561-7d80-4f7d-b165-2fdd6506aa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285cd585-02b8-4894-a0e0-c3c501952289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e76258a-93d5-4b3b-a10c-be506a5df8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8c37f2-2061-4d5f-b16d-e2a6dc31edae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63a1fce-cbe6-4ecb-9e8b-2b9371bee736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed6e141-9594-47db-b03a-e68a31e32c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad34be1c-a85a-429e-96bd-244115eadb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0db3ce9-abf5-40da-b1a3-ad862a61fb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8811d8-d6f6-4363-a80d-947d047be17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0103dd63-13dc-4e0d-a96b-59320cb77dc2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(4483, 24), y=(4483,)
   Test:  X=(1121, 24), y=(1121,)

⚠️  Limiting training data: 4483 → 800 samples
⚠️  Limiting test data: 1121 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2485, R²: 0.0020

============================================================
🔄 Round 4 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0723 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0843, val=0.0716 (↓), lr=0.001000
   • Epoch   3/100: train=0.0842, val=0.0715, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0841, val=0.0714, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0840, val=0.0714, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0833, val=0.0713, patience=9/15, lr=0.001000
   • Epoch  21/100: train=0.0799, val=0.0707, patience=5/15, lr=0.001000
   📉 Epoch 31: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0729, val=0.0712, patience=6/15, lr=0.000500
   📉 Epoch 39: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 4 Summary - Client client_3
   Epochs: 40/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.1000
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0223
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0038

📊 Round 4 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 6 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0809 (↓), lr=0.000250
   • Epoch   2/100: train=0.0821, val=0.0807, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0809, val=0.0801, patience=13/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 6 Summary - Client client_3
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0082
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0177
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2488, R²: 0.0014

============================================================
🔄 Round 7 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000031
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0798, val=0.0850, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 7 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0031
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0003
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 7 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0019

============================================================
🔄 Round 10 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000008
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 10 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0076
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0019

============================================================
🔄 Round 11 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0715 (↓), lr=0.000002
   • Epoch   2/100: train=0.0833, val=0.0715, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0833, val=0.0715, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0833, val=0.0715, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0833, val=0.0715, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0833, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 11 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0054
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0089
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0015

============================================================
🔄 Round 14 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 14 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0050
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0080
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0017

📊 Round 14 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0014

📊 Round 14 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0012

============================================================
🔄 Round 17 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 17 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0054
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0048
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0012

============================================================
🔄 Round 18 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 18 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0042
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0023
============================================================


============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0013
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0022
============================================================


============================================================
🔄 Round 20 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 20 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0013
   Val:   Loss=0.0693, RMSE=0.2632, R²=-0.0063
============================================================


============================================================
🔄 Round 21 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 21 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0037
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0137
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0013

============================================================
🔄 Round 26 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 26 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0025
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0004
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0014

📊 Round 26 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0014

📊 Round 26 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0015

📊 Round 26 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0015

📊 Round 26 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0015

============================================================
🔄 Round 35 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 35 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0015
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0103
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0016

============================================================
🔄 Round 39 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 39 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0028
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0136
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0016

============================================================
🔄 Round 40 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 40 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0040
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0061
============================================================


============================================================
🔄 Round 42 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 42 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0052
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0046
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0016

============================================================
🔄 Round 46 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 46 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0044
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0003
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0017

============================================================
🔄 Round 47 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 47 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0022
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0001
============================================================


============================================================
🔄 Round 49 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 49 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0030
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0031
============================================================


============================================================
🔄 Round 50 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 50 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0066
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0100
============================================================


============================================================
🔄 Round 51 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 51 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0031
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0006
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0018

============================================================
🔄 Round 52 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 52 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0029
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0031
============================================================


============================================================
🔄 Round 53 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 53 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0063
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0094
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0018

============================================================
🔄 Round 55 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 55 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0047
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0018
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0018

============================================================
🔄 Round 56 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 56 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0026
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0072
============================================================


============================================================
🔄 Round 57 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 57 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0041
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0005
============================================================


============================================================
🔄 Round 60 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 60 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0046
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0058
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0019

============================================================
🔄 Round 62 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 62 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0023
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0035
============================================================


============================================================
🔄 Round 63 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 63 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0016
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0098
============================================================


============================================================
🔄 Round 64 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 64 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0025
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0070
============================================================


============================================================
🔄 Round 69 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 69 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0013
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0039
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

============================================================
🔄 Round 73 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 73 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0036
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0017
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

============================================================
🔄 Round 75 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 75 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0096
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

============================================================
🔄 Round 77 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 77 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0027
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0003
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

============================================================
🔄 Round 78 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 78 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0295
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

📊 Round 78 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0020

============================================================
🔄 Round 86 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 86 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0034
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0038
============================================================


============================================================
🔄 Round 89 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 89 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0045
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0051
============================================================


============================================================
🔄 Round 90 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 90 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0023
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0011
============================================================


============================================================
🔄 Round 92 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 92 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0045
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0079
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0021

============================================================
🔄 Round 93 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 93 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0024
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0058
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0021

============================================================
🔄 Round 97 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 97 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0019
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0050
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0021

============================================================
🔄 Round 100 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 100 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0047
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0018
============================================================


============================================================
🔄 Round 101 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 101 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0031
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0100
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0021

============================================================
🔄 Round 104 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 104 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0053
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0061
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

📊 Round 104 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

📊 Round 104 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

📊 Round 104 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

============================================================
🔄 Round 109 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 109 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0036
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0137
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

============================================================
🔄 Round 111 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 111 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0044
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0047
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

============================================================
🔄 Round 113 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 113 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0048
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0018
============================================================


============================================================
🔄 Round 115 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 115 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0027
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0064
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

============================================================
🔄 Round 118 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 118 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0022
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0009
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0022

📊 Round 118 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

📊 Round 118 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 130 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 130 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0039
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0010
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 131 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 131 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0064
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0089
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

📊 Round 131 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 134 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 134 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0022
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0077
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 135 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 135 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0023
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0054
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 139 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 139 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0034
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0038
============================================================


============================================================
🔄 Round 140 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 140 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0047
============================================================


============================================================
🔄 Round 143 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 143 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0047
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0012
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 146 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 146 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0013
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0039
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 147 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 147 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0011
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0048
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0023

📊 Round 147 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0023

============================================================
🔄 Round 149 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 149 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0029
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0060
============================================================


============================================================
🔄 Round 150 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 150 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0020
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0011
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 154 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 154 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0002
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0131
============================================================


============================================================
🔄 Round 155 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 155 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0054
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0078
============================================================


============================================================
🔄 Round 158 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 158 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0400
============================================================


============================================================
🔄 Round 159 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 159 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0026
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0044
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

📊 Round 159 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 163 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 163 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0014
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0074
============================================================


============================================================
🔄 Round 165 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 165 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0024
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0075
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

📊 Round 165 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 171 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 171 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0033
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0056
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 174 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 174 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0023
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0060
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

📊 Round 174 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 181 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 181 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0008
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0095
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0025

============================================================
🔄 Round 183 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 183 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0044
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0015
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0025

============================================================
🔄 Round 185 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 185 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0017
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0105
============================================================


============================================================
🔄 Round 186 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 186 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0005
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0084
============================================================


============================================================
🔄 Round 187 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 187 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0036
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0034
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0025

📊 Round 187 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2486, R²: 0.0025

============================================================
🔄 Round 189 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 189 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0031
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0051
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 198 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 198 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0026
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0252
============================================================


============================================================
🔄 Round 199 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 199 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0030
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0052
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 201 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 201 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0209
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

📊 Round 201 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 204 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 204 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0020
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0092
============================================================


============================================================
🔄 Round 207 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 207 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0046
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0202
============================================================


============================================================
🔄 Round 208 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 208 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0024
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0084
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

📊 Round 208 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 213 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 213 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0047
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0021
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 215 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 215 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0040
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0003
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 216 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 216 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0030
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0067
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 217 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 217 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0029
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0104
============================================================


============================================================
🔄 Round 221 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 221 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0011
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0126
============================================================


============================================================
🔄 Round 223 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 223 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0062
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0092
============================================================


============================================================
🔄 Round 224 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 224 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0054
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0175
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 226 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 226 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0031
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0025
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 228 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 228 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0044
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0005
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 230 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 230 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0048
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0077
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 231 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 231 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0026
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0018
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 233 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 233 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0040
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0123
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 233 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 233 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 237 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 237 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0019
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0089
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 239 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 239 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0021
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0022
============================================================


============================================================
🔄 Round 240 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 240 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0031
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0136
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 247 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 247 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0166
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 247 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 253 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 253 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0043
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0001
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 253 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 258 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 258 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0104
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 258 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

📊 Round 258 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 265 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 265 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0039
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0073
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 268 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 268 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0044
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0092
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0027

============================================================
🔄 Round 269 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 269 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0026
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0067
============================================================


============================================================
🔄 Round 271 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 271 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0034
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0031
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 275 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 275 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0092
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 277 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 277 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0068
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0087
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 279 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 279 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0037
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0154
============================================================


============================================================
🔄 Round 280 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 280 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0049
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0183
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 283 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 283 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0027
============================================================


============================================================
🔄 Round 285 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 285 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0038
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0000
============================================================


============================================================
🔄 Round 286 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 286 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0041
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0089
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 288 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 288 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0033
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0043
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 288 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 288 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 293 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 293 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0033
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0037
============================================================


============================================================
🔄 Round 294 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 294 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0061
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0060
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 294 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 297 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 297 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0061
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0080
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 302 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 302 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0049
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0065
============================================================


============================================================
🔄 Round 303 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 303 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0034
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0114
============================================================


============================================================
🔄 Round 304 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 304 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0034
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0015
============================================================


============================================================
🔄 Round 305 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 305 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0049
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0013
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 306 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 306 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0033
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0037
============================================================


============================================================
🔄 Round 307 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 307 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0036
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0004
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 308 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 308 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0047
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0138
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 311 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 311 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0034
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0045
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 311 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 311 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 314 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 314 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0014
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0039
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 318 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 318 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0054
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0032
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 321 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 321 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0035
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0042
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 322 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 322 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0049
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0015
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 322 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 325 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 325 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0049
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0086
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 326 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 326 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0061
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0288
============================================================


============================================================
🔄 Round 328 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 328 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0044
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0009
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 330 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 330 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0038
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0030
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 333 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 333 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0030
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0065
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 335 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 335 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0021
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0097
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 337 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 337 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0050
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0179
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 338 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 338 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0020
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0319
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 339 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 339 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0025
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0085
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 340 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 340 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0047
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0254
============================================================


============================================================
🔄 Round 341 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 341 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0029
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0062
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 344 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 344 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0014
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0115
============================================================


============================================================
🔄 Round 345 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 345 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0030
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0034
============================================================


============================================================
🔄 Round 346 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 346 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0012
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0124
============================================================


============================================================
🔄 Round 347 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 347 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0017
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0025
============================================================


============================================================
🔄 Round 348 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 348 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0016
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0110
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 348 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 348 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 348 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 353 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 353 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0040
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0126
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 357 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 357 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0036
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0040
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 358 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 358 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0015
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0111
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

📊 Round 358 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 362 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 362 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0051
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0058
============================================================


============================================================
🔄 Round 363 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 363 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0042
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0068
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 365 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 365 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0062
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0103
============================================================


============================================================
🔄 Round 366 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 366 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0029
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0048
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 367 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 367 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0021
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0035
============================================================


============================================================
🔄 Round 368 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 368 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0006
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0398
============================================================


============================================================
🔄 Round 369 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 369 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0021
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0165
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 378 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 378 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0036
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0033
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 380 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 380 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0032
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0039
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 380 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 382 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 382 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0060
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0104
============================================================


============================================================
🔄 Round 384 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 384 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0034
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0021
============================================================


============================================================
🔄 Round 385 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 385 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0029
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0038
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 385 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 388 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 388 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0057
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0043
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 388 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 388 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 392 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 392 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0028
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0047
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 392 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 395 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 395 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0030
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0009
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 397 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 397 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0035
   Val:   Loss=0.0727, RMSE=0.2695, R²=0.0021
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 404 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 404 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0033
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0054
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

📊 Round 404 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 408 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 408 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0048
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0015
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 410 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 410 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0045
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0023
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 416 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 416 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0058
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0139
============================================================


============================================================
🔄 Round 417 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 417 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0035
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0024
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 419 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 419 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0055
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0071
============================================================


============================================================
🔄 Round 420 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 420 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0011
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0119
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 420 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 420 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 424 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 424 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0042
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0338
============================================================


============================================================
🔄 Round 425 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 425 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0032
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0051
============================================================


============================================================
🔄 Round 426 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 426 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0040
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0021
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 431 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 431 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0025
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0074
============================================================


============================================================
🔄 Round 432 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 432 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0048
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0037
============================================================


============================================================
🔄 Round 433 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 433 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0060
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0059
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 433 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 436 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 436 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0076
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0209
============================================================


============================================================
🔄 Round 437 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 437 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0042
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0017
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 439 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 439 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0044
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0152
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 442 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 442 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0049
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0075
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 444 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 444 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0040
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0009
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 444 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 447 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 447 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0065
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0078
============================================================


============================================================
🔄 Round 449 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 449 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0046
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0036
============================================================


============================================================
🔄 Round 450 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 450 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0032
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0030
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 451 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 451 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0045
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0171
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 453 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 453 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0037
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0034
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 454 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 454 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0029
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0018
============================================================


============================================================
🔄 Round 455 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 455 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0031
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0024
============================================================


============================================================
🔄 Round 456 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 456 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0050
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0025
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

📊 Round 456 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 460 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 460 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0023
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0094
============================================================


============================================================
🔄 Round 461 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 461 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0026
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0048
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 463 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 463 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0008
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0042
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 465 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 465 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0034
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0042
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 465 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 474 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 474 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0021
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0101
============================================================


============================================================
🔄 Round 475 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 475 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0039
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0064
============================================================


============================================================
🔄 Round 476 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 476 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0016
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0091
============================================================


============================================================
🔄 Round 478 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 478 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0035
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0161
============================================================


============================================================
🔄 Round 480 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 480 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0044
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0031
============================================================


============================================================
🔄 Round 481 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 481 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0037
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0033
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 482 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 482 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0038
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0019
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 482 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 482 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 494 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 494 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0056
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0073
============================================================


============================================================
🔄 Round 495 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 495 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0042
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0007
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 496 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 496 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0028
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0006
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 498 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 498 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0051
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0054
============================================================


============================================================
🔄 Round 500 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 500 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0014
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0079
============================================================


============================================================
🔄 Round 502 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 502 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0019
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0110
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 506 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 506 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0069
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 507 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 507 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0040
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0003
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 508 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 508 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0035
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0020
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 511 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 511 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0028
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0021
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 513 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 513 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0108
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 513 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 513 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 518 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 518 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0031
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0029
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 518 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 521 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 521 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0046
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0005
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 523 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 523 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0026
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0074
============================================================


============================================================
🔄 Round 524 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 524 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0061
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0082
============================================================


============================================================
🔄 Round 527 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 527 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0030
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0062
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 529 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 529 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0041
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0120
============================================================


============================================================
🔄 Round 530 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 530 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0023
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0086
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 534 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 534 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0051
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0078
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 534 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 536 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 536 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0014
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0097
============================================================


============================================================
🔄 Round 537 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 537 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0056
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0059
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 537 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0032

📊 Round 537 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 541 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 541 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0020
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0029
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

📊 Round 541 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 547 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 547 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0050
   Val:   Loss=0.0683, RMSE=0.2613, R²=-0.0160
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 549 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 549 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0043
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0048
============================================================


============================================================
🔄 Round 550 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 550 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0047
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0028
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 552 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 552 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0044
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0003
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

📊 Round 552 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 556 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 556 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0038
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0015
============================================================


============================================================
🔄 Round 557 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 557 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0018
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0023
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 558 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 558 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0053
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0033
============================================================


============================================================
🔄 Round 562 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 562 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0037
============================================================


============================================================
🔄 Round 563 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 563 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0019
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0106
============================================================


============================================================
🔄 Round 566 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 566 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0010
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0113
============================================================


============================================================
🔄 Round 567 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 567 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0051
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0103
============================================================


============================================================
🔄 Round 570 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 570 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0049
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0015
============================================================


============================================================
🔄 Round 571 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 571 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0051
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0140
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

📊 Round 571 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

============================================================
🔄 Round 574 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 574 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0016
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0114
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

📊 Round 574 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

============================================================
🔄 Round 576 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 576 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0035
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0050
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

📊 Round 576 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

============================================================
🔄 Round 581 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 581 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0027
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0061
============================================================


============================================================
🔄 Round 582 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 582 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0060
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0041
============================================================


============================================================
🔄 Round 584 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 584 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0012
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0101
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 591 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 591 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0020
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0065
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0033

============================================================
🔄 Round 593 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 593 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0035
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0076
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 594 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 594 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0072
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0089
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 594 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 599 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 599 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0029
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0069
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 599 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 599 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 599 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 604 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 604 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0048
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0003
============================================================


============================================================
🔄 Round 605 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 605 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0036
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0019
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 609 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 609 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0031
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0134
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 611 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 611 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0037
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0018
============================================================


============================================================
🔄 Round 612 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 612 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0030
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0013
============================================================


============================================================
🔄 Round 613 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 613 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0032
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0039
============================================================


============================================================
🔄 Round 614 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 614 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0029
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0023
============================================================


============================================================
🔄 Round 617 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 617 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0063
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0107
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 618 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 618 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0046
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0053
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 619 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 619 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0033
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0145
============================================================


============================================================
🔄 Round 620 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 620 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0046
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0041
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 633 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 633 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0026
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0015
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 635 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 635 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0050
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0037
============================================================


============================================================
🔄 Round 643 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 643 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0048
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0055
============================================================


============================================================
🔄 Round 644 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 644 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0036
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0045
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 645 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 645 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0042
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0000
============================================================


============================================================
🔄 Round 646 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 646 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0056
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0082
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 648 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 648 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0013
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0107
============================================================


============================================================
🔄 Round 649 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 649 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0061
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0062
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 650 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 650 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0030
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0069
============================================================


============================================================
🔄 Round 652 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 652 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0025
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0094
============================================================


============================================================
🔄 Round 654 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 654 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0033
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0006
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 655 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 655 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0018
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0117
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 661 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 661 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0033
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0000
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 665 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 665 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0062
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0144
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 667 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 667 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0040
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0081
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 667 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 669 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 669 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0033
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0021
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 671 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 671 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0042
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0021
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 673 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 673 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0045
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0021
============================================================


============================================================
🔄 Round 677 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 677 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0019
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0024
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 682 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 682 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0057
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0064
============================================================


============================================================
🔄 Round 690 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 690 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0047
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0003
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

============================================================
🔄 Round 691 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 691 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0038
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0007
============================================================


============================================================
🔄 Round 693 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 693 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0021
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0176
============================================================


============================================================
🔄 Round 694 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 694 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0022
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0091
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 694 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 698 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 698 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0002
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0195
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 699 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 699 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0040
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0016
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 702 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 702 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0035
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0059
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 706 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 706 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0033
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0057
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 706 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0034

📊 Round 706 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 715 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 715 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0044
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0099
============================================================


============================================================
🔄 Round 717 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 717 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0001
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0159
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 720 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 720 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0014
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0099
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 720 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 722 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 722 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0049
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0274
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 725 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 725 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0025
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0086
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 727 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 727 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0026
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0082
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 729 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 729 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0036
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0025
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 731 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 731 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0032
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0056
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 733 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 733 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0038
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0034
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 733 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 736 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 736 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0039
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0034
============================================================


============================================================
🔄 Round 737 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 737 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0022
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0001
============================================================


============================================================
🔄 Round 738 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 738 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0035
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0132
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 740 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 740 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0087
============================================================


============================================================
🔄 Round 741 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 741 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0047
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0004
============================================================


============================================================
🔄 Round 747 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 747 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0032
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 750 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 750 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0041
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0010
============================================================


============================================================
🔄 Round 751 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 751 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0053
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0040
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 751 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 755 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 755 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0040
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0090
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 757 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 757 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0060
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0053
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 758 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 758 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0033
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0005
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 759 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 759 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0038
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0039
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 762 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 762 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0032
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0088
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

📊 Round 762 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 764 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 764 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0053
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0090
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 765 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 765 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0050
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0018
============================================================


============================================================
🔄 Round 766 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 766 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0024
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0024
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 768 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 768 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0017
   Val:   Loss=0.0975, RMSE=0.3123, R²=0.0061
============================================================


============================================================
🔄 Round 770 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 770 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0041
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0092
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 771 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 771 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0039
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0032
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 774 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 774 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0020
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0016
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 776 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 776 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0020
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0099
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 779 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 779 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0037
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0050
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 780 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 780 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0005
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0163
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 780 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 784 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 784 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0012
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0148
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 784 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 784 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 790 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 790 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0044
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0014
============================================================


============================================================
🔄 Round 791 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 791 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0032
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0013
============================================================


============================================================
🔄 Round 792 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 792 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0035
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0031
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 793 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 793 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0037
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0009
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 793 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 796 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 796 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0024
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0066
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 799 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 799 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0055
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0064
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 800 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 800 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0051
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0013
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 802 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 802 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0001
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0093
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 804 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 804 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0005
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0011
============================================================


============================================================
🔄 Round 805 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 805 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0016
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0007
============================================================


============================================================
🔄 Round 808 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 808 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0032
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0032
============================================================


📊 Round 808 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 809 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 809 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0046
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0005
============================================================


============================================================
🔄 Round 810 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 810 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0065
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0105
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 810 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 813 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 813 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0027
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0016
============================================================


📊 Round 813 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 817 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 817 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0030
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0079
============================================================


============================================================
🔄 Round 818 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 818 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0058
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0182
============================================================


============================================================
🔄 Round 819 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 819 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0031
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0043
============================================================


============================================================
🔄 Round 820 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 820 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0013
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0143
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 820 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 823 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 823 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0028
============================================================


============================================================
🔄 Round 825 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 825 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0018
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0118
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 827 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 827 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0056
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0051
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 827 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 831 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 831 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0030
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0051
============================================================


📊 Round 831 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 834 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 834 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0027
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0268
============================================================


📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 841 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 841 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0033
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0372
============================================================


============================================================
🔄 Round 843 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 843 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0058
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0156
============================================================


============================================================
🔄 Round 844 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 844 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0028
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0082
============================================================


============================================================
🔄 Round 845 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 845 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0059
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0045
============================================================


============================================================
🔄 Round 847 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 847 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0036
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0384
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 848 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 848 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0043
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0052
============================================================


============================================================
🔄 Round 849 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 849 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0066
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0123
============================================================


============================================================
🔄 Round 851 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 851 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0013
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0047
============================================================


============================================================
🔄 Round 853 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 853 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0028
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0001
============================================================


============================================================
🔄 Round 854 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 854 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0033
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0057
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 854 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

📊 Round 854 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 860 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 860 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0036
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0043
============================================================


============================================================
🔄 Round 863 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 863 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0042
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0018
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 864 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 864 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0068
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0095
============================================================


============================================================
🔄 Round 865 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 865 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0038
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0073
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 867 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 867 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0028
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0078
============================================================


============================================================
🔄 Round 869 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 869 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0037
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0033
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 869 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 873 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 873 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0026
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0090
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 873 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 881 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 881 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0006
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0003
============================================================


============================================================
🔄 Round 882 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 882 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0046
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0020
============================================================


============================================================
🔄 Round 883 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 883 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0042
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0054
============================================================


📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 893 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 893 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0043
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0004
============================================================


============================================================
🔄 Round 894 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 894 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0051
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0043
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 895 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 895 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0053
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0027
============================================================


============================================================
🔄 Round 896 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 896 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0090
============================================================


============================================================
🔄 Round 898 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 898 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0023
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0099
============================================================


📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 905 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 905 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0060
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0118
============================================================


============================================================
🔄 Round 906 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 906 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0038
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0041
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 906 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 908 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 908 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0041
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0008
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 911 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 911 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0002
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0146
============================================================


============================================================
🔄 Round 913 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 913 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0067
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0088
============================================================


📊 Round 913 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 914 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 914 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0068
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0151
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 916 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 916 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0021
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0106
============================================================


📊 Round 916 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 917 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 917 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0045
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0053
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 918 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 918 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0030
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0021
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 921 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 921 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0052
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0053
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 927 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 927 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0017
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0050
============================================================


📊 Round 927 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 928 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 928 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0033
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0118
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 929 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 929 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0031
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0065
============================================================


============================================================
🔄 Round 930 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 930 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0042
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0021
============================================================


============================================================
🔄 Round 931 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 931 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0045
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0008
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 931 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 933 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 933 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0034
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0056
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 933 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 936 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 936 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0011
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0037
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 939 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 939 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0120
============================================================


============================================================
🔄 Round 940 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 940 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0038
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0010
============================================================


============================================================
🔄 Round 942 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 942 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0039
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0038
============================================================


============================================================
🔄 Round 943 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 943 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0039
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0014
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 943 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 945 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 945 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0065
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0058
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 945 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

📊 Round 945 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2484, R²: 0.0037

❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
