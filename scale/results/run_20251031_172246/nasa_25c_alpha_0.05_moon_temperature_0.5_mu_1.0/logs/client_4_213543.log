[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee3e102-eacc-4739-af96-1a8cf1722aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6d1e21-f71a-457c-9fd8-f09b37294b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac068fe-5a1c-45a1-9962-09b26876f3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b563c4f-3fb2-40ec-a661-6eb87de561b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b065fb-7f05-425f-9558-e586df63d78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc2e013-5867-4ee0-8d3b-4b61c06898b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0eee4e-bc2f-48c4-add9-31ac5e5f56eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67094cf7-cbf8-4910-b8f0-5809485e91cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214dd678-927b-4a96-aab5-fb897df912c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b6b70b-abc9-4b85-a410-341223f2d8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8a1de9-f674-4150-9fee-4981e1fdd6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2beb4f33-e91d-495e-9f47-98401232786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ea5ec5-befc-48f6-a511-43b429caf188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2ff73d-7bfd-4e66-aa86-a742b8deff95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db99412-c33d-42e1-adf8-4ce816dd9dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de4bc63-e4b8-41e7-817e-4ce7391a6423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32433b8-1742-4c2c-af86-5ba2c343e863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a46fed22-0fa0-4d73-a846-6186d2e24909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32850828-ae1d-4c55-a92e-38dfca0d75f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a737e1d9-3c7c-4a7d-bedc-c04de40b7f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa990db-0363-475e-8dcf-bafb2dcc56be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ab00db-027a-4789-972e-28689f6a19b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177e72e8-6f3a-4b2f-8d5a-84688944ff1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4411e5-5235-4995-ab5a-35379355d87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0c5056-3657-4629-b1cc-16f99100e71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d886899a-0313-4ae3-9bf0-a1fc7c9c77d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16b1ab9-52a7-4a3c-bb6b-038f780e9c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d5ff6a-a6b7-46a0-8d60-e49bfc070daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8288f9-e79a-4de7-aafd-29e5d99d471c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a096e1-fad9-4490-85ae-52ed84692b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d2b3d61-e0ae-4720-b421-fc8d4b3a34c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa036ee-a8ca-4ceb-8759-382db76bcd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ed4a61-f525-4b9a-9caf-5e275e8ebd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d5bd2c-185b-4a2a-9c14-a9c936d4deef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57534b2d-4828-4359-8646-dc54d1fe7d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd47a041-e31b-4d47-9611-a260ce139154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c565d989-a19c-470a-a199-81231e250a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc020d8-b3b6-40ef-b112-e66ca999e620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf1f75b-968e-45c7-8817-67a79e6afae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867fd8b7-32b5-4994-bde6-5c4680941cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da7163a-ee9e-421d-9948-c70eecc12237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7d1719-c629-4e1c-b54c-554b52b739a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb6839e-4c91-42e8-a289-3f3efec6fa22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a69b8a-856c-469c-8fde-8c128b3b6c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f8ae39-0e9c-42e0-9bea-4967a8bcebd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e12c0ce-f3c3-4d8d-90da-cda5fc2db91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479071bb-1308-467e-b1ac-137c0bc77acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e7b4d6-a958-4065-bf40-3fd3fa726f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5ccb5c-2c4b-45b8-8555-9cbdb423bbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2db2be9-9229-4cae-88c7-0139c8094faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ab62b3-a53f-4487-984e-e0b04f860a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7f1b171-2d5a-4592-ba77-45fd5cd1ca91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5841232c-0ea4-43d9-ab53-698cf7ea0991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b91ce8-b626-4049-adf4-8a3196d312e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd465a92-383e-4aa1-852e-31cbb68639ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eacc28d0-3c22-4486-bcb6-3026412593d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9401e8-9614-47d1-9964-da8edc838a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bb2274-018f-40de-a65b-3b49901559c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082eb86e-9358-41ef-9e5e-93de3e9eab27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40cd3f05-d27e-4b67-9a8d-5dcea1ad1b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1333da20-e484-4405-abfd-70b6ea8adb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6823a0-ac5f-434b-8ca1-6e4a816183fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167d863a-9e7f-4e8a-8e7f-bf6f443dd9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a5f0af-8dc2-40f2-b3bb-afbd0dec5acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27e4e61-062f-47ba-b42e-6dca57c5047a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e666db4-73b6-4540-811a-68f584b43e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf01f59c-1744-4480-8862-610b8286faf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380f8604-4640-4ed0-8e88-d4813d864c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0252d936-0c5f-47fe-a4a2-1b88c69a9155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8877dc-78bf-4b7e-acb7-de1bfb8fd1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d40a3e9-60c6-4727-b9f2-0980f79b3b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749b40a7-ddda-4364-976e-b99454de3f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b2fc78-0539-484f-97d8-598d4356139b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c5ddc5-1dcd-47d4-adf9-f84658dc943d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8412672b-3642-4531-b085-06e5275e827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3780d94f-40da-4a7e-add3-fc6e82bf81cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf9b969-70dc-4637-831d-43ed66e62316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ff0e35-5758-40a7-920f-6f694efd9743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b154432-61e9-40c8-9518-af910bb91164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7c2dc8-c587-4a4c-92d1-9569d9535042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ac4a00-13ed-4de4-a59a-6a67e0eca0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aca3dcf-7a2f-4d12-b9e0-cf3de3a7fe11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0981c71-0bd7-401a-9ee7-2c8b72ae9df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1113f3-03d3-4425-9cc6-70594089934e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81d6dd3-fd20-48aa-8ad4-fe2b93536b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68637c5-49ca-46ac-8dc1-3c5cf964f171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 935e47f8-e618-4442-9737-65c658b2b5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd914b7-5265-4f2b-aefe-5a2ea38a7f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78fb009a-fd2e-4a35-b13c-2299b3a7ed4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788016ca-d9b1-4c12-a383-267bf27ebdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1885f7c9-61d3-4124-a268-06a0e5c408b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d40388-92d9-4343-b7b0-cead928ff6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7a6c31-2ea1-4c21-a24a-eb37fb24e909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0e00fa-c9f1-42fc-9175-2cf990054cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811d848d-d215-4d38-8c69-0d9de6552e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5cbfb5f-bc84-4130-ad7b-a4c73b59a384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb56561-b6b8-4d76-a7bd-70ea69a900af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47943e1b-39b6-4453-a938-5ba62104de58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701e7f09-56b2-454e-817d-3cd2c0f2f463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55423ed6-17db-4092-9cd6-2002e8b93fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a78e5d-e3db-49c6-96f7-1164d81362ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a100d71-4b36-4974-a823-60e59ab0f31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a7fead-bba3-4946-8541-4bd37b847aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16cfa0f-2de2-4834-8175-6cca008198fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80b8532-7b8f-4611-9c16-2236df30e4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7843b8e-99f7-428b-a183-e7b8f412d573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31148fc6-312a-4be9-aa6e-843304b62400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e18008-8b28-4c2c-937e-aba56521ffca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ecd1f9-26fe-4490-9b5d-5689e4785c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86cdedc5-0aca-43ab-9e0b-230dcbea17e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a9bed2-1318-44fe-ab15-c9f213646583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5a2dad-e80a-4456-b7bc-7120dbcc0370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f22b28-69d0-4a83-829b-674c4d00c0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a6238b-ac28-41e9-b124-aa13f9e2231e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d08ce620-96e0-4365-94bd-dde1ebb1d8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397721eb-1abb-47b0-bb6c-cf1da9d652e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf25cd9a-a2ae-4ced-ab92-ba593b2eca63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049eb1cc-785d-4816-964e-bce0451c5f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b0d437-9796-41fb-85e5-c2c22e3b9947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459d699e-7272-4438-9883-4946032f1c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36859d8-287d-4cfe-a7dd-07a34a265969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f03c91-abc9-439e-8ead-1ffae3f6d45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6fedac-deb5-4bde-9a84-45317e318af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b313e02-3220-4bc1-98ec-6671dd0989e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 060917b7-9383-4189-aeec-dcddff4370ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6aa8523-393b-4026-920a-9a3c07c80aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e51639-8c28-4ea4-82e0-a4ad22f995eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e550b895-75c3-4a4b-8962-7ba511b21401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3860a32-143c-4a01-949c-708314331db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17644c31-78df-4b04-afb3-ba2f10624b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee92942-ac65-420e-aef4-efc2f7dda5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d05496-a553-44a0-a3c1-6df1d2cdf3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6603af-e31a-4ca7-9aaa-4474ef97ba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c3cce3-d211-4a3d-9755-1d191afab144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4476671-ad6b-433e-9395-fa6403c6af1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86d2eb6-5d29-4dba-966a-8cf7bdacf5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d698855-4b8a-4d6c-8478-2aade601c3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3f3fb4-5d5d-4dd2-98f7-b12b4f8155c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e12feb3-7f14-4cf7-b580-f1b72319d0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6334cdbc-dd2d-4bf9-818e-8682b16bfe11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef8e3d9-25f5-4f87-884b-bd6b57dff03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a949f42-1468-4fac-b5fd-2ac7bd18b58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc1bbce-c1d2-44ba-bc0c-94295ba48937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a4ebf0-32b4-48cc-88be-3c524cc3dcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178a0f37-8462-4dad-9625-518a90f33817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7cbb27-76f6-44c1-85da-802cd3e5d92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d94d7a-7cb4-46dc-a807-e97209e78920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1fab0b0-5080-48be-a232-cfec285ec388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a973a8-8776-4b18-9cdc-ec57e3aad64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd2ebab-676e-4964-a6f8-659be603d7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c783e817-699f-4f25-9e95-944ada61be2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1a878b7-0054-45b8-8f9c-38b792411a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a018246-94b4-408b-832b-c1288e652992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba6ea98-48d9-45f6-b24d-fe4aa6de180c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4aab761-2336-4301-ad20-e4e6351a0fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd576115-2ca0-4cf7-b074-792d5c8da477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283f428e-519d-4ada-9c0b-4599955904c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182e91e4-4092-46a8-9f62-32d67b2268e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1569a704-3a0a-47be-b152-fa0f72ffd48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ea644a-52ac-4a44-8f06-41028214cf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186430e8-d99c-44eb-b0fd-0db5c049749e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63deec8-fd0b-4447-92a8-7cd4fb051734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ce65b0-19b1-49b0-9aaa-9660dd18d470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5366b8-f1a0-4e26-a82d-ca7e547e81af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6c979c-e4b3-48d8-ac12-ce059f81b072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f03751-5df4-40ae-a3b0-aab5bd64ec61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15c4e8f0-3534-4351-ba5f-cdc32b537e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c045397c-150d-42a4-b530-ac8a5b9031e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b15d0df-7861-4c78-a0e4-266a53c29786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800e2f7f-ac04-463e-8047-41170d64af4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba094a14-492f-43fb-85f0-22fb9dfde52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc5d3ca-61c0-4840-8cd7-81855d341aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87651f7a-f988-4d70-bd3c-0797dfc0e298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55aa3a53-d1ff-48ff-8c06-3ec5d87ac8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284953a9-d071-4e74-bde4-4feb9e774bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a99c1a-b787-484d-8a56-2231c1106232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ef2e06e-339a-4e3f-bee0-b67fa26d48e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe25f0d-bbba-4d02-bf1c-670852381b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0f7afa0-fa34-4300-939d-89b800f77d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777f0998-2549-421b-b996-430998140361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad51359f-ca3f-467b-afbb-6cdb69bc47d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec98c22-a437-4fc8-9c93-014120b7d3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9b6c15-8db3-4fb8-afb9-95cdc41b82c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc35182e-2a52-411b-90b3-060bcbab0bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5d71a9-13ab-4d5d-81d5-652ac3b16994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa97d7f9-996f-4837-9621-fe27fa25c63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cb2fce-1cf0-4fab-83a0-0b9c22555f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21602556-4bc0-4330-86d4-008cf4674c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6109c0d2-a8e3-45b0-a1b6-0d65b9d3b5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a5bf547-32c6-41f4-b260-c923cefbd999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99ca4ab-984a-4c08-a8c3-09e637b633a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a43bb9b3-1eb5-4823-afeb-b2c7f90cf3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3402b4a7-e14a-4c94-bbae-f67eae0a1563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d2d512-ae4a-4219-bc6d-bd00beed3f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3376e0-97f9-42a9-9239-6df7f598eb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c9cbf5-618c-41b0-b50e-39829fd3277d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e117c3-8757-42ae-a880-56981045811d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208b98af-340a-4d3f-9ebb-da55d7c4d370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f381e85-c45d-4ac5-b3b6-e6e8cd3b308f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ead671-5170-47a1-ae8f-9e72deeaad1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0329f41-6579-4c4a-a6ca-4b54575f8b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d8a5ae-71b3-41e4-997b-34db43d37bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8d4632-9923-4707-87c5-8a838a065eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80879eaa-52b2-4cd6-952e-66ef815c03d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0afe0b63-ebab-40a7-a630-8e3dde8e6449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe45f3ab-6c2f-4723-a233-6fcbcfa3f5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 167c4292-0d7b-4fa8-8dc0-34dc4da75ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff314c9-0021-45f5-b8df-6e2910e06e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37ad478-9ec7-4510-9201-734bb7d3c511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd78f51-c984-4f5d-81c4-cefcb42659ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a6944b-161a-489c-ab80-421975d3aa95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3f33bdd-a389-4945-9ac6-1a7c11b0132d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6357c08-d01c-4b8e-ac21-0e87b6cd1dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd706005-d848-4340-af02-df5ad6166de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939bb4e3-d733-45bc-b639-809609e56838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27cc99e8-4a98-4c28-a6f7-0365b22422a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aa1cf5-4ddc-49b8-893c-b832b2c93640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18159d7f-c2ff-4f5d-a84d-e66758aff64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1512024-6c69-4455-a362-012724d5ac17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da545143-ee58-4e2a-b3b1-52bd2b65f81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d23d3ca-c5c5-42dd-bebd-aeb2140545eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25830365-3701-4d8f-aff7-d97247b49f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3a65c9-c95c-4293-a0ca-b77690e15f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efcee0d4-7d8b-41cd-b6bf-4327e38133a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9047b8f5-060f-4a55-aef2-e42d6dd75534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8431b9c0-db12-4ad2-aad7-3fc4f140b126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d484008d-16da-412c-b068-73d756f68b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f42b3d-00ce-4cdd-9c1c-5d1b9dd0e09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051ba9ad-9d44-45d1-a65c-b9ef057345d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5df61f-c335-4168-9625-f445dd4506fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78cdaf3-e0d6-408b-a01e-3ab75f23cd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72df345-0bea-4cae-b4e3-44ebfba0d09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5971d8-12ef-4fb9-816b-a5c462d19c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67a5bfd-9cb2-40b7-a680-12f4abfbc773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539a63cf-b6b0-4e45-a275-c275f63508b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eee9a2b-9086-421d-a7bd-86b03f4e7dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f25a76-ebb3-4eb8-a5e8-cfc268a251be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da536649-9bca-4bb0-8e31-531ca38fd8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f6f0f5-062b-445a-805d-9d7de0eae68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01370ed8-2d4b-4cc2-a500-efded266bf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520f2640-fa0b-438f-bb52-0b343e921070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6027ca67-be90-443b-88e2-9514735081e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d47189f-6cf0-4b52-9c45-93662296a672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f7e89b-4c97-4a66-a03c-e56dab0d23ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97afa217-5218-4fb1-95ae-e2a97388e484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e099f02-7ba5-418a-b1a6-0d2c5a13fea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6c05c6-93e7-4643-9bff-d53d290cda8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb4b06b-c854-46d4-8134-a48535fd506e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768d0627-00d9-4fc7-ad51-1a5abe727e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a8d464-6876-43e2-85b9-ba744c723e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb95a6f-605c-47cc-9943-155c7679764e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb991130-d172-4922-8703-ad7182d076bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97aacb6b-0490-4a51-ad40-49d30e2095ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4935aa80-7d21-451b-ba2f-c102c832fe9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839e96d4-2a65-4a9c-961b-37deace05e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b60e439e-7571-4f32-89e5-f7aa93420037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6450d892-272d-4a74-973b-40c471998976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c1b35e-afc6-498a-b777-43d2f9846cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04bbd9ac-7f25-4854-bb48-16ba77f6daa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb22ab3-893e-4b00-a520-2d53a012ac90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2197ca-56d4-4554-ae0b-c3fbf186ab5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2678bdc8-8bcb-4c2e-8735-40dc04161bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46269a95-8837-44f9-970d-4489304ee100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e51a0f-d6fe-4e5a-b7cf-ad8ba7c9f867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526a9ed9-63c1-48a0-9670-886bcc229488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ee0e2e-8e87-42b2-8aea-d156d32f505e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6682d26-4e61-49ac-bb36-22677ee541da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d67f2b7-5678-4e6c-b8f9-867e31607b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac8be9a-397b-46b7-b7b1-2f2d66aa4156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2e5587-574c-4a7d-847a-a134e89779cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b018d9-952c-4868-bc1d-b288141401df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ebba48-202c-420a-ae0a-a90226919b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9923068-b762-456e-9042-b837b51d178f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9f9172-dc0e-4206-b719-a83d071180da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee8710f-1341-4f9d-b0b1-8312dc37e0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008548c9-d9fd-470e-8179-74eb532f66ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4224714c-ece2-44a3-bc06-f1f7dbef361a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1afb0333-0cfb-4485-8c69-f2711db33647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8887a4-f157-4886-8c01-c6ece4d8a0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb813c2-7dcb-4dd7-ad44-a97f74032078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6ef2d8-7a2c-458f-a054-de4d55882e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726f2437-cb54-425c-ad3e-3aa317f56678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb2bfee-c2fb-4349-95ef-56df9df72b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76111958-510e-43fe-ae81-1b30fcf18975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed33f9d-abc4-4328-b84c-18bb3bb7548f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 742fd5fa-96f4-4e27-8ba3-8d13df8fb787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ada404-0b23-4b01-8769-015aa03292f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b29648-da69-44f6-9a8d-ab49dd3bb2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ee553b-e677-4e94-a784-e0202a4114f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f079a4b4-c197-46b4-9862-a78b90c90a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e9afc6-9d8d-490c-b931-53614fdd7f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf1add08-feba-41cb-8e5f-2a6677a6b8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ea35b4-b9b9-4327-b71c-6164623876b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2f0f14-741a-4046-935e-1ad1d995b8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1074f4aa-a576-4ecc-be87-9a28c0ba207a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6770d75-50fb-453e-ac89-7dd51510b771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ed28b9-3245-4662-a6a2-e54aa8c80afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3847c35-fd11-4418-86d5-86b6e52f2430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f70314-7da5-4c79-ad5e-d676b6317cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ce7d51-24aa-44e6-ac67-efbfcc400ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b376312-93c3-4546-98fd-c51cf638abdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2cd2c3-cb81-4575-a0b8-dee8e935783d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75eb61c5-a19e-4cca-8f7e-f58b59e15be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb8085f-37e8-4af8-aa7d-dd56d426fc23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24da78e7-4438-465c-92b6-dfcae61c8424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caead34f-42be-4aab-b51d-aa12148f60db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf5b47cd-ba68-422d-93d3-ab6a379e1076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9c071d-c2ee-45ba-906c-058680a4a677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f5f2aa-b1c7-4694-9430-3e9a1598b5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980336aa-fc75-44bf-b692-24cb9a9dd3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480570e7-1541-4439-9980-b391ee3929fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e277e7-8889-4ad3-a1a1-0a4d9e4b99ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771dc93f-cf8c-4ec7-8c75-5d1927112819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aaba147-1672-480c-a02c-179183b50f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9a4f33-c342-4547-9619-ab8efd0270f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc595e66-a487-47c2-95bb-52734209633a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b71539d-92a7-460e-bdd6-eee6602c1113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3dd0e8-2bb4-4c7e-9296-e7e3cfa8a2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31116053-084f-4006-a008-c01117b4120f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08038b8-3605-4005-963c-8370a47835a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653175ce-fbed-4825-b700-351181d93fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4aaaccb-f15b-4e27-960c-f8c2ab0e45d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f31a5d6-6c1c-4093-90c3-e06b63aa8a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9471e617-9395-4078-9a80-8da45587fdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446f659f-cd59-45f2-b96d-4290419e3d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9bd9bd-0d24-4a17-8418-f9dd5646b76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b012d82-1ea3-4662-bed8-6b38124bc63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28721535-1df8-4fa5-b256-9c12fa8903af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e823a1d-22dc-470d-8afb-09f50189feb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5eb9068-368e-4c2d-93bc-fdafd6f14a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b16a2a-b399-4e19-a1f2-2f8443dc827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cac0760-dd99-4de1-ac59-4264c8882a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286d8ed7-46e4-4e40-8c83-30f287e033ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aabe262-f25a-4a2e-97eb-6f4855296ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed4b2ba-d866-411a-a967-1048bf59c679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25693fe5-f47b-4599-b7e6-04761e77988a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b342abed-435f-4ad9-905d-7ee915c7e249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7401c3d-4a4f-423d-8cde-d153ae03b889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7af4774-ad79-4f95-a04f-b42a391f4417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a9d7d4-681d-44d8-bb0a-cb1baed4e900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51410fa4-f1a3-40b8-87a2-bb08867414a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7e4af8-c6f7-4b64-95cb-b4137ad0546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348edcb0-ffcd-438f-8238-cd61be35b5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab78e84-427e-4654-b9d7-2f6df64c52bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba6c36e-8a8a-45e5-b23f-9fb6f502306a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfba3d4b-a3e6-4ccc-b3d8-9204970007f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1cf53bb-5ec2-4c3a-a395-cfb07a9e5fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d70de37-4d0c-464d-bd24-5f6f2746ee6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36347364-3616-4774-a359-febc2be2ab27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d5c642-a903-41a4-9984-9bd22250c64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ad31e2-4a26-4bec-bc83-915ed3c911c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a00c691-4974-45de-8471-4fd6e326794f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbae21a-4c08-4e65-9334-732237eeec78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5d3684-93b9-425b-9e1a-a3d3a23f469b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4075dbff-c8ca-4d72-b002-a0d19ca65355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f129f9a-ffb2-4ab4-ac90-f5277636088a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5a506f-4752-4d80-b803-972795c50e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76521b9e-4db5-4c4a-b0a1-811e36b95edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb69316-c4ff-4aea-a972-bc4d7047d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7b745d-3c5f-4e9f-bf23-d08d35d980ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc614078-3360-4705-ba24-f1325463fb8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f18e68-3f02-4dfe-8f64-ac11fdfaebf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4b9daf-0466-4811-b673-874cf493f611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7758cba3-5307-4edf-ae84-b6beec56f084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b67542a7-f1a0-41e0-b936-ac6f10673faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c54a34f-89b0-46b1-9886-9340d62235e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf73fa97-9a44-42ea-9a4e-1185322d6627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe97bbd-e445-4a2e-a071-59cf442310e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaaed3a5-4502-4b41-b1fb-43c7d021f291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79e8634-f1e6-49c4-adbb-1b3795f1f74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eeafd77-3bb9-4853-9ffe-15a03b65bb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c89fe0b-3759-4cde-ae30-0ee1931ff022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4238ad-c18e-4b05-a4ed-fd8b40cdc396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca27b5d-9f71-4516-adac-19a0245057cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd4f4ee-b13d-4313-8da4-54e2602c8141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21dc457-bb77-47e9-9d84-21cd24b94497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c168b9-e315-4e05-a881-63949270eed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327a4f6c-52b3-4212-8e5b-c26f9f66940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8071b30-0749-42ef-8924-f0e53040ea5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5277422c-1d55-4f21-adc5-31650f1ea0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5e82a3-b653-4d18-a2fa-f7424ea9b88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00df94e-3e72-4183-9989-d13a8a5571a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb95898-5cb7-46ae-bf61-eb3f6490baee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dff2a71-c980-41d1-85b5-61ad77eac11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3be32b-4400-43f6-a7a4-f089753c0eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8b55bf-b9d3-4223-a916-76cb53f7c352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0840ac1b-9102-40a5-b3c7-21eca7100eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3fef4e-3842-431c-92b8-4c6b214d4adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9b7ddc-e6c6-42c4-9a8c-0427954c697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30727d6-b114-4bfa-95c7-79269e83b61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0138747a-e7d1-4b90-8a41-7fd9ff5f99da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e9a18df-a616-4387-bfe8-348610948fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d998b950-63dd-41f0-95c7-5158895ae2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ea76df-3009-4cdf-9ad4-e98c2f66aa4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada92d99-a43d-4ca0-a88d-79f461caea06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba810bf9-d6ae-46f4-85c6-ae46a7966773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0e78d5-9c65-443e-b6c5-011833fd3262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7b9a4b-38df-4517-b1bb-85765cd6b120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f17bfd-59f5-4da9-b903-0504e7e9b7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf31dd83-6874-4e1e-8e57-80c2b241bed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f049afe-a0ec-4579-a4c0-2dce6655f631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4336369b-c6c8-4a12-9ebe-a5a0c854e539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38267846-8e9a-40c7-be72-5075d4223772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d972cc9d-08fb-4938-b422-623efeab4ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef832383-4494-41c0-b2ce-4d78a95d693f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2063d1-492f-4e33-aedb-aa0e26945815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ddf3a9-c5d6-4949-b710-975063c47f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1669534c-a435-45ad-8fa3-c15f5a45a543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51e415e-95ff-487f-9467-d46801bb69fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54f7ef3-b62a-4d7a-b322-44fc9fb7ec72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ac1f13-4777-41aa-843d-123844731773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d25fd0da-dfc3-40e4-a031-382bc798c465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57ce6959-1124-48e1-a531-94ca2754efa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d15fa8-dc3a-49d6-b4b5-c1f1ca385fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 316eb0b0-cd24-450c-9cae-54c6ad20e0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1caec23-bf81-417f-a410-eacf886ffd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71edafda-4658-4603-9235-f8c1cc74d838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 952e2330-f07a-4865-b7c8-42a3ae23004a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cfa880a-afc5-4959-b2bc-1cecc30574ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa192b5f-c070-4044-ab13-4b710b21c26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791d0152-f28e-47b7-8b06-7800d3725555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c27f69-b15f-4927-9f1a-667047ef6868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ac0c34-dd15-4338-9c4b-4adc3df69675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b306b11-9456-4f6c-9788-d337b0aac862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088af220-aa8c-4566-89a4-58e1a7a9c67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a5bda5-0f62-4eba-9b7f-1c663ad4a943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fef53ca-aaa7-499f-be38-76d0886fd80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9682db-c00b-44e8-8c5c-88dc6c8dc931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c311616e-ba34-4d2e-9552-cd2a3a221392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04541ba1-6d23-4caa-9338-4ccc89be51e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b8268b-6191-4194-b477-467187134607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b248b124-d623-4a24-87f1-22e514779b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f062666-58f5-43fa-88a8-768617995c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a002f71d-04b6-49b9-b5b2-f3e8ee9cc0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45bf21b-4bbf-45eb-ab7f-8b220544b22f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29328692-6e9b-4480-ac83-3506a0720377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45361fa6-2ee7-4eb0-afa2-43b8cf91cd65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0068c6f-368d-44a4-8c90-b94834b7b63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea0ebcc-35b8-4b5b-b2a0-1466f1cfc002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea5d5fb-cbd6-4872-b938-a603fb78626c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0448a9-2487-44f7-b65f-7c680512562f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aced0c66-44f3-46a6-a747-0a713c733d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f48a41-e3b6-4e1f-ada2-f114152ae61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02540a6d-61f0-410d-a3e9-57ba68fef5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022d6456-35ae-47e5-bd92-ce1fb75f1793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9395230e-6c3b-4d7e-84f8-0af85bb5561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1c67d8-484f-4ad4-9bbb-434b3b74be11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469ee7dc-1186-4ced-ada7-12c0ee51f967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e3f1959-ff9e-40b5-afe2-e30bda2ac77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25c4330-6b58-400d-84a2-0f6fd245c27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac469791-70b1-4aa6-afac-acaaf1ccd1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aae8e07-e4a7-4c5b-b503-f2e08252cce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489f96f1-15d7-41ff-86e8-39b5a3a888d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbc6a72-9a51-4a29-a036-76f7089489af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56913084-977d-403d-9997-74c291da306a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58818271-f91d-45bc-8d83-1b2cc72910dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705097aa-6126-48df-af9b-be08fe39ecb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5695523-aaf6-43e4-a8d9-36dd5effd576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c1180a-9536-4349-85ee-4850ca8a390f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4a2d89-e6b1-4efa-960c-6d5fe7d143f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1f7b57-86c5-4c6b-a009-90b3f0b52cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57cfcbd5-b77b-42a6-b0a2-435cc2f6258c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31cf3b0-b0d0-40e9-9745-4f0b75077c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22d8986-a0c9-4891-93df-5cf9277dcc39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f723d7c-2419-4548-83ac-89279193da51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f62ba95-647a-4604-99e9-34976c5f6bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf1c7349-6dc1-414c-b263-621c18ae334d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b800d1-0698-413c-842d-42060b7e9456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb7877d-a6cc-4d60-84b9-0aa0be0d70ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e436ec68-6062-43db-bd1a-ac9486c2f68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b8ec99-2f58-42de-b905-0d8d099fa27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012ee2e4-55bd-4e3e-ae31-41d3bc2961a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5553c965-f380-4c04-9f93-11b55fb03551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f737d2b-6f6d-483f-a78e-8839b3236b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a633f008-f339-4615-9cee-4ae8289b7cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61694fa7-95e4-416c-8a07-a34c95f9f14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f27f15-0522-4a54-bb56-9466d3f2e3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08ed327-5598-4acb-9c1b-737b93a7ddfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388c572d-aaa4-498e-855c-a01c0edc17d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eed5266-89f0-4c1e-ad93-eead78a8ac60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b0017c2-bdde-42fc-ba65-f8aada6937ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e83d51-399d-49ae-a308-26f8553e55c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba65a33-db55-48fb-980f-c0c61a61b579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6d441d-0e8e-4f19-a298-82c8f43f1538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3251603c-df9b-4f4e-be1e-f4c92df0b52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72218df8-9a45-469b-b1d0-ae07796e83ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc03fdee-26c8-4c40-9489-8b62248f2eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0337cbdd-c820-473f-837a-6045fd05383b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b552d1c-7414-4ef7-a15e-a3750cdedee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81cf6ea-b3fa-4dd6-b759-b07ea76fe896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e47dd10-e376-4bfa-a006-44f1f6d98a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9a8203-effd-4bb3-accc-5ac245eab048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bd2371-288f-4277-9aa7-66a9d29c8fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9150dc4-c700-4993-a71b-0cb0b28ddee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d316aa6-1c3d-478b-84ab-012f41aa39fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0615d3fc-9317-4f34-b124-845a142af23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec590b8-504a-476d-a8ae-ca79f2e38112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba31d8a-e24f-413a-877b-7761a11aefa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e662db9-1a14-4576-bb6d-31f0acf560d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90cb77d-d2f5-4168-b75a-3ff706286086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6127815-60d1-4952-a7ad-71da584d46d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040cd8de-fe9e-495c-9c61-e03f62e8dc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde37aa1-72b8-42da-b356-fd6eac2904d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73dbfb0b-0e8a-4959-94bf-2a4c733fd49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffa4b8b-13e9-4c2f-9f3d-650fe7b5b7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f99a7a7-ba41-4309-a895-75d24680008e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e572708b-da29-4dfa-8d83-453f4dd889d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf89a1b5-94d6-4763-9112-6c102f71afad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362ea5d4-93b3-4463-8be2-75ddebc87052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d228e71-9b1d-4fa4-9759-80c421420950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326abbe9-87a4-47e4-a186-86a93685c829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908864ab-8e3a-4d97-8814-58860eb83a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ba9049-5525-4af2-b9c9-716dea430f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6d2609-6f40-402c-8998-9967b64ed261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6b6cd8-35b1-4dfd-ac17-211e25ee14e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fb93f7-cd8e-4abf-b968-f40813687244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a154f985-71f0-4e0d-914a-9b4c716eecf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fd2082-3943-461c-b0cc-e5e2082184b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c8e83fe-837c-4b70-b77f-9273f26ed724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cf6da95-2c04-44b9-afb4-f0d6deec0a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796a2114-011c-4797-8e15-21e6dfdf2302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fd370a-ebfb-4e9a-a603-48c4f78a56be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a15e6099-8e49-4785-9493-a9e38608ab1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ab7578-7fc7-45dd-ad18-5cc3257b52e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c373185e-24e7-49d5-8bea-dba148f7b083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c7bd2c-7ffd-40b0-8177-5a7cd3e77068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef689ac0-4010-4c0a-91af-a406ac38460d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4b7bb8-7f82-4627-9376-de3ab149fdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50507191-1dd3-4cb1-87a0-0546abf72c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4788abbf-c45f-40d2-b0ba-455022607731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3289b589-0398-46ef-989e-474202f606ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8236e8e9-2070-41f7-9b83-f48cb84da76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a31d689-b5e4-4fa6-bbdd-44493d7ead6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448b68df-070d-46b8-b861-80eb7307ae69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa6fbc9c-d5e1-4884-9f9f-f4efa4429a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbf9dfe-dcfe-4b77-86b4-0adc9ce4f360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2824ad-c86a-4be4-827a-e91f76844e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2a5663-951c-4055-a946-903c736d62d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d2f0026-5558-42f7-bc20-0ed8e1085137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca16a47-30ef-44d7-bc3a-6bd851cb4ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3d393f-6756-4b4f-885c-2bf6d3c1d51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8dcfc84-b110-4d18-8b9f-d92a6cb0fa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9264f4c4-03df-4fb5-b513-cb8d1684695c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8378ecb-82e8-44ab-b79e-294a9d01499d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd8c230-40d9-4f0b-89da-f0eeee6610f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a50ed87-5373-45b4-9791-63936be74d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a273f2d-0772-454b-8094-8a19f982e06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14e25da-5d71-428c-9a14-ca7a239ca454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c72b5d-f615-4782-ba53-e8981e6e8121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a594ca-1d3e-4ca5-9551-b9588cc0dc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1034a38f-9e0f-45ca-b99c-50e70ee27779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8331c1bf-7431-4afb-b4e4-e84f63ef2683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ac3817-dc07-4a74-9a9f-61b16fa3e1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633dace4-7705-4fdc-80cc-856d619e7b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa0c0c2d-acc2-4b6c-a85d-856a13ad64c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a0f132-a5a0-4089-b7f8-83ea92044eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f82064-9eaf-4c3f-894e-855717332e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59dfc90e-ea36-44fa-b4b1-78948e9ee55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61662d16-a254-46c4-a777-145da5d0e924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36c16de-7aa2-438b-8c70-06476c4b271e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9351298e-c43e-4408-9da4-2bab495d1f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bcb811d-d432-4eea-9851-181acce1d6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50880499-ab59-410c-adbc-7c976322f7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a351740-bbdb-4843-9789-35bdb8e804ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2dcb89-ce02-421e-afb0-cdfe83ab67fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67feffd-dfc6-4346-864b-db6533872f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2265f39-d712-4f33-b403-2c67a763bbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267ead90-f943-4697-a6cf-7fa1fea5b860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f016b8dc-a6dd-4bec-94bd-b9e279bcf541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6161a4e8-a877-4f6d-b92f-78a97a1dc385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148caf5c-a387-4368-b22b-9253372f8d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707de53f-a624-4c7e-a023-f5dc06f82547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006cc7cb-cb58-4271-9798-dc3951f02c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83368f7e-728d-474b-94e5-b8714ae3813c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b9a241-ca39-4625-9f1b-4b044a1fd4f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd640231-3ad4-4161-96f8-4f25c90bd422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cebaeef-fb18-49b9-911a-c6a1aeb5ce08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8dc248a-85ea-4611-9620-f45f3e3bb9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85cd161c-40fd-4368-a9a1-75766374cf20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5030de99-1a2c-4034-9e0b-767ddac1aa30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da58e82a-1180-4395-b426-cdd808d75bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3923b7c-cfdd-4ccf-bf65-955dce79afc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45346230-3d97-432c-8fd0-751868756149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff6d8b6-1048-471c-829b-83ea57503750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22b3a301-7f56-4b3f-b6a3-38264b8c356e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37747487-201d-4635-b026-9f5739cd7079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0c0d63-a675-473d-8230-4bda87dd7030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c58baa-ddef-4819-bbea-7af463ec97e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdcff26-f205-4e7e-aa35-2afbbcdc778c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec393c1-1842-409e-aab6-829d5899fb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d17ebb-b82e-42ac-8166-488e0271caee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31987c8-e4be-4c11-9029-8c5e391a5fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4dc308-1f15-422b-b3e7-892e86c67378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81dd22c3-5144-4197-b64c-657d2e1c1725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db27ca32-79ee-4938-908a-e53ccfac6ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d92b63a-f362-4321-98db-cf064c6ce7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c792dac-27b0-4ee7-beda-08a444ee5708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d88f0a3-9836-4949-8f21-ab7cbf4ded4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7721b3e-a47f-4d20-8702-91a67b189030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e004e3ea-6c82-4da5-9822-0342e3ce9463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d504349-cf48-4b9c-9e0e-2bb3060d325d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682ce0fe-c403-4d1d-89b5-4055881b9f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a941092-2d60-46dd-98cd-01d670d9dae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231bc5b6-c75f-4aa4-9707-7f2818136b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bc4d65-d3ce-4900-8b4c-292cd36944fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a5a3b6-c47e-4f27-938b-441aa5648f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c7126a-3273-4683-808e-9f7f131bee86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9545d4-5008-4be6-b86a-7b6b8d24f3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed55f0d-d063-46c6-8ce4-40b8523d1b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac4d592-93c0-4824-9194-7cbfc9e02ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b96e4bb-0116-4873-b43c-ed8648f1e854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923926bf-132b-49c6-9f0b-890f82fdd39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f864376b-5207-4917-b118-35e18e80b051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0704272-717a-4cd2-8521-c10c068a3fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0e0a47-74c8-41e1-a081-2a987a655dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b394a0d5-acf8-4458-9c89-b41ac71abb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599e6274-7f40-418a-a287-a644074f9d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01fed591-ffc1-4d94-922f-1fab2ea0663b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c2ceba-4420-4c67-953a-994c8ebb1dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f0d5da-16e4-4c9e-96e7-96cc83c81339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e228cb0-0ebb-4b83-90e0-dc249827124f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c356c43-51fe-4600-9cc2-f3bc9ce15ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2cba86c-8c8b-45ba-a5ce-753d4ec3c134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47cf22d9-6ae3-4b59-9796-471d3d6c5e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457f3754-c38b-45c5-b02b-9a3ca4cdb9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69fe1fa-9c6d-4d60-9e02-e736ddf6de80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610e9bd3-d644-416f-8a6b-f3a299bdae16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96f4593-24b1-4f0a-aa37-a5eea9d83553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa57cfa2-4238-4594-9f06-cd1267b9b337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfaac7fa-8cca-4506-abb3-eea2bb0df806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd91dec-c663-4333-b3e9-e7c8b4de1177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc781fc-d773-4d32-8b87-6633b60daf15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a0b83b-4056-4ef1-8ce6-b122d209e1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27440e19-a104-4441-97a3-d1aafe43bcba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c0714b-fef8-4a86-b934-9c34ee8808d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90c3ade-6499-496e-a00c-97bc8b9751ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e3b025-e7ed-4b67-90ba-fbb3f02c5a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc0aed8-2832-4856-a14f-06cf4893d331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e68deeb-07b0-4d85-9cc4-7500877cb70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f286e5b-8379-4b95-8ee2-8ac3d65049a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6e6637-3180-4bbe-b149-e1def4e8534c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83aa121d-c87a-4876-9dc4-89f25d8cc5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5629499-ca47-4b3c-9e8b-4d0c5e7d72d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f67159e-cda3-4e3c-aa19-7d0042a3b42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1d1b2f-4cb6-4924-9673-b2bb6001b76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7aa38c6-9df7-43a4-8910-5610b7434366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07c9471-a06d-4cc8-9540-8946a08eb4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee01fcd0-8407-4617-a80d-a7a4b3b091e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63eb66a4-d5ac-47fd-bcbe-dc3f54d30805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b548ed-2f60-4c1b-b8d9-c9f7983d576c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5643ea-f663-4a8f-a7da-e44a27323dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a723df9e-f08f-4d5f-80f1-2843524492ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24338b06-96af-44f5-8315-118b75a16df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2274a9-01ef-442d-a6f9-5f6e4fe0676d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a69749a8-c992-442e-8776-9b140f91b2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cec440f-aca6-4b7c-b223-4036aff7aaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ad07e0-9b8e-449d-8ff7-d6a6523d80ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5914ea4-4e75-4e57-9cc4-f2fbf86e4ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a31014-c43d-4af9-afb3-ad0c56a14c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05b0fb3-1198-42e2-8b09-cf46887a3f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d6f0bd-3208-42d2-a88a-bbcce795eab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d551635-0afa-41b8-9e12-e484a2de8e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e2334f-39fc-479d-9e4f-a8c45ca2cd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd518df6-9b88-4b58-836b-2315693b41f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f391205e-d42e-4149-ab25-f1056c455fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95202b19-fbd3-4e6a-b226-2f3c3298ff6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677dfefe-34fa-43e7-8ae4-5f0736020d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ac15ea-d8e6-49a4-855c-e954ca2cdc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4aad99-e2d1-4ab5-b7a5-72e46632d990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7969f1-44ce-4dfd-acbf-cffede3106fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0bfb6a-e0c2-4379-967b-6911283e30b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b2ed80-0a81-45f8-be29-9b0d4120b644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e183de0e-8d0d-45ea-a9b9-c1309cc3e4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12947279-6052-4c93-8455-47fe99654556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebbb13c-9aab-46d7-b388-4d15f950555e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5caabc4-59d6-433c-a9b8-d04816c2d541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6ce249-b757-4987-8606-9ace3a85a40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741b70ec-e134-4a28-a183-754aa5a15fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9754cd31-36fc-47e1-9e61-4a6df0eeca45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4871404b-47ce-406f-934d-d51da235c543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b5962f-c8eb-4ea7-a6ec-4e7ba0689ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12bbbbf-6595-4861-a070-a6ff4fbe2e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c689932-d458-44a0-93fe-530e14937741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b397a7-fe36-47d5-8501-5bd9dd50b6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7930ba-53b8-46e4-b8af-0766c779167b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39af7a3-583b-401a-ae69-024cbefb77a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1425d5dd-d63a-4137-a213-aacb7fdb6016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59d4671-7b5d-425d-a893-0584dda2722a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6869a023-e98b-4ee0-8b2b-831ff1a6cd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1aba70-c954-4020-9084-7f25ad1ece34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bee325-4bb8-4371-a0cc-006891639487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bae4749-b775-44f6-ab46-e7c9b09ccfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b9a2ee-ef8b-4118-875c-4c263681e9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3e2c8c-d5c3-448e-aff8-c102e30be7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9e7a57-bb59-4814-ae24-16b6db2c88d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1a9e56-3db3-4cca-9f3f-da24bcb9d48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4449fb-5929-4da0-8f95-d6fbb33c4991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1c9c25-d614-4243-83fe-bcb0ca909f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25f2dd6-35f2-454e-b029-187a4eafc96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c85445c-b182-4cd2-be91-7914eb048e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989c854b-f5f5-490e-bb5d-0a50cd716121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2e2c1e-2d7d-4a13-828d-33605d954153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5792f2eb-f6a6-41f4-81f9-06b116f81ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df429b4-e74a-414a-91aa-e714bccfa55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8dc68c-82b7-4f38-b257-bca28d701ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94085e81-4ac5-44f3-9ac7-7d4083300389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a87617-5e32-42fc-ad4d-cc8bda8fa299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcd8f597-13b5-47dd-9bb0-0caabfb6af7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546b981d-53c4-4943-8c2f-0f8b58981426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b8f2b5-04b6-4a4e-a359-9a2a753880ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f99f53-f651-456c-bb0e-b9b2373cd4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aae9a34-e724-49aa-8739-a58841b0ba5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef67bd42-2f7e-4c0d-87c6-09808b31bd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c1977f-bb8c-437a-8aad-ae6ea6f497dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a7889a-8307-4756-a6b1-8d0e71509af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc0b0a6-2dd4-41b3-a9f6-3e3ffb54cb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a84f812c-69c7-481c-90d4-ff97e4b8da71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28612bea-fcab-446d-a3fe-832fca91c91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b2bf58-c6df-4bc6-b33b-3b104422928f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6cfcf14-1c8a-4b2a-ba86-06b8322914ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58c8c1b-b322-469e-829f-cafeefe8cdee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039d4e8e-8d78-4ad3-af27-187cbfed0f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd07515f-2b13-4619-bfe6-66fff6eb8720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7f055e-7a89-4524-b85c-0841871b999b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716644c8-8c72-4e49-9914-1bd40e7ac8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d49131-9cf3-415a-8493-06fe9ea390c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0274842d-b233-4177-b94c-4ae17adcdde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01d3fce-214c-42a5-ad0a-09c8efc72208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359b5f6e-6209-4c6d-90bc-660efe625a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7df148a-ad5f-4ffd-8949-b69fe75470ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e661d0-5d3f-46be-a241-e299912674f6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(5467, 24), y=(5467,)
   Test:  X=(1367, 24), y=(1367,)

⚠️  Limiting training data: 5467 → 800 samples
⚠️  Limiting test data: 1367 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1775, val=0.0740 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0901, val=0.0724 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0902, val=0.0711 (↓), lr=0.001000
   • Epoch   4/100: train=0.0895, val=0.0708, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0880, val=0.0707, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0871, val=0.0717, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 1 Summary - Client client_4
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0161
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0031
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2534, R²: -0.0022

============================================================
🔄 Round 3 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0866, val=0.0786 (↓), lr=0.000250
   • Epoch   2/100: train=0.0861, val=0.0782, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0860, val=0.0783, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0860, val=0.0782, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0859, val=0.0781, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0857, val=0.0779, patience=5/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0855, val=0.0779, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 3 Summary - Client client_4
   Epochs: 21/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0049
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0094
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: -0.0003

📊 Round 3 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2520, R²: 0.0054

📊 Round 3 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2520, R²: 0.0054

============================================================
🔄 Round 13 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0875 (↓), lr=0.000063
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0835, val=0.0883, patience=2/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   • Epoch   4/100: train=0.0835, val=0.0883, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0834, val=0.0883, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0833, val=0.0883, patience=10/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 13 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0024
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0093
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0056

============================================================
🔄 Round 14 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0871 (↓), lr=0.000016
   • Epoch   2/100: train=0.0840, val=0.0871, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0839, val=0.0871, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0839, val=0.0871, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0839, val=0.0871, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0838, val=0.0872, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 14 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0045
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0151
============================================================


============================================================
🔄 Round 15 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0827 (↓), lr=0.000004
   • Epoch   2/100: train=0.0850, val=0.0827, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0850, val=0.0827, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0849, val=0.0827, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0849, val=0.0827, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 15 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0020
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0047
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 17 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 17 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0002
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0093
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 18 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 18 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0018
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0022
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 21 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 21 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0004
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0051
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

📊 Round 21 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 23 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 23 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0010
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0074
============================================================


============================================================
🔄 Round 24 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 24 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0001
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0027
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 26 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 26 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0000
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0194
============================================================


============================================================
🔄 Round 27 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 27 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0020
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0111
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 29 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 29 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0101
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0057

============================================================
🔄 Round 31 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 31 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0008
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0215
============================================================


============================================================
🔄 Round 33 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 33 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0022
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0039
============================================================


============================================================
🔄 Round 35 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 35 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0001
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0077
============================================================


============================================================
🔄 Round 37 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 37 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0020
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0050
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

============================================================
🔄 Round 38 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 38 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0004
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0258
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

============================================================
🔄 Round 42 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 42 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0010
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0065
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2518, R²: 0.0058

============================================================
🔄 Round 53 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 53 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0044
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0010
============================================================


============================================================
🔄 Round 56 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 56 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0017
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0135
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 59 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 59 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0175
============================================================


============================================================
🔄 Round 61 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 61 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0006
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0068
============================================================


============================================================
🔄 Round 62 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 62 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0010
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0113
============================================================


============================================================
🔄 Round 64 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 64 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0012
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0237
============================================================


============================================================
🔄 Round 65 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 65 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0024
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0128
============================================================


============================================================
🔄 Round 68 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 68 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0116
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 72 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 72 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0016
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0144
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 73 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 73 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0004
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0129
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 74 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 74 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0009
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0220
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 74 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 80 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 80 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0069
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 81 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 81 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0001
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0039
============================================================


============================================================
🔄 Round 82 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 82 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0005
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0060
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 83 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 83 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0047
============================================================


============================================================
🔄 Round 84 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 84 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0016
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0007
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 86 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 86 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0032
   Val:   Loss=0.1006, RMSE=0.3171, R²=-0.0069
============================================================


============================================================
🔄 Round 89 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 89 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0007
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0082
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 93 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 93 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0022
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0052
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0083
============================================================


============================================================
🔄 Round 96 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 96 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0016
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0241
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 96 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 96 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 106 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 106 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0022
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0046
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 108 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 108 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0006
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0017
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 108 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 111 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 111 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0007
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0036
============================================================


============================================================
🔄 Round 112 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 112 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0043
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 114 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 114 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0005
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0127
============================================================


============================================================
🔄 Round 116 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 116 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0012
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0012
============================================================


============================================================
🔄 Round 117 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 117 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0008
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 119 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 119 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0065
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0076
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 122 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 122 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0025
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0060
============================================================


============================================================
🔄 Round 123 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 123 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0006
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0073
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0010
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0019
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 127 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 127 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0011
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0140
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 131 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 131 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0039
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0008
============================================================


============================================================
🔄 Round 132 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 132 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0092
============================================================


============================================================
🔄 Round 133 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 133 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0041
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0012
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 133 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0005
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0141
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 137 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 137 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 137 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 142 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 142 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0032
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 143 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 143 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0015
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0009
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 143 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 152 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 152 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0035
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0034
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 153 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 153 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0025
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0000
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 153 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 157 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 157 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0203
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 157 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 160 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 160 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0020
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0139
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 161 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 161 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0013
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0095
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 164 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 164 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0014
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0022
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 166 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 166 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0025
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0081
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 166 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 168 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 168 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0013
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0011
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 169 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 169 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0043
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0015
============================================================


============================================================
🔄 Round 170 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 170 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0024
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0064
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 172 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 172 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0037
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0105
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 172 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 177 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 177 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0027
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0063
============================================================


============================================================
🔄 Round 178 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 178 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0099
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 182 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 182 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0024
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0147
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 182 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 188 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 188 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0038
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0126
============================================================


============================================================
🔄 Round 193 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 193 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0011
============================================================


============================================================
🔄 Round 194 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 194 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0025
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0058
============================================================


============================================================
🔄 Round 196 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 196 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0019
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 199 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 199 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0002
============================================================


============================================================
🔄 Round 200 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 200 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0045
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 200 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 209 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 209 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0029
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0131
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 215 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 215 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0017
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0305
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 215 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 222 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 222 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0023
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 223 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 223 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0037
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0050
============================================================


============================================================
🔄 Round 225 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 225 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0005
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0066
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 228 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 228 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0011
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0159
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 231 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 231 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0004
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0054
============================================================


============================================================
🔄 Round 233 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 233 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0022
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0048
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 237 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 237 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0057
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0015
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 237 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 240 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 240 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0233
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

📊 Round 240 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0058

============================================================
🔄 Round 242 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 242 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0001
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0033
============================================================


============================================================
🔄 Round 243 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 243 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0023
============================================================


============================================================
🔄 Round 244 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 244 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0119
============================================================


============================================================
🔄 Round 245 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 245 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0025
============================================================


============================================================
🔄 Round 248 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 248 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0140
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 248 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 251 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 251 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0101
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 252 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 252 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0006
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0074
============================================================


============================================================
🔄 Round 253 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 253 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0073
============================================================


============================================================
🔄 Round 254 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 254 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0035
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0050
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 254 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 254 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 258 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 258 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0025
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0068
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 259 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 259 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0008
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0004
============================================================


============================================================
🔄 Round 260 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 260 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0025
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0026
============================================================


============================================================
🔄 Round 261 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 261 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0054
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 263 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 263 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0002
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0045
============================================================


============================================================
🔄 Round 266 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 266 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0034
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0162
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 267 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 267 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0069
============================================================


============================================================
🔄 Round 269 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 269 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0018
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0042
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 274 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 274 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0006
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0045
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 276 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 276 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0004
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0016
============================================================


============================================================
🔄 Round 277 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 277 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0018
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0042
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 281 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 281 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0029
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0089
============================================================


============================================================
🔄 Round 282 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 282 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0051
============================================================


============================================================
🔄 Round 284 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 284 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0023
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0165
============================================================


============================================================
🔄 Round 285 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 285 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0026
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0139
============================================================


============================================================
🔄 Round 286 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 286 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0003
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0054
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 287 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 287 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0020
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0050
============================================================


============================================================
🔄 Round 288 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 288 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0004
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0084
============================================================


============================================================
🔄 Round 291 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 291 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0013
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0026
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 291 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 295 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 295 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0016
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0101
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 299 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 299 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0013
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0110
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 299 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 299 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 305 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 305 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0018
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0007
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 305 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 313 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 313 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0020
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0004
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 314 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 314 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0010
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0005
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 314 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 317 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 317 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0025
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0060
============================================================


============================================================
🔄 Round 318 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 318 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0025
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0319
============================================================


============================================================
🔄 Round 320 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 320 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0011
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.0037
============================================================


============================================================
🔄 Round 322 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 322 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0026
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0069
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 326 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 326 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0006
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0063
============================================================


============================================================
🔄 Round 327 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 327 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0008
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0092
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 327 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 330 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 330 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0003
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0053
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 332 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 332 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0003
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0045
============================================================


============================================================
🔄 Round 335 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 335 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0254
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 336 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 336 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0009
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0066
============================================================


============================================================
🔄 Round 338 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 338 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0013
   Val:   Loss=0.0982, RMSE=0.3133, R²=-0.0068
============================================================


============================================================
🔄 Round 340 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.1006, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 340 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0001
   Val:   Loss=0.1005, RMSE=0.3171, R²=-0.0076
============================================================


============================================================
🔄 Round 343 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 343 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0006
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0050
============================================================


============================================================
🔄 Round 345 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 345 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0014
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 346 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 346 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0002
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0042
============================================================


============================================================
🔄 Round 348 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 348 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0005
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0085
============================================================


============================================================
🔄 Round 350 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 350 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0031
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0375
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 351 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 351 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0010
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0256
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 352 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 352 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0006
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0105
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 354 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 354 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0008
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0115
============================================================


============================================================
🔄 Round 356 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 356 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0034
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0264
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 356 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 358 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 358 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0041
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0048
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 360 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 360 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0004
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0142
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 361 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 361 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0026
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0053
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 363 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 363 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0053
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0484
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 366 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 366 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0001
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0034
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 366 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 369 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 369 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0121
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

============================================================
🔄 Round 370 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 370 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0131
============================================================


============================================================
🔄 Round 371 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 371 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0002
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0054
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 371 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 374 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 374 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0023
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0043
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 374 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0059

📊 Round 374 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 380 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 380 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0027
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0031
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 382 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 382 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0009
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0001
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 385 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 385 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0004
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0043
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 385 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 390 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 390 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0041
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0071
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 396 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 396 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0008
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0041
============================================================


============================================================
🔄 Round 398 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 398 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0087
============================================================


============================================================
🔄 Round 400 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 400 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0020
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0023
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 402 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 402 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0012
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0023
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 402 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 408 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 408 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0086
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 409 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 409 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0309
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 413 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 413 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0013
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0129
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 415 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 415 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0018
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0248
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 416 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 416 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0051
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 418 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 418 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0207
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 418 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 421 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 421 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0006
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0008
============================================================


============================================================
🔄 Round 422 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 422 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0013
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0034
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 422 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 426 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 426 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0031
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0112
============================================================


============================================================
🔄 Round 427 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 427 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0030
   Val:   Loss=0.0937, RMSE=0.3062, R²=0.0024
============================================================


============================================================
🔄 Round 429 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 429 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0023
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0013
============================================================


============================================================
🔄 Round 432 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 432 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0012
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0095
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 432 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 437 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 437 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0008
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0039
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 438 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 438 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0159
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 440 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 440 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0017
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0055
============================================================


============================================================
🔄 Round 441 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 441 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0022
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0067
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 441 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 443 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 443 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0029
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0130
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 444 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 444 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0007
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0484
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 445 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 445 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0001
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0027
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 447 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 447 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0009
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0002
============================================================


============================================================
🔄 Round 449 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 449 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0010
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0091
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 451 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 451 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0062
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0320
============================================================


============================================================
🔄 Round 452 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 452 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0017
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0008
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 452 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 455 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 455 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0020
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0050
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 455 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 460 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 460 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0048
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0052
============================================================


============================================================
🔄 Round 461 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 461 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0006
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0008
============================================================


============================================================
🔄 Round 464 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 464 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0000
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0095
============================================================


============================================================
🔄 Round 466 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 466 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0029
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0079
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 468 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 468 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0016
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0025
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 469 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 469 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0026
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0151
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 469 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 469 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 475 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 475 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0027
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 482 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 482 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0015
============================================================


============================================================
🔄 Round 483 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 483 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0033
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0071
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 483 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 483 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 483 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 492 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 492 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0015
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0018
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

📊 Round 492 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 495 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 495 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0001
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0028
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 497 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 497 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0058
============================================================


============================================================
🔄 Round 499 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 499 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0024
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0008
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 505 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 505 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0003
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0034
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 510 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 510 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0066
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0060

============================================================
🔄 Round 511 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 511 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0017
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0035
============================================================


============================================================
🔄 Round 512 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 512 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0010
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0011
============================================================


============================================================
🔄 Round 514 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 514 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0006
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0125
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 515 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 515 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0041
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 515 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 517 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 517 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0074
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 519 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 519 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0015
   Val:   Loss=0.0963, RMSE=0.3103, R²=0.0039
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 521 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 521 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0001
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0014
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 524 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 524 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0019
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0053
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 525 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 525 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0002
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0025
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 528 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 528 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0020
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0077
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 531 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 531 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0036
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 533 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 533 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0036
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0004
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 533 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 535 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 535 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0012
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0064
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 540 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 540 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0012
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0239
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 541 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 541 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0006
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0037
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 542 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 542 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0027
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0101
============================================================


============================================================
🔄 Round 543 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 543 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0026
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0028
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 545 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 545 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0009
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0080
============================================================


============================================================
🔄 Round 549 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 549 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0008
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0005
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 549 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 551 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 551 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0009
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0101
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 553 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 553 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0001
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0023
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 553 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 553 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 560 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 560 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0000
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0018
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 565 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 565 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0034
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0116
============================================================


============================================================
🔄 Round 566 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 566 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0010
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0053
============================================================


============================================================
🔄 Round 568 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 568 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0020
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0058
============================================================


============================================================
🔄 Round 569 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 569 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0007
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0011
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 575 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 575 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0113
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 579 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 579 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0021
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0011
============================================================


============================================================
🔄 Round 580 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 580 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0091
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 580 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 580 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 584 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 584 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0006
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0019
============================================================


============================================================
🔄 Round 586 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 586 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0013
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0034
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 592 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 592 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0013
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0039
============================================================


============================================================
🔄 Round 595 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 595 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0007
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0027
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 596 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 596 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0009
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 598 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 598 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0006
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0045
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 600 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 600 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0021
============================================================


============================================================
🔄 Round 601 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 601 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0018
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0116
============================================================


============================================================
🔄 Round 604 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 604 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0010
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0098
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 606 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 606 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0197
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 606 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 609 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 609 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0060
============================================================


============================================================
🔄 Round 610 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 610 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0003
   Val:   Loss=0.0969, RMSE=0.3112, R²=-0.0003
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 611 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 611 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0018
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0188
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 613 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 613 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0006
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0035
============================================================


============================================================
🔄 Round 615 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 615 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0029
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0248
============================================================


============================================================
🔄 Round 616 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 616 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0009
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0020
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 619 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 619 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0048
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0071
============================================================


============================================================
🔄 Round 620 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 620 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0008
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0045
============================================================


============================================================
🔄 Round 622 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 622 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0023
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0002
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 623 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 623 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0008
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0214
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 624 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 624 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0121
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 626 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 626 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0031
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0116
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 627 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 627 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0279
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 628 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 628 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0026
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0118
============================================================


============================================================
🔄 Round 629 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 629 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0006
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0281
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 630 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 630 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0003
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0144
============================================================


============================================================
🔄 Round 632 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 632 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0023
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0082
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 632 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 632 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 638 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 638 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0020
============================================================


============================================================
🔄 Round 639 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 639 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0045
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 642 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 642 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0044
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0218
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 643 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 643 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0002
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0030
============================================================


============================================================
🔄 Round 645 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 645 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0013
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0030
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 647 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 647 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0012
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0103
============================================================


============================================================
🔄 Round 648 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 648 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0028
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0090
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 649 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 649 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0000
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0021
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 652 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 652 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0020
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0060
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 653 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 653 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0021
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0114
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

📊 Round 653 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 658 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 658 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0030
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0027
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 661 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 661 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0012
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0030
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 669 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 669 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0053
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0089
============================================================


============================================================
🔄 Round 670 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 670 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0006
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0182
============================================================


============================================================
🔄 Round 671 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 671 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0009
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0051
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 673 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 673 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0017
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0056
============================================================


============================================================
🔄 Round 674 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 674 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0059
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0061

============================================================
🔄 Round 677 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 677 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0002
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0084
============================================================


============================================================
🔄 Round 680 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 680 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0018
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0205
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 681 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 681 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0037
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0137
============================================================


============================================================
🔄 Round 684 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 684 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=0.0017
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0105
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 685 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 685 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0010
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0030
============================================================


============================================================
🔄 Round 686 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 686 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0001
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0087
============================================================


============================================================
🔄 Round 688 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 688 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0010
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0020
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 690 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 690 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0028
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0120
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 690 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 693 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 693 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0023
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0072
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 698 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 698 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0003
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0025
============================================================


============================================================
🔄 Round 699 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 699 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0025
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0062
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 699 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 705 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 705 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0011
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0008
============================================================


============================================================
🔄 Round 706 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 706 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0000
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0013
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 712 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 712 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0019
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0212
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 712 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 714 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 714 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0002
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0106
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 718 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 718 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0017
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 720 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 720 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0007
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0042
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 721 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 721 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0023
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 721 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 726 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 726 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0010
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0135
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 726 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 730 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 730 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0015
============================================================


============================================================
🔄 Round 733 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 733 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0015
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0043
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 734 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 734 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0023
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0131
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 734 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 736 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 736 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0009
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0376
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 736 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

📊 Round 736 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 740 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 740 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0006
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0322
============================================================


============================================================
🔄 Round 741 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 741 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0030
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0146
============================================================


============================================================
🔄 Round 743 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 743 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0015
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0051
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 744 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 744 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0027
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0088
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 744 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 746 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 746 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0001
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0035
============================================================


============================================================
🔄 Round 748 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 748 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0014
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0046
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 749 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 749 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0003
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0004
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 753 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 753 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0038
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0017
============================================================


============================================================
🔄 Round 756 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 756 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0031
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 759 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 759 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0037
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0087
============================================================


============================================================
🔄 Round 760 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 760 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0019
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0029
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 761 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 761 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0029
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0091
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 761 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 764 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 764 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0022
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0027
============================================================


============================================================
🔄 Round 766 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 766 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0024
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0188
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 769 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 769 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0013
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0060
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 770 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 770 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0266
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 770 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 770 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 770 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 774 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 774 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0009
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0175
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 775 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 775 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0042
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0323
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 775 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 775 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 780 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 780 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0048
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 780 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 782 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 782 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0006
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0086
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 784 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 784 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0011
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0025
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 784 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 787 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 787 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0003
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0228
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 789 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 789 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0001
============================================================


============================================================
🔄 Round 790 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 790 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0017
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0062
============================================================


============================================================
🔄 Round 791 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 791 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0008
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0064
============================================================


============================================================
🔄 Round 792 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 792 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0004
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0003
============================================================


============================================================
🔄 Round 793 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 793 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0064
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 795 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 795 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0032
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0166
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 795 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 795 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 795 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 802 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 802 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0009
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0035
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 806 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 806 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0021
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0032
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 806 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 809 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 809 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0009
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0030
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 809 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 812 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 812 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0026
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0027
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 812 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 814 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 814 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0087
============================================================


============================================================
🔄 Round 815 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 815 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0016
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0042
============================================================


📊 Round 815 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 815 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 817 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 817 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0005
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0302
============================================================


============================================================
🔄 Round 818 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 818 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0010
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0146
============================================================


============================================================
🔄 Round 820 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 820 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0081
============================================================


============================================================
🔄 Round 821 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 821 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0008
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0099
============================================================


📊 Round 821 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 822 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 822 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0037
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0079
============================================================


============================================================
🔄 Round 825 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 825 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0020
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0077
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 826 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 826 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0007
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0018
============================================================


============================================================
🔄 Round 830 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 830 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0016
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0067
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 830 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 833 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 833 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0034
============================================================


============================================================
🔄 Round 836 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 836 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0004
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0009
============================================================


============================================================
🔄 Round 838 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 838 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0021
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0094
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0062

============================================================
🔄 Round 840 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 840 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0000
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0068
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 840 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 851 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 851 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0004
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0195
============================================================


📊 Round 851 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 852 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 852 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0030
============================================================


📊 Round 852 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 852 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 852 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 857 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 857 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0063
============================================================


============================================================
🔄 Round 858 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 858 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0002
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0075
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 858 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 864 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 864 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0157
============================================================


📊 Round 864 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 868 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 868 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0008
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0027
============================================================


📊 Round 868 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 870 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 870 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0032
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0006
============================================================


============================================================
🔄 Round 873 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 873 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0058
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0062

============================================================
🔄 Round 875 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 875 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0020
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0088
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 876 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 876 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0011
   Val:   Loss=0.0697, RMSE=0.2641, R²=-0.0198
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 877 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 877 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0002
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0014
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 880 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 880 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0023
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0185
============================================================


📊 Round 880 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 880 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 884 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 884 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0001
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0024
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 884 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 884 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 884 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 891 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 891 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0021
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0121
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 891 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 895 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 895 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0025
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0110
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 896 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 896 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0058
============================================================


📊 Round 896 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 896 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 896 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

📊 Round 896 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0063

============================================================
🔄 Round 905 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 905 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0002
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0001
============================================================


============================================================
🔄 Round 909 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 909 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0000
============================================================


============================================================
🔄 Round 912 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 912 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0011
   Val:   Loss=0.0776, RMSE=0.2787, R²=-0.0161
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 914 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 914 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0024
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0102
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 919 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 919 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0017
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0087
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 920 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 920 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0016
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0006
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 921 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 921 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0052
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0020
============================================================


============================================================
🔄 Round 922 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 922 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0010
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0049
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 923 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 923 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0023
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0272
============================================================


============================================================
🔄 Round 924 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 924 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0032
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0181
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 924 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 924 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 924 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 924 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 935 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 935 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0045
============================================================


📊 Round 935 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 937 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 937 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0060
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 937 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 941 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 941 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0012
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0005
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 944 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 944 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0022
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0361
============================================================


============================================================
🔄 Round 945 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 945 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0018
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0099
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

============================================================
🔄 Round 946 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 946 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0008
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0107
============================================================


📊 Round 946 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

📊 Round 946 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2518, R²: 0.0063

❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
