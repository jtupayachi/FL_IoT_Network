[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f938e604-0f18-44c2-a5b2-3bba0767b5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80518ad7-c22a-432d-b644-302862a19e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ecdfd40-13f4-4236-b98a-ed7d020497f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190981ca-c43e-438d-931f-bd0f1b99f148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02593637-d0d8-40c7-b67a-24b9edfe1745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5eea05-a0df-4b34-8e0f-11d20c72166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43115db-70e7-4a19-bb81-9905ab2b7d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1f9d08-ef91-474c-86d1-60d0a89193e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d50301-2fd0-463f-ba89-0b4bc72fa262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ab5f5b-91d3-482c-aade-e64e524ea53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5de64e-a10d-4f4e-9b27-fa2ebc233fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f5cfee5-3598-4763-a63e-6385e65488b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca38f1b0-8ad2-4f6a-b6a1-b36d027e6f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837e4389-a53d-435f-acec-8f0a42a93537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921186ee-7c3f-4675-bae9-7df06dfd9bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e3844c-f4ae-42ec-afe7-7e80f925ee8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a261dd-e588-4d9f-af0a-d1b73aba9c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d71d12-fac9-4a98-b7cc-246c0da6f8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d045316a-ee9d-4b7c-a4ff-f5c28be43fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 563fd0d9-5ca0-4c02-bcc2-ec4cca940a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f128fb1d-dafe-4d35-a96f-d8ee5d755d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b986f96-232f-485f-8687-aa02be08ae7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22ed0f0-8d22-4846-b99b-51bf66d2d34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19624d7-07ca-490b-82da-dffd94d694e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b120d4e8-6d5c-4d22-af73-5f11c608c59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d8f2531-5952-4a08-86f3-45da2b2cb808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822809b6-05f2-457f-840b-9df07949b765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6cdbd1d-6a58-4b5c-87e3-28f632570edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9bbc0a8-c7cd-47a9-95f7-57ff4606f402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8e302b-a123-443e-a37c-1f5f1a244d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed554381-77f5-473f-bd09-a4f880aedd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3c78be-5ad6-4904-b94e-1705f1d54be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d205377-722c-4c2a-bb65-70bd57802e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a351df05-39ce-45a5-905a-baced83f5455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d29da7-c367-428d-9447-9c19e76c09d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c4a3be-e4ca-41de-b7bd-9e3320e6b019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330df2f2-617e-4f10-8f54-84dc453fe39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd9db27-2703-4403-9a46-feae55c2d71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fe5f1a-833c-4dbf-bcc4-7c29b962b4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4910c351-e644-4b37-84e6-a44878c899ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6b1013-a15e-4303-8484-8d1772d67359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0f8a72-ae60-458a-b5f0-8691663e565a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426e1313-0b53-46fd-9985-395e9c750751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dedfd3b-d13a-4820-80b1-360749c501eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79a48b5-d144-4901-87dd-905b67d6b39a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413bb94d-805f-4efc-b3a6-1b74124c6082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17cdab8-9fbd-4402-9064-6f1e86e52f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cfe328-f24b-4146-bf62-296bbeb963c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62e1f40-46c4-422f-962c-635250ccccb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95bf9e1e-caef-4a14-bc29-0a08aefa7af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75de0a09-274c-4276-8622-1934ca56d413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67fb20e-95f3-468b-b5fd-96b727852323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7727e7e-6936-4ba2-ba70-a8e9d39b5aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dbcbaa-62fc-4aac-8953-980c4afad23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9533c6-4bab-4a12-b157-cb92296d28d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6358398a-4b21-4e06-bad4-e9fea4fba3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc6226c9-7d89-40a0-8b4c-cc19308f2f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd04ea2-7350-425b-943e-431dc0974725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715a78d2-54d3-4032-985b-dfdd95b2a7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c9e304-27d9-4a94-bf0c-f320ad65e143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89f1428-9e53-4ccc-8507-db9eee894978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88565e36-1333-4e6f-a412-cf49ac5e6809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbc838e-572a-44d6-86f8-59b7050fa973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d31d0db-49fd-4eca-977a-459c8e710b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050f8104-019b-44bb-b7cd-40654062963c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 031c3ba2-8b0e-4e4b-8450-f0cf0936acfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62289377-0e0e-484e-82e7-4e7d43c61b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c15ed1fe-9120-4ab0-a8ec-6e6f7211bcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a8f4a7-4254-4343-b821-057df7b58fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4333b0f-902d-46cb-b289-bd74d496220d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a4aee2e-ab6e-4998-84f0-90f03f7063bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d517ca-b06e-4948-bb74-8ef3a5ffbf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57487e89-0705-41d5-ac1a-d817182e47d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ceb6dc1-941c-4b40-83d7-5291a3e248b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3c31fd-ac90-4cbc-a0e0-5aa5903fc5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a6ad14-b850-4ede-aedf-e79d14598c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953678c4-5be5-49e3-aa87-23e213c3f595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1c8696-0a46-4e9f-8bd7-d3c3c8eae139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd3e1d23-3267-4d8f-9bb1-d92a8e0edd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67c4775-eed3-44c5-8461-e835777cfae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064a5332-938b-4f0e-9de6-89b5cf989d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b28c0d-3551-42e6-adef-13e96c012674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9164cfa-e12e-40eb-9848-8192025d8385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6b9723a-e31f-4004-9c66-f86aab6a0f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f87311-4a4b-41c4-b040-d27174e34847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0526717-2598-4594-8f7e-cf7f6f21d0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa1e0ab-eda2-4cd7-ab9c-84a2c5bf8278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7756a551-ebc8-4a59-8478-b5b04871a79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1630bf6-9181-4595-9d43-46c3dafca9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a8494d6-4966-4e2e-8dfc-7cd6ecdb4164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b41d168-4b73-41e4-bc51-ca096ce24173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae8566b-ecae-45cc-9d08-46973c3b36b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825ba5ff-5856-4ea6-a6a2-408b1f0f1080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36868cb9-2955-44f0-8ddf-d6c7f702f183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94315d70-820f-496a-8aaa-cb1b69af29fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4b4dfc-6d85-4567-a7a4-fcc84b01a1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b5560d-d9ca-4a1d-ab56-dc2ab069b7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201170bd-d193-4b3a-859b-6a6f923c6f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbeb758-63d3-401e-9721-ab5b4fd48d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186a1c3e-890a-4f9a-bcf2-6a8e20eb7f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d32c44-020a-46e8-9296-f0aca8ec0fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6995b088-add2-4925-bcf3-13aa8a17e05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99060ad0-eb32-49af-ac2a-ed76d54ae5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54be5ea8-4415-4096-97e1-5f2cf462f8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f087d1e9-e343-4290-a037-2254fad8f707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e3070f-93a4-438d-ad13-dcf18df1cf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f210593-d7bd-4c60-a4a3-7de3d215e070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75f62b9-9a9e-4f8c-bb0d-cf04d43d73e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27af76be-95e7-4365-9375-d6e1226978d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9326b3b2-a1ef-4827-a615-fdbe7fc18c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d1626c-3b15-4828-b17d-7d4bdfe20f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d808cf-1bd7-4c83-a030-e74682d4459b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64930a1d-2730-480e-9482-fa60095f73fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8dd666c-a8ee-42e8-ad78-ef109b0d49ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef1fcd70-1154-4ed0-b196-384ff26956cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7aba960-3a94-4a1f-a039-0cf85a27b856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8e35ff-192c-4e21-96fa-b1b070a3c099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17ffd07-d11f-437d-993a-f9822d6fc5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132d24db-15dd-4eb2-ace2-6982c7fb469d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25326013-e119-499b-a4bf-17fac9d2d67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4ae811-c514-47ed-99a6-3f5e4073a048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176bf339-fb9c-42c4-a4f9-108846b2d292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8326bbb-da02-4c5a-aea2-76446e51497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ed7e31-68a9-496f-9d78-e77d7a229867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f4c5250-7e76-4e2e-9f5a-43fa5f9f505d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1e88c9-2936-4930-8310-49f6d581cb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38993277-290c-4d92-9f86-9fbea6aa5642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8116b1a3-fcb1-450e-b9d3-f63597923fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43c873c-f929-4b31-bec1-439f84b8fbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4496579-b9cc-4860-ad7e-7a2a229549ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d71341-a9d7-4266-aca0-4f34aa4fea0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0c11ec-3ccb-4c35-872f-48a5d0694fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371547fa-6334-49c5-8bc7-3b9fa88936ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9518d29c-2abd-4d5b-b136-b3379207677a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c12bef-c452-4ecd-a9a7-23d5bd84cfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41501079-0b6c-475e-90aa-62bb1113c20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4aa228-0696-44b4-ba31-3d8d74104801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f0eb36-396b-44a8-8a48-0bc9a2aa1725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c787f758-4cde-4e46-8652-a8a6a0648ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06747edd-bac0-4ed4-bd30-22a9d1a522ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55d400f4-b240-4e6a-805d-37f602a3bd1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3833335a-370a-4b5e-b08a-ccfa6ae8327d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921e5c02-d460-40dc-94ee-35f8671725e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba80eeb6-6b14-4704-b16b-31d300e9d2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d1be136-57b8-4bd6-a7c8-9e1fec30447f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ea518a-4fe4-4032-98fb-b337582c3460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca799ca-f769-4a45-a46a-e239af7f19f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03ef910-12ad-4e79-baf2-361225d626b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a025819-986f-49bf-8c56-344aac7985d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7d2c97-04ca-4613-9dfa-4f11ee7a64df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d1eaff-fbd0-40e3-8acb-d9e7b2820e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edfd436f-2bcc-4c05-8bb9-5d68c8aa96bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310436c4-93c3-4db1-ac1c-396db4b2f827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56e7ff0-94f9-421a-855a-125fb1f9c1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8be06d2-f0a8-4f01-8cac-0eca07308538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fb9fa1-d975-464e-bfcf-16a86b04cbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dfe3be0-fcfc-4fc3-ad49-66dfd977c887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1eb041e-b7ff-4f9a-9178-b5e1a4663687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7f09cf-8240-44df-8b98-46bf6a24c3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fdcb690-a129-4481-bdbb-e87f59415415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aecee4d-d9f5-4990-b2f3-7ba283808af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 442b8e4a-1cc0-49d8-9d59-627ada81eb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f33c702-9a3b-4833-90f8-34c81aa63d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8fd3711-e844-45ba-8ca2-b57d3ac3c888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ccbfdc-04a6-4526-9794-9d8d994dee8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3b680a-1535-40f6-9015-8971586c5b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc25b604-2525-4b82-8579-c2a5544bdad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b88ba74-17f5-4d59-86ce-4abbf3f4aa5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1f3650-0e52-485e-a4e0-df9e78894d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f563992-57fc-44a8-985a-4e6bd27ca45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4b6eaa-8026-444f-882d-a65c252a991e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64d7db9-e7a1-422c-9bd3-98bce967d80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e48458-da87-48ea-9d65-a17fed384621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c48f5c-4e10-4583-9cbf-2e931f834327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847cc8e7-cc88-4e5e-bb24-c159ecef2583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6e2fbde-4117-4260-be87-fce653015b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a758b1-ca03-42c7-ba0b-ad2e474d2eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ba1085-e2db-4eb0-b0dd-d5077f47bc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d6cbeca-62b4-4f9b-9db4-7350cedd8fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a54d318-c09e-48b4-9377-0dc9dcf52688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7d2f27-5007-49ef-a9d0-05074f5c54ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a531e36d-b2ee-4382-9b9b-44869b1bf1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571cf745-95a8-4a95-87b2-f57db8364fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58db9133-c4e6-4286-a5dd-ef703ba1e904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d81708b-aed3-4c86-bb12-469bfc944c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cfa9a13-b60b-45d0-ab1a-adfe622dee63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0578f60-b4c8-4afc-a0e8-8bc0fa47c14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a279bcb-145c-48a2-a894-bbe77147a5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f198a04-5964-4fd7-82de-d10e726feff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae4efb4-bcf1-4c72-9971-2b428eea7f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f17ae97-785f-4a1f-b771-1cc69080f094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e2bcb5-8e30-4fd8-82e3-aa7453024ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e981ab-848c-4100-99bc-8c1d0b814044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54af49cf-3cf5-4b6b-b0ff-1dad4618912a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a96a23-c375-4818-bd83-87afe8035e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb8ca88-3a9a-46f7-a9a7-9e132ffab68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9717aac-0b2b-4d51-9a08-01a1be2fb17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f9ff27-9997-4e6f-806e-3248c67cfe50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12311003-8f4d-49e3-be0a-92f06acaf243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac230262-1d36-4cbb-af18-7a1201b774f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725a3ecd-cccc-47ae-9f0b-051ce7da5824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c24aee0-89c7-4916-9749-1e152df1fdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccce9178-2c93-4008-8931-bcf35bab80e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85747c0d-87a0-4739-960c-6d715ffc5173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6350f24-baa1-4c1b-98dd-d1ee7bb94033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 576d1037-ea36-443f-a3e1-eecf8467b158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce20c040-04f0-4e59-86a6-79df8547fd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65f9531-c675-465d-a84e-34dd0b2fac31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d483d026-faa3-4d22-9e26-f22f33460ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e42a1c8-dbed-4edc-b5f9-68dc03ab4e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3355f2e-542a-453f-a566-373a64be4093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649b58cb-b520-4075-9f1a-e71cf5b82f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9e45b8-9223-4cf0-bd7b-cbaec9bc94e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626234cd-1d03-4417-a811-603cec0b0176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351e1d9c-dd3d-4f66-86d2-20cf7239ea86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39fecc79-2c10-4ba5-80f7-e45febfa6634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9433e931-2317-4909-8991-068a9a39da17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4388a9-ff42-46ca-9f67-51ed9fc43f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a778211-8b0f-4044-8fe0-5cb8b7831813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed4b7b2-1602-41f2-a134-7cdf2dce3380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a8cede-303c-408e-bee6-91d0d539abdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab033b4-ad39-4e31-b70e-5256ab0874fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92603970-fcd6-4bb9-a482-16e410b594cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1534a6e-b53e-4480-b921-e97988e7ca06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bccd540-8aa6-4039-bbb8-bab67d3494a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67640d27-6d90-43b4-af1a-4cdb76fba210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cca1200-26af-4e06-8c67-c1b6cd9536fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc98e539-e0b0-4f69-8ae0-305856da17f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e02e9a-2f2b-4978-aa04-8c6c8929a490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d0df9b-baf5-4a66-83ba-cbf6f8b149a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041bc8eb-fd49-4a24-93a4-3f565e4fab62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e847bea3-b4c4-444f-9504-81100e516a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9cf35a6-f5b4-4d8c-88b7-be2d9816f144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b4f82d-c127-4199-a097-791edb9ffd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2a0696-eb54-4973-be62-344cba348734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf17899-4676-4a09-a013-dc01b7d8d31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4abfbf-568e-4402-978c-ce7a0ecb46c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc96c04d-0f11-4658-95fa-6b1b4bdfcbf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f49a240-24be-426e-a956-a34937677a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef616f6d-059a-4a1c-a0e0-8b7c16aae620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9782b1a-4494-454e-baad-563b9465fe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17200721-86b2-4b7e-bf61-f0882efe91e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 342fa5d4-3172-4cd1-8b58-7e5fc90e8128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151c71e1-6642-4259-9edf-18386f7a3a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b38e62-4574-48bb-96cf-af2dd4b86217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 416637e2-d8e9-4ed0-a03f-017b397bc680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a038340a-86e3-44e9-ae13-0899358d5b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0e5631-83bc-475a-ba01-ec57b577fd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f595289-3b2d-46f9-9d15-b7f1817e1a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10ee878-839c-463a-be52-0c1bddc0cbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2db3b6a-f41f-4593-9b7c-23dfce9b5f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5b8a34-cfb1-4087-87b4-0d136b6e3f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb2ad46-5b33-46ae-b732-fac572e5ffd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d587556-3adb-46c5-a269-2bc27e2fbe58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd9f4262-f09b-40e6-b436-ddf09b034390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761c3871-bf1f-44e1-92a1-585043fcf81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544816ee-d955-4f6a-892f-7d8b58086495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92be7654-c201-47fb-a9c5-e435f5c54a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce51d0a3-f250-48d3-9227-0570e134ea0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbaa0d32-e706-43ed-86f5-dc13928c9d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e2783b-1f12-4dde-b06d-8b5ee6387042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece946dc-4222-4986-97e8-874dc0f8f2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff62dc99-f0df-4556-860c-bc2e2af4137f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446e60cb-69cf-4032-a6e8-a1ec2fbb190a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51635cc-c71a-47a0-abf0-0a4075117f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab649b7-61c4-4613-9b09-9e271f3a1222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b66cdb-b342-4736-81bd-fd8ea47c96d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883c42ce-0429-4f65-a0aa-3d452a99f4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3634a16-6443-4b14-9dbb-c06d00cca1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5a8ded-1394-4194-8a9e-c090be9d5fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6594003d-cf8c-460e-9948-286d4af15e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008c4b61-8323-4cad-b308-75d59d9d38a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2399ada-f54d-4da8-b8be-585ed2e1f4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead4aacc-e6bb-4fd5-8d8d-3d12be2a2540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77fd4797-4845-41d6-aec4-b1d0380a0af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c38aa2-7087-42c4-8181-65ec80ca945c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabfc56e-4171-4b05-978c-07488eebd175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a6baaae-f1c2-4f21-8924-d44a4e863a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92b6c8f-fcc5-4e87-ba57-224d5dddeaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e5f6c4-a5ee-4676-aae3-75dceef5e7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5ee286-8122-4d5c-9946-8790aafabb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87207ed3-bad7-404f-8233-1b2cf5f64845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ad7e8f-afd0-48ff-b222-4c7e612127c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e38365-f3d5-464a-8f80-9280e7f99dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc801261-0537-4390-8b93-addd597fd7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed40a96-bb6d-49c6-8202-e96131c6a01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b70de7-df1d-436f-84b3-c618e1902cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7316e921-1b5a-4444-aac8-d2397d6b3d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4d0826-990a-4b46-9362-225bd5caca37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3eb6505-fc69-4232-89db-11e201baa85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a86f95-159a-43a9-a574-c6abf76a764f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c19de9f-6169-44aa-8298-3bce19d0d732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7a9485-8c58-450f-a802-a6e2c2fa03a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d19900-96a0-4370-aeb7-298306019ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bc7b5b-f730-46eb-ae33-aa72081c676d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6895e61-c1b0-46d1-9354-22584f1a1703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a714bf4f-63f8-49d3-a46f-4cec05b5358c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7113205a-74cb-49a1-b6bf-38b8849ef635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55afbfc5-6aff-44db-b672-84ffd9c6c18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cd4481-8e85-47e7-8212-0e9edde543f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baddfff2-9cd0-4de1-93b3-7efa545d1d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b34cd8-45d1-44c1-b575-a5864a32c17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010bfd34-3fde-4c0f-9197-2258a8ec2f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221ef988-8a0d-47e2-be57-4f84778b0d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cdf383-aefd-4c79-b370-c3c90620ff90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d4d2e6-ba5d-425f-bdd0-5c2e49f629d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b657e80-e19f-4662-bb4e-591d275c7781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1638136f-e743-4ac6-82f4-ce470455e8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4a7cfe-beaf-4123-8ade-0b6b3cf06184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde09ab9-ee73-42c4-85e1-5906d4fcf52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5004e25-4cc6-48f5-9591-49f88f292c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6a6808-bde3-40d8-90e2-ffb35f5884ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927991e9-1b71-476b-bcf9-166b296bd8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cc97dd-6223-4249-9ff9-4be2d33ffda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44ce626-8b4e-484e-8226-74297fd0ede7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92eff302-113a-4021-b09a-9982e8341b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1683412-046c-49ee-a55e-8d354dbc4b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd482338-bed6-4410-be08-bdfb08e91819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536a58f6-63b4-45d4-957e-b79d9782f932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430203ae-aa16-4d71-b955-2e3a2e5228a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b370e7f-e632-4226-b907-e17917e34eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929b654c-32aa-4429-a919-3ea6edfdd3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 809c0738-aead-4267-b354-035d00edd6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee306c51-f411-4921-900f-09755ba6ef9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84647839-6e0c-412a-9dc7-4fd755ae6bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bcdfd6-9cdd-4ba5-9c22-9a1184f5e4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f219cd4-82bb-43aa-9bcb-ba0a00a325b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db482c4-c00a-4226-983d-396d13d7a5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6648ca7d-71a6-40ca-8baf-087ef50c339f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1644261-7d8b-4e58-9199-d0ee9526f38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834e6d78-7160-41f0-838b-624977b59740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b603ba2-4b53-4ffe-9e8c-419457bf9fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192437e6-7b03-469e-8b1e-72bbad09c10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e58ca9-c4d4-4060-9e4b-e8eef00c7851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3dddfd-470e-46a7-8b9d-caa76e493154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e6e5ae-97e1-4362-b9ba-e5f266eb8fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde345cc-dc2d-4183-ab47-cd30c955494e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a31bd0-fdf1-46e5-a3a6-70b8ca62e0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bc0c9b-93d2-4de8-8276-10ef9ce6526b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44541451-4b91-48c1-917e-8e6bc0711bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db13e46-f614-4fdc-9baf-2820123c3a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4695f6f-bef0-4672-9edb-2b5eaba637de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3bbc70-428d-4002-beb6-d5c0856d9816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e53873-f947-4b58-bb63-6a66304efaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6117fe37-53a5-4455-a6ac-a03caaf2128d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87929672-b736-44f7-82e7-23bfc26a5de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506af199-da23-4989-960f-b8358d26c20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187838be-71c8-4b28-a91e-7f732f725ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 058a2fb4-9ae3-4ec9-9908-4da0fe3a528f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bf42f9-ba30-45cc-b3f8-f6aca7f87844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc5929a-f885-455f-a01d-e3c36801b680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a8d1e3-9950-44cf-8fae-62bfac5addd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c9cb3fb-7bb9-4250-a321-abf3b81e219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904b5833-cdcd-487a-acb5-ef58fe75d60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64409816-bead-4fe4-8c18-125e04278285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10f11cc-ebc7-4908-908a-6232d064afea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5561a8ad-943c-4a76-89b2-4d1585202f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d51459-c6f0-407e-9386-312a0e0fed54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371c2eaa-1c77-4c78-9249-afc39344bfd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ecdf025-6af0-4f09-9f60-2e8c0e754c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca275a1-3556-4075-a432-cadd3d0219d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1086dc30-14d8-48e4-bbac-379b2eda212f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa69c41-469b-4387-bbbb-31e38dfa46ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10816a63-de98-44f6-95ac-93ee40a8d0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fb8caa-e89c-44c7-83e5-d3d711aa2fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edaa0b29-4690-42d3-be4c-b1bc7c6ecacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241286b3-fc0a-45ec-8a47-cb7b42521dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad1597c2-d863-4c53-aad7-1d540213bced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040736d1-df68-4e52-9b53-d001c75cc7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1160443-f235-4890-9078-037877f877f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffdb53af-7525-460a-9e85-cf8a6f2ca585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0d218f-88ba-4e08-854e-f67665dcf3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f5b13ec-37f3-4035-8134-49f94d91b26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e0ddab-9a27-4c5b-87b9-ff9a6fbc1a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5665d4-accd-4e66-98fa-9ba6879bc5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07c64e4-81d9-4e4c-bcb0-65d67c7678f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b11e948-eb1c-408f-a92a-2e5078921f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10d4c95-4f90-4621-884d-22f79d686494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3d5b20-489d-4180-8736-b5478a68213f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf0be61-30b2-4b59-a1ba-924f20ce3955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8791a821-3194-49d9-966f-72abc725d879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8652f563-ae5b-494a-92cd-575c3ba2c30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b695aa-599e-451d-be2e-42fde6e4b767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b260d695-3de4-4b79-9f75-0c2a3a97778b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89ba0f6-1f43-4197-a290-f77f9a43c080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea90b655-13f5-4f08-8090-6653d1cd0f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9752ae-27d0-4b6f-9554-0471f8e233e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab39d5a-49bc-449e-bfec-958a4ece953b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad373d02-8801-454f-b10d-62f913269146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed7629c-9944-434f-ac37-1ef78b2a33f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3845d348-9773-4eab-a088-abf28d86cc11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d616ecd9-5499-41e9-a3b8-30b2c15c8529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bc04a3-b615-4d6b-9e76-6364cf1ced62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d53b4d3-9627-4c5b-b695-96a08e9a83fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a13c0d-1b56-41b5-9e31-c09e9d5cb0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea78ce2-0d71-4d8f-a592-285dbc599dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4203305f-36a7-403f-b095-a17c6abba95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94f5113-8bbf-42f5-b098-fb9a5a2d0afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb595c3-6d4a-45ca-ba56-33e8b4718415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493a568b-6433-4e46-b079-8fbf736a7c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ac88ae-c8ac-456b-af4f-c4c08cf94de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e48c3e2-4c6b-42ee-acbd-612188617003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae528ef-d8e7-4b9a-a3df-a52cfb781f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab3744c-71d6-4324-afeb-ecd30866f51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa85e19-2dfa-41d6-8b63-95d1962ff132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78610fd0-903b-40bb-9360-e611e83143c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d720f89-1c89-4f63-bbdd-d9fd3ab70c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163a864a-1f8c-482d-8d2f-ece6806a9fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40494d75-8dc3-43b8-8a97-da4dd466da9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2cf6ac-0612-4d6a-a5fd-1ca0a82f26e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ce2bf2-2b93-4122-9060-962c007f1008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340eed6e-ce15-4442-bf4f-94c295cb8259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c437bf3e-b2d1-48f7-aea7-9dd418baa8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d59ca0-dc87-4917-97aa-6e2e38011b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe192c84-a1c1-44d2-9dda-ce917d9b7d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9afa12-2bd1-4365-bb46-5563e8232609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c5bf64-cc34-491d-b4a2-0156156db493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb5a48b-2063-481f-9ca2-e9dca1716be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb1bf3e-5154-4f3b-b034-6bcc7bfcaec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb73428-95d9-4885-951c-428ad84cd667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0673ff3-f86d-421b-898f-cc5ed1b5c6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a4ed49-4e65-47f6-a458-e1028cff7bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db2c6475-4012-4034-a8c4-f0e948fb633a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891f913b-60fb-48de-8143-2fcb267a4e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c6c179-0027-4717-9bb0-4dd6817bb57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4150f3d-22f5-462e-9074-51080cbf8790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe43bc34-f986-4792-92bb-78a551bd9732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132a77c6-ce2e-48b0-8603-8b41ba6faf37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47421a8-6912-4bc3-b553-3e48496f7289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1de4032-bd25-49bb-96fe-0ee1a75c16ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6101d8a5-a26b-4d50-9a72-8315a3754a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2613504b-57f9-4302-90d2-2529fe8b4f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e40484d-0ec7-4329-868b-4879ec1e5e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0695c8a0-5cef-41f9-bf74-02a65bb838ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d42543a-d312-41cf-a20e-a829bef42c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0ce3b9-760a-4d07-9912-76c2c7ec68d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef986388-25a1-448d-800b-8d78934ff7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b64a3b-fa6d-41e6-805e-a19aaf2c91d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a5c88a-05ab-4368-86ab-7375213f06c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61301231-6832-4d10-95e3-52d9c6a77ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ff27ca-2b37-4993-b7f6-e7662e0059c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5276e86-2cd2-4b9e-88f0-5f9ac3dd4eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379a51a4-4cd6-4525-98a0-59b2715c2a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08361e9-8af8-4cf6-a413-ab18fe40e876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7791e15b-1149-467f-92e9-b49e6fca4f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6f5a02-972c-4129-ba5e-3c37b0b3e30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f007e2d8-bc91-4477-b1d7-870406fab842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394dd0b0-3d9e-490f-92cc-f406868dec9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf7499d-1380-4636-9a61-20eed08614aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820e0e96-3c47-4acb-b5e6-5269e0a4d1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd0e20e-d746-4312-9cff-4e698f25cd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ae5ffd-df25-40db-abd7-b301e35c4e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ed88e0-67a8-4d48-98d9-9bf19b06ec39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092d853f-0030-4650-8902-6bc1ba1f19d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26f6b4d-6106-4dd6-8902-be0be1545bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4355401b-ba48-4e46-bc3e-da31f5d18deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22a66fec-bba5-48db-ab78-a72c7aacf5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4b9adc-6427-46c2-a65e-48facf1526c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa099252-f61c-4e2d-a9ea-da3cd7a3f7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac65d7df-fdc6-4440-9587-6722cafbd029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60d34d3-d5f8-48b0-9f5b-376e6f83d311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b29d8b-fdac-4f99-8342-e0b0380fad48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67400d9-e5d2-49c6-9620-40ca8cafeae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65207fcd-e171-4c98-a7f0-71a2528383cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7209679-d3db-486e-aec4-73a1a6e128d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e605809a-0361-45c1-a575-367eb1125ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc68fcf-b5f4-4c3b-92c2-0a8c75a4f26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a371524-daa6-4e25-9ceb-550fbf58fef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecf2386-3ff1-4e56-9276-046b9d4742fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3651a1ea-4cee-4153-80f3-6a65656dfb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215f9c5d-45ba-4ec4-9227-18cf2f90b692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 616de6a2-eded-47e9-a18e-039eb92ef4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc68cdf-b978-436e-8b8f-7448ce915ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd3caa8-9916-4e88-aa56-b61542cf1c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4557d376-7da5-4c5c-a0df-ad118733b937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee85e8c-bb58-485e-ac26-60aa72cfbf2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c5f3db-c02c-4b05-81a8-8abb2c6aaa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2bcd9a2-8ebe-4096-887c-4a59bb72394a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f118ee29-332c-45d5-8c85-5987bb2606bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e706da65-6160-425a-a223-173554eef4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d4ebf23-8c9d-41fd-86eb-c953dd5ef085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ebaffa1-7181-4268-b903-4412a53027bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8832f146-532b-456c-a94f-c2c0037e2dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d133ce51-7fe3-4531-b3c7-479eb1c58815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd8dfe30-6acd-4cc3-bbf1-631307e7ff97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34ffdd4-ca12-481c-bab7-bfe4dc232c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e12684d-6c3f-43a4-8b7c-c5930f7465fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b24b4424-1755-4742-a0db-75051b2ef97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c316e1-2d29-4a8b-9a8f-8805550ae8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0efc10-7283-4956-8631-b71ec55d1d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb617cbf-4c15-4a96-9e0e-1584341edfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f5995e-b337-4527-8b85-fa4952c3421a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6576cf99-e8cf-4aa3-8e6a-3b95aa4b238d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ea6fc8-320a-48ef-af8a-690990863ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77697c08-5d0e-412e-b4a1-91f8f9a59247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b2a488-eb92-4a75-a2eb-fd5b5e029235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd45edb-d85e-4129-a93b-f50679849e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c28c277-df88-4de1-bb0b-42d0c1c5dfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 563e9c12-6e2b-4850-96da-0f73da72f3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99d618c-6dfa-43c7-b6a3-73dd6450678c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c238e91f-34d7-40d5-ae96-f6efc166a600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f05361-d767-4eb8-a7c3-929d298f3cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a6d8b9-2b40-47ed-8386-a5665c098446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f31327e-5a00-495a-856a-b39c605b917d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd983646-d91b-4106-b292-7f83cb5d8373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa62e8c-1276-426c-9181-2af4339a1b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647679ab-2af0-48c9-8c72-5871ad77a076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c42514a-dc9c-42f4-b6a9-c904c9f7a0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbf7b56-89cb-42ee-b42b-1b6ab1270e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e28c570-80db-4d7a-ad72-a93f61cc1885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314ad95f-0ba8-45e8-b91e-accb5cf862a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bd141f-4249-4bcb-aed1-310141ef0b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3647c0f1-1fd8-4113-a363-9642a52e555c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec25e7a6-982a-450f-8af6-48ea0676573d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbe554c-8e54-4992-a66a-2b8b0ca05d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6041c4-b2b0-4d2e-93c4-1456b829b9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d99985-f7d5-4947-8f5d-60eb0681fda4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f305877c-c680-40f5-a0f1-ed929f74cac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fcd1ba-7015-4e2a-abf7-d4cdcbfc9e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735c4e36-300b-4998-8a8a-7964b530ee67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c9eb50-ace8-483f-9bdd-c25751919bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ecf1b7-94cf-4f28-840b-1e98c10c8f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6db0915-d707-48e0-82b7-cfc4501d53ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611bf536-9a21-4e22-b979-71ab2857cbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0a32ee-8552-4cb7-bcdb-061281cd69ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8879865-2a50-453e-b4e1-86541c8768d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc77591-6f19-4100-8752-f33d8a2234aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e01fdd-f69a-481a-b219-f3a66ac556ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 649572f4-56c8-45b7-8af7-7909a22be878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0222934d-5767-4b2c-b0c7-af7f63b4f52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9f912c1-cc5b-4383-9173-f8a81509bfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473d8958-ea3a-4adf-a1c2-468b868a4c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083fdfde-fad2-4da0-b5bf-766d1ea60ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c35892-a2af-47a6-b933-f54011435a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7617e98-b4fa-407a-8b70-215d6e385d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b612aee0-4ddd-4ff1-b8b5-ed6f72e613a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ecffae-30dd-410a-8235-14ef901244f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b26f78-cd76-4580-8fbe-8b819bd42b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6704f2-8cb2-4ed7-8309-26256063ae54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe88b4f-52b2-44ea-a0fd-f0abfbf05751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf646725-6bd2-4502-8474-acd9fb8bf26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 517d548c-872c-4bdd-a154-3f3a49f89635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21553694-b494-4a5a-ad99-47d7c19fdc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9200446b-63c5-43d2-bb84-29354720cc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be1d6eb-d5fd-4198-bf55-c2392a9499e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 956b3d0f-2d90-4688-b716-28c1876292d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e002771b-bbea-452e-8cee-505b6b731efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085b2057-40db-4e6f-85c7-ae9e6fe71c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61be1a44-e459-4f5f-acd6-685607363116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84cbf4ab-21a0-4fa9-aca0-226dcc770d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e48c6f0-c87e-411a-9435-cfec28c09900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5627b96c-c3a7-4f29-b188-67cfe1ba13ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5899169f-2d76-4675-b48d-f5d1350d8000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa967fa-1d0b-4b68-b60a-0aee84a3b1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1deceab4-901e-439b-b6f1-fca0172463d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4ea105-07e7-4cee-a0d8-55bd04150f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4dd8403-9f2c-435b-a95c-57dba4dfe592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7eec0bb-c97d-46ad-bd82-89b431c83fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0bf9b1-fd9f-4966-9f90-e159d99f097a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150e0d3c-eb8f-4526-9408-cd347198c55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1238b26a-7271-4b96-98e6-795489781f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc60f0de-ab8a-416c-b0fa-77924a36e2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ffe1177-6937-42a7-86db-a5324c05800a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbefb9dd-a463-4b39-924d-9241176995cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d21905f-daf2-4c83-9a02-68f017e1ede7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ced308-b1c4-41a1-9088-0f1be26d1bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1c042e-0df6-44dd-8f85-3431bf32957b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ab6127-387b-484a-bc1b-219862d8d598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb625e38-42cc-40e2-aaa4-d4226a9eada5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da42d6a-e57b-41e5-8a1c-1af858f283eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40b5c37-afb2-41c4-b75c-56fa15545421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fdefd4-038c-4936-8d1e-9d2e401d6e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2f5059-df7c-4adf-8c48-015219b2566e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb0d40d-b770-4192-9875-6bcc79783e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf92bea7-9cf7-4ac7-8335-b304cb6832f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e280adad-5851-419c-8a39-5b17224e5537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29131816-f1e9-45d7-a94f-15bea7653609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e805219-9006-4c5f-b9df-f5669fef29ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a19262d-d927-4ee7-8e7a-64d98ca3ced9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d88fe2fc-3981-4f98-96c4-0a97a0792098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6fe841-63a7-4720-a541-b4d9c9b1ab9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b37b4e7-8d07-4a03-b1b0-4ff28b8c5769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 334c451f-ab5a-421b-96d6-6463972d60a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a05abb3-a2f0-4c3c-8c4c-b2cbf53cd66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9dd6e7-0963-4f18-8cc5-39aadae9e4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58dff8c-6975-4a27-906e-4063b66af9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f221baa-e953-4be7-a2dd-8a5c4fd64005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f086ce83-7773-484d-8236-e8435dee8523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca67ab9-e244-4e49-8702-cae4b67cb03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42aa5c5b-dad6-4cae-9e95-3ad8d29fbcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850b7d4f-4697-4369-9be8-d94c84762711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fec6bdd-daa3-4f3d-8329-bc8379008165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d41fccc1-71de-479b-bebb-f467a414b6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a558f872-ad25-4e74-b200-fa3b1e0193cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07960d7f-1cde-459c-ad87-4557b0d2634b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eba5fdf-0ad7-428d-a2dc-f118b71fa698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd3285c-6c80-4331-b06d-34b257b2eb59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2726342b-cb8b-4a93-91a9-4c37462d7d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523a9a5c-0f84-496e-a735-8109cda588c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd026a76-c98c-4b3a-9356-7d15fed2e7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf15009-6329-4a16-92a0-9993cea4efe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da28e09-cede-492f-a49c-f5b4a9c9a7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00c019d-ca73-40a9-b0f6-4629f1245b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218d317e-ae58-4951-ae38-30b1342d9a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04041908-99d2-49cb-90c8-f3119372a782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fe77f19-ea3f-4957-a2a9-f4b2cfbe1b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40f040f-5247-4aba-baef-50df7f9b5a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2926c98b-5f99-4e81-9773-45cc97940f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480596d4-c04b-486e-a775-9782d110fe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6900b3-651c-4120-982a-da8ef44916f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7feb72-b193-46c7-b253-1746e6d24af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46dacef-e5f4-4c60-a0d6-17952bf88082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a081783-9550-457a-b3c3-52cd94a2c1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a7cb1c-d30e-423c-93ea-749315a32524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9fb155f-7b5b-47d2-8a03-035c3fbbb3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3765c278-26de-48d0-93f9-11ee6a356cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de04e1c-5776-4b34-b758-00214a8bfa2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0183e775-5862-44ae-865c-a024076efb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85aee19b-4d50-474c-9245-8cd0c0010cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58eb71eb-2a8b-49c3-ba13-78392cfa2df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7050b5-01c9-48f2-bd04-6faaf9ac9fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6d00b0-edcf-4b7e-96de-646b27278522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33b96d0-5337-4e72-897c-703c28e2c7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2906b2fc-e114-4d0a-a889-f768286a5124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557190b0-aeb2-4aed-a01a-01b7a7df904d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897480db-9086-431c-b213-62cc9340366a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79f9646-7b90-4c42-8d9b-b6e2e3ade73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961fb172-e074-4979-9c9c-4f43878b4de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c711561-7fe1-4dfa-a3b3-a7908052a3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc7f221-bb9a-48a2-a233-9462a6eebddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf497fad-6163-4b7b-b8f7-6811f27e607d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b70c512-18d8-410e-b352-3c35fd38ed04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45fcd24d-f455-4111-a5f5-63e166756cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d224339-03b0-4a93-9807-eaff2a681822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9451173-c091-4271-88e7-60f4f8997a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842f0de7-423b-477f-b8a1-9472be9d79a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d90cb6d8-7f5e-4007-995d-a8720b6e4467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d96dc63-6fcc-4aff-9e33-9a0d41683f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcc2db2-3c92-43e5-809f-bc35f88e9e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68866f22-b4c0-42e9-b6e9-f799ac1c4c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d2d096-70ed-44d8-8665-7f26c415b99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7623cb99-b9d9-4fa6-bc0a-2d05887d0ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218ae30c-2c84-4c49-89cd-ec8abde7271f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0fe90a-5220-4073-bb21-8f710498ff4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e88064-7e12-4839-8360-2b43bd9f7cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74fc2fcc-3176-49a7-a7b7-26d2ccaf84c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f3d390-c070-44a9-9c01-07e9956fc4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7afeb27-40c3-4d74-8e39-235a658044b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93cef171-6825-42c0-b929-e1c0dc3fd73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f022c9a-8615-4fad-9b20-70eef02f2803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c16025-ea3c-4113-9cfb-95a035f78755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca57ede6-16af-4447-a983-b3816e14bc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d46892-632f-4e5b-8af8-2277c929d239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c43fa8-50ef-4afb-85db-b934fb4a04f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b01d379-695c-4f0e-abd5-f5a74d81a727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 945709d4-d147-4552-b647-5b6c101e71a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea78fca-cec6-4f76-88d3-87678519776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcec258-4037-422b-b96f-a4a7e9afb180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533b2e59-2eb6-465d-abaa-09bfa1baef09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb8e37e-b7cf-4d2b-906d-e5c099776d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e80db8-5e59-4878-824b-7b6f709e8e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239ef795-9dcb-441f-a9a5-09e785bc2c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4e8a88-cafa-4ec7-88b4-5b1e37492218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea2c444-2f34-4436-98e2-88fd58eef269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b03ea8-37e3-4289-9870-a0202a1fdcfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe251bb-8b3d-42eb-b4f1-d3cfb9606db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcabeae-6230-4a23-a840-6816f18a7b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1985836-b35e-4a5d-99f8-4c841c53f133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9aaf862-dce9-4856-bc9e-f203523b5048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5e6a79-af37-41e9-be9f-fdc5a038ef54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6639fa9-2eb3-4ec2-b509-b6f535417fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9a10c2-c82c-40ff-aa0c-d2125d715361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee024699-804b-4825-b4ae-27e35e5b3e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726529d0-e4db-4be4-bc07-9342a42065b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d738c3-33de-4c4b-a0bf-043a41f01d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d0e0eb6-4689-4810-adf1-38899efd45b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025c6e8c-f4f8-4c5a-8fac-fc5c9a31c73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fc23d7-f619-42c7-8858-af7f33da3638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a053509-0992-4e0d-bddd-bf13c910fb5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c15b508-7768-449e-aa9c-b8dc8f561963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e72a10-c2aa-49b3-bc25-354cf381e522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a6d61a-acfb-48a9-808f-d1496f83cd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d3c477-7cef-4f69-b254-2884524df3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bc8861-ba26-404f-9cc9-b2c94a62c6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf9ecdf-4ed5-4f13-bc75-c706a3033224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067877fe-189f-457d-bf09-7a6ee2882e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b832c7-ff39-471c-91c8-415b279a3fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e6989f-2402-4b4d-b635-071e5293fda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c54377ea-6df1-4f7f-94b2-25844b69dad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af4de686-7e15-47a0-8996-e4b0fd1d0bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ddb342-dfdc-4857-a780-5818f194e5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027399cb-d06c-4519-8ee5-8fbf06aae9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5434c32-396c-4249-88a4-6d6c774aa9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8aa980f-569d-4129-bffb-36abe8dbc9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d33198-c082-4e89-aba2-e99ba309f597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49f551c-cce4-4821-84cb-a467b7e5b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140fa6f2-4c31-4014-a861-0821c6e925af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93783488-4bfe-455b-a1d8-3b586df447d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c35f0a-b071-4dfe-93a5-b1e0f38bd34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acec233a-df14-4833-ae04-61dac2f62754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2670130c-c99d-463c-b77b-a6e7782aa1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d611b5ef-7930-47e5-a7e1-26a8702c5a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eeff984-09ca-4482-be84-413a5ec44a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb88610-eb2f-48f9-b689-9b8993caeab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5895793d-2ec6-4336-849a-8589ed04cc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25b9fed-ff8c-4e17-90c4-896681c89bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa33683f-d8f7-492e-a8cd-6e7653c11082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0629078-e0af-4a17-a125-e6c3835e78fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111f4d92-4bf8-4c0f-a106-ae3d9083bfa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219471c4-a291-46d7-9260-a866ad04ed38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008c53a8-b9f3-4e1b-8e50-6a1aed52bcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d12b8a-dea2-4c7f-94d8-ebd68ac794e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8491fd-6d62-47a4-a604-7aa0c1376cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ef4f70-fdc0-4f1d-9bf4-41fcd0f36c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b30e00-d789-4a7f-8528-d9a4088940eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdfe9282-817a-44dc-8cbf-e89078ad274f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3377e2f-7ac4-4bd7-a375-3b01a1f98a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe0dc12-9e94-4dc9-b8f1-b8dee900316b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994ff49b-3311-4ede-a995-e4063497d979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f694ef3-da89-4476-8f24-8593fe6e9dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd76b618-f2a7-41e4-bced-c9070d20acc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c0d1eda-7124-44a9-bd22-dba44bf0f1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aad7388-61bc-4628-9388-1808ee0f3884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7437bd46-d38e-4a34-b46f-df8bbd76d06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4aae5d-b7cb-4cc5-ae21-1d5fb1fca240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c84f234-1deb-4c6c-b607-417109853998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b241f477-14f0-420f-92fd-447e7d457209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0faa03bd-5468-4f2e-9434-c9555a8370d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c4e230-3348-4828-9f3d-512170532c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1defab1-48c2-45e3-90ca-79c7b90ebc4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b91c1f-1146-4117-983c-fe55e6997616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdf6608-d29c-4dce-ab4a-7723b797bc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209d1213-b656-4cef-b593-2e44f3dc31e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa58a88c-d0d5-469f-8013-857f6a332893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e398834-1560-4fc7-a608-9b71544a53f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd723d9-2bb6-454c-96bc-72bad72b831d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19bf16a-ed5b-426b-90b2-c139adf9f769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 565480ae-ff11-4a52-8040-27fffa5e7661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20425a23-e48e-4935-8d5f-449da84ef71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae2f3e3-5357-4c66-a869-0793acd731d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51668f0-3ef8-4afb-aaec-73f22232eee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be6a1c2-582c-44c4-a47d-8d8046d9f6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4854754-73f4-48d2-b2b7-a9136cf66b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5c2dd5-893d-4e27-bdaf-4b67bd4a4e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5bc8f0b-e67b-409c-a1a8-e17a45694494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cf8e11-876b-4af1-9d3b-454e83090e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c970de50-2cec-4932-a140-a8d45d92eeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cfcf1e-af7b-4ae9-bcc5-672a16dffb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2124787e-c1b1-4165-9c3c-ed77b9db36f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb22a5f7-a168-4fcc-8dfb-f120d9145071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302cbbdf-c75b-4472-9c33-09182755b87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d3bf95-20cb-4803-b0e8-53113048ad29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1771ff9-a9da-4c85-b577-1bfd26b7cef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e187c1-bb83-46c7-b8a6-09d8ef2c6003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb49871-1d64-4a8a-8c8f-99137e56b1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38142101-09ff-46d2-8e1f-891f0b6f1621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b098d7-3626-4351-a7a7-73d786552b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a2b03a-cd17-4bd9-b8d5-0097986e6b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a8baed-0955-4d33-ba37-ed44936da41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4778ca03-2709-49cc-8b31-b1f95eee7b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 017369c1-1140-46de-b9c5-99abb205f2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb775cd2-845f-497f-b086-c389be8df532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759a4da4-f5e4-41ca-b31d-4b414abc142f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42c5746-5ead-4808-852c-acadf9b19ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c85b604-3792-4b9e-897c-aab1fd55b1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320e60b6-0c3e-46d1-ab4f-8db1f98d0dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef4874c-953f-439f-9198-0b4149daee79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c639f2-19aa-49a6-a084-68c8fb05cfcb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(4759, 24), y=(4759,)
   Test:  X=(1190, 24), y=(1190,)

⚠️  Limiting training data: 4759 → 800 samples
⚠️  Limiting test data: 1190 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0782 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0794, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0833, val=0.0793, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0788, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0825, val=0.0786, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0806, val=0.0779, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 2 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0057
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0059
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2396, R²: 0.0023

📊 Round 2 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2399, R²: -0.0000

============================================================
🔄 Round 4 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0832 (↓), lr=0.000250
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0810, val=0.0829, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0828, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0828, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0801, val=0.0825, patience=11/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 4 Summary - Client client_6
   Epochs: 25/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0128
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0159
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2394, R²: 0.0045

============================================================
🔄 Round 5 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000031
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0803, val=0.0847, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0802, val=0.0847, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 5 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0070
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0009
============================================================


============================================================
🔄 Round 6 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0776 (↓), lr=0.000008
   • Epoch   2/100: train=0.0820, val=0.0776, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0820, val=0.0776, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0820, val=0.0776, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0820, val=0.0776, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 6 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0090
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0058
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2393, R²: 0.0057

📊 Round 6 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

📊 Round 6 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0074

📊 Round 6 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0073

============================================================
🔄 Round 15 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0860 (↓), lr=0.000002
   • Epoch   2/100: train=0.0791, val=0.0860, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0791, val=0.0860, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0791, val=0.0860, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0791, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 15 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0112
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0075
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0068

============================================================
🔄 Round 16 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 16 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0109
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0150
============================================================


============================================================
🔄 Round 18 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 18 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0128
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0037
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2390, R²: 0.0066

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0095
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0133
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2390, R²: 0.0066

============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0087
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0152
============================================================


============================================================
🔄 Round 23 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 23 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0125
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0097
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2390, R²: 0.0067

============================================================
🔄 Round 24 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 24 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0113
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0149
============================================================


============================================================
🔄 Round 25 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 25 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0115
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0080
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0067

============================================================
🔄 Round 26 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 26 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0108
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0171
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0068

📊 Round 26 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0069

📊 Round 26 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0069

============================================================
🔄 Round 30 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 30 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0091
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0198
============================================================


============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0137
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0045
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0069

📊 Round 32 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2390, R²: 0.0069

============================================================
🔄 Round 34 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 34 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0094
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0167
============================================================


============================================================
🔄 Round 35 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 35 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0123
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0113
============================================================


============================================================
🔄 Round 36 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 36 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0125
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0115
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0070

📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0071

📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0071

📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0071

📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0071

============================================================
🔄 Round 43 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 43 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0113
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0028
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0071

============================================================
🔄 Round 44 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 44 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0117
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0126
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0072

============================================================
🔄 Round 45 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 45 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0141
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0047
============================================================


============================================================
🔄 Round 47 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 47 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0131
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0092
============================================================


============================================================
🔄 Round 49 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 49 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0111
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0043
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0073

📊 Round 49 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0074

============================================================
🔄 Round 54 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 54 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0133
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0052
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0074

============================================================
🔄 Round 55 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 55 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0131
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0098
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2389, R²: 0.0074

============================================================
🔄 Round 57 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 57 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0122
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0137
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0074

📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0075

============================================================
🔄 Round 61 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 61 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0135
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0087
============================================================


============================================================
🔄 Round 66 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 66 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0130
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0105
============================================================


============================================================
🔄 Round 67 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 67 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0152
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0004
============================================================


============================================================
🔄 Round 70 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 70 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0117
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0103
============================================================


============================================================
🔄 Round 72 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 72 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0108
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0141
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

📊 Round 72 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

============================================================
🔄 Round 75 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 75 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0107
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0009
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

============================================================
🔄 Round 78 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 78 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0146
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0015
============================================================


============================================================
🔄 Round 79 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 79 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0144
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0013
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

============================================================
🔄 Round 82 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 82 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0140
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0064
============================================================


============================================================
🔄 Round 83 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 83 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0126
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0127
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0104
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0173
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0077

============================================================
🔄 Round 86 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 86 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0107
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0191
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0078

============================================================
🔄 Round 91 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 91 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0127
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0081
============================================================


============================================================
🔄 Round 92 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 92 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0100
   Val:   Loss=0.0720, RMSE=0.2682, R²=0.0244
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0078

============================================================
🔄 Round 93 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 93 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0139
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0062
============================================================


============================================================
🔄 Round 94 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 94 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0103
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0164
============================================================


============================================================
🔄 Round 95 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 95 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0148
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0036
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0078

============================================================
🔄 Round 98 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 98 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0141
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0065
============================================================


============================================================
🔄 Round 99 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0124
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0135
============================================================


============================================================
🔄 Round 106 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 106 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0139
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0013
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0079

============================================================
🔄 Round 107 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 107 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0116
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0093
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 108 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 108 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0115
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0121
============================================================


============================================================
🔄 Round 111 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 111 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0139
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0049
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0119
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0139
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 116 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 116 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0137
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0073
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 120 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 120 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0117
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0200
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 120 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 123 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 123 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0167
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0036
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 127 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 127 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0123
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0042
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 129 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 129 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0161
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0001
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 131 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 131 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0156
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0002
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 131 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 133 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 133 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0121
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0103
============================================================


============================================================
🔄 Round 134 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 134 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0101
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0118
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 136 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 136 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0104
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0158
============================================================


============================================================
🔄 Round 139 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 139 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0109
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0168
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 142 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 142 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0116
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0118
============================================================


============================================================
🔄 Round 143 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 143 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0127
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0128
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 151 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 151 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0112
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0167
============================================================


============================================================
🔄 Round 152 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 152 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0129
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0051
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 153 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 153 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0092
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0257
============================================================


============================================================
🔄 Round 155 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 155 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0113
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0179
============================================================


============================================================
🔄 Round 156 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 156 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0134
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0088
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 158 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 158 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0106
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0130
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 163 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 163 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0086
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0165
============================================================


============================================================
🔄 Round 164 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 164 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0141
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0006
============================================================


============================================================
🔄 Round 165 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 165 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0126
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0133
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 167 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 167 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0137
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0073
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0080

============================================================
🔄 Round 172 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 172 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0134
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0108
============================================================


============================================================
🔄 Round 173 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 173 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0142
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0069
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

📊 Round 173 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 175 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 175 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0113
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0131
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

📊 Round 175 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0081

============================================================
🔄 Round 178 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 178 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0154
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0030
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2389, R²: 0.0082

📊 Round 178 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2389, R²: 0.0082

📊 Round 178 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2389, R²: 0.0082

============================================================
🔄 Round 184 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 184 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0123
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0128
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2389, R²: 0.0082

📊 Round 184 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 187 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 187 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0150
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0032
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 188 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 188 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0118
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0167
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 197 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 197 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0120
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0041
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 198 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 198 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0140
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0070
============================================================


============================================================
🔄 Round 200 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 200 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0113
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0034
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 202 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 202 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0128
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0130
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 203 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 203 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0154
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0007
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 205 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 205 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0115
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0183
============================================================


============================================================
🔄 Round 206 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 206 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0136
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0080
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 208 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 208 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0085
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0056
============================================================


============================================================
🔄 Round 210 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 210 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0060
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0137
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 212 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 212 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0092
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0216
============================================================


============================================================
🔄 Round 213 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 213 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0094
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0124
============================================================


============================================================
🔄 Round 214 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 214 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0152
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0116
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 214 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 216 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 216 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0128
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0133
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 219 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 219 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0137
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0099
============================================================


============================================================
🔄 Round 222 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 222 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0125
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0145
============================================================


============================================================
🔄 Round 224 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 224 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0137
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0062
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 225 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 225 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0122
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0075
============================================================


============================================================
🔄 Round 227 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 227 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0152
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0019
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 230 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 230 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0131
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0122
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 231 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 231 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0125
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0065
============================================================


============================================================
🔄 Round 233 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 233 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0127
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0141
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 234 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 234 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0129
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0193
============================================================


============================================================
🔄 Round 235 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 235 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0096
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0262
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 239 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 239 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0125
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0150
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 241 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 241 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0147
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0049
============================================================


============================================================
🔄 Round 242 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 242 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0129
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0125
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 242 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 252 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 252 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0147
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0013
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 259 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 259 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0126
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0135
============================================================


============================================================
🔄 Round 262 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 262 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0141
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0082
============================================================


============================================================
🔄 Round 263 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 263 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0112
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0194
============================================================


============================================================
🔄 Round 264 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 264 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0126
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0101
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 267 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 267 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0152
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0044
============================================================


============================================================
🔄 Round 268 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 268 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0134
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0071
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 270 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 270 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0125
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0126
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0083

============================================================
🔄 Round 274 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 274 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0138
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0091
============================================================


============================================================
🔄 Round 275 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 275 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0108
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0163
============================================================


============================================================
🔄 Round 276 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 276 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0120
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0148
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 276 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 276 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 283 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 283 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0114
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0010
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 284 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 284 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0144
   Val:   Loss=0.0659, RMSE=0.2568, R²=0.0045
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 286 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 286 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0110
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0195
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 286 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 288 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 288 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0126
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0095
============================================================


============================================================
🔄 Round 291 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 291 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0141
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0023
============================================================


============================================================
🔄 Round 293 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 293 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0125
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0072
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 293 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 297 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 297 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0120
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0115
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 301 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 301 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0115
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0145
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 302 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 302 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0121
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0124
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 303 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 303 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0107
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0033
============================================================


============================================================
🔄 Round 305 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 305 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0122
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0038
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 305 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 305 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 305 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 312 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 312 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0134
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0110
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 313 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 313 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0127
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0130
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 313 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 315 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 315 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0163
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0057
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 316 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 316 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0081
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0336
============================================================


============================================================
🔄 Round 319 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 319 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0160
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0102
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 319 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 319 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 323 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 323 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0137
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0020
============================================================


============================================================
🔄 Round 324 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 324 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0127
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0115
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 324 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 327 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 327 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0120
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0137
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 328 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 328 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0135
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0027
============================================================


============================================================
🔄 Round 329 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 329 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0153
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0001
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 331 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 331 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0131
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0115
============================================================


============================================================
🔄 Round 332 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 332 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0109
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0209
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 332 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 332 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 338 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 338 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0141
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0085
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 341 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 341 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0129
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0130
============================================================


============================================================
🔄 Round 342 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 342 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0125
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0135
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 347 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 347 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0116
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0179
============================================================


============================================================
🔄 Round 348 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 348 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0133
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0091
============================================================


============================================================
🔄 Round 350 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 350 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0104
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0219
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 351 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 351 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0133
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0102
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 354 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 354 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0116
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0179
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 355 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 355 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0136
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0109
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 355 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 358 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 358 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0104
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0227
============================================================


============================================================
🔄 Round 359 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 359 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0119
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0055
============================================================


============================================================
🔄 Round 360 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 360 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0142
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0012
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 362 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 362 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0093
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0146
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 364 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 364 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0153
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0009
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 366 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 366 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0129
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0125
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 369 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 369 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0147
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0054
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 369 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 369 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 376 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 376 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0163
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0119
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 377 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 377 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0108
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0220
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 378 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 378 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0168
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0035
============================================================


============================================================
🔄 Round 379 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 379 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0137
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0085
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 380 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 380 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0122
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0147
============================================================


============================================================
🔄 Round 381 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 381 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0132
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0102
============================================================


============================================================
🔄 Round 382 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 382 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0140
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0060
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 384 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 384 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0123
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0140
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 384 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 384 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 384 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 384 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 394 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 394 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0128
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0143
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 397 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 397 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0117
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0030
============================================================


============================================================
🔄 Round 398 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 398 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0157
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0016
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 400 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 400 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0157
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0010
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 402 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 402 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0135
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0091
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 404 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 404 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0087
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0041
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

📊 Round 404 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0084

============================================================
🔄 Round 412 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 412 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0144
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0072
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 412 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 412 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 412 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 412 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 422 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 422 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0127
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0103
============================================================


============================================================
🔄 Round 423 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 423 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0084
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0249
============================================================


============================================================
🔄 Round 424 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 424 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0118
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0183
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 424 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 424 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 424 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 424 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 430 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 430 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0125
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0056
============================================================


============================================================
🔄 Round 431 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 431 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0144
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0017
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 432 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 432 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0097
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0216
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 436 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 436 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0115
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0139
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 436 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 439 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 439 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0122
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0157
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 439 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 439 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 442 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 442 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0112
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0199
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 442 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 442 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 448 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0667 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 448 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0161
   Val:   Loss=0.0667, RMSE=0.2582, R²=-0.0146
============================================================


============================================================
🔄 Round 451 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 451 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0115
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0282
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 453 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 453 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0137
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0050
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 454 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 454 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0125
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0032
============================================================


============================================================
🔄 Round 455 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 455 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0144
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0072
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 456 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 456 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0084
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0001
============================================================


============================================================
🔄 Round 457 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 457 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0136
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0110
============================================================


============================================================
🔄 Round 458 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 458 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0136
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0105
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 462 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 462 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0119
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0112
============================================================


============================================================
🔄 Round 465 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 465 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0134
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0070
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 465 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 469 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 469 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0150
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0055
============================================================


============================================================
🔄 Round 471 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 471 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0138
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0100
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 475 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 475 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0144
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0077
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 479 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 479 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0120
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0150
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 479 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 483 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 483 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0139
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0034
============================================================


============================================================
🔄 Round 485 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 485 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0130
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0134
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 489 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 489 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0132
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0117
============================================================


============================================================
🔄 Round 490 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 490 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0120
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0157
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 493 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 493 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0104
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0055
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 493 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 493 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 497 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 497 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0124
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0066
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 497 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 497 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 503 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 503 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0168
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0165
============================================================


============================================================
🔄 Round 504 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 504 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0117
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0191
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 504 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 506 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 506 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0111
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0215
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 509 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 509 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0109
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0078
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 510 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 510 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0132
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0092
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 510 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 521 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 521 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0134
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0102
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 523 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 523 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0109
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0206
============================================================


============================================================
🔄 Round 526 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 526 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0122
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0153
============================================================


============================================================
🔄 Round 527 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 527 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0077
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0237
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 529 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 529 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0099
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0022
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 530 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 530 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0140
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0087
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 530 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 532 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 532 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0101
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0178
============================================================


============================================================
🔄 Round 535 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 535 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0123
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0029
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

============================================================
🔄 Round 536 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 536 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0146
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0068
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 536 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 536 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0085

📊 Round 536 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 536 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 541 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 541 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0132
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0103
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 544 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 544 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0139
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0062
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 545 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 545 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0143
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0099
============================================================


============================================================
🔄 Round 546 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 546 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0120
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0164
============================================================


============================================================
🔄 Round 547 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 547 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0120
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0037
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 547 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 554 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 554 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0143
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0303
============================================================


============================================================
🔄 Round 555 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 555 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0140
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0005
============================================================


============================================================
🔄 Round 556 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 556 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0142
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0233
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 557 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 557 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0111
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0150
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 557 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 560 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 560 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0115
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0014
============================================================


============================================================
🔄 Round 562 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 562 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0119
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0174
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 562 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 562 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 566 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 566 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0113
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0213
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 571 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 571 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0147
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0002
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 572 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 572 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0162
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0038
============================================================


============================================================
🔄 Round 573 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 573 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0128
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0119
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 575 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 575 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0123
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0160
============================================================


============================================================
🔄 Round 576 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 576 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0154
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0024
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 578 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 578 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0143
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0060
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 581 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 581 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0151
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0031
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 582 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 582 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0138
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0102
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 582 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 586 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 586 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0134
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0120
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 587 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 587 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0098
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0267
============================================================


============================================================
🔄 Round 588 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 588 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0166
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0097
============================================================


============================================================
🔄 Round 589 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 589 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0116
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0184
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 589 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 591 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 591 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0124
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0087
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 593 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 593 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0138
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0071
============================================================


============================================================
🔄 Round 594 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 594 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0113
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0185
============================================================


============================================================
🔄 Round 597 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 597 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0123
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0097
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 598 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 598 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0105
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0230
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 599 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 599 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0106
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0125
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 606 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 606 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0128
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0125
============================================================


============================================================
🔄 Round 610 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 610 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0149
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0038
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 610 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 612 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 612 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0131
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0075
============================================================


============================================================
🔄 Round 613 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 613 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0135
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0099
============================================================


============================================================
🔄 Round 614 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 614 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0144
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0077
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 615 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 615 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0144
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0071
============================================================


============================================================
🔄 Round 616 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 616 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0124
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0039
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 619 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 619 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0110
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0160
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 620 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 620 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0105
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0230
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 622 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 622 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0109
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0148
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 622 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 627 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 627 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0110
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0121
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 627 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 629 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 629 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0155
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0011
============================================================


============================================================
🔄 Round 630 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 630 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0148
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0046
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 630 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 630 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 634 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 634 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0147
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0056
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 635 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 635 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0156
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0098
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 639 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 639 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0101
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0177
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 639 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 643 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0624 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0624, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0624, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0624, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0624, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0624, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0624)

============================================================
📊 Round 643 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0141
   Val:   Loss=0.0624, RMSE=0.2498, R²=0.0060
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 645 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 645 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0144
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0081
============================================================


============================================================
🔄 Round 646 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 646 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0104
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0237
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 647 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 647 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0127
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0022
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 649 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 649 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0150
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0044
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 650 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 650 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0122
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0166
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 652 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 652 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0130
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0135
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 653 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 653 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0126
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0048
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 658 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 658 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0137
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0097
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 658 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 661 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 661 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0143
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0054
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 662 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 662 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0128
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0094
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 662 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 668 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 668 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0123
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0142
============================================================


============================================================
🔄 Round 670 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 670 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0150
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0059
============================================================


============================================================
🔄 Round 671 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 671 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0115
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0133
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 673 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 673 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0120
   Val:   Loss=0.0678, RMSE=0.2605, R²=0.0150
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 673 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 676 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 676 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0122
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0074
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 677 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 677 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0143
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0249
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 678 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 678 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0153
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0018
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 679 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 679 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0141
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0094
============================================================


============================================================
🔄 Round 682 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 682 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0122
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0169
============================================================


============================================================
🔄 Round 683 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 683 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0102
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0209
============================================================


============================================================
🔄 Round 685 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 685 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0130
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0120
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 691 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 691 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0131
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0131
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 691 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 691 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 691 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 691 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 698 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 698 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0117
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0062
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 700 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 700 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0111
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0080
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 701 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 701 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0151
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0057
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 702 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 702 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0126
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0126
============================================================


============================================================
🔄 Round 703 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 703 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0158
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0017
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 703 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 708 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 708 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0124
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0066
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 712 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 712 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0151
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0094
============================================================


============================================================
🔄 Round 713 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 713 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0118
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0182
============================================================


============================================================
🔄 Round 715 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 715 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0132
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0011
============================================================


============================================================
🔄 Round 716 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 716 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0125
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0149
============================================================


============================================================
🔄 Round 717 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 717 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0115
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0198
============================================================


============================================================
🔄 Round 718 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 718 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0130
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0127
============================================================


============================================================
🔄 Round 720 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 720 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0122
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0167
============================================================


============================================================
🔄 Round 721 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 721 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0134
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0065
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 723 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 723 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0147
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0018
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 723 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 723 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 723 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 731 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 731 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0144
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0000
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 732 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 732 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0152
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0024
============================================================


============================================================
🔄 Round 734 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 734 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0119
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0104
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 735 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 735 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0103
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0023
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 741 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 741 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0133
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0116
============================================================


============================================================
🔄 Round 742 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 742 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0121
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0151
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 743 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 743 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0144
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0044
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 744 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 744 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0117
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0086
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 744 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 744 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 744 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 751 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 751 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0121
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0166
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 755 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 755 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0152
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0048
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

📊 Round 755 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 758 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 758 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0133
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0108
============================================================


============================================================
🔄 Round 759 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 759 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0097
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0202
============================================================


============================================================
🔄 Round 762 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 762 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0101
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0095
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 769 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 769 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0124
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0088
============================================================


============================================================
🔄 Round 770 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 770 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0121
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0136
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 773 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 773 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0102
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0001
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 777 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 777 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0148
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0004
============================================================


============================================================
🔄 Round 778 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 778 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0130
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0138
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 782 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 782 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0126
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0155
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 784 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 784 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0130
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0137
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 785 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 785 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0132
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0123
============================================================


============================================================
🔄 Round 787 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 787 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0113
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0173
============================================================


============================================================
🔄 Round 789 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 789 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0119
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0187
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 789 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 793 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 793 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0097
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0259
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 793 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 796 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 796 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0136
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0114
============================================================


============================================================
🔄 Round 797 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 797 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0154
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0031
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 797 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 803 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 803 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0124
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0155
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 804 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 804 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0110
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.0107
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 804 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 811 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 811 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0137
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0111
============================================================


📊 Round 811 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 813 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 813 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0127
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0150
============================================================


📊 Round 813 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 814 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 814 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0125
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0136
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 814 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 819 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 819 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0151
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0039
============================================================


📊 Round 819 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 819 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 822 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 822 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0123
   Val:   Loss=0.0932, RMSE=0.3054, R²=0.0053
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 822 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 824 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 824 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0101
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0228
============================================================


============================================================
🔄 Round 825 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 825 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0132
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0115
============================================================


============================================================
🔄 Round 826 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 826 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0108
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0138
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 827 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 827 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0166
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0022
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 827 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 830 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 830 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0105
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0034
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 832 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 832 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0131
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0135
============================================================


============================================================
🔄 Round 833 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 833 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0078
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0249
============================================================


📊 Round 833 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 833 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 835 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 835 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0111
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0175
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 840 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 840 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0155
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0003
============================================================


============================================================
🔄 Round 841 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 841 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0109
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0207
============================================================


============================================================
🔄 Round 843 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 843 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0103
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0248
============================================================


📊 Round 843 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 844 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 844 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0129
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0052
============================================================


============================================================
🔄 Round 845 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 845 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0145
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0046
============================================================


📊 Round 845 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 847 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 847 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0131
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0119
============================================================


============================================================
🔄 Round 848 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 848 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0138
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0008
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 848 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 853 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 853 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0129
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0141
============================================================


============================================================
🔄 Round 854 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 854 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0095
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0028
============================================================


============================================================
🔄 Round 855 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 855 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0110
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0034
============================================================


============================================================
🔄 Round 856 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 856 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0137
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0111
============================================================


📊 Round 856 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 857 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 857 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0094
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0259
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 857 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 859 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 859 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0129
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0105
============================================================


📊 Round 859 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 860 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 860 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0139
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0057
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 861 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 861 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0128
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0114
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0086

============================================================
🔄 Round 863 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 863 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0125
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0139
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

============================================================
🔄 Round 867 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 867 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0108
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0131
============================================================


============================================================
🔄 Round 868 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 868 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0114
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0103
============================================================


============================================================
🔄 Round 869 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 869 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0129
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0149
============================================================


============================================================
🔄 Round 870 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 870 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0125
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0131
============================================================


📊 Round 870 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 870 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 873 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 873 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0118
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0189
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 873 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 875 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 875 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0142
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0084
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 875 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 875 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 879 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 879 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0123
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0162
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 879 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 879 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 879 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 879 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 886 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 886 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0134
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0089
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 888 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 888 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0155
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0001
============================================================


============================================================
🔄 Round 889 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 889 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0135
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0098
============================================================


📊 Round 889 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 890 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 890 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0161
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0098
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 895 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 895 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0120
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0161
============================================================


============================================================
🔄 Round 897 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 897 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0121
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0173
============================================================


============================================================
🔄 Round 899 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 899 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0148
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0045
============================================================


============================================================
🔄 Round 900 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 900 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0082
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0008
============================================================


============================================================
🔄 Round 902 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 902 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0130
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0129
============================================================


📊 Round 902 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 902 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 907 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 907 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0138
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0098
============================================================


📊 Round 907 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 907 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 909 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 909 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0135
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0117
============================================================


📊 Round 909 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 910 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 910 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0126
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0043
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 912 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 912 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0103
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0237
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 913 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 913 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0129
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0141
============================================================


============================================================
🔄 Round 914 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 914 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0142
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0016
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 914 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 914 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 923 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 923 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0166
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0017
============================================================


============================================================
🔄 Round 924 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 924 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0148
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0062
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0087

📊 Round 924 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 926 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 926 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0113
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0153
============================================================


============================================================
🔄 Round 929 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 929 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0117
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0038
============================================================


============================================================
🔄 Round 930 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 930 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0140
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0064
============================================================


============================================================
🔄 Round 933 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 933 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0161
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0005
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 938 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 938 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0110
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0042
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 938 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

📊 Round 938 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

============================================================
🔄 Round 946 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 946 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0141
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0028
============================================================


📊 Round 946 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2389, R²: 0.0088

❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
