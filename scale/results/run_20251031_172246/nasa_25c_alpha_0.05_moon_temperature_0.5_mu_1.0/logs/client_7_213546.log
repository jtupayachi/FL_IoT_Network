[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206ef850-e6d3-4700-8068-f3e7ca9bb832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc048b9-97ce-45bc-abf5-611247ddedec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd01e37-8d0d-4bff-ad32-7d8ec2c41233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d388b119-62af-4464-ac26-fd07594431da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73eb9661-bec2-4afb-971e-168c627b0b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd13d92-3733-43fb-8d0b-1c7a50a58974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fecbedc-b8c4-4290-86d4-3e55c0c778e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6534e8aa-937e-460e-beec-7af0101a665e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9978554b-3851-46f3-b7a2-8075efbeab9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a9f6e5d-c56e-4116-9ba4-a35651f1bca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02540d69-f25d-4276-8a85-dc7ced2943e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0228503-e449-49aa-9179-8ede324d2944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c605c4-f371-40b8-ac07-0a5e20d02497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27949797-9ce1-45cd-84ad-15b15d9718c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e9cd81a-c508-4772-9e4d-9e7585d5c6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdeb72f-5aaa-4303-8e9c-b41c95f3aa45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85349bdd-92fa-45ca-b320-6970146ef4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece760ef-f081-4c70-b464-df131c22b4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a46f526-0ce6-400a-8c81-5e2b0c07937f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7faf396f-1ad8-499b-ae9c-e14c8a351831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a58eba-bede-4408-a276-be4bd28010e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4437c67a-e72c-4cfd-956d-a0cf9a2b167f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11087caf-36cd-440c-a67a-f88447a69cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e69da66d-97cb-4e47-b865-43547fb31b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8a6c54-2f05-495d-8392-c5719fbe1527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3fcca9-59c8-48fd-af99-e6bc53a40c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6406c8e3-1d0d-411b-8b2c-1dcec6e7d9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8791fbe1-7361-45b6-9d02-5ee5c232cd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b92a347-bff3-40b2-bf45-476d69844262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4192534-4b6a-4d0b-a9dd-332885aa9c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7375b16-afab-4be6-9ea9-878d5cc7dd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fb7231-f169-4c25-b98e-2f6e06eefce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88be52e-ec2f-4faa-8cb0-5e4c1b847ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb01ddf2-3131-4df9-aaa8-7e647dd4b9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae6bed8-0524-44c4-b691-65581d2950ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429b89b2-44b2-4ec6-8b50-024424476c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334fbe52-3005-4020-9e28-c36b87712dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cab5ba-e63c-41a9-9ec8-c696a83effa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3a2d22-f86e-4743-a805-4de34afb9068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b05dbf-0e5b-4733-80b8-bb27eefcf043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4adee4-56c0-4abb-95d8-3980191f46af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebd1584-6a5f-467d-b0ee-7a60a53150d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ff90a2-3c74-4ba0-b8c2-0cc8f85d2da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f52e76-de54-45a5-9971-ca2158fb46f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f4fc5f-1c35-4f9f-91e9-2106b6196a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30890974-9ca7-4a37-956a-81e28a68cd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8539f947-aa05-4a0c-ab1d-0db6e278fcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10601479-4652-4c07-9e88-4847350495ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65631f59-1737-4ee4-908d-6346346e18bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf1d7f1-49b4-4c34-82c7-726144980eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b61125-c233-40ad-8896-99a446d84965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0004ed-6ef0-4565-b694-bb53ca83e738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61211ad9-ab9c-405a-a9da-cd2d853a9e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 336dfa3a-f616-4b64-9ad2-fa39703b13fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8ee061-c020-417c-b49d-d1214311301e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fbca2c-19c3-41de-a3d9-2759eea74e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c24ce33-21fd-45f0-ba83-6f89e29bb983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28a8858-ccc6-4b6f-9cdd-afdcc35031fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d42e889-1136-4d23-95dc-1c91918fbca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe72f4e8-51e7-4461-a118-82f4098b9110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee4a424-8d1a-44e3-b8c6-132790bae8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1669bba-9a21-4f97-aeff-00e8588e4d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4637f45-907c-411f-83e1-d01987fb9dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a123fbcb-1874-41b5-8253-8ebb3f76ae03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f41684-218b-43d5-8ce7-553bc4a0d6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ce4508-3eb1-4b6f-a44a-c40e6e6d7dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f62689e-189e-4ec9-8bf3-dee50a25203b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4427bdca-3f48-4b4f-a624-e591d7a9cd02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff158900-4174-4ca7-afea-249101166c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228bc2ce-d8a8-4280-8d40-a185b7beac65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be189bd-7b16-4550-895e-3aa16f04483c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1231b8f7-cee4-440f-bc7d-bc31c1484999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5faa3b2d-3669-4955-bd39-97118c0a23f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27283c2e-04c0-4f98-9ea2-e0de9540234d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95f5d57-fc07-4675-ada9-0596d6982539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab791f9-f410-46c4-84cb-d637ea9e4c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91cfa997-1100-40d2-b8c3-e1e807f45bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8aa049-af9d-4603-9547-b4f78b4da8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fccd1c6-4509-4089-96dd-0e5ef802c563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164c4362-96b5-411a-af86-da40e1c09aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f30a86-2142-4cf9-9728-2df28dfc737c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f03ef6-2540-4109-af80-87ebdfe856b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9b9a41-65d1-4dcd-b2c1-6e55377bbf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ecffd2-0ae9-4fec-a884-896dacf21603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eaabea6-d332-4faa-ba29-f37f0ab3413b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d433e8f-601d-443d-8582-49e7c5875340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b396ccd-fd29-4b45-9475-7de8bee48a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922c6230-cddc-43b1-80ae-7e4e546bfe4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24477b5-ff11-4aa0-9747-c85070021e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b54cc9-da4d-4920-bbe9-2f8d0642f782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51391442-2200-4191-bf21-218d31e2f8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa733c44-632d-4cca-8937-0f4982f04315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e25d3b-c840-4d4c-a718-c5d49f7aaecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097d4032-e969-4d61-a10f-2689d9eece95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e14d8d0-3e26-4847-a628-edd112e7ce59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac3cc87-9df7-4588-8243-5a7322ec2981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee53171f-dac5-42a5-b633-a19e50cde935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e3b9a5-cd35-4491-88e3-3e01d9729fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb2b85e-c8af-4f6b-beba-c6a6d6d8bdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ef41f1-eb0f-477e-87a4-70968190d03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96eb601-7823-4fa8-b053-d7a2a347f2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec3a0c3-144c-40db-a4cb-60c52d4b7091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf195d5f-6f2d-4c15-8007-19f4cebc9de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19cd027d-ba2c-421f-bc1b-8109ed7e1906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff44a2d8-90ae-448f-9e42-1bd97daa9747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d84e341-79da-4295-a6ad-dd84e13ad74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff44dbb-76b6-435c-a158-03a5bbb35915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b628e5-4217-4114-bcb4-602c5c896115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f01c00ec-c14a-46bc-a1bc-a7dfa2f8c8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4b5750-8226-47d1-81c2-4be7adb20e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0ae275-8b23-4d45-bd6a-de3146107379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175c3cd8-b5f7-4f0e-8177-add7126b6bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcab52f8-96c0-45fb-b3bf-7e6dfd2cb031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfdb254-df70-45ba-b423-c8e1f4a9b481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5664710-4ea7-4360-9890-751d73c23ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33dc63d9-08c6-4afd-9a06-04eaf37f382a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f39a781-0b51-4c16-9edf-d02dcd2609eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ce58f8-0a1a-445b-be40-9fe94567906e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e30bef-8694-4b98-b981-106e6d9db5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61780de6-6b95-44cc-8c57-b386542282bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 523dad71-1dd9-4702-8f93-6be059a74bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717fe768-fc56-4ed2-bb90-b9af0eb982c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5ebef9-eb60-4e6a-8434-700771d24bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d0c458-d9d4-423a-a4d5-1cd364641233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7bebf2-6e01-4dac-b91b-2b219303ed58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5cebc9-f653-4dc0-a9e4-e168ac3e9051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39181783-12f6-4f97-a161-0da0ea2ba67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c821a16e-4999-48ae-b9b3-ba93d159f7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf16370b-3c6a-47b9-840a-de93ef7548e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff2b5eb-0c18-44e5-9a24-403891a9d6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1989829f-8f74-4381-a7d4-011f277e3ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da7ffb3-a5be-4cc0-b9c6-f0a0d55bcbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3183b9-d4eb-41d7-9688-a67193308a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5e29fa-f6d7-4680-acc0-f7a94684c43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8106dd2f-dd29-469b-8cdc-a0e0d8f54580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e209579c-a660-4bc5-aa3c-aad8f6cc8d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d55ba2-bf1a-4f94-ab15-c074ddc43004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d68363-2d30-464b-bcb9-a99a28ab8638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b250711-67c0-4ab9-889f-a7479cb07c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c73d8b2-d2e5-44b6-8567-eec568d31213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43120a5f-d5c9-4fb4-b40e-0404e41dad09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b4b705-8a86-4dcd-93ae-9416f5eaf35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef22420-e23e-44a7-a23c-5de7534ef1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 548fe951-107d-4f76-be1b-c670ba3249dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8358822-f342-407c-be95-a5c151e3fd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6febf7e-a40d-48cc-94b9-a773baeea2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c744c15a-5f7e-41fd-b5c4-8cfbaa114e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9360fcb6-50a4-44f9-b577-209c672cb74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47d0865-c17d-4954-a694-2b9b7c2b0b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322c1cd9-820a-4097-bd71-95e541fb8cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b39484-bcbb-4879-a275-c0210d82913a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e470cbaa-4766-4184-a896-3413c55f9138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c377fd1-c5ec-456f-9289-08ab1af8a400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f3e03e-b69b-495c-a78b-1bb1a6f77225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6517c50-36cf-4fbd-b7ec-e9698d3b8c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c07c55-f834-446a-8cb4-7ee62c25205d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb75d30-c61a-4a62-94c3-334aa7a28bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a099888-0194-4013-8edb-2b3c0bfeb607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bcaa12f-4338-438e-9886-f714f9443aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40400fe4-b3f9-4119-b11d-bf8689eb13c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6365d915-0a4d-4b66-ae91-ce9c2df0b2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ae8b69-026d-4681-9161-3aec109852a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f789e88c-4c45-47ae-9ff8-ff38addd5946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad696d7f-5761-45f5-b8da-4749cbefbe4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbbb48b-3914-4a6c-afd0-19e7f4d387b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d438741-d1b9-43eb-9efb-cec38bfc1472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33fb82b-cc07-4119-87ff-308d2b44af75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f31af5-04b0-40d8-9c3e-1b2458c22952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f136295-6d97-4eaf-9091-f8f04d0e4ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed3a3dd7-390f-48f4-a560-c085009dd938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0ca25b-1387-4c78-97b6-acd8b19b214c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c73e09d-05b7-472e-b5fd-59b9258ddf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c80f0f5-de87-468a-aed0-7f7795a09cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6d1960-4c27-4ead-a33f-dbbb8715113f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e337c02-4e6b-4c40-ab1f-9d60a598f148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc42da7d-13c7-472c-88e1-bf400166672b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03562c9c-ad24-448b-a09e-8968cdd7cc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f09d16-20da-47eb-9ae7-81993389bc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d5e573-c3df-421c-8939-9d4696d08253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb3a519-e65b-4598-a9bc-83e7b2ecec2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf3d637-da97-48dc-8890-bab65cfafd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154bbd72-3f31-478c-b8a6-bf7d7d459372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a8fcff-3fa2-49cb-b9b8-5c2ca5995e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df76406a-4ca8-4f6a-bf50-e9c4512c2855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a5980a-4923-46bd-9d70-38b55d6bb2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4350ce61-f408-4391-8a93-4e8d929ff5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2819a70-d340-4d69-835a-3a897c5cc382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5770e65-3bb8-4a11-a7b0-11332a5893ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d964b8d-4cf5-4ce3-82c4-256b084ccc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e190b32f-c834-46be-986f-dbd883ee5805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d27f8f0-c5fb-4485-868d-f3afd2c5f896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ea0db6-71b2-433d-8cd9-a65f68df55a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356a767b-ff7b-4e74-bdc8-271828cf09fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9820b14e-78dd-4597-8db1-a5e68e4a580d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04881b4-afc3-4bbe-92b9-41a4cc53ea27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6178f920-05e7-4f9a-84f7-02fd9b08eaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b2944a-5241-428a-b95b-cc8876bd99ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82feea78-19c6-4470-9abb-1d351ecb9d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38cae97e-455c-4e99-83d5-11bf0c798628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42270227-0227-489d-aaf8-e4a587e0034a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79078bda-096a-4d39-9d6f-abc55d9018dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be5d3498-cc1f-4cc2-a602-584bcba2a3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6f1352-1b46-4fcf-9379-2297286abdf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c89151-4f57-48d0-ab24-2581530dfa4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40dfb43d-efb6-4a6e-ac42-0c2f9232c6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1a64b4-23d2-40f4-93e9-04437273538f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32312475-a1fd-4005-9a99-278c28911e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e8c8f2-af3a-4b3d-8576-009a6a7dce5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da0ee32-86a2-4a24-8f2a-87b634120207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0189b31f-dc84-4b76-b02f-3baa78cf66df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8e4f37-144a-45a4-b64e-7d602372e71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a3aa29-d07a-4ee2-933d-27bebb200367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9b96f4-605e-4fbd-a84f-8d80f606a661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796f9273-dca9-4ee5-a319-fdcc2afccad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 169ac254-a8cd-4314-984d-2a9978c9aacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864d0d35-de86-4c45-be39-6f5c95694b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ad297b-c96a-4c5d-98ea-f26c8539cd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ab718b-0cea-4332-9dc0-3b1ac95a1059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11e56190-bf89-423c-9f64-a5e33a4c78aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6013c223-3619-4de8-87a7-51eabea23093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31da611f-33e7-485f-94cd-4860a2c0d463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85953c5-58f1-4dd8-b1de-512b40e484eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de7aa81-576a-4d21-aed5-bcf99cb22914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b2b979-e66e-473c-9b65-206502ebad16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e577eda-3411-4a89-bd61-a4379532bc7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe504e4-5ae3-4a05-924e-8791fe02bdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3946c2bb-4fb7-4145-8d76-ac8afecd99d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8caeac5-b877-4dbf-ba86-70e449ffe63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6dfcaa-0f00-435f-a903-227299baf243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ddff37b-eb4a-40a0-a52e-2a8a520bf2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee1d782-006f-43c4-8550-4df54e82c599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75c7dca-7ac2-452c-afaf-f750804e1be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dec1db2-714f-45c1-a619-46df1860bfab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb328720-f80c-432d-81ca-5a0f610f8e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b861b50-5d09-41d0-b550-95019d09bc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b72e3f-76dc-469a-bd27-19786061477e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d6113b-f749-4d8a-9235-4ce3e75887d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222a8783-d674-43de-bed9-b4bf2eec7263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f670817-0234-4dda-b26a-35809692862b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e486c6d9-1d3e-40a1-9fb1-1bf9baebe9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ebb63a-69bc-47bf-bece-3f5e2003f39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07ab3a9-1e78-41aa-ac82-5cfec09a65d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de9dedc-cc95-4e61-9d9b-9c61e8d5770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a4cb191-b62b-4848-887c-fc3f299d63ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a12f1ee-fe0c-41d9-a0a8-619e09dc293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b57cc8-037c-493f-bbfb-c99aa70f7d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2963252b-d19a-46e0-a77a-30a084403b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca10ef1-91e7-42f3-9710-601649938979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c37c7cb-831a-411a-8720-28bacec6964f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd51f52e-3505-4ce6-b111-85edb0d2b7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041b7f41-3dc1-4dd3-bde6-069d80bfa257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a7ae46-1681-4924-a733-89b2b33a84b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9237f0b1-9044-4c26-b216-94fbf88ae1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe74f7d1-4958-4d62-9a56-9c802a0abcfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807559bb-32a0-413d-a791-70e89e8615c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4cf1a7d-71b3-4a04-b2b8-397432cfc7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c841194-016d-4bbc-9c6e-a973c4fbac9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b296c66b-b982-4d52-91a0-1fbb60aa9b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3355cbc8-c666-45fe-9953-e43900f5559f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db52057b-cd47-445f-a171-f60e3c286f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b2f915-7e2d-4c6e-8a91-2f44d56e6cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ce3ace-6539-44b4-8f8c-e5c189eb1a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f34ce4-cae8-4344-ad04-07aedd4cfd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f28de7-0305-4a75-8dd2-e32cb18bb503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f28f646-8658-42d8-b76e-f94eb94712ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ccd98a1-fffc-4b78-9bd8-132190c9abde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1949e6ad-494e-4b27-85cf-3e489c1aab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9da96c-8717-4c71-ba5b-ea01292e6d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5eb6f94-dcd3-48df-a419-1883f717d649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7323f6-b77e-4b9a-a3c3-2e6d98437a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c3d4aa-b821-48e5-8739-5353e4ef2c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ab5bfd-3068-4e14-84e3-e32d94632a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81c273c-98f7-489f-853f-a82bd2b81253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60151148-dfa5-4a32-8e90-0f31f676a027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce1d7a5-bffa-4e05-a2d9-ad9497548c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e892a9ca-49b9-4e3a-8d04-9c0228868c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b05647-f5cb-4653-b1b4-9f33ea709aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1647a95e-8b0f-44d3-98f5-e75c3963d1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0091e7b9-1c24-407b-beb2-5b97a5088d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3a2ea0-e220-4f18-91d5-63bad374b95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033e67e9-43aa-4651-ab61-9ccf2a91e1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22a13ee-8b8a-4874-8374-393ee2c1c1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07749522-8069-4dd0-9d1b-e56ad41ac5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306e62af-42e6-4244-86ad-03e2d850d6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1b9e996-7c0a-4fa0-b33b-c7149e9b7a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08ca4005-f2ca-41ca-9246-d9db5f87d9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be01dc1-b4f6-45b0-b23f-73f153b4486c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932010f0-f7cd-457d-9122-c27a5866806c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d92244-46e1-4a9a-aae4-d8457f0ba36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a21f11e-b094-4ba8-af41-16eecaf7b993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963249f9-82f0-47a3-8b64-c4ca2dc8d274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3749ddd-b50b-4c14-a2cf-cf5d3d6c6cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7b86ea-e340-4cbd-a114-79e43aae982b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417202b4-4ff6-4eba-8776-af55b65767ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74858c2a-15fd-4332-96af-0bf7331dae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf51aceb-189f-41bf-ac47-788cdc9a10da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc47e45-c263-455c-b0d0-1c083cb05e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19d337f-07e1-4e3e-9325-9373175258ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911a93aa-1019-4f39-af42-03a94c3f6c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06929de-3d6d-4977-8362-9b90070d9439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69d835f-d6c2-4f3a-af1d-4f6450757dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0b791f-d779-406c-82fa-2cd8c124bff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2c202a-e569-4786-9881-ebc25038a242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd169c6-fe08-4ca4-b944-0ff3f64c9af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 153eddcf-6b24-4a85-a1f6-4be581ab50c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62caf6a-a1f0-4527-babb-2314d8fa0035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d05880-43d0-46dd-ad55-7c0137440762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f39a14eb-6cf2-4a6a-914d-0abe38899c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a1c8ac-73d2-4d07-9d78-86b085415559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a33ecf-b041-4580-ac34-0269877f3a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ddc8c08-4344-4e1b-9b0e-adb798afe3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d01eab6-5bdc-4aaa-9b79-617a1b509e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aac3817-4699-42d2-a44a-abd9e8d88a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c838c0f-795d-4bd9-8bca-82264ee6450b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d850d6f-a94c-40df-a34c-24a1445d8767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf5a8255-c2bc-4412-a81e-a37c7790e884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcd5ff6-47e8-43f0-8202-585220d46d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f2cf7e-7847-410f-b5be-443f2f2f3308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f25bb07-fe04-4a6b-890d-c119998fa2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475e4ab8-e923-485c-8d5e-5d7af9351248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea9a92c-91a3-4aae-9dcd-0f6f0b750e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece9e7dc-b5a4-40b1-8873-1b6160a094df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d374ffcc-3185-4cec-ac65-21d96ca39854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04bc784-1178-4b68-90ed-aa0eb429da1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75f4e06a-26f0-4c50-9fac-a16bbcf2e36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8b986c-db2d-4a3b-85e7-3c07b6a24223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b45b6c8-0ed3-4f5d-8cdd-f7511b2b94ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6348b7d8-5caa-47db-9756-f9b2cb823486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c92efafe-74c7-4acf-ba13-45a846d7ebe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c372b3bc-9be1-4a56-8016-6f85869cd021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14da5c0a-fc72-415b-8de2-ac57ab680357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912b1fe5-4f18-42df-bed1-b0d67fe7d444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f0ee2b8-4982-42c0-9da7-84701518dc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aef3ae1-0a73-4a34-9bfc-344496eb81e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50c781f-99a6-429e-bf76-cb108429505d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1fec465-6573-4b3a-9e7c-ac51339cd389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc9a309-f0aa-40a5-9972-3d7b680e169c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d6b978-89bf-4c3e-9e97-1e45306e5873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c76550-a041-4b0f-814c-c9114a64253d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067ba533-4c66-4574-a96b-9ad8066ba489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989f52c7-f0ab-4cdf-882f-07bd70603e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774bb7d3-3058-4a66-ba7d-802d317fe6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b50bf2-9281-42f4-a416-80181c8c46c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ef544df-8cf0-44ff-8e4b-9264b318e053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb41530b-ee19-401a-a788-431bcd47fea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c71086-f57e-40c7-b755-ee17ffecabf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4755a8-d1c2-4133-920e-57e41a83296a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad543b15-0400-4996-8de3-5fdef389f6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7cfef9-0c7c-43b2-8eb1-4ae2fd7710e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee91085c-d417-454f-83a6-c9b452105bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086eedec-bcf8-4b7a-865b-5e519c8fdf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93d6c7b-ca12-41ad-8fa2-d9d0f7ae2c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e532eb7-27f6-4124-9d04-31fa7473aae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538ea6dd-da07-4c4b-8ff1-73e2e66f4272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d11ac5d-3cd0-48e2-9879-e0130fc7cdef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 616b9862-6ebc-4ce2-9a66-86df2d428c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5ee66d-9da0-4c36-98b0-c773bdbdfeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f90f352-e129-4b1e-96d8-db2b36b63e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062ab5e1-06da-4bd6-adde-1a240e951976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d11e00b-a4ed-4909-a236-29df48de4ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec19117-5e9b-41f8-adae-e1da2d9d145b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d4c2536-1cbd-410f-8203-2d98d450595f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04c23e6-8f74-4331-abef-0d122c2240a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd31ea8-0f8e-4ec8-bfc4-3fac7baee02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c58ba3-92a8-4a4e-9d0d-c6b6096d3ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 924a6869-66eb-4b4b-90d3-8c18929808e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ad59d5-c87a-49ee-9b4f-f36734c01096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18c4e67-fa6a-40ed-aa0b-e82d4ce907ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa02c8f-e982-4fdc-af9e-caec63b4fde1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97353344-f8ad-49e9-be33-05c8e09c824e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7a5910-b779-4459-9633-1d8ea237f209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4c92b7-42eb-40bd-9e3e-7f7303214371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6626b1-c1ed-4d97-a15b-010c612fef60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e0e2d35-0b94-4140-b60d-4dcaa3b44dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9747402-0c59-4621-b39e-673841b65e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4f0ec5-6ebe-43f2-b447-5c68b509abbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a071e2-84ac-415e-ae2f-f15ceb37c7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4527c60d-7d35-4ce1-b5cf-03ae4b2609c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68c527f-9278-4987-ad6d-8dbfeca63f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccf2578-95ac-42fb-af97-cc228b29b797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e23f39f-a90f-4fc1-a402-9099a01273b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44877e4-abad-4fb9-9b5b-c31e194f04df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f69878-52f4-4b37-9278-c95a78ae7d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115d3c90-a6d1-4288-a0a9-213322733ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f73779-d701-4368-aef6-cf32c207edb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 410c1ece-4f32-4abe-9b92-b90d22924d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ae0810-6a46-470b-b81f-1e24d4da4067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346bb214-2686-4af5-b2a7-c765ef69bdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bccc2d57-ccda-4328-b5dc-e47d5eee4ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb98a07-bac8-483e-8987-0d3a3890e3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0ae721-ec71-4e49-a8cf-14109b4f4947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e051383-ae02-4fc5-b5d9-b72bf1b27d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 842cb5fe-5a4a-40a3-8bc6-6bc8e8400461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfaf0e7d-0286-4006-9844-49004618b3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af5b999-d799-4b5c-97e3-728e983599b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d97843-b7b8-4b30-a43c-e9bd24530880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf92b32-ccd7-4e48-ad02-7d61a7377d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01982b1e-96ae-45a5-b5d5-652920ecb3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ae8f897-1db5-4f9b-ac53-09e5e65b0fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f184110-ea43-4515-ac83-2d40f84d0a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bdaa544-5bbb-411d-a5b2-42be01039772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203f1a34-b3e0-4055-863f-e3b10c31045e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4abf54-9841-4838-bc8e-daa9eb3a217c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c013a60f-f513-468b-b451-5a6f6d3bb944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca49833-09c1-4b26-acad-f5577a19bb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acf4ed2-0910-4fed-bce7-fc3480f0013f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf1c110-e15d-4e6d-a6fb-e4d02373351f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac570826-29fb-4c6d-a277-eb8db64b4798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a376bf08-2f82-410d-82ba-9e42998d0f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0f8bfc-b4fd-4d65-9c7d-7166eb582c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bd176f-66d4-4e4f-a53f-128c5e878b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78b57a3-28ce-46bc-978d-99e84bb67fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b635505-832e-4f48-874f-d876796146fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a1c428-a479-4963-b45b-5d18df742c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322bc8e0-4153-4116-a923-6cbdbfe8cbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 156a532c-d8f5-4ada-b16e-cb2f83fe5713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63409132-bac0-4691-8b17-cad53c82c670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9620e224-477a-4359-bd2d-618b1b8c11b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b0c26d-57ce-41ff-9fc6-d9a48659def1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd9e313-d3ab-4d28-a0a7-3a852f452752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d18508-3d01-4dd7-867f-a7a1b2a9b59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4016e86b-37d5-4df9-adf3-f31bd48e0796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bed2cfa-2570-46a1-b9b1-cec373abe1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efca1e4-129e-4da9-b132-59c9520c8ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e228f6-1b3c-4fc2-84e7-32e163b7e975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6be63e-671d-495a-9de1-1625c05b1487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d441fd-bd4d-4201-95cb-04ca9e82c706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a201a90-fbbc-4216-828c-324057fd2332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aedc684e-49a0-4e7e-aed1-a82d78aff4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b752ad-b193-4ad7-87c9-5bded76318d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd24f584-3144-4c98-a00a-c8c78a4df63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c69d8b-f876-4fe6-82b9-37e11c18c092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c79164f6-3c6b-44e8-973e-7533355771cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb856a67-1549-49c9-97f3-dff39a872d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 382a2c52-fcdd-4ab2-b582-f679b5497fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed204492-4af0-42bb-9ccc-c596d3c22577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043d88b4-6516-453b-afdf-accbf18b750e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35ace02-7233-40de-b35f-2ec7cd153fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65922ee-a33f-408f-b354-2b126e0e7f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62022c92-edcd-4aa3-b80c-5d9d19fe693c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3583cdb8-ed05-4a9d-95c5-bf558bcf6813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c999ff-446a-4da8-81dc-01b7fe1cea25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00838fc6-5eef-436f-89cd-bfe8f9a54c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61745dfa-1f23-4b25-96a4-47ecfe1b9c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66f9a2d-8b0b-4c06-a2df-b27bdf31747c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f493935-7f05-41b2-83d7-9e39054c800c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b8ce1e4-ef36-4dbc-9d08-b997896bd481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b23fe79-88d9-410d-81f3-cf48d1153f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6dc9aa5-c4aa-4a6b-be5a-c2d962c48e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8742d0f2-cc06-4cd9-bef7-68dbd9281ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140b72df-2c94-4cf4-b2ed-4d7ee2407c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a2ec10-0006-4c85-9ff7-5009b26bdcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ab99e2-8353-46f7-8954-4f3fc7b18036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59842bc5-40ce-453d-bdce-ddd8f6368d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d40ac1-5ec2-4c6d-8a50-b1b8e59c36b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9616e50-f94a-410f-bd40-91964d4ea0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40657cfa-003d-41c2-ad89-170b267784cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0741049-9366-43a9-bcd4-730539f2a587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8481ab9c-6748-457f-ad45-47dc9b4f7e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b635748-202c-4716-8458-fa6df3f75325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66db12b3-181e-485d-9db5-b7519b83c447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff535910-e7e4-402c-ae3b-b1a4463e79ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0deecb-7897-4b5d-904b-c112b43e9ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf6c587-8c58-411d-9121-a2c2227d7a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96c8c5d-6144-407c-ae29-5e8201a1fa74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a543d1b-7eba-40cd-87ba-6bbbea55402c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9281a224-a187-4f06-af97-575cf00f49d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea3e8baf-8377-428f-8cb0-0cc154437f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e5f2b3-5e97-4d16-96d7-303fd3be6ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c282d79d-d0e2-4531-97d8-9990f0d52f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fd60e0-56d8-4c55-8962-53e25761df35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b8580c5-e46c-4adc-87b7-c6542c2efe29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad26f82-d726-4a7f-9c73-8be571ce12d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12945c82-1849-4f70-867d-4ca97d4bcaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50afb239-71df-4163-9392-aa492179d506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e445c560-a903-4f35-9948-007c9b82dfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911c18ac-3e72-439d-941a-1ecbdd23b566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1efa799-ad27-4c89-9a65-aff88657c34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db845e06-6d61-4915-9db3-b51b9ce69b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2642e1-ae02-44a9-a4b5-7156fee36f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af47abe9-2df0-481e-8407-e7a94bc9c9b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a132caf0-d5a4-4a25-89e3-2c0ac81ee510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705ad90a-130e-4a72-a3a5-193ee08f2597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f27ee3-8ff5-4771-8d76-acf18ead1b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac78fa0a-2cf3-4f43-92ee-873806d09dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680ec350-1db7-485f-a489-713edd99d03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f03d322-7701-4b58-9a15-8465a62e5a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f90ead-4946-497f-ad2c-a3118190067f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ea68df-888a-4661-837b-3b35ee3bd322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53de6e10-ecaa-4baa-8cee-c03254c32bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c966b4e0-8f32-4db7-81c7-57c043a077a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65bebe64-e575-43d2-b96b-702d681e30c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e652524-2f08-4a55-9dd3-a918fae03efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8984bd6d-3c40-42b8-acb1-8b2abd944c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0067d011-3622-4491-b5ad-df1a3e0cc043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74ecbad-8f5b-4b1c-b0f1-0f057756c249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6dfd52-4e06-429d-b2c9-b6bd833daef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d00336-c69c-43de-a647-c39b7269a4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9aa9a2-5024-4979-ad81-3761c4376ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cfa1fa-1a74-4dea-ba64-314cc1b9834c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a70491e-cc94-42a8-a3a7-63bf8d391c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e643194-75ea-4630-948d-7716483831a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781387c2-e0d7-4035-9fb5-585d625861fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1f43c8-d240-4e3d-b867-dc7a92c4b14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148d8d9f-4a32-418c-8f70-311d05850ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90580930-4bc7-4461-9f8e-d494714f4c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e455767b-85ce-40d0-93b4-6871582d1e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f62a4f-0c7d-4394-9fdc-fd2666be8499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f072e406-fcfd-4888-ad84-eb1dac1b04fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9330729d-dbe8-46dc-ac27-491b089db0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fafb050d-41fe-49c5-b9b4-6de8721e990e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7824955-45e5-4217-9e55-c7b51b6472d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf2f685-a817-4caa-a6f4-c3194a1ee314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a7f88d-d10c-421f-85a9-a29af95ac289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aee7d05-c7d3-47c5-972b-03422588db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e573ef0-cebb-4601-b7d6-e6cf74afeed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed3f9ae-2046-4b06-9d03-f553e28c3488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea81115-cc63-4274-ba30-6f599b5d1aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404f76f3-01f6-429b-9c93-efbfe2ee8b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4301ae0e-fa7a-4f02-9dd8-d428714fb3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693599cb-fb24-4e18-8016-7d84726298ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b06495-f316-4ff3-b3a0-744ae0b07da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6004219-1d3d-457a-a3ec-033cab2f639a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f80d768-f17d-4a85-8eca-589435ba6d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a91dbe-04e3-4162-89a7-b3b4c50dcac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a8796e-3a0e-45bc-96e0-2ee1818a0dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5756ac36-572c-4125-8e2c-d4db90c9e3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bf8040-0651-4bed-8bb8-d0b9e1b0de26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9813df0b-a047-40ab-8434-0c7ced25b38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a079a649-1522-4df7-8eef-5b0d7ae86b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0a575d-9276-4fed-bc05-71b32fb018ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a420442-41bc-49f5-aff3-b0920303ac41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bcb0a18-1a2f-45ab-b0f5-fa9d55b9961b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2638d1b-dcd9-42a1-9098-719aec338694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcbf3c8a-68c8-4143-bd8b-a8b9bea2d70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cc974d-7eb3-4be4-8950-cfc22068ea84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ebc29d5-4aaa-4879-b4ac-33a566f2aab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c030951f-994f-4c48-8780-c278be2fb466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3f8b16-43bf-496a-96d8-e21943173c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3536807b-3b2c-4acd-90ed-50eb1d3c734c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7939207-69a5-476d-bd2b-db8354e386d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11a84d8-dbf8-4f2c-be4c-71b7d6a03462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8fa2d2d-3e67-4aaf-a320-737130b19717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208ff0fd-7d8f-407f-b07f-2695753895e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70ffb1a-7522-45a3-9d29-a3142fb0d5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5952e278-df15-4af7-b284-081be4c3b758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85777ea7-a33d-4ead-9f6b-bf8b80e5827e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1c35b6-9564-49dc-97b6-0a989ebd3f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15064e2-5179-4ea8-9db8-d863049eb35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51804f7e-1a2d-45f0-8485-0cb49ecc7ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24dff229-8403-487f-9c0d-6419eca17ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9211711a-a58a-4ddd-962a-309a7065ecea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d47d2dd-3d94-4ad1-bfcb-7727e953f82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f48ef74-5fbd-413c-8042-35f29cfc26a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e41ba76-2336-492e-b93c-0135fe63e74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84cb054f-834f-4e9e-ac6d-034d17f70cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e83f7b-ec52-4d19-8317-acdba1893974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466f4dcc-38ef-4179-bc61-7a21e4d2abcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2267c75-6c41-4ad3-90ec-6b4e9df5a90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f093eb1-febe-4111-a9aa-34d0911e29d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb628ee-3879-42f9-88ae-051d5e5dec54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3feb9dc3-c302-4a63-9749-1e8d7c09e611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e4e7e2-959e-4236-b3dd-ba1fbf031fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d14d9f9-d28f-4077-855c-c782938d361d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0682bb41-462b-4c4a-bf6e-fc0f836b260f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162fdeca-1cf1-4f91-aaa9-765bcfb09e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b88da3-1f97-42d6-b0b1-c274f439272d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86ab848-7cac-4ada-8271-a707bf84c129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1233dbfc-bd74-4734-88eb-a4ff9a7d7d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f8da8e-9ff1-4605-b711-86f7ee69ee45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283bbab4-719d-4a1d-b0de-ef2e87b6c94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7b0b07-61ed-4cf1-9128-0632a06a718b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9623fa11-dd94-4f27-8edd-bd46def1f1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e18a5ea-3cc7-47ad-981b-48f145e3ec74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240d357a-f6c0-463f-b359-af70760c7f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39983bf6-252f-4cc6-b207-56132432d3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8376df6-ba12-48e7-9b1f-aecf0e22a754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0662a243-7e00-48ac-85a2-b5a221112f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 648bd8fb-3958-4bf1-a519-f2aef386d4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65a4c79-a330-49a6-94c2-4fb9b96c82b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aefb45a-6504-4752-8da4-11629308106e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5719e83-3c5e-4b0c-8234-5f9758bcbd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d8a589-2758-49b4-a513-b330e424e89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc7b3a9-8502-4af0-9811-69c258e5f5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bcc087e-cc6a-49f0-9444-865ff47e6299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5b6fc3-091c-48bc-84f0-f1708a090c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e3c617-4a4e-471d-91e7-b276e78be1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ffb404-f2a0-4a53-8dde-a8be07cfd73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 671ac35c-cf48-4506-94ff-ffce146caf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcdf5c8-853a-417f-a32f-18ce15d5fa17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f04876-dc69-498a-963b-cbbc99bb6a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b523a433-a25f-44c7-a893-67fe04ce90e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033850cb-693d-43fe-847a-25ed59b07004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f9412be-3ee7-4a04-a983-1d488da80b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d17f4be-76d5-4f9f-a2f4-72c9609564ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51c3c96-60af-4501-913b-48d1224141d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2dbf53-87f5-43af-af39-29e2fe3253b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc6d560b-5816-48d4-b1da-ed38eef6c147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6addec0-9664-499f-8d5f-7718efb344e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff9196b-930d-477b-977d-3f7b47147e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c123f1b1-03ce-4c44-8956-109bfe8bfa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d43d9a7-cc8c-4a37-9546-703e6a67c02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0353560f-ca2e-4bca-8b1a-301d4157525b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f06324-d860-4f8c-9f83-231cbc304581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d838cd-1cd7-44b0-a75a-8f0225ebbabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed4645f8-dcc6-4e21-b619-63ff1a55425f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f595e44d-73f9-440e-b289-2771cac64027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d37b144-95cd-4cbf-a389-5bcc94fef37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 354b2ef9-2685-4de0-ac15-c9850829c491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3099d8-9457-478d-8fbd-dc946ab23074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 458ad238-aacd-463a-8460-7ceff904d54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7999c155-c934-44e5-aebd-8c17dca07e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee0ff1a-d023-4cef-ba7a-3d82d6ae9612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7b17d5-55f1-45ea-b350-6b963158c823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0bace43-b22a-40b3-a015-a8fd5a754751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c5c065-7901-44d6-9cfa-d69ab0c64cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47c367c-3db8-45e7-9740-b04230fbd226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc52357e-76d5-4100-9bf8-78100c70f653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f76b75-1339-4159-bff6-3a11decb6ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa0394e-7605-4018-b3d9-f87815b78387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 265f6d60-775d-46aa-b259-4ffdaf044527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 687bd3bf-d2ef-4b17-a5ed-1245476ff0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cddc6cda-3eb0-4951-9888-ebc1581d09f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e6d492-14f1-4205-8d9f-3bd51d1d8fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce583165-d99f-4144-9084-e9db0576fdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f57d52-9344-4d67-9e6a-c2841738618d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6df317-ffc7-46bc-80c2-822f0dc323c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ea9f07-bb26-4cbb-80a7-c0466b0c27ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3bd1b9-03a0-4cac-89fa-91ac0c0a13e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088edebf-e5b7-4ad8-9850-cf2613725448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64982cb-c9c6-45d8-99b1-60b1e0d2b95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5bc98be-0952-46b3-a181-532df8aa9722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a5e41f-9588-4c28-819b-9b796a96482e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf2ab18-7366-4548-be8f-378e3ec42d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57cbc5b-d9a2-4b6d-b801-2611ee84d028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347fecf3-ff34-4325-8347-059cc879e5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ded38b-e91f-48eb-877b-8352b308ef34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404e9d1a-2a4e-43fa-8488-a26574f0fa10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a299386a-8dec-4d68-b9b5-009080c1792c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd81181-b911-4b23-90b6-9f9cb71e6036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90d435b-2fe5-4097-ac6b-ff6053a62db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10c0e111-54a8-4a34-abed-50d6c8b0defb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbeb059c-2326-4625-8c3a-83e8049d8289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7586f05a-7b0d-4549-9787-0a0453c5d3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9151e1-7291-440a-a8e9-97de332c207a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661904f7-4fcf-45e9-918e-87323586fe41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e715bb7-b17b-4694-a926-af3dc4407bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae45e778-b6b5-4c9c-8432-418133fd4ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4bdeeca-171b-405e-8bef-914a488228f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71ddbbf-efe3-416a-8b64-ceee4959f071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c43c558-5a25-41dd-9ba9-11f39d7f4c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19ef8ce-169d-4bb7-b6ec-8a369df71996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09cfdb27-0453-4d52-a204-15b6147ad16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97de14c2-a30d-4951-847c-8d4676892892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e7d7d0-ea16-4b1b-a233-420c81a0e546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a043d9-2d08-41fc-819e-508c9caab4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae32ad3-1a4d-4508-8b7c-b5899c41da5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daec683c-8d8b-4c0c-b0ad-9f523258940f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a6322e-2256-4ce5-9dbb-d68e13e9f48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 696fc62e-fd74-4402-9c1c-2a9147c26355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8366e56d-b838-4b0c-9d49-79221d30122e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6645bd-3335-4768-8d56-05ad5cadbcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e52692-975b-43bf-8a62-66d548f58766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404d079c-c5e3-4093-a8ab-ba0ca352adf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf5acb6-75a3-43fd-b28f-8e2a7e5bbb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d68f523d-2868-4801-8288-3a3ed7bef590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f357a884-ccd8-4c5b-b48f-436e3ff290b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b416c9ac-ad94-4e79-a813-f9f3c034e0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355c8e1f-26c5-42c4-a08c-5e2d40691637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b591ed1-9b1a-4a93-8b36-a3a722969451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5dabc40-4fcf-4016-8aae-f7b4447aba39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b276f941-6228-4ce6-b347-8810d56c40b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72004523-78a5-4d24-b1e9-e52d7256fe24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a7a7fd-2acd-47bf-a04a-76915fbcf8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef9156d-5285-4ab5-b35a-42d4b1031db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63688640-f246-426e-9abf-87d965756b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d3c713-3d25-4ec5-95f3-41182d6975b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3d90a3-e005-4bd8-a294-ef31e665f84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c527d5d0-ec7f-453e-b9e6-4f1e07cfb830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f93e78b-b797-47ee-bfc1-7524fee3ce63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b213266-fb72-4ecd-9d96-02760d1c676f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a39961a-7eb6-45b3-8398-a1f37b585ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263a7b39-8a9c-4dc4-892c-a7e69bbacbc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bad842a-efed-4585-bd9d-4c76b3457c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31402f08-7dd0-4ea7-bed4-486a5880e2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f6270c-93d3-49f9-aa2d-6d46480d500e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d310a4-dc10-4658-bba0-6fc635af4085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fdd4d0-1e55-4bbc-b86d-cc0495422666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d474e611-abfc-4805-8835-c749206e4ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae12dc6f-ec63-43a3-ad7c-8b0f91da584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639070c5-7fee-4649-94d6-e989ef439618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85901f1c-ec60-4742-a070-9f70c3386cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f224869-1725-4ecf-8adb-31f59794eb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3cf699-e7d3-4f95-ab98-cdd1f161be10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89598ab8-adc1-4663-beab-9d5d186a595f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0511ac-fca4-41df-9d1b-6ee8f5fd174e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7e27e5-36ae-43b2-93c2-a0748314f537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8839220-8232-46a6-b3c4-f3a78c6de331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e40f7c-4690-4111-88b5-252a5e2f28fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b5261d-6581-4563-a962-89e2cb6cfe23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e460c687-9533-49dc-8b30-93ab67bff267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b03328-7721-4245-833a-4e12003541c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef2d163-72b4-4b6c-be8c-b46d8db4b3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4f3189-421a-4875-ada0-5cd01c343faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f9d2b5-e2e0-47ab-9970-ed3d2cfe6982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3ebe89-bce7-445f-9152-404b984e65de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2fbd99-4c06-47ee-b6c8-53ad4c21669d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7790cdf-acb9-4b47-8f5f-bee6d35d2549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a627a2c-fdc9-442a-a3a3-4edb990ef5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0899f7-753b-4eac-a440-2443d4a3ddd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e529245e-f6d1-4dc1-b532-7d64053dddd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807fcd87-663d-4223-b248-3442ac8d4e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcb3a0f-48d6-4dcf-b056-8be8843fc4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09fa31f6-f351-4ade-bc37-6cc44250c71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a47047b-3fa4-43a3-9507-eaa0a7b09f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1617b9b-8166-4efd-9b1a-815fba9f07c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4338bfd5-7a11-4c17-a842-ef76c66d33df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397c61b0-04d7-476c-abbc-785989a411e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4e4b06-c271-4a6d-a772-267e87744c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edfe44ff-ac49-476d-bb58-f745534b73dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955f89a8-00b4-46e2-b492-6a02cb91424c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e242d7a9-df8b-49ea-9bd0-a8acb9d09e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c595fde-7d8c-4f63-bc12-27396a8fa8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210acbc6-52a3-4fd3-905a-b4e07cbfe7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96908837-2eb3-4a51-add3-a5d969d02237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d70541-5dc0-493c-a593-338252186810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f011a294-a9d7-407e-b327-71b709b170e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a9b2ae-7322-474f-add6-dc8780296642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26c971f-43cb-43d6-9462-bf4649000ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44b7ce9-412b-420f-ac2b-de440a733c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4892f3a6-4568-4b55-88c9-7f84f74a59a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb92af6-0fbf-49de-b91f-b87385c718ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4db13d-3c19-403e-9edb-27d3e609d701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab22cb6-426a-48f0-8015-5d275e09eff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9913fd41-1c41-42f2-87fa-273da1eb37b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773d2d53-81a9-4112-919f-12b47cc6c0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fb9711f-1f40-4fde-9d42-750dfe4ba1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b004735-bc33-4d4e-9365-68b735b5bdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbd69aa-45f0-404e-8ec1-1629cdccfdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2218df55-4e0a-48e7-82f8-bfcb1c0f69a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42f7f8c-b2e8-4142-84ea-fdec55936d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb040e9-d22a-4f7a-9d41-45e5cb2375bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb06f749-cffa-47e2-b879-070cf1ab1ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdcdf099-a956-4d72-879d-18534df07a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09599891-c0bd-4249-8b17-19d2c4c31c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503d1887-6a13-46fa-8265-45a1e323ef4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25012f9f-9b4c-4e53-babc-134dcc593f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fd1f66-2caf-4d17-8503-faf7444ceb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8088ae8-5188-4808-9727-022402cf123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be70dfe-cd00-4a2e-a4e2-d8b4ac73f212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0636444-e19e-4b4f-a06a-6e68d2a75ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8627e1df-eb68-4d20-92f7-7a1cadc94ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f830b73-0763-437c-b9b1-a7dd577087d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a251f8-b101-4cbd-8dcd-97293cc79aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90b529a-ce41-4fbe-b780-1dda2fbf7309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069a3e55-94de-4a53-8b5e-141db7b72c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c3759b-6fd2-4758-93d3-9490f9735828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f388b6e8-ba2f-4212-9c00-73417601a131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac8c833-05f0-47d6-bb3f-3ddef3c95e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25349d5a-0a69-4b71-bfdc-aff15a48bc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b48087f-d47e-4dae-a59d-1e41a1ea96ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad12e72-4db9-446d-8891-961f748b9e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457c868a-d962-4a5b-9605-c54f63fcef76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3712329a-800a-4af1-b035-a222de42a776
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(6192, 24), y=(6192,)
   Test:  X=(1549, 24), y=(1549,)

⚠️  Limiting training data: 6192 → 800 samples
⚠️  Limiting test data: 1549 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2504, R²: -0.0190

============================================================
🔄 Round 2 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0825 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0819, val=0.0798 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0825, val=0.0786 (↓), lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0784, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0784, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0798, val=0.0778, patience=2/15, lr=0.001000
   • Epoch  21/100: train=0.0723, val=0.0752, patience=1/15, lr=0.001000
   • Epoch  31/100: train=0.0603, val=0.0769, patience=5/15, lr=0.001000
   📉 Epoch 33: LR reduced 0.001000 → 0.000500
   📉 Epoch 41: LR reduced 0.000500 → 0.000250
   • Epoch  41/100: train=0.0469, val=0.0872, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 2 Summary - Client client_7
   Epochs: 41/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0645, RMSE=0.2540, R²=0.2105
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0660
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2482, R²: 0.0012

============================================================
🔄 Round 7 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0769 (↓), lr=0.000250
   • Epoch   2/100: train=0.0809, val=0.0768, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0767, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0767, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0805, val=0.0766, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0798, val=0.0764, patience=2/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0794, val=0.0761, patience=12/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 7 Summary - Client client_7
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0267
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0219
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 9 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0905 (↓), lr=0.000031
   • Epoch   2/100: train=0.0771, val=0.0905, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0771, val=0.0905, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0770, val=0.0905, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0770, val=0.0905, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0769, val=0.0905, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 9 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0179
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0045
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0001

============================================================
🔄 Round 12 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0841 (↓), lr=0.000008
   • Epoch   2/100: train=0.0789, val=0.0841, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0789, val=0.0841, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0788, val=0.0841, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0788, val=0.0841, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0788, val=0.0841, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 12 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0168
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0092
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2484, R²: -0.0014

📊 Round 12 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2484, R²: -0.0014

============================================================
🔄 Round 18 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0762 (↓), lr=0.000002
   • Epoch   2/100: train=0.0810, val=0.0762, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0809, val=0.0762, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0809, val=0.0762, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0809, val=0.0762, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0809, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 18 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0129
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0155
============================================================


============================================================
🔄 Round 19 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 19 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0131
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0194
============================================================


============================================================
🔄 Round 20 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 20 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0177
   Val:   Loss=0.0684, RMSE=0.2616, R²=0.0032
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2484, R²: -0.0013

============================================================
🔄 Round 21 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 21 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0161
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0102
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2484, R²: -0.0012

============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0140
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0205
============================================================


============================================================
🔄 Round 25 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 25 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0168
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0083
============================================================


============================================================
🔄 Round 26 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 26 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0121
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0209
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2484, R²: -0.0011

📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2484, R²: -0.0010

============================================================
🔄 Round 32 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 32 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0168
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0099
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2483, R²: -0.0009

📊 Round 32 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2483, R²: -0.0009

📊 Round 32 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2483, R²: -0.0008

============================================================
🔄 Round 40 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 40 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0143
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0167
============================================================


============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0189
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0006
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2483, R²: -0.0007

📊 Round 41 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0007

============================================================
🔄 Round 45 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 45 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0143
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0190
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0005

============================================================
🔄 Round 49 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 49 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0143
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0213
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0005

============================================================
🔄 Round 53 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 53 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0129
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0178
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0004

============================================================
🔄 Round 54 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 54 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0167
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0056
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0004

============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0166
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0071
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0003

============================================================
🔄 Round 56 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 56 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0148
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0151
============================================================


============================================================
🔄 Round 57 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 57 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0188
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0020
============================================================


============================================================
🔄 Round 60 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 60 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0166
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0114
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0003

============================================================
🔄 Round 61 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 61 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0165
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0058
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0002

📊 Round 61 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0002

============================================================
🔄 Round 65 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 65 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0142
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0214
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0001

📊 Round 65 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0002

📊 Round 65 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2483, R²: -0.0001

📊 Round 65 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: -0.0000

============================================================
🔄 Round 74 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 74 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0161
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0142
============================================================


============================================================
🔄 Round 76 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 76 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0175
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0074
============================================================


============================================================
🔄 Round 78 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 78 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0166
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0121
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0000

📊 Round 78 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0001

============================================================
🔄 Round 85 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 85 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0144
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0204
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0001

============================================================
🔄 Round 86 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 86 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0137
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0239
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0001

============================================================
🔄 Round 88 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 88 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0150
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0180
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0001

============================================================
🔄 Round 93 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 93 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0145
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0202
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0002

📊 Round 93 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0002

📊 Round 93 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0002

============================================================
🔄 Round 101 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 101 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0162
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0140
============================================================


============================================================
🔄 Round 103 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 103 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0150
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0134
============================================================


============================================================
🔄 Round 104 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 104 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0118
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0230
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0003

============================================================
🔄 Round 105 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 105 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0156
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0126
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0003

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

============================================================
🔄 Round 115 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 115 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0160
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0087
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

============================================================
🔄 Round 117 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 117 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0158
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0261
============================================================


============================================================
🔄 Round 119 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 119 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0156
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0206
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

============================================================
🔄 Round 122 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 122 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0166
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0111
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

📊 Round 122 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

📊 Round 122 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0004

============================================================
🔄 Round 126 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 126 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0187
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0016
============================================================


============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0143
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0179
============================================================


============================================================
🔄 Round 130 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 130 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0187
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0037
============================================================


============================================================
🔄 Round 131 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 131 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0168
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0024
============================================================


============================================================
🔄 Round 132 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 132 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0173
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0090
============================================================


============================================================
🔄 Round 134 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 134 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0148
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0168
============================================================


============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0159
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0145
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

📊 Round 138 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0153
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0066
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 144 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 144 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0147
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0189
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 145 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 145 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0141
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0270
============================================================


============================================================
🔄 Round 146 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 146 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0152
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0004
============================================================


============================================================
🔄 Round 147 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 147 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0166
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0004
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 150 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 150 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0134
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0244
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 151 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 151 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0161
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0147
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 151 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 153 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 153 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0125
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0304
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 153 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 153 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 158 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 158 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0148
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0205
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 159 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 159 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0158
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0004
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 159 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 162 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 162 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0159
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0066
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 164 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 164 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0153
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0047
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 164 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 166 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 166 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0138
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0233
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0005

============================================================
🔄 Round 171 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 171 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0171
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0112
============================================================


============================================================
🔄 Round 172 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 172 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0117
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0605
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 173 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 173 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0172
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0058
============================================================


============================================================
🔄 Round 174 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 174 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0170
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0063
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 175 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 175 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0153
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0145
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2482, R²: 0.0006

============================================================
🔄 Round 179 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 179 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0162
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0107
============================================================


============================================================
🔄 Round 180 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 180 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0151
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0189
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2482, R²: 0.0007

============================================================
🔄 Round 184 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 184 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0143
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0205
============================================================


============================================================
🔄 Round 185 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 185 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0148
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0083
============================================================


============================================================
🔄 Round 187 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 187 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0179
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0073
============================================================


============================================================
🔄 Round 190 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 190 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0132
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0026
============================================================


============================================================
🔄 Round 192 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 192 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0198
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0009
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 192 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 192 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 192 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 192 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 201 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 201 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0119
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0297
============================================================


============================================================
🔄 Round 203 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 203 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0129
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0172
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 204 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 204 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0168
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0123
============================================================


============================================================
🔄 Round 205 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 205 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0173
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0042
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 207 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 207 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0152
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0162
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

📊 Round 207 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 210 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 210 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0181
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0165
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 210 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 212 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 212 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0134
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0237
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 213 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 213 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0160
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0127
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 213 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

📊 Round 213 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 216 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 216 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0150
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0163
============================================================


============================================================
🔄 Round 220 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 220 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0167
   Val:   Loss=0.0660, RMSE=0.2568, R²=0.0121
============================================================


============================================================
🔄 Round 222 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 222 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0155
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0117
============================================================


============================================================
🔄 Round 224 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 224 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0179
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0074
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0009

============================================================
🔄 Round 226 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 226 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0161
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0034
============================================================


============================================================
🔄 Round 228 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 228 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0148
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0206
============================================================


============================================================
🔄 Round 229 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 229 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0174
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0081
============================================================


============================================================
🔄 Round 232 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 232 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0164
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0139
============================================================


============================================================
🔄 Round 233 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 233 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0160
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0161
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 239 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 239 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0133
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0217
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 240 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 240 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0142
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0204
============================================================


============================================================
🔄 Round 241 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 241 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0168
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0108
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 244 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 244 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0162
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0151
============================================================


============================================================
🔄 Round 245 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 245 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0172
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0113
============================================================


============================================================
🔄 Round 246 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 246 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0129
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0149
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 247 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 247 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0121
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0093
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 250 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 250 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0182
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0048
============================================================


============================================================
🔄 Round 251 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 251 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0155
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0164
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 253 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 253 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0169
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0073
============================================================


============================================================
🔄 Round 254 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 254 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0185
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0040
============================================================


============================================================
🔄 Round 255 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 255 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0165
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0135
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 256 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 256 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0137
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0263
============================================================


============================================================
🔄 Round 257 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 257 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0141
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0241
============================================================


============================================================
🔄 Round 258 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 258 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0154
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0122
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 258 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 258 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 258 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 266 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 266 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0146
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0131
============================================================


============================================================
🔄 Round 267 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 267 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0133
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0268
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 268 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 268 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0159
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0171
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 269 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 269 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0176
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0102
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0010

============================================================
🔄 Round 271 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0657 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 271 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0127
   Val:   Loss=0.0657, RMSE=0.2563, R²=0.0325
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 271 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 274 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 274 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0181
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0012
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 274 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 274 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 278 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 278 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0164
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0150
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

============================================================
🔄 Round 280 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 280 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0201
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0014
============================================================


============================================================
🔄 Round 281 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 281 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0104
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0135
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

============================================================
🔄 Round 282 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 282 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0148
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0154
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

📊 Round 282 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

📊 Round 282 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 289 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 289 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0162
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0047
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 291 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 291 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0167
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0121
============================================================


============================================================
🔄 Round 293 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 293 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0120
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0339
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0011

============================================================
🔄 Round 296 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 296 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0161
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0106
============================================================


============================================================
🔄 Round 299 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 299 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0171
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0216
============================================================


============================================================
🔄 Round 302 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 302 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0176
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0073
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

📊 Round 302 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

📊 Round 302 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

============================================================
🔄 Round 308 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 308 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0185
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0039
============================================================


============================================================
🔄 Round 309 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 309 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0163
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0159
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

============================================================
🔄 Round 310 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 310 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0166
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0136
============================================================


============================================================
🔄 Round 311 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 311 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0167
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0118
============================================================


============================================================
🔄 Round 313 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 313 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0162
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0149
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 315 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 315 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0116
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0293
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 315 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 315 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

============================================================
🔄 Round 320 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 320 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0142
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0225
============================================================


============================================================
🔄 Round 321 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 321 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0175
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0116
============================================================


============================================================
🔄 Round 322 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 322 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0185
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0052
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 323 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 323 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0143
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0240
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 323 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 326 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 326 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0149
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0200
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 326 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 326 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 334 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 334 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0149
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0204
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 335 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 335 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0142
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0042
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 335 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 335 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0012

📊 Round 335 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 343 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 343 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0167
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0133
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 344 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 344 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0168
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0049
============================================================


============================================================
🔄 Round 345 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 345 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0147
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0229
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 345 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 345 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 345 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 354 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 354 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0146
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0225
============================================================


============================================================
🔄 Round 355 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 355 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0153
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0200
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 357 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 357 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0151
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0190
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 357 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 357 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 357 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 367 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 367 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0183
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0073
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 369 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 369 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0163
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0055
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 372 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 372 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0145
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0083
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 372 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 374 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 374 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0138
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0181
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 376 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 376 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0167
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0102
============================================================


============================================================
🔄 Round 377 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 377 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0156
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0022
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 377 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 381 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 381 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0131
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0192
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 381 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 381 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 384 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 384 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0156
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0188
============================================================


============================================================
🔄 Round 386 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 386 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0135
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0133
============================================================


============================================================
🔄 Round 389 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 389 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0144
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0219
============================================================


============================================================
🔄 Round 390 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 390 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0153
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0203
============================================================


============================================================
🔄 Round 392 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 392 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0131
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0176
============================================================


============================================================
🔄 Round 394 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 394 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0177
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0053
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 396 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 396 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0158
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0178
============================================================


============================================================
🔄 Round 397 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 397 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0131
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0253
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 399 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 399 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0124
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0024
============================================================


============================================================
🔄 Round 401 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 401 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0172
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0127
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 406 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 406 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0127
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0150
============================================================


============================================================
🔄 Round 407 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 407 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0167
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0152
============================================================


============================================================
🔄 Round 409 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 409 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0144
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0238
============================================================


============================================================
🔄 Round 410 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 410 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0149
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0164
============================================================


============================================================
🔄 Round 413 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 413 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0169
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0118
============================================================


============================================================
🔄 Round 414 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 414 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0158
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0188
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 415 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 415 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0161
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0175
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 415 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

============================================================
🔄 Round 418 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 418 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0158
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0028
============================================================


============================================================
🔄 Round 419 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 419 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0144
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0037
============================================================


============================================================
🔄 Round 420 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 420 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0166
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0157
============================================================


============================================================
🔄 Round 424 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 424 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0146
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0224
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 424 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 426 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 426 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0122
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0279
============================================================


============================================================
🔄 Round 427 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 427 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0145
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0177
============================================================


============================================================
🔄 Round 428 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 428 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0194
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0035
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0013

📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2481, R²: 0.0014

📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 434 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 434 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0146
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0207
============================================================


============================================================
🔄 Round 435 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 435 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0175
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0045
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 436 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 436 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0190
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0049
============================================================


============================================================
🔄 Round 438 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 438 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0164
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0110
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 439 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 439 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0172
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0136
============================================================


============================================================
🔄 Round 440 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 440 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0147
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0318
============================================================


============================================================
🔄 Round 443 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 443 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0148
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0105
============================================================


============================================================
🔄 Round 445 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 445 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0166
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0110
============================================================


============================================================
🔄 Round 446 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 446 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0193
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0003
============================================================


============================================================
🔄 Round 447 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 447 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0182
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0075
============================================================


============================================================
🔄 Round 448 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 448 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0146
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0170
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 448 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 448 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 456 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 456 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0175
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0079
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 456 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 459 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 459 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0169
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0087
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 460 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 460 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0191
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0039
============================================================


============================================================
🔄 Round 461 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 461 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0128
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0069
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 461 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 466 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 466 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0142
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0218
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 468 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 468 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0151
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0223
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 468 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 474 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 474 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0167
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0110
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 474 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 479 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 479 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0165
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0111
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 481 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 481 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0197
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0142
============================================================


============================================================
🔄 Round 482 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 482 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0176
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0003
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 484 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 484 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0155
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0189
============================================================


============================================================
🔄 Round 485 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 485 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0156
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0208
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 485 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 487 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 487 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0167
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0132
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 487 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 492 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 492 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0173
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0137
============================================================


============================================================
🔄 Round 494 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 494 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0179
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0112
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 494 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 496 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 496 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0180
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0099
============================================================


============================================================
🔄 Round 497 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 497 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0144
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0219
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 500 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 500 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0156
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0199
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 502 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 502 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0166
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0163
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 504 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 504 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0124
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0315
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 506 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 506 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0208
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0020
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 507 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 507 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0165
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0165
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 507 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 507 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 507 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 516 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 516 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0158
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0184
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 516 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 523 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 523 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0167
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0217
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

📊 Round 523 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 525 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 525 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0162
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0007
============================================================


============================================================
🔄 Round 526 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 526 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0163
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0174
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0014

============================================================
🔄 Round 528 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 528 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0195
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0040
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 529 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 529 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0157
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0195
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 529 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 529 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 533 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 533 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0178
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0003
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 535 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 535 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0154
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0112
============================================================


============================================================
🔄 Round 537 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 537 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0151
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0089
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 541 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 541 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0182
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0080
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 543 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 543 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0154
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0161
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 544 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 544 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0169
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0019
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

📊 Round 544 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0015

============================================================
🔄 Round 548 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 548 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0175
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0117
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 552 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 552 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0131
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0167
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 554 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 554 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0159
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0180
============================================================


============================================================
🔄 Round 555 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 555 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0149
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0227
============================================================


============================================================
🔄 Round 557 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 557 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0123
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0169
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 557 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 557 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 569 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 569 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0183
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0054
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 569 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 572 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 572 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0177
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0011
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 573 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 573 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0168
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0156
============================================================


============================================================
🔄 Round 575 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 575 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0138
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0269
============================================================


============================================================
🔄 Round 579 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 579 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0173
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0118
============================================================


============================================================
🔄 Round 580 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 580 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0154
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0195
============================================================


============================================================
🔄 Round 581 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 581 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0132
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0282
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 581 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 581 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 584 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 584 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0143
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0247
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 584 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 588 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 588 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0172
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0016
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 588 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 590 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 590 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0177
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0127
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 593 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 593 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0205
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0051
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 595 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 595 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0183
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0087
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 595 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 595 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 602 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 602 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0160
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0159
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 605 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 605 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0181
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0076
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 606 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 606 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0170
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0152
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 606 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 606 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 610 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 610 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0167
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0121
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 611 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 611 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0156
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0082
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 613 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 613 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0190
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0048
============================================================


============================================================
🔄 Round 614 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 614 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0169
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0154
============================================================


============================================================
🔄 Round 615 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 615 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0149
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0216
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 615 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 620 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 620 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0154
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0185
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 620 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 620 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 623 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 623 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0159
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0198
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 625 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 625 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0118
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0170
============================================================


============================================================
🔄 Round 627 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 627 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0136
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0234
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 627 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 629 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 629 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0145
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0242
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 631 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 631 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0184
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0076
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 631 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 637 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 637 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0183
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0060
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 640 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 640 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0154
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0152
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 640 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 648 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 648 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0142
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0006
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 648 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 650 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 650 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0168
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0033
============================================================


============================================================
🔄 Round 651 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 651 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0137
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0185
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 654 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 654 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0134
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0246
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 660 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 660 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0146
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0210
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 660 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 670 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 670 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0161
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0183
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 670 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 670 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 673 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 673 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0164
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0056
============================================================


============================================================
🔄 Round 674 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 674 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0173
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0147
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 675 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 675 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0137
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0267
============================================================


============================================================
🔄 Round 676 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 676 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0148
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0251
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 678 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 678 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0172
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0149
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 680 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 680 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0195
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0065
============================================================


============================================================
🔄 Round 682 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 682 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0144
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0255
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 683 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 683 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0116
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0228
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 683 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 683 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 686 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 686 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0129
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0252
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

📊 Round 686 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 690 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 690 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0168
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0065
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0016

============================================================
🔄 Round 692 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 692 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0191
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0007
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 693 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 693 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0164
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0187
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 694 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 694 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0169
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0110
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 695 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 695 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0153
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0229
============================================================


============================================================
🔄 Round 696 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 696 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0143
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0161
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 701 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 701 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0187
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0068
============================================================


============================================================
🔄 Round 702 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 702 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0164
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0175
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 705 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 705 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0166
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0060
============================================================


============================================================
🔄 Round 706 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 706 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0130
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0325
============================================================


============================================================
🔄 Round 707 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 707 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0153
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0229
============================================================


============================================================
🔄 Round 708 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 708 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0163
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0187
============================================================


============================================================
🔄 Round 709 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 709 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0160
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0201
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 709 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 712 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 712 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0188
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0004
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 712 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 717 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 717 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0172
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0119
============================================================


============================================================
🔄 Round 718 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 718 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0181
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0103
============================================================


============================================================
🔄 Round 719 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 719 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0159
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0194
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 719 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

📊 Round 719 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 722 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 722 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0156
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0043
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 723 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 723 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0158
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0115
============================================================


============================================================
🔄 Round 726 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 726 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0173
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0237
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 728 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 728 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0182
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0042
============================================================


============================================================
🔄 Round 730 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 730 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0169
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0144
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 732 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 732 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0125
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0094
============================================================


============================================================
🔄 Round 733 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 733 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0171
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0149
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 734 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 734 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0178
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0090
============================================================


============================================================
🔄 Round 735 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 735 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0147
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0187
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

📊 Round 735 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 741 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 741 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0133
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0212
============================================================


============================================================
🔄 Round 742 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 742 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0179
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0082
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 745 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 745 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0130
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0247
============================================================


============================================================
🔄 Round 746 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 746 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0149
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0176
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 747 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 747 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0145
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0120
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 748 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 748 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0131
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0164
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 753 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 753 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0168
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0174
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 754 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 754 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0195
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0037
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 756 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 756 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0175
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0120
============================================================


============================================================
🔄 Round 757 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 757 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0155
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0195
============================================================


============================================================
🔄 Round 758 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 758 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0146
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0259
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

📊 Round 758 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

📊 Round 758 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 761 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 761 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0174
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0140
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 764 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 764 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0202
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0039
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 765 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 765 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0174
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0149
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 766 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 766 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0185
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0108
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0017

============================================================
🔄 Round 770 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 770 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0131
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0204
============================================================


============================================================
🔄 Round 772 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 772 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0201
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0022
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 777 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 777 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0196
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0069
============================================================


============================================================
🔄 Round 780 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 780 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0160
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0179
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 781 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 781 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0154
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0206
============================================================


============================================================
🔄 Round 782 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 782 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0182
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0115
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 782 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 788 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 788 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0155
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0085
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 794 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 794 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0180
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0120
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 796 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 796 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0175
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0145
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 797 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 797 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0204
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0052
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 797 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 800 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 800 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0141
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0132
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 802 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 802 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0143
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0242
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 803 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 803 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0202
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0005
============================================================


============================================================
🔄 Round 804 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 804 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0164
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0186
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 807 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 807 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0184
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0113
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 810 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 810 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0181
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0076
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 811 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 811 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0141
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0277
============================================================


📊 Round 811 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 812 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 812 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0138
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0269
============================================================


============================================================
🔄 Round 815 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 815 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0175
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0146
============================================================


============================================================
🔄 Round 816 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 816 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0196
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0015
============================================================


============================================================
🔄 Round 817 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 817 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0188
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0088
============================================================


📊 Round 817 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 818 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 818 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0169
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0093
============================================================


📊 Round 818 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 818 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 820 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 820 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0147
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0263
============================================================


============================================================
🔄 Round 821 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 821 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0175
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0146
============================================================


============================================================
🔄 Round 822 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 822 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0189
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0092
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

📊 Round 822 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 825 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 825 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0123
   Val:   Loss=0.0813, RMSE=0.2850, R²=0.0349
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 830 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 830 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0124
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0255
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 830 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 830 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 833 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 833 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0174
   Val:   Loss=0.0716, RMSE=0.2677, R²=-0.0038
============================================================


============================================================
🔄 Round 835 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 835 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0159
   Val:   Loss=0.0652, RMSE=0.2553, R²=0.0192
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 836 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 836 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0164
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0097
============================================================


📊 Round 836 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 837 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 837 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0163
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0181
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 840 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 840 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0191
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0060
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 841 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 841 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0179
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0139
============================================================


📊 Round 841 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

📊 Round 841 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 846 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 846 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0169
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0157
============================================================


============================================================
🔄 Round 848 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 848 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0143
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0264
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 850 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 850 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0176
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0084
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 854 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 854 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0150
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0252
============================================================


============================================================
🔄 Round 856 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 856 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0178
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0117
============================================================


📊 Round 856 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 858 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 858 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0201
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0052
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 859 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 859 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0135
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0168
============================================================


============================================================
🔄 Round 861 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 861 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0161
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0200
============================================================


============================================================
🔄 Round 862 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 862 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0151
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0200
============================================================


📊 Round 862 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

📊 Round 862 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2481, R²: 0.0018

============================================================
🔄 Round 865 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 865 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0149
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0207
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0018

============================================================
🔄 Round 866 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 866 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0172
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0150
============================================================


============================================================
🔄 Round 868 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 868 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0149
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0253
============================================================


============================================================
🔄 Round 871 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 871 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0176
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0142
============================================================


============================================================
🔄 Round 872 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 872 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0172
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0148
============================================================


============================================================
🔄 Round 873 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 873 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0167
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0088
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 875 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 875 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0164
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0082
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 876 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 876 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0167
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0129
============================================================


============================================================
🔄 Round 877 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 877 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0184
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0093
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 877 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 877 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 885 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 885 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0165
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0183
============================================================


============================================================
🔄 Round 887 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 887 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0186
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0060
============================================================


📊 Round 887 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 890 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 890 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0179
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0080
============================================================


============================================================
🔄 Round 891 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 891 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0156
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0200
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 891 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 894 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 894 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0150
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0219
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 894 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 898 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 898 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0167
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0186
============================================================


============================================================
🔄 Round 899 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 899 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0150
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0086
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 899 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 899 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 906 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 906 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0138
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0150
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 906 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 906 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 915 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 915 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0171
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0151
============================================================


============================================================
🔄 Round 916 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 916 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0209
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0050
============================================================


📊 Round 916 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 918 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 918 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0160
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0129
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 919 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 919 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0193
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0011
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 921 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 921 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0166
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0185
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 921 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 925 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 925 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0184
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0044
============================================================


============================================================
🔄 Round 927 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 927 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0166
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0194
============================================================


============================================================
🔄 Round 928 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 928 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0169
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0102
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 929 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 929 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0169
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0163
============================================================


📊 Round 929 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 931 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 931 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0171
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0098
============================================================


============================================================
🔄 Round 932 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 932 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0180
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0042
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 934 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 934 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0176
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0135
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 935 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 935 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0130
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0324
============================================================


📊 Round 935 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 937 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 937 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0199
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0045
============================================================


============================================================
🔄 Round 938 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 938 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0158
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0198
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0020

📊 Round 938 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 942 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 942 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0164
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0185
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 942 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 942 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

📊 Round 942 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 946 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 946 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0171
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0167
============================================================


============================================================
🔄 Round 947 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 947 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0151
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0118
============================================================


📊 Round 947 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2480, R²: 0.0019

============================================================
🔄 Round 948 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 948 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0171
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0172
============================================================


❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
