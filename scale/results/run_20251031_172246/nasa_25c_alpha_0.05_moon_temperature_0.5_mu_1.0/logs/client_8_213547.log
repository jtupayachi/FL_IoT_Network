[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8f8244-49e4-4434-884b-572d98846125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60952c0-e55b-4be7-8eb2-236c1da0e643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d61eac-da54-4290-b9ec-31026d5263dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8984dd9-03d1-4e73-8f54-6209799710b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee79c71c-cca0-418d-ade7-b6e73a507663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05106706-616e-437f-8e6e-5263febfe1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc2c497-8677-4fc3-8f19-400b8bc89125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33547819-1d19-4cfd-a80b-a45889fed553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7650a3b-2f4c-4404-a260-6cb1a44e03c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecd6f3d-e378-4946-b764-000e8264a4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e4f643-1804-4ea2-87e0-49d08b50f4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325ac395-4940-4146-b51a-d31275424a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0290c1-aa24-4ab7-8d87-d86f0e087e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e665a6-1427-4bb5-8938-97acdb1d6309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2597f9-18b2-4175-b47e-d0c2c612b9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50529e41-2038-4f66-b85c-b25980655279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf1a25e-88f9-45c7-bc4f-ed5288ce96cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddced3b6-a0a0-4195-9150-c5bdbdac4ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb0001a-6d4c-401c-85dd-7dfe8a004aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cfdac00-4862-4bff-bc23-b4b58427fdcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0cba1a-a20b-4c07-8170-06b7b77a4c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ebe002-89c6-4dc8-a6ca-7209dbc0282b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573d9885-9eb7-4cb4-8117-1deee705adc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acbb128-43c8-4dfb-bbc7-227ade55322b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628d07fe-d7ec-49e5-81a9-42d781a7bbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e15c3e6-3a96-460d-8528-6abf02b35640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b60451b-5c01-46b3-9028-a5615de2238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31b5067-2ff3-49c3-a1e2-fe213a462597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79b677a-4692-4d20-b6db-75e31c11a4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c0738c-0e6d-4336-a993-2210cdf7a7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c2ba47-e452-41d7-9c58-58d2dbc5b52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92caac3d-79d0-46c4-be81-c98c3902621f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213b3e3c-b13c-4780-8fdb-d2d0019ce10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686730a4-a83e-4ad8-a04d-163a0f558fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a012c2-125b-44ed-961c-27e4662b71de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f1e2fd-c3a9-4589-9fb3-ed419a251981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 126445f5-ac08-4aca-b508-aa7184791076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ee3ade-9382-40f9-a183-40034d5500d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709bf388-9150-469d-bd8a-9f7650ad4ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918a3bdb-7761-49bb-ade9-0f41a8882f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13604897-9dae-44e1-8dbd-924f76086c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1508ce5e-7bec-42da-a31d-c2f89b5ada26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e045d567-a920-4f37-a592-44dc346e9bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ec8146-900a-4fd3-9f11-5a543569084b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d715f4b-fd16-4e30-bed9-1a764bd07b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7aca26-3f5f-45bf-b3a3-2e9b3edac6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee70a21-0d83-4bd7-a866-b76a1f5e9aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0b17bd-f0c6-42f1-b727-05609a5a8353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fd64743-615e-4355-b547-8853a83b531d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa8418d-ee0f-4a0a-9cf9-2d47232fffb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2152da-48c8-47c1-93f6-f85f7ee0148d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1cd6ee-5333-4e36-bc82-5a9ecc62de66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7d68ee-2971-4783-9234-20e68a9b31b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5450d8-20c5-4a06-9bd9-28e4988ad338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73dc1cd-e29c-4641-b281-116bf61f5ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d623c896-8bc1-49ca-a3b5-9cb1d036bcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc32412-d839-4491-901c-b7192d9dd8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fdeb4a-3d24-4876-92cb-cdb0aa8371d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dae9f59-39ee-4c83-8639-f214107d7d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41c10c6-dd72-45c7-8fd2-bc0e7edc56f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda13405-eb71-49e0-82f5-e60ac31a2252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c016fc-5854-4712-adea-e00aadfeca8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9031343d-57ff-4e20-aae5-1a34a47c6440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfabd896-260c-4e66-9eb2-53c1853358e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cfe139-b97b-4333-b104-8a243bacfd65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf6efd62-799b-4c71-aa8f-527c470a2c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab884cbe-f316-4d23-b874-2ca26e7d8671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ca22d1-4133-4789-aec8-97bcad240e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31780038-3ca3-4c4f-8a91-56164c1a565e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a353a1ca-f9e4-4b98-b279-9d0c3a66c3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3565a2dd-8f31-4808-b040-a8cf749bf4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ee0968-038f-4d88-a433-b5534cfbcbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b80099-32b3-4567-ab20-681ceac25fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9517fd8c-2639-471c-958f-8b1c9447d0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff62ba5-06db-4b9c-b208-c3e0f7750723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd1faa2-959d-4e92-a362-faa2261f8a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4254d1-4438-4383-b7d3-e1c9ecc251c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616623bb-1472-4104-a0e3-4a797e9be3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b0a5d8-bdbc-49a2-9deb-7268bbb5bfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d638955d-1132-475d-9574-0663ff3e5b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d575075-ff7c-40af-b639-a770b830d2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a4558a-e4f1-4861-8d03-e00cf2f03a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f013df3-724d-4704-8f7f-5bc3c46d20e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6642f26b-12e8-4847-94ea-0bf8966754e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70de35d2-ca82-4a3c-9cae-cdc23d5a15ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2671aff6-f941-4d29-97c1-6218204415fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72eb2eb8-3358-4fc8-b56f-45503c7d3e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261b3a03-b681-4a4d-9f3b-7247e1581252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fae364e-18bd-4d30-9c96-6902c03b78cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449e2ebf-6072-445b-90fb-da908e64ff3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbcc7f48-8112-44ea-8ce2-9b2b00f32a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7e0f53-d3c1-4ac0-8467-f9cc0375c4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51c40cf-b2e7-4b5e-8347-36cb51f5daf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d0a335-52ea-41ed-af19-f67a93d55e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43490d4e-dff8-49a5-972c-0cd6b06f241c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c809c083-849a-440d-86c4-7b9c47883ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48541503-6987-49c1-adff-d589ee0ec2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67fe322e-ca14-4c8a-a19d-04b67d39436b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3b6bf0-f648-4024-a2e2-1480b76fbdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef2a969-5e2b-47a1-8c6f-d542ce97d2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54798096-4d64-49d5-976d-ce5a7d397589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60be98c5-242e-4646-a968-a91720f8532a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba80520e-f5ff-4a3a-990f-324ad8ef66a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85342b2-1afc-45de-81f6-240593ca0a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72c8a7dd-3ddf-44ed-aca0-d42b9ee2c1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5beaa705-e7b1-4152-8fd7-85c6998b7909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7058e9-e069-40b0-9204-c4faac05e678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d6e77e8-9a3f-4c95-9dc4-3d89b3c3650f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7567b3-ffc8-43fc-9bd0-ed5ae5e27eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344c163c-c49a-437e-9876-1a4cb619f8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ac6192-40c6-43aa-9815-b817c79d4107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a010e114-61df-4f3c-8f6d-b6ae77d83544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac9156f-f401-4ca5-9693-e9c6165ba551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f2e80a-a7a0-4515-b27e-1e27f2a45234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069f679f-44a0-4729-aa08-f455b170dcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a444934f-70de-442d-9f95-fae4252ad4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b888936f-c9ec-4d1a-9927-2fb897bba3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eccf9f6-14d8-4451-a989-709ab8b8f54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5cb936-33ef-4d06-847e-c6c734cded65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5057c6-60bc-4c32-b6ce-6b50e3bd8948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c568ec9-22c8-4e4a-b90f-c0c51d271d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95c207b-7b7b-4333-bbc5-7d93043c29fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49cd8ac6-8f4b-4283-acb8-321f661334ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad646504-1bb0-4e77-b7fd-9e6c0fe9feff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3556fff-b8be-4772-bd10-9393ec5de70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4467760f-08d0-4fe8-8659-85384e1aae9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f439a1b2-6277-4ea8-a037-a87551275ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b70bb58-810c-494b-beea-f4cdb11a198c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5e0eca-479e-4ab3-bdb5-6e9fc6f1b2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9035747e-712b-4ba9-b52f-45b114f1f267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e691f174-14d3-4bd0-8a43-3cbfea42c66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6424f005-54ab-4f7a-8028-05823c71df4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79ea2ba-d039-44b2-b2db-464b456b39d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93d736f-73e4-4c01-aebe-b7fff394d6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4d5d90-ee64-45f4-929e-9b017549e6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c18360-9671-4daa-ac66-697ddcce7daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a90ccfd7-d7fd-4d4c-93a8-32e69ef243c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f093bf-9a4d-4be7-9022-bc3b0e66fcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6519ded1-7f8a-4fad-aed2-02d7365f91bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2bc0326-aa0f-4243-b3e6-dd8d63c834c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7045e987-23de-486a-89e3-0f8e84838e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28139dac-cc84-4b15-a3ce-7856119cbbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca78b937-a182-40dd-b14f-7cdecaf2aba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdf0d52-9eaf-4c50-9fc5-52b6e0d50ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47777b4-8e64-40c0-b056-d73a9c0ce16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a365895-2522-4939-876e-ef89aeeaaf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ec0438-c6ad-4a42-95d9-3f2fba2e1298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc83ef6-35f7-41af-a1bd-8cee4e2fc1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f50311-5ce3-44b2-8187-6586946481b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b362d1c-3f16-41a2-81f7-fdd11791f643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167fee2f-f74c-4776-b4c7-3d274721511a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e88e47c-af33-4055-8198-10e204614445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91e795f-5dda-4f18-af23-ab69fffb21a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31c9865-6b8a-4580-92dd-518b1a550ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e047612-75e1-4f42-8552-ad75ba2c4325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f506619-4186-40f7-843a-d5cc42e48881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e1d410-5fdf-427f-bd48-8fb7cda367a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f11e49f-d8ef-4514-9b51-1ff843c8816d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e30e1e-11cc-4c62-903d-9881d3953736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ad5c3a-12a0-4b54-bbdb-0c79a7fdceb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6258bca-a19a-447e-bdcd-fa957ed8ab32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85c1948-48ea-4822-a1a7-dc3dd7857c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469d1b5f-6377-4920-a11f-5fd3b91682d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167a1437-e1a2-42ba-b7f0-df548dc94099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c05d91-d26b-4943-be2e-3a10a81f6d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e22d4f-385f-413c-a86d-827f894bf36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e9e66e-c422-44f0-b062-82d592542326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc4cbf9-b845-402c-9715-2bb734bdf6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25cbc413-3202-4d5a-b6b6-d9b8a89ec0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e3d170-6d1c-44ca-b206-17619a1d36fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50065451-4ffb-42f8-bbc6-714dc38a4632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fec872-8241-4985-bc11-5dda90fe77c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cc13c0-470a-4210-a1b1-c24a33525d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31eeffe-86c8-402a-973f-524c7ab5e728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61818353-73bc-4710-8ee9-2a0cee98be75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6843da3a-55a0-4d1e-9457-de512058c9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b007a47-5838-415b-8783-2e4aa1a268ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed62671-843c-4136-a16f-74b6c1b790fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be6dbb3-cb94-435b-8d6d-a4d47511acd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5deac2c-ca21-4792-92e7-808f481a4a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be43d124-81f4-4a05-af8d-fcbdf7c3e839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 519aa9a6-b8ae-47a7-be66-13193f43a9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950ab941-2b65-49e1-862d-0e464b63db1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8ccc53-8109-4cff-b2d1-cf8ad4a4abae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7efc48e-4f28-420d-bf16-3b3f6c847628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d5a11b-2616-4a5f-969a-235908cfeaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0045cdc0-091e-4a1b-b80d-33e30c8cb3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8251e7-6abe-4ddd-b1ce-ac307f75b003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033999e6-6dea-44e2-b771-6e833e5eddf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb1ee96-f9a2-4715-a7d3-4c24c5d4f05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661029d7-ce84-4fdf-8c61-ccc3e3628243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166a87ee-6b6e-46e1-9183-4dd2255eb94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9e9794-dd71-42bd-8b80-bbd326355c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186e8892-17e9-4a47-bbf5-46e6d93f3418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae759eb0-6d90-4762-9fda-800dd5d9c127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b32b80-5ba2-4d13-86dc-f939089cb2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce224c45-b8f4-44f4-a0d4-a58722627e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee0cc37-a471-4aba-99cc-0b15775fc3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a255f9-4f96-42b8-aff7-aaed858a8374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda1ea93-e710-4339-b5ff-197227a57dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af4375e-8ca5-4732-932f-452dd6aab828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cb9f32-07d8-470b-bcf4-3da1e2919185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d131d1c-339d-412a-8d55-52848dafe301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd5d93e1-bb7d-4fc4-abda-3509c1e3a223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d1d83d-e030-4ccb-8ba3-e5ee63b2c36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cbcd58-bc2c-4b07-8401-9b8b35354b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27218da-16b4-4e2b-8255-88c7fb5d5606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab75eaa3-9150-4ae7-9520-711d15c81540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fa5aaf-0dd4-4891-93a4-7e5994381047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35291f71-a30b-44e4-9821-ba360a77992e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056520a3-82eb-4882-af9d-eee92e9638dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f74040-ce20-4413-9fda-d40ddb660f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70a5c8c-a3a3-4e61-9dc5-2ffa26d5f06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa89aba5-ede0-4630-b1e5-0d516bbbb4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5beb89e-7a9f-4daa-8e53-b52e20dcb1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122635bb-db45-4ff4-a417-02281abe57b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a223fcf-41a7-4178-affe-39e4553316b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d57bb6b-76f2-4f41-80a2-c68c993f72c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f2243b-1715-4269-ad37-a4fc8346557f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e025176d-76e0-4b56-8b19-f54d76271606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c79b67-4ffb-4d04-9211-8949d85c058e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd71fba6-6362-4395-b97f-72d74e28acf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6a2876-a335-48d0-8aa3-76cd65f8f4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb46b67-5062-4a83-a744-5d83cea0fc26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3c0509-2687-4741-b088-f648341722d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552772bf-c3b2-448c-b46c-c5b2d35194a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6507f0-a244-4e63-874e-84636f787620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4884d3c3-1577-4c6c-bb75-672c64db288c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4fb4c5e-0de7-4b68-8dc1-d352acca9574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fb9cd6-ca28-422f-aec6-14cb12adf946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f687d76b-fb64-410a-9fe0-4a63c2f1b469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aba37bbd-5ed7-4602-bdcb-18031c481327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b82b187e-bfbc-40fe-b6a2-743f58ba4f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2ca675-71c3-4f37-9533-2a5329eb6997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9560ec6f-d618-4c18-a9e6-f2d855859e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e203c6c1-db48-4340-a26b-7a697dc947d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc90865-8aa9-4a19-89d3-632360c793a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c2f54f-9174-45d6-9b76-c92831d328c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1694fc8-b4f3-4525-96de-d2e105e93e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e294e06-5192-4735-903e-b9e9140d5724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbd6f18-996f-4b3c-b298-c424a389eab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a56ba40-9bf6-4848-b463-a4f4a41359f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e830ab7-4d66-4059-b2e0-c5b9df13808b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e1dfcdc-000c-499d-a337-a3313be621bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ca4e16-61c3-46d2-a39f-88aa4ca9a56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7774d38-cc87-472c-87e0-91f50dd59e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a983be6d-def2-4042-9ba7-a7ee128dd941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9ca6a1-7727-4ef2-8352-450e43b0d35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec085108-d626-4976-8797-07c08f4f3f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40278f1-c479-4a79-a6eb-0fef1043136b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1d4a07-54e9-4d47-8ec7-5e4e869f43b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 719af43b-a6e5-4ed6-94e8-4e68f967bb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2064fde2-7886-4d55-a74d-1ac912b1d1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3a896e-9298-499a-995e-2c880090ac42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f9d221-c37f-4119-a4bc-be224a24e966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc89f705-2a12-40c7-b95b-2edb68bb93f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7041ad91-bf6b-47eb-9e1a-f6516c94a5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ebe0c9-becd-4a2a-b362-579b843859b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977cd5b5-8865-4134-994d-66edb7280f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddebee72-30f6-4dd9-ab10-5760d86f065e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97da63d-a63a-4804-bb4e-db7ebf41c9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a4663a-a3c1-4dd0-9881-9c664d165305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1d05a9-8488-47d1-bcdf-01f8a8cb5abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4823b8f2-675b-41b5-a400-51846b713617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8f5297-36e1-4624-a459-ec678f024eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5944a891-1428-4f4d-a7f0-03082c715124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1c0761-6859-4ead-9308-ba3636f36c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896ded63-5869-4a9b-99bf-5c188aff82c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c288308-0ce0-4bac-a959-f7a6d8a46c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62ab29c-8103-463c-a31b-5214e6e06663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6528fc2-a0e5-49c7-a7c8-779e19fb22c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2a3a25-aab9-467f-844f-6738397d3f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9efb455-93d9-4898-aae9-b7a4e682e828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55ea362-2e59-4aad-958a-52958ebfebdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53dbf6e5-f255-4564-8639-1036028a500e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcee1711-1c98-49b9-9b12-1a0ac392cfa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52ca312-21bd-4e07-8819-253691ffe9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411782bd-de27-4ea8-b59f-ccecbd9690df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a367c8-a534-436d-87dc-4ed8a0c16e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c031aba3-eb05-4717-b408-4fd0c45811d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94bc44f-873a-4bf3-9983-910525bd9f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab7e0b4-2397-4777-933c-b68f12b9326e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f52ebc8-6535-4ad8-87c7-dccbe34c2729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7095733-e25a-4f3c-b37e-804a67d4015b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3b4790-ebb1-4756-9861-fbd4c1a7854f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0b8ab5-f288-435d-8115-f0f5ce8ecd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abfdc1c-cc90-420d-95d3-3ec40edae3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96cffd6b-eb09-4c1b-af30-8227be65af91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9357e695-6aa0-4996-89ca-ea4ce1c66dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240ff062-8b76-4181-99ff-fa30f079e6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2444dbcb-7254-4e61-a308-1579b6aca51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbfa976b-557c-41ec-a8d6-0721df1f0b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ac7fb45-a89a-4a76-b8d7-90ead9492952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a484d8-6575-4d88-b3ee-382b7fb723a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ebb839-5ba8-449b-89bf-8b225bfe17f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c9f12b-f199-4115-8b77-2a8d6be482de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7da2aa4-d1ce-4465-a619-d81c624621ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7dd76b4-6111-437f-aace-c871cc124bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ad05a9-f770-4a64-91a2-ec7105430b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b75fce-553d-463f-81ee-9b7da01bd0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f398ec4f-94e5-469a-bd2f-2fe26ee5c7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796984fe-7066-434f-850c-d359e5318183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e18de5-82ff-4ecf-a522-3c35a460bdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06db228-9754-4224-8e1f-828daac9d9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251a18da-962b-4b9b-bad8-a38377368878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d37255-fc7d-40aa-acbf-c4fbfbfa8e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e699455-b688-435d-8a0b-01bca5ab891e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a58b335-e177-4361-ba68-d98de94a0d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8529d124-4327-4158-ac4d-59e5131b2398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac50591-d7ac-4777-a4fe-956a298926c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b697cf6-69f8-4bd5-8670-b42e3c639022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c797c26d-3f03-4a10-917d-75e00cd2555e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1517ed15-8eb6-4a8b-a6d1-bdb877eb5133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782ec054-e957-4904-8f70-f5d5e038c2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64791b72-9e25-43b3-8a4e-df9c36d94209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325db836-e8ca-4807-a13d-ebe7b2125cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1e12e5-70f2-4ecb-886f-3e92fd56546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a8b5ec5-e470-4da0-831c-eace0039e82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6c6bcf-c9ee-46fe-9297-7debdde1426c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b75c9f8-be61-451c-802b-dfaa918c3acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94e57cb-e2a3-4dd2-a4a0-25a869bed605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590f69c7-0467-4856-93ec-fe0f2615b82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9057958-0f49-4199-857e-65295ff97671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb516794-c30b-4fc3-aa54-a6ff2eb658e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d57f372-26b3-472c-a641-3fc5632432dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5ebcf7-6423-4a56-b687-2f97db99bbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941d9f09-7787-4be1-a174-0d580578efe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc77791-dc22-4d75-9050-f14e464409f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13db29a5-5707-436c-bf44-c4ca8b67ce54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e14080-fdc5-40b5-a2f1-49ec08cc852f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d2c5ae-c89f-43f6-a709-b48877a30978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa71b3f-2e1d-4ec7-b93e-a9b60ac40b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e1142e-54b3-4ed5-b2e8-17eaded1cdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6c9a56-93d4-4fca-9bf4-c87b4d75155e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ea2a33-deff-463c-8812-73c569703771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c576b779-186b-40f9-a4dc-67911d64235f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a135e69e-8252-4931-b738-6eeb8e9394ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8e9f69-712a-40fb-924c-e452a436a4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6767cf0-dfab-4ebe-9069-0e67470bfdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1b0859-dc1f-4d08-a7ed-4b3049dcc52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faaf2cd1-9011-4a72-bc09-fa914be508a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4a0b42-2ab5-41c6-8dab-25f6f74312a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b304328-2f40-49e3-8523-b03f33364536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9806aa96-999e-4df6-80f0-67345ccd4998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97217db6-af5e-40ea-9737-b10a777fcf3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0535219e-362b-49a0-809d-3e782564ccd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81581ea4-57dc-4b5e-910a-709bc6b51b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab1fc45-92cb-40a9-9970-96074fb144de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28cda21-9324-49b4-8e32-44bd6a53171f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4c898a-a700-4055-859f-f4fec7fea9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae9556d-9b72-4e86-8704-5afd33a4b77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe9f67b-e82b-4c46-bfea-b07d6bb98c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2c25c2-ae9e-45ae-999c-4fd7c446f1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5091f89-c501-455d-9349-2ddc43ec7361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef0edc3a-6b51-43c7-9095-581615520a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c76b92-c1a2-40c7-acd6-b8658d27f85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd432fac-96eb-4d4c-bae0-de461a0fb3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b99be54-8b80-45e5-a753-48178dd9b313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63b9974-a2d1-484c-86ef-2c6e98147396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d015372-6647-4f38-a047-9f71f2b718ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fcf8e0-f223-4713-a4ab-72a3573f2aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25cef6b6-f0c7-46ba-a042-cbf03c0d6366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70c777c-571c-4ceb-8929-395c69047bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e76e972-ec25-4923-83cf-c278d6a1fb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fcf2ddd-2ea5-4261-a2df-1489980d0550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ac8e80-1adf-46ec-aca0-6f4a5a50c1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487c557b-3ad9-4601-a7e5-0e9d59bccbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2986d96-5f85-41e5-aaae-201886c5f541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b32f8da-c384-4b94-aed6-f536cc5feccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a54aaa-8534-4dea-af5e-2325a6536421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a47ebb-a271-40ae-b64a-8bdda1dbf9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c95e3b0-ae7c-4c4b-9748-269732a80c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d6bdd5-9fcd-4af7-a4cb-0b3070aebe8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e5e4e1-ab0b-4451-abf1-54fc360b5941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047d36e8-1da0-48e9-a4da-040a5761b652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ae1aac-46cb-43dd-900d-6cf13e02bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e623117-5866-48ae-abf4-c2fbfff5ca98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a19bb6-c008-4a6f-8857-69eb2ab1025a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00efc7bc-0904-4e77-94df-d3ae427617aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8b38c5-54be-459e-bc60-10d56b155efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5436fe22-e078-41ea-a75c-d197339ceb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 528ab362-36d6-4372-a67b-265338f0db7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c59a024-9b8b-4cc2-884d-680444176740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9911aa60-50ae-4e1c-8b35-69b2a0413481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e194498f-fc25-431e-821c-114e71d0b59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200b82b6-4c00-403e-923d-e50da19c70f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9620e1-f9d7-4c7c-a78d-9b70fbe1779f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6a97e8-e5c1-423f-9fb0-628826b042aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b8e287-32af-4d17-892b-7d6c84752268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def789c7-5d5a-430b-a27c-0c4ed674116f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77f2f26d-5060-4743-b1bb-6f64a6565346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e53c6b-847d-4f39-bb53-84c2712024e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e875181-eb2f-44dc-9ef0-d073b0519239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642b9fcd-59a8-4a1d-bd90-2ed96ac13a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008b4e22-3f52-43da-8600-d38d23c935d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b190acc-aa4f-4e3f-b6af-b0c320d59984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1901917e-c62b-451d-b4db-0ea43de1d201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbae381f-7f26-465c-b5f4-a7995f9985c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 109e4381-fd5d-4e0b-979c-f722a9ad5794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5080e662-e67d-4d76-b779-e5cf85c8ee36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e662f0-8a0c-4d7e-a4e8-38d28f17005d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d58191a-c698-4b43-9571-2a0d1f5513ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088e79f4-41ed-4736-bce4-55f370045a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9356126e-851c-49b4-9205-9f4c26d46e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3625a4c-d6a8-4b9e-93cd-42fe24cf710d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c454ec8-fb00-427b-9771-3ef652d428e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73076caa-b1ed-4e29-941b-43fbbdbb17ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86dd4266-8308-4efc-aee2-d3860054c5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471e106c-4e86-44a0-a284-150c8d8d471c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3ffc78-7938-4196-b04a-454323fcd114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c098eb41-9039-4ebb-83aa-43e43213714c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02be316-abd3-4750-826f-f357817a2ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919e0a6d-5484-4eb3-9801-13fff6bdaaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05c33ff-4823-48fc-b0d5-4f65c51aa54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5704a2c3-e332-42e9-aec6-e512a1292cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f25b4d0-9663-464b-b3e8-549b6fc12076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00cd3a01-e1e0-4d7e-a5ab-4fbe53850f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b11a826-6d33-4f08-95cd-926e8bc66f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba5f411-f85c-4081-a9c6-11f13503dfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e7df42-2401-44ec-9c51-791acab6ffbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0d905e-6a0e-45a6-b4fb-d5994899ca9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac0bf82-d01c-4851-b484-38b27d8f383b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff7b620-def8-4a38-bd22-941930de1900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1a2415-75e2-4de6-aae4-89ab69a5c511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f408d4b-70e9-437d-b0c3-5c99b69e6b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05380db-bfbc-4f1c-82d0-e734ef40a748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219ab1a9-104a-4079-b2b5-1b8b26af0f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c04afbe-b740-434d-963a-d19b0bd29cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b094837e-ac0e-42a3-b2ba-77bdf264ebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55caddb3-eb3e-492e-9238-6c95bec7b46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bca3de-8990-4b19-bb53-011bb80f2c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5550273a-54c5-4719-9e05-1464cc2ae278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51ad215-dd73-4b66-8b6f-d449927a3c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a11691-f802-4953-9ca4-e0592d05ea24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1220af9f-ced2-4cff-8fc3-08342ebd97b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bacb4a6-15ff-43ae-8179-c3d0236cf4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed8a448-6f02-4d72-ae5d-a0daaed10dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13747fc-06b6-45e1-b7b2-5b3f42aa5055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b734150-df10-4c3c-a3ae-686097b21df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316dd6a9-d0ed-4fc9-bf94-9248c6c34280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb34321-57ef-4b16-b8f2-59af8bd72ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08e9e3b-d060-4ba0-9d27-4764d9d94a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d228658-382f-4a1d-b4bb-6569cd5f35ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15309cc5-bb0b-4bcc-bdec-b87e7d454d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fdc971-da19-4b7a-8256-3e66b71f2205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1778c7ae-3db2-4777-a53a-52c0847ee7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ddf8649-3780-447f-b98d-7a707072b4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2505491e-6f4e-4432-8f59-1dd3d6bc6dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98580ebd-4080-4fde-9d57-331985e9ad32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5578a962-3ada-4d9d-8f03-d04c5233c3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988ec703-365d-408d-ad1b-993dd72d8de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d01e29a-04b3-4052-bc72-5f15db09ee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94db239-c8fa-47cf-a763-d041b6872a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb3c915-278c-4dcf-b1cd-7b5ad1673d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a849fa-636c-4c28-b80e-f3c466abd738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b05bde21-9f93-4b09-ae49-b8558ad74215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9abc8fa-bf83-46ee-ab2b-7dab2a89f6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e975bd-0c4f-425f-b376-c4ee3f9746ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eca4822-8b7d-4462-b83b-3ff01c03107b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1560a1f2-8680-42fd-8bc1-99023a532705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde1614a-d836-4e54-a670-0c2a4e446eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb90bc3-2877-48fb-81d1-4becbbe02761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c399c5f2-4f28-4a48-a63b-30819df7673b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a2633d-dfbb-49a3-8ac7-b182be744c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3daad142-63f2-4a06-ad1f-cdc64d261a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bbd3a00-1683-411e-97fa-d7a281bb54fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d92cff5-a5df-458b-8302-b5355dee8f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ace8666-08d8-48ba-a612-a1e0edd9b155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feec7cac-ee07-47c9-a06f-a21109a10736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d3dcea-d911-476a-9666-e611a2ae9a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a8d956-e6a2-47d6-bee6-e8bd9f0494cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c215d23-aa01-46b2-b07a-e4e7ec0ea337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4126806b-8ab8-4902-910f-48436e3e12a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f76d04-e45a-435e-8b51-81ac78eab6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77606a0-4462-448d-8e73-b783330e3aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35426795-fa17-46ea-8fd5-2c994160c622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f0aff4-24f7-48d3-a453-64b5f91836c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da130ea-d925-42eb-bb8e-64222a4cd6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ef4d4f-4533-49e3-8634-82bce8d74c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22921aef-6de5-415b-addc-7564eb244e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d4d421-2260-43fc-9204-7640425975e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0a975e-9f9b-41d1-9dee-c83740fbde5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f79b14-5de0-49ef-9c87-3e2249b9e5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ec9cf4-3d77-4491-b707-200d940afad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1688f98e-a309-40a4-a0ac-2f3a6b6770b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22e497a-bc5d-40d4-b0ed-230eecd641b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae082df4-5739-44d1-b352-8b5866045995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b4e3e4-779b-4b25-be31-6495163e9873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccaf887d-7c0d-4a69-8824-dd59e5727b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bacbb2e-8214-41bf-952d-ae285be2fd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ce7376-9ea7-4f4e-bc90-5841eef37f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943c5eb0-9cb9-4423-a799-30f5bdb8d731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d4a702-4925-4d9f-acb5-67eb6a732c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1774b78d-1ddf-412f-b28b-60f8a2e4fe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9098e32c-bb0e-4500-8ddd-357badc46827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc1adf9-57f5-4e42-b6d7-4e18bf3af4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7542a6cd-7374-4f2c-9de5-70922f49d48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9009bc9-2afe-4516-bcc1-339353d339f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ea6e8f-a4dd-4859-941a-2f47f91bfd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60979fe2-d053-4617-91b0-57abaa2fce2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc501c71-4231-4269-b7bf-ac9f242d01fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a5490d-bbf7-4b5f-a16d-8a35c717dad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b5d76e-a767-4591-a2e1-be771f77dcf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9a8e56-cb18-48ed-88bc-c01c895394d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce8b9f9-8e56-45e4-a1b5-4113701ccb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c915ecf4-49d0-468a-885e-15ed0e774712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70f9416-91d9-4984-b1c3-27814c2b3f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9719f147-f6b7-444a-a62f-60f43aed6c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e97cbc6-0cac-428c-903d-059f8bf6516e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731fd5ea-2cc1-4497-a65c-16e6e38ace9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3260e8b-f7f6-4516-a5cb-664a0cf54a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27f0489-97f1-4cd3-8b92-b7b4877baec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbafd5a0-ae25-49cc-a4f2-25c172c8210b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5606e154-91c6-44f8-8cfb-0426c8a0069b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551b7e6f-5bd9-4734-af81-3dcbbd0735bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2c82a8-53d4-4bdf-80b4-0610122695dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6554f4ac-c059-4d00-8d6d-19c8b39311e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1f4ef6-d464-445f-b58d-f92200c982e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453700a7-3109-401a-abeb-7247ee3860e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b175322-7a4e-430f-8c97-cb649ac9ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57363fa9-08c0-48aa-aad5-5ef777bc9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4731eaf5-ebc3-469f-98bc-922cea3a394f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8652adcb-161b-4d68-9aaa-a26cacc20fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd987cf7-99d2-4d78-89cb-c8b88549d3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cf435e-8aef-44f9-8278-582d85548e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b63797-5f5c-464e-85c9-8a96abd16f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d50290-e201-43bb-a28d-8da9cb57592c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a256a0-adc7-4acf-80a8-cfaa55f88bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a9dc7b-5b3e-41e4-9095-3acff25ad465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ce1ae8-fabe-4e64-b578-e34601c2eb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c74cb8-c079-4f96-b9a9-d95750904b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b211677-b00a-4f96-bce5-ccd777385789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe9de6d-2cf5-4abe-b513-41e214b3a010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a0d981-0d4e-4ec8-aa71-a788bb542226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8823369a-e9d2-4420-b22a-114e2db87ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c886948-5b99-4694-8601-b4e9f696ac49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e330cf8-6e39-4c4a-85ef-c20af6292a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28858853-e4ad-4012-93ad-125390b1af3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50fc0772-1477-4672-952f-bdf6f6f0d7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e055ae-a38a-4328-bcf9-9e661a6a3b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085a7ff8-ad6e-4bf9-bdda-08585e3b2ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac34218-d2c5-48d6-920a-2fa5d5b8a811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d418cb-8d31-4098-8334-fcc6347a6b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436d99af-1833-4bdc-8162-31f5386304a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6839e6-23b0-4ea1-a9ee-933b18ab6c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed80212-8c72-4eee-b156-8ec57df3ad38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1719b6-54de-4b3b-8d32-7abceaf6f2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16038222-532b-4d97-b539-d88c32e8c3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411f2d2a-b665-4719-92f3-5d3565c68f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f05f97-c16a-460b-8ade-a6a4ad21dc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e520046-6e52-4c63-8fb8-0bcceda2d666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7580ad5-efdd-4460-a22a-fbda8ddd62a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d57429c-2ab9-40b5-ad58-d154c9028f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75e521b-876c-4cd8-9904-a4c367c7cbee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9581d1-5c2f-4ac2-ace2-eef333c2985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa61d84-796b-434b-b672-29b4677e4872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df88093-0e8b-4833-a57a-828698e1064b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ad617b-848e-4322-adae-3b2ef89fedac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c36e2c-da4a-4e55-9c6a-3ad3d53d16f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bc515d-bde7-4455-9efb-486c0511afec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a6068a1-7033-41a8-b1bc-dab16a0b88b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c949da7c-08f7-4792-b6c5-e0955421c42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc5b488-047c-44c2-84bb-3da58f15e8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50a2894-51e8-45a3-a3e6-49ec219093d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c784195-4539-4659-9cf7-bc04212ef315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e117a2-f624-4d71-8621-a6a57a8cda4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a52db506-5b49-486e-8a47-6dbe28bb6a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be66cc9-2bed-4dbb-8d68-dd420d5ce7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50463488-033a-4155-8aca-cf8e6aa133e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68842c1-3604-45b0-b222-afe56f0a6fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c19de6-6a2c-495f-87b4-57373cc0dabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8feeab0-f652-491b-9aad-33eb529ad45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ba263d-12f8-4bed-a16e-63edf952e208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05edfe4c-6fca-40af-b404-b03157aabcd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c84b59e6-831d-4dfa-acef-13e5272d2e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd62158-30e7-454e-b400-aea0b7ed9efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4e5c3c-db23-482d-b4ae-33b655dadf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33655bf4-2dcd-4cad-9b48-34a099175a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7aa519-d8da-489a-96fe-24669cf93723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d4c95f-93f2-4dd9-a58c-7ffc038e6034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffe0080-314f-44f7-aa13-e7131bc16c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79a66aa-ff0d-43eb-a3fa-6258dcfae43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ac9133-9cfe-4396-919d-8861c4a583c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e17095-8331-4649-a9e3-02ec56571be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4654dec7-687f-4ac8-a014-c10ff584d9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd74c34e-189b-4724-9a0c-c5dce9fbfb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4cddf6-6a19-4961-b747-a94fed69d4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa82e09-596d-434b-ba48-502640b0634c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ecc0e0-ff60-4bd4-9863-04518e03fc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb6e922-a838-4d48-a29d-683fa34ef485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f51172-dd35-413c-a30a-70fe8235e409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01eaa1f9-ba69-414f-a0aa-f9740d6a585c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca733a3-5cd6-4046-889c-668b62ef36e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c2f57c-5be5-4013-b586-57954d3a7f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1287d8-1212-4a05-9afe-93aaa71e7536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91b9f64-ec77-4fea-b3f3-35b168251289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb368609-1a52-4836-8c73-2c618f1e5b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2e3ba9-5615-4c8e-a956-7a9d16d120c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39b8fe4-39f5-42f4-87df-31b2acfd51de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6777f2a4-d8b9-422d-ab72-75f9ef810d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e801ef0a-f3d1-493a-8430-0a7ed901d03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23a98e44-809b-49de-ade0-ede36644539f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cdd9e71-c99c-41f6-85b3-e36849bfa275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b0cb94-320a-4b31-a777-51e4e62a9945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6e8542-1335-4a80-ac6a-6621396c4009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743043c3-7018-4b22-9bf9-e6d8de98393b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3abbc5-8985-46d2-84b8-91a805ab9ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05deb927-0cf8-4b91-a0f9-c8440222893c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c50aeba-0663-4251-8394-8ece931a8365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c096aa-2094-4f4e-910b-02b2937047da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e58088a-1fb1-4ffc-8869-305d6fb8160d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac81efcb-b326-4e52-9817-d91fc36ad29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504b9ad6-95ff-4afd-8a4a-dd0f5e0ea9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d5a5b5-4d31-4f40-8117-76bbc46a40ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7f3fa6-cd43-4476-a905-6a9210824137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6404a9-fbde-4ad4-bedc-6e3ec063dcce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5edb342e-aad2-41b0-b49e-f7692022ea5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba07b06-cff6-471c-b896-e2f2e83694d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66516c0-b231-4282-9284-acc82ebd0fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a017e585-f0ca-4542-bdce-71d0e767bd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af2966a-628b-43e4-b71a-6b4c0f2e735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 475b6c31-e1f0-4383-8cc7-f8d51619000b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643d1b5e-7e4a-4a87-a889-968dc8da7e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06b6395-b553-40a2-ab60-5f3236885111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9647dc6f-4896-444c-abe6-76e5da697437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f9069b-a4cf-4bbf-bdd3-91087188864d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f88375-a56c-4879-b493-2332338e0f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b700d71f-1329-4896-ad4f-ebeae81ba7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d8f73d-8afe-4080-8fc9-64502177918b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa8f607f-089c-4cc5-8050-5091f227a5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423fc3d1-86fb-49e2-8649-49885f53783a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecdaebf-df7e-49f8-a35a-f86be927c1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124038df-b715-432a-9e7e-b959c76134d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785ec8df-289d-4c09-a498-5d855ccc061e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f250431b-55ad-4396-b002-693302f4eaa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f4e127-c17c-4e53-88af-e1d67fae0e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7a6397-bc35-4d99-8501-17eff589b494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d2ca4e-02bb-44b8-98d4-4b7487388a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3503fb8-7c8d-4476-9cf2-dfd66339f547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd2a907-6564-4113-a517-c80824b8b5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd76d49a-15c3-4089-a74d-3de90087ecaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3679d5-f4d8-403e-bc14-6309e83b282a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a90c8a57-8391-42f1-9797-59cb83364de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72764dfa-1392-4671-b6ee-470332377ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be419bc-8f75-42bb-9a49-d0b463af1494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17133c9a-52eb-4eef-97a1-7fb00c8d7d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f7ab5a-2a62-4f50-bc8c-edb05abed7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8db06b-7320-48e4-bc9d-d88a035ff095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e100772-b098-4bab-b766-e0ef60e74c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8e9f19-8cf5-48c4-b361-595854714ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0e671b-fab0-4616-b69b-18994ff627c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e66209c8-0c17-4f9b-bbb7-6f5d096abc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4496217d-719e-440e-a08a-b29541ec261c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ecd363-75d0-49d5-835e-299d930a5526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6022fca9-fd5b-4828-928f-54850fcd2526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fee4169-0a47-438d-98ec-d10fbe7dd9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046d1c6c-1d7b-4d4b-a711-15a504b3b7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4db5954-2752-4702-b55d-86dfc7226a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a8baa6-94fe-4ef5-94c7-f697dd014d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 730e1d82-7f37-4c83-b286-1ccd1268f645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b9ab86-8311-410c-a6ba-0c2e0d06f839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 531f49ce-69f1-4caf-8ac2-74b15ca587c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804ca751-de5b-49ee-9d84-3e764a3722b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d362e4b-9684-423e-ad95-7c7822ec4852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68c49ec-e4a5-498a-b8e3-571347203dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c752f9b-8a3b-4742-baf5-99121d5713ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c4d95d-5ed3-41cf-9129-0be6df1a0baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f34dd282-83bd-458a-b13f-e70c87a8bc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 763d85fa-9684-442f-aff5-6a01bdb1303b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e2b737-0042-4354-9514-83501e48c94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5774cdb-4251-40c5-a9f4-8cb4b6615502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c55853a-7510-40b6-8153-855a246144d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0134c8cb-4727-4275-9d03-1b3b0bd8d232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3d7e7c-f718-485c-9daf-20a75932ba80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f383bb-8d50-48ee-9da3-0c9483e6f806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3d4d3f-a5b5-42d5-a95d-9a5b9459b05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a27671e-bd58-42cd-99c4-d59f51d27e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46feec52-376c-460b-aa14-00aeab602c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bece6a02-e284-415a-acf4-030b90fa5bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7ef8e5-f7ec-4498-bc9e-a25f8596d2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808317b3-e246-43cf-8c43-5d6bd392bf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97646e9e-83a5-4ee4-8243-4e8125d6cbc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995fb4ea-030a-4c44-80d5-4f4a45006964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820fd870-aeb4-48cc-b5c1-7ddf6cf22050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32a1316-a5eb-4da1-b197-cd2173c7490c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a161b7e-1eaa-46a8-b771-cced80359485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f484716a-4bf5-47bf-860c-326e0918a866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4802bf60-011b-42cb-b9c9-d3480f1e4fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee9184c-e33c-470b-8da8-259b37078341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7210e898-c8c9-44af-963e-5c627988ff83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918efa04-2d2c-4166-9489-6c45561190d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735cc3bd-ae2e-4783-b881-083e7085372e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04208a5-e8b1-4c3f-b953-67a19251eed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9f903a-6dae-4404-88a5-9fb62bdad52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f85a541-44e5-44b0-b074-d5a270ff269a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ace6727-9f23-49e5-a3f6-6eb93399652a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7852d743-41c4-40ab-958a-5f8b272a449e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6ff235-3606-4fe4-9888-751137de1c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fead9e-7224-43fb-a365-463fd7924242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85eb9541-85f8-4520-b6d3-7f7d23b8cb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73caabd4-499f-4119-973e-35ef5081ada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e937d05e-15e5-4d56-8f51-35b33c98cf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24bbe0a-19c2-41b8-a15c-a5da3094966b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186ad52e-ec76-4aff-b126-0e23add3579e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce04caf-8c91-496a-ab2f-f6e5dfc5d0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f755ecf4-a635-4d4d-83af-1a570da032c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c3c987f-1890-4c2c-bda1-8a34443b3cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca582617-b696-4bae-9092-86e95685197c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d035d22-4cc0-4839-bc49-950e0953a4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6deb5915-818d-489c-bb70-3ab21efa96e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303b9f51-6a5b-41fd-a3b6-7823fd6cf1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d0bf65-b146-4b43-8707-a09dbc1ea1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee303efb-2846-48fb-8d04-1f1cd2f8adfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c30bddb-e0cd-4414-9570-c1a0eb21809c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e089881c-8e20-400e-932b-11e4a3b5bcab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6fd4620-857b-4e24-9e5c-b9e0997f03e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b399695c-d7ae-4777-a4cd-27de80d18db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8204ba-4e91-4475-bf14-f62afabbc880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb10245-b6e5-4029-9c97-c85401531e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725b6b68-515a-4317-8d8f-4a08cd2e3b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295803ec-0a57-476e-bfa9-20cd227afaa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cf1741-9ade-4f1f-ae44-aade4f4ea3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c581b09-b69d-4b76-beb1-c2e17454b900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980bbd49-4e3e-4af4-8bef-916e79a00a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250e4133-2346-4413-80dd-7b7fe0375177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c93b82d-76ff-46ea-8d2f-3851ea3bb07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090edeb7-4b54-4382-9b9c-e5ffc9c7c41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 691f8e86-bd03-4a4d-93c0-66cdfbcc813e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414e6f28-f8a0-413f-b5c3-0d382215aef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f42600e-62d7-4e99-a32c-e27cd8db09e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd4fa92-790c-456a-8090-588f719a661c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb37cadc-cf6c-4556-8c33-1c5d6b88fbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510b12f0-4443-4058-b7a8-9a038b5468f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17434a21-3e50-4d7a-be4d-96bd9633f04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6224c7-0d2c-4b4b-9cd2-71373a3c3a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ce422f-9a14-4c66-8b5f-b8f68ece324f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c49495-ac0d-4d36-ad12-3b8a381af37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f87fadb-0fac-4d2a-b8b2-c9553e9caced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd0736c-d9a0-49da-8e5d-640f6fa1adab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4e6f52-3f3f-45b7-9edc-1d9ef5219dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc236db-8c1b-4e94-a31d-8ae8908ec5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a2208f2-c918-423f-a1bc-bfca10d112ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364b30fd-4c37-40ac-98b8-789057e58a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2cba1b-aa15-4862-ad01-4db16ae27483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92387f7e-8d6f-4b84-bdfa-b7e4106a89ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52785f7-aa0c-4f42-b227-7b79e89d2f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8eb931c-60da-48a1-a4bb-34cdbddd5d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65a2a62-293d-4b3f-b2fd-291a09c5ae3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3943dfa9-27b0-4794-8854-ae8da7bc3446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b522e5ef-a056-452e-bb0f-45e4dbcd6eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0256f094-ace2-4dc9-8293-16988010e4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf254fcb-96c9-4154-be45-b20d3f92e86d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac38fe7-bb99-4d59-9d8c-3da1f276092b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a60ba88-1bd7-4378-8d94-134724ac80f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0d49ab-166c-43ef-8730-e1237c78d17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ddc388-c307-4b31-b2d7-d47a869766f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0065a199-fd2c-4790-ba7f-08352ce6adda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b7c82a-e26a-4244-ade1-974786e6893b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3cdc7d-f407-45b9-af28-32072581de43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cff452-be52-4224-a009-88b8c86f9a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5511e0c-384b-4f67-a0b8-1ab43f58cebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3f5702-f34f-42ae-ba7c-625187f65413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9cfb01-1edc-472b-9865-e150bb8f9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bcf54d-abe0-4e50-b079-1c2d73c7750e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557d2452-67de-44f2-bb33-0afbe66bb704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe008f4-548c-44bd-ab67-8245e7878bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7087d33-f406-4ece-8c61-437872c19d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f2607e-e1ef-466d-9fd6-c910d81d30fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a2f84c-f86f-401c-bb44-8261ff417e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7374838-3d49-49f6-89c3-4a2e746f8c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4594dc-d5a9-46f5-abc0-3d441071d365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926c3af8-1cae-4ade-88fd-a3d5ef07eb50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85cdef2-aceb-4ce8-bf40-342e0f9f81bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b40afa8-e751-4a46-a147-585a6798b225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b32e27-1dda-4286-995b-639bd65d11b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec78f002-febf-4c16-aa60-997cedd2a98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4da5a2-7169-4df4-a7b4-aefc39b2bd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3caeeb-ffe1-4b93-9fe4-c1726e5459d1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(5265, 24), y=(5265,)
   Test:  X=(1317, 24), y=(1317,)

⚠️  Limiting training data: 5265 → 800 samples
⚠️  Limiting test data: 1317 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1708, val=0.0792 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0904, val=0.0683 (↓), lr=0.001000
   • Epoch   3/100: train=0.0864, val=0.0700, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0856, val=0.0720, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0853, val=0.0719, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0847, val=0.0728, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 1 Summary - Client client_8
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0175
   Val:   Loss=0.0683, RMSE=0.2614, R²=-0.0128
============================================================


============================================================
🔄 Round 2 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0762 (↓), lr=0.000250
   • Epoch   2/100: train=0.0851, val=0.0761, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0849, val=0.0760, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0849, val=0.0759, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0848, val=0.0759, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0845, val=0.0758, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 2 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0027
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0068
============================================================


============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0852 (↓), lr=0.000063
   • Epoch   2/100: train=0.0825, val=0.0852, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0823, val=0.0852, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0852, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0006
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0013
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2511, R²: -0.0013

📊 Round 3 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 3 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 10 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0905 (↓), lr=0.000016
   • Epoch   2/100: train=0.0811, val=0.0904, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0811, val=0.0904, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0811, val=0.0904, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0811, val=0.0904, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0810, val=0.0904, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 10 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0032
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0014
============================================================


============================================================
🔄 Round 12 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000004
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0841, val=0.0804, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0841, val=0.0804, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0841, val=0.0804, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0841, val=0.0805, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 12 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0042
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0022
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0038

📊 Round 12 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0038

📊 Round 12 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

============================================================
🔄 Round 20 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 20 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0032
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0029
============================================================


============================================================
🔄 Round 21 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 21 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0149
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

============================================================
🔄 Round 22 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 22 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0024
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0031
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

============================================================
🔄 Round 23 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 23 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0016
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0089
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0026
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0240
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

============================================================
🔄 Round 30 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 30 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0034
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0074
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: -0.0038

📊 Round 30 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 33 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 33 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0029
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0035
============================================================


============================================================
🔄 Round 35 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 35 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0024
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0030
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 36 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 36 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0011
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0111
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 39 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 39 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0019
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0086
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 40 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 40 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0019
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0058
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 41 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 41 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0100
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 43 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 43 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0064
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0077
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 45 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 45 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0012
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0122
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 46 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 46 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0043
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0017
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 47 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 47 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0042
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0050
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 49 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 49 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=-0.0052
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0006
============================================================


============================================================
🔄 Round 50 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 50 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0052
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0049
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 52 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 52 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0013
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0088
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 56 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 56 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0019
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0073
============================================================


============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0011
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0097
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

📊 Round 59 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 63 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 63 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0029
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0116
============================================================


============================================================
🔄 Round 64 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 64 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0017
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0128
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 65 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 65 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0053
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0088
============================================================


============================================================
🔄 Round 66 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 66 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0023
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0040
============================================================


============================================================
🔄 Round 68 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 68 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0043
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0051
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 75 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 75 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0023
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0066
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 76 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 76 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0041
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0067
============================================================


============================================================
🔄 Round 77 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 77 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0040
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0006
============================================================


============================================================
🔄 Round 78 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 78 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0017
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0082
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 80 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 80 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0037
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0111
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 80 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 80 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 85 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 85 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0157
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0033
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0034
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 88 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 91 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 91 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0179
============================================================


============================================================
🔄 Round 93 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 93 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0019
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0073
============================================================


============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0047
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0026
============================================================


============================================================
🔄 Round 96 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 96 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0045
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0038
============================================================


============================================================
🔄 Round 97 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 97 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0029
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0017
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 98 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 98 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0021
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0050
============================================================


============================================================
🔄 Round 99 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 99 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0075
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 99 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 99 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 99 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 103 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 103 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0030
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0024
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 108 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 108 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0030
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0033
============================================================


============================================================
🔄 Round 109 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 109 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0065
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0060
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 109 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 112 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 112 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0009
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0235
============================================================


============================================================
🔄 Round 113 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 113 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0033
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0009
============================================================


============================================================
🔄 Round 114 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 114 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0026
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0030
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 115 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 115 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0050
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0024
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 116 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 116 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0024
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0117
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 116 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 120 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 120 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0030
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0071
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 130 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 130 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0128
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0036

============================================================
🔄 Round 132 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 132 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0034
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0010
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 133 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 133 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0189
============================================================


============================================================
🔄 Round 134 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 134 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0059
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0084
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 136 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 136 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0002
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0118
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 138 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 138 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0051
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0055
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 147 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 147 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0031
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0059
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 148 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 148 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0015
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0121
============================================================


============================================================
🔄 Round 149 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 149 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0003
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0182
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 150 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 150 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0066
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0106
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 151 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 151 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0018
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0141
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0288
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0042
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0141
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0044
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0039
============================================================


============================================================
🔄 Round 164 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 164 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0030
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0062
============================================================


============================================================
🔄 Round 167 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 167 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0040
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0032
============================================================


============================================================
🔄 Round 168 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 168 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0095
============================================================


============================================================
🔄 Round 169 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 169 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0024
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0093
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 175 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 175 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0110
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 176 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 176 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0052
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0079
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 180 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 180 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0440
============================================================


============================================================
🔄 Round 183 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 183 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0013
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0085
============================================================


============================================================
🔄 Round 184 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 184 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0139
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 185 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 185 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0035
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0003
============================================================


============================================================
🔄 Round 186 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 186 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0047
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0063
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 188 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 188 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0011
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0192
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 189 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 189 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0031
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0163
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 192 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 192 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0065
   Val:   Loss=0.0945, RMSE=0.3075, R²=0.0092
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 195 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 195 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0047
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0015
============================================================


============================================================
🔄 Round 197 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 197 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0029
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0161
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0035

============================================================
🔄 Round 203 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 203 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0043
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0010
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 204 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 204 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0142
============================================================


============================================================
🔄 Round 205 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 205 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0016
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0094
============================================================


============================================================
🔄 Round 207 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 207 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0013
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 210 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 210 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0044
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0015
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 212 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 212 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0036
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0042
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 212 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 217 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 217 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0028
============================================================


============================================================
🔄 Round 218 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 218 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0034
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0039
============================================================


============================================================
🔄 Round 219 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 219 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0017
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0081
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 221 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 221 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0028
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0029
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 221 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 221 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 224 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 224 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0062
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0041
============================================================


============================================================
🔄 Round 225 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 225 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0115
============================================================


============================================================
🔄 Round 226 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 226 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0024
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0039
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 228 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 228 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0031
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0017
============================================================


============================================================
🔄 Round 231 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 231 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0027
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0136
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 232 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 232 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0055
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0022
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 237 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 237 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0009
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 238 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 238 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0023
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0071
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 238 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 240 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 240 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0054
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0104
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 241 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 241 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0266
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 241 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

============================================================
🔄 Round 246 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 246 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0063
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0013
============================================================


============================================================
🔄 Round 250 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 250 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0026
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0032
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 250 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 250 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 250 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0034

📊 Round 250 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 258 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 258 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0036
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0009
============================================================


============================================================
🔄 Round 259 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 259 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0193
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 259 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 261 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 261 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0029
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0135
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 264 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 264 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0073
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0121
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 266 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 266 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0023
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0064
============================================================


============================================================
🔄 Round 267 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 267 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0043
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0046
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 267 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 270 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 270 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0035
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0017
============================================================


============================================================
🔄 Round 272 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 272 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0019
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0060
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 273 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 273 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0037
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0005
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 273 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 275 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 275 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0020
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0065
============================================================


============================================================
🔄 Round 276 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 276 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0045
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0165
============================================================


============================================================
🔄 Round 279 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 279 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0028
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0027
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 280 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 280 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0033
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 281 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 281 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0049
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0149
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 282 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 282 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0001
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0148
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 282 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 282 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 285 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 285 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0032
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0005
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 287 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 287 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0029
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0250
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 287 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 287 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 290 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 290 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0040
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0202
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 290 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 290 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 296 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 296 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0025
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0133
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 298 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 298 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0098
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 304 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 304 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0040
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0018
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 306 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 306 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0022
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0159
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 308 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 308 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0038
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0022
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 309 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 309 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0035
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0045
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 309 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 309 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 316 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 316 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0038
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0006
============================================================


============================================================
🔄 Round 317 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 317 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0032
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0026
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 319 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 319 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0062
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0009
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 319 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 322 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 322 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0048
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0016
============================================================


============================================================
🔄 Round 323 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 323 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0034
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0130
============================================================


============================================================
🔄 Round 325 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 325 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0032
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0011
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 326 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 326 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0046
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0040
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 327 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 327 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0020
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0102
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 327 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 332 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 332 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0051
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0051
============================================================


============================================================
🔄 Round 334 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 334 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0029
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0047
============================================================


============================================================
🔄 Round 335 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 335 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0271
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

============================================================
🔄 Round 337 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 337 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0035
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0090
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0033

📊 Round 337 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 337 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 337 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 342 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 342 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0025
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0034
============================================================


============================================================
🔄 Round 343 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 343 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0006
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0103
============================================================


============================================================
🔄 Round 344 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 344 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0036
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0071
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 344 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 347 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 347 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0013
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0298
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 347 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 351 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 351 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0020
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0094
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 352 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 352 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0039
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0128
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 352 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 355 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 355 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0039
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0019
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 355 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 355 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 358 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 358 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0040
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0052
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 362 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 362 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0016
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0107
============================================================


============================================================
🔄 Round 364 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 364 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0000
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0248
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 367 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 367 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0028
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0027
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 370 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 370 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0039
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0306
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 373 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 373 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0032
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0087
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 375 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 375 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0010
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0105
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 375 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 379 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 379 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0051
============================================================


============================================================
🔄 Round 380 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 380 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0028
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0022
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 381 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 381 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0033
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0168
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

📊 Round 381 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 383 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 383 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0019
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0481
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 387 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 387 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0599
============================================================


============================================================
🔄 Round 388 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 388 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0048
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0002
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 392 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 392 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0041
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0019
============================================================


============================================================
🔄 Round 393 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 393 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0030
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0071
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: -0.0032

============================================================
🔄 Round 400 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 400 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0038
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0073
============================================================


============================================================
🔄 Round 401 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 401 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0070
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 405 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 405 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0045
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0002
============================================================


============================================================
🔄 Round 406 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 406 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0025
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0064
============================================================


============================================================
🔄 Round 409 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 409 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0042
   Val:   Loss=0.0709, RMSE=0.2664, R²=-0.0329
============================================================


============================================================
🔄 Round 411 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 411 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0037
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0280
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 411 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 411 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 415 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 415 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0019
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0072
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 417 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 417 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0025
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0073
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 417 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 425 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 425 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0019
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0120
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 426 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 426 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0020
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0086
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 428 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 428 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0066
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0354
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 431 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 431 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0036
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0005
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 431 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 434 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 434 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0034
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0002
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 434 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 438 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 438 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0045
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0047
============================================================


============================================================
🔄 Round 440 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 440 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0045
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0038
============================================================


============================================================
🔄 Round 441 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 441 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0036
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0180
============================================================


============================================================
🔄 Round 446 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 446 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0037
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0002
============================================================


============================================================
🔄 Round 447 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 447 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0038
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0039
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 448 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 448 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0048
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0063
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 450 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 450 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0010
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0109
============================================================


============================================================
🔄 Round 452 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 452 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0065
============================================================


============================================================
🔄 Round 454 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 454 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0053
============================================================


============================================================
🔄 Round 456 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 456 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0019
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0076
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 456 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 460 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 460 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0026
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0045
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 461 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 461 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0024
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0035
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 462 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 462 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0055
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0259
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 464 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 464 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0153
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 464 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 475 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 475 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0021
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0483
============================================================


============================================================
🔄 Round 476 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 476 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0194
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 479 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 479 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0028
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0497
============================================================


============================================================
🔄 Round 480 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 480 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0016
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0107
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 481 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 481 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0035
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 481 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 481 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 487 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 487 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0053
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0051
============================================================


============================================================
🔄 Round 488 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 488 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0064
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0092
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 490 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 490 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0023
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0050
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 490 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 493 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 493 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0050
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0067
============================================================


============================================================
🔄 Round 494 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 494 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0025
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0156
============================================================


============================================================
🔄 Round 495 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 495 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0036
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0010
============================================================


============================================================
🔄 Round 496 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 496 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0107
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 497 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 497 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0022
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0063
============================================================


============================================================
🔄 Round 498 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 498 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0005
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0161
============================================================


============================================================
🔄 Round 499 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 499 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0024
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0121
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 500 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 500 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0050
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0072
============================================================


============================================================
🔄 Round 501 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 501 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0029
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0017
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 501 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 501 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 504 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 504 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0019
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0182
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 504 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

📊 Round 504 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0031

============================================================
🔄 Round 508 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 508 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0051
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0115
============================================================


============================================================
🔄 Round 510 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 510 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0043
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0025
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 510 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 514 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 514 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0019
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0049
============================================================


============================================================
🔄 Round 515 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 515 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0014
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0133
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 518 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 518 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0066
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0020
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 520 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 520 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0075
============================================================


============================================================
🔄 Round 521 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 521 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0029
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0122
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 522 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 522 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0046
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0014
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 523 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 523 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0044
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0036
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 523 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 523 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 523 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 530 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 530 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0011
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0144
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 531 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 531 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0063
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0030
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 531 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 534 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 534 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0010
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0126
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 538 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 538 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0010
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0094
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 539 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 539 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0029
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0033
============================================================


============================================================
🔄 Round 543 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 543 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0031
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0031
============================================================


============================================================
🔄 Round 544 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 544 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0007
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0206
============================================================


============================================================
🔄 Round 545 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 545 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0033
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0238
============================================================


============================================================
🔄 Round 546 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 546 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0002
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0238
============================================================


============================================================
🔄 Round 548 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 548 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0132
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 548 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 550 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 550 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0019
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0065
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 550 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 550 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 550 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 558 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 558 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0025
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0035
============================================================


============================================================
🔄 Round 559 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 559 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0006
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 562 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 562 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0008
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0114
============================================================


============================================================
🔄 Round 564 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 564 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0025
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0037
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 564 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 567 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 567 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0056
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0074
============================================================


============================================================
🔄 Round 571 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 571 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0036
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0017
============================================================


============================================================
🔄 Round 572 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 572 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0029
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0135
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 575 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 575 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0048
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0053
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 575 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 577 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 577 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0032
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0048
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 580 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 580 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0036
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0016
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 582 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 582 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0032
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0045
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 582 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 585 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 585 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0053
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 585 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 589 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 589 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0040
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0004
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 592 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 592 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0051
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0054
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 594 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 594 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0038
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0062
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 594 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

📊 Round 594 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 598 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 598 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0023
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0243
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 599 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 599 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0024
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0039
============================================================


============================================================
🔄 Round 600 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 600 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0036
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0011
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 601 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 601 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0033
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0006
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 602 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 602 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0033
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0003
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0030

============================================================
🔄 Round 606 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 606 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0022
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0123
============================================================


============================================================
🔄 Round 607 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 607 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0036
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0004
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 607 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 616 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 616 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0036
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0022
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 618 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 618 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0018
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0159
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 618 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 624 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 624 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0042
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0018
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 624 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 626 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 626 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0032
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0005
============================================================


============================================================
🔄 Round 627 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 627 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0024
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 628 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 628 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0029
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0036
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 628 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 628 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 632 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 632 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0209
============================================================


============================================================
🔄 Round 634 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 634 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0140
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 634 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 634 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 637 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 637 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0169
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 637 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 646 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 646 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0032
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0006
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 650 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 650 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0036
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0051
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 654 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 654 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0167
============================================================


============================================================
🔄 Round 655 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 655 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0027
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0031
============================================================


============================================================
🔄 Round 656 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 656 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0090
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 657 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 657 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0082
============================================================


============================================================
🔄 Round 658 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 658 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0034
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0009
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 659 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 659 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0048
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0163
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 661 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 661 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0054
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0272
============================================================


============================================================
🔄 Round 662 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 662 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0033
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0112
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 664 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 664 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0011
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0174
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 665 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 665 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0038
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0003
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 666 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 666 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0031
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0045
============================================================


============================================================
🔄 Round 669 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 669 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0002
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0265
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 672 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 672 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0005
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0140
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 672 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 675 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 675 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0007
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 675 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 679 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 679 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0043
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0397
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 680 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 680 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0069
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0279
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 681 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 681 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0025
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0036
============================================================


============================================================
🔄 Round 683 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 683 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0028
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0019
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 687 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 687 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0047
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0106
============================================================


============================================================
🔄 Round 688 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 688 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0053
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0031
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 689 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 689 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0041
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0037
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 692 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 692 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0009
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0091
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 692 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 696 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 696 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0035
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0015
============================================================


============================================================
🔄 Round 697 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 697 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0012
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0118
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 697 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 699 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 699 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0031
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0004
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 700 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 700 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0044
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0014
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 700 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 700 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 700 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 700 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 707 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 707 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0030
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0031
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 710 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 710 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0054
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0219
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 711 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 711 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0007
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0103
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 711 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 713 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 713 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0039
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0022
============================================================


============================================================
🔄 Round 714 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 714 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0062
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0081
============================================================


============================================================
🔄 Round 715 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 715 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0017
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0066
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 716 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 716 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0012
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0081
============================================================


============================================================
🔄 Round 717 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 717 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0169
============================================================


============================================================
🔄 Round 718 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 718 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0067
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0287
============================================================


============================================================
🔄 Round 722 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 722 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0005
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0101
============================================================


============================================================
🔄 Round 723 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 723 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0044
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0018
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 723 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 727 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 727 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0037
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0448
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 727 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 727 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 733 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 733 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0027
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0029
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 733 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 740 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 740 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0039
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0009
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 741 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 741 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0098
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 742 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 742 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0025
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0087
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 742 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 742 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

📊 Round 742 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 747 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 747 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0020
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0045
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0029

============================================================
🔄 Round 749 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 749 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0030
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0106
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 750 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 750 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0031
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0054
============================================================


============================================================
🔄 Round 751 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 751 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0074
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0127
============================================================


============================================================
🔄 Round 752 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 752 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0038
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0026
============================================================


============================================================
🔄 Round 754 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 754 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0020
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0077
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 754 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 758 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 758 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0040
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0053
============================================================


============================================================
🔄 Round 760 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 760 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0045
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0039
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 760 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 763 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 763 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0041
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0016
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 763 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 763 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 767 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 767 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0044
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0015
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 768 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 768 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0025
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0023
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 769 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 769 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0023
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0038
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 771 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 771 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0045
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0049
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 771 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 773 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 773 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0013
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0078
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 775 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 775 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0016
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0276
============================================================


============================================================
🔄 Round 777 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 777 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0079
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0146
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 777 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 777 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 781 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 781 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0162
============================================================


============================================================
🔄 Round 783 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 783 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0033
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0025
============================================================


============================================================
🔄 Round 786 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 786 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0032
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0046
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 788 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 788 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0010
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0085
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 789 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 789 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0044
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0026
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 790 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 790 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0049
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0046
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 792 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 792 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0023
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0033
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 792 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 796 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 796 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0105
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 798 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 798 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0036
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0018
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 800 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 800 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0005
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0147
============================================================


============================================================
🔄 Round 801 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 801 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0024
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0027
============================================================


============================================================
🔄 Round 802 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 802 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0034
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0061
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 802 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 802 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 808 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 808 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0044
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0043
============================================================


📊 Round 808 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 808 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 808 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 812 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 812 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0009
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0088
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 812 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 815 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 815 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0244
============================================================


📊 Round 815 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 821 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 821 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0043
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0008
============================================================


============================================================
🔄 Round 823 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 823 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0036
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0005
============================================================


============================================================
🔄 Round 824 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 824 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0016
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0104
============================================================


📊 Round 824 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 827 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 827 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0028
============================================================


============================================================
🔄 Round 828 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 828 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0042
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0024
============================================================


============================================================
🔄 Round 832 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 832 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0003
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0130
============================================================


============================================================
🔄 Round 834 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 834 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0099
============================================================


📊 Round 834 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 837 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 837 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0018
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0092
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 837 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 842 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 842 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0034
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0013
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 842 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 849 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 849 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0006
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0252
============================================================


============================================================
🔄 Round 850 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 850 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0020
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0060
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 851 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 851 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0026
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0056
============================================================


============================================================
🔄 Round 854 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 854 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0032
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0010
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 854 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 856 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 856 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0018
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0064
============================================================


📊 Round 856 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 856 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 860 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 860 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0049
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0023
============================================================


============================================================
🔄 Round 862 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 862 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0072
============================================================


============================================================
🔄 Round 866 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 866 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0026
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0155
============================================================


============================================================
🔄 Round 870 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 870 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0026
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0085
============================================================


============================================================
🔄 Round 871 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 871 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0047
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0009
============================================================


============================================================
🔄 Round 874 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 874 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0037
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0414
============================================================


📊 Round 874 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 874 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 876 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 876 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0030
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0001
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 879 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 879 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0010
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0122
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 880 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 880 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0015
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0085
============================================================


📊 Round 880 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 883 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 883 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0040
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0015
============================================================


============================================================
🔄 Round 885 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 885 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0111
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 887 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 887 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0017
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0518
============================================================


============================================================
🔄 Round 888 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 888 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0073
============================================================


============================================================
🔄 Round 889 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 889 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0023
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0031
============================================================


📊 Round 889 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 891 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 891 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0014
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0079
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 895 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 895 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0116
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 896 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 896 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0008
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0202
============================================================


📊 Round 896 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 900 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 900 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0048
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0008
============================================================


============================================================
🔄 Round 905 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 905 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0010
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0083
============================================================


📊 Round 905 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 905 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

============================================================
🔄 Round 911 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 911 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0035
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0222
============================================================


📊 Round 911 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 911 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0028

📊 Round 911 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 918 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 918 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0032
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0009
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

📊 Round 918 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 930 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 930 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0020
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0051
============================================================


============================================================
🔄 Round 931 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 931 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0021
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0072
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 934 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 934 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0029
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0010
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 936 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 936 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0025
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0036
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 937 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 937 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0024
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0119
============================================================


============================================================
🔄 Round 938 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 938 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0029
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0002
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 941 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 941 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0025
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0051
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 942 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 942 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0031
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0004
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 944 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 944 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0042
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0036
============================================================


📊 Round 944 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 947 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 947 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0034
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0035
============================================================


📊 Round 947 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2515, R²: -0.0027

============================================================
🔄 Round 948 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 948 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0026
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0275
============================================================


❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
