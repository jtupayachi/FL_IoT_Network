[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9be613-8468-4139-bf60-f6b697b671a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2118e4a-c537-4f59-9593-ade81adeeeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586b855e-cb86-402e-9207-953a7bf717dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937c71fa-0de4-4550-9f2b-a176398188b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1cf949-1737-49c4-8809-abda5025119f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7710b8-d2d3-4fa9-aaf2-24f85c033b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d721484f-a95f-414c-be75-30a4f4ff7b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ded01a2-0332-49a8-8fdd-04a9a95641c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063058e1-dea3-4d3b-bff1-e323dc9fb216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c08cbe4-1403-4add-8565-7d5c6409c409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b3fdc8-7c74-4122-9efa-5a205bef962d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a5f950-2f48-4f7c-bb5d-aedeae72c0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3a7646-ad34-4383-b51e-b717886928ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62d9cc8-ccdf-4c85-b568-73658c15a26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce9cfd6-d5ba-4f31-babd-a863ca2d04b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ce3761-0873-46b8-9355-a48c823ce361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1072d6-8638-43d9-8bd0-31dfee66c70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb54de95-a384-4677-9dab-420bf82aba35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aae51ad-543d-44fa-bda7-f6f12d50c994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1ec01c-244b-4e77-97f0-10784eae7738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580207c0-8193-4aea-aaf9-3ceddfa6046d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95a47df-3580-43d7-9eca-3a0fac51a0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b616cb9-fbff-4b7d-865f-10e6c722b454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c154e382-5402-415e-bc13-255184b7f61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ed78d1-9567-446b-b7d8-3a41f705c35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bb0f4c-4cfb-4f29-8702-d5e4086269f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ac2601-8ee7-4df3-8679-70ab0dfe3db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644b7bbe-145c-4cbd-8cab-097f57a0723c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af6065f-3f37-4426-bcd5-13e4026eb374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4001575-692d-425c-92f0-0adcac2c38ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffd8d4f-e469-4235-bc11-17d3583af25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332629a5-415e-4bda-a5dc-f8d4c90aa96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6aa62c-1e2c-43bc-b62f-0792c3ba171d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7aac23-2444-42ee-8f20-3696e2dbcb29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a8bb34-f15a-4c66-8353-f0bfeca32158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8edce290-d3b4-4445-a1f9-e2bfd6978354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e333f9-3374-4e7f-9d9c-effce1245348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dac515-e1b4-4e6f-bb71-acbf18fd0f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7a2308-1cf8-4d94-804f-7687983d7be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d100271-371a-4244-8524-624ac81b58eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7816fab-ff0b-43b2-a953-257d7915d005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed21e6e-470d-4439-a555-870df2d7034b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26d8f13-4b52-4ae9-bbf8-44865cb86bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e78ab7-bcdc-4765-bf05-3b9d901a2544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b8b683-caa1-4698-8b14-37aee9826d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46fdcc9-7efc-4199-9554-312dd8f38977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43101022-360a-485c-bc47-1c82338eb822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07eaebca-23d3-471f-842d-714b5ed40756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19bc3a5-3d26-47dc-a786-09f99086b666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf1d185-0b25-452e-b437-4e60b56ee076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310ce53e-d39a-4ff2-be7f-a9196fcdbbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc7579d-669f-4a70-8d2d-73cdc83fc69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e06d2e2-985b-4c34-b629-04bf702b6824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3170c27d-924c-4c4f-9f89-b42e54b2228a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66bdeb0-9722-4dc4-8a10-a3e35044d136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fffdb505-34c7-4ab7-a9c6-a97c5868c765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e9b507b-527e-4e2b-9983-cf5aca129fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd92d76-2c97-4355-9058-c1433c301eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda23b5a-e20d-4ec1-b3ac-031124915db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c62ae81-4007-44f4-8030-a7579f20e0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b054c5-263d-4a1d-a806-261486231f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0527963-f753-4a56-8dc2-3bc86507e8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a87814-7f78-4e80-9a4d-e7ec84e03945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6036b9ae-62d9-4b20-ac64-cf3a70d973d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9088d202-9527-4f21-bd9c-e5922b2590c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3634cd-9ae2-43e7-8c19-fbe021667438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3cbefcd-5654-4258-8a3c-04d61594ddde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6323b25-4c17-4874-8165-d1fe5d98e377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0322c76e-efc0-401e-b916-c9a20963ea32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5417750e-9f29-449e-ac59-451dd3f7c53e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33924e12-49b1-460c-a892-6b695a83ba11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ea24b6-11f6-42e4-84c5-2e485b4dbcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdef96c2-d924-42cf-b465-f27fe475aee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280854f7-aa7b-4653-b90c-d5cdaf16382d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ba7d3c-19ed-401b-8130-adc460b04806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e874c2-c130-4026-85e5-a962917afc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6464b11a-54a5-40f1-9dca-0596b1ec577e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42550c8-c5be-4bc5-85c6-ba4a5994a2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56445b5a-caea-4d25-b14e-2442c0a90ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab886a8-fe5f-4f36-8de7-c76f63129606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6d8dd7-4ac3-4548-b7c3-92378e9c8ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a5a1ca-e0f9-46f6-b518-f0df5993bed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6e3c10-35a1-4537-9c7f-c493c5657833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2620a4-7b6d-44c5-bb31-6a98596650e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07441c2c-3813-4b78-951b-3daa7cae6b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9976c6ce-0b09-478e-97c2-7bc7cf06ed3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26204b82-8a29-4ff3-a4e7-9536ae714b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e32fc7d-94e9-479b-8257-ea2a8a5e427e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721599b0-e74c-4053-ab4d-891545af2671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba5466b-3b08-43df-b5b8-ed599be03c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb59006-2d3b-4e3a-b91f-91f2a047bcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7243343-280b-4e34-b1a8-7b87c493429e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c421f2da-4965-4986-9e23-7c2a69985e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2b74a8-118c-4527-acdc-6a2113c41ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b25a1da-539e-4641-bc4a-70c53db90996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107b3f45-03fc-4266-bf22-5fdd0d8947b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3d9199-dc23-4b9c-a3f8-7bcbb9fa7c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4efb01e-175b-4f60-a2c7-54352ae5a91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b67027f-0811-48b1-886a-84fb37cb606f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114bb822-d95c-478f-89d9-51fcc21ee47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923690ff-8d77-4a6b-bfe9-00aaa5479241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a58202-bdf2-4b8a-b762-30a1ee5f58cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a7748b-98d4-4a20-b3ef-b107e78ebc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c32794a3-fde5-42a3-86f5-ce8e18e6aadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5f7506-5029-4095-b3e1-81efc10081e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5b3153-80ad-4865-9350-167e911ac2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377a57eb-99b1-4c3d-846b-1358700d0768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b43f90d-9462-404e-93ab-ba40b64b04a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0790aab7-f2c3-4619-a7be-c29a48dcd9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e17e1b1-7a58-4797-8066-6ac700d24a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31416d92-119e-42c0-b325-fee4e00ffb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b302339-b58c-4a9b-b8b7-36317bd8d263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108a3276-6c4f-4560-9807-46b27013e214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31f7dc9-30a9-4a17-8d76-6c3e6de2cecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b335359-e218-4854-a2dc-e6bedaf2557e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddf2b5d-1d85-40d6-aa27-c22b097be919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353d8db6-ff0a-4b11-937b-feee7da9939e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7378cb7e-86e3-42a3-a8e5-b47d96ccef8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25867c5-e556-468e-a358-c45a1dbb02ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afe3d34-1ca0-4f67-9c80-70262c4f0800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be5e0fb1-0322-4bf1-a22e-b9bbf34f67a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be1f253-46fb-4ce0-974d-937eda133a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fdceff-aca0-42ea-be99-cc9bf2bd7f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66efbe0f-f815-4bae-9325-18991eb83112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bf1537-ffdf-4ef9-b29a-484b3ef759dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b4cd10-419b-4d22-b47c-9599a90c9d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7f597a-8015-4776-9427-324e7fbbf753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88c0328-3013-4709-a0f6-fa4ada571dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec658b8-3ca1-4216-b02e-d904c8a6dc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1beebfe4-1b3e-4593-ab2b-adfd288df011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e21ff98-d6f5-4988-b9c1-e9125a71c2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4efa613-5943-49d4-ace9-e697fff28355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bff1e765-29a3-4ad1-b9c9-227ad010e82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d1c55c-631d-4bd8-b8a3-e69b58520f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5339c6-234d-47b4-a416-8d034c631836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c88ee87-d173-4961-bd06-f9e0c6def552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58dbbdb6-55f5-499b-82af-5bb351ecfd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a579965c-8aaf-4729-acff-96f5eb375478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4ff01a-0ee6-4c73-970e-612ed678bf2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1c6f049-4016-44b3-87d2-18124695db24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94216457-798e-4a28-8cc1-9c8cd08b6cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30746d92-f2b7-49a6-839c-b0abe2b7ee68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e509b879-aaf8-451d-8f48-fcacd442eecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f570f985-6d52-4323-9f1b-75e1104cd71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d29788b-d24f-4978-90ce-02aae24008ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dea9750-55ff-41c8-983c-876160e1de64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb699017-7c16-4c4a-be84-d0dbe0ed504e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78002e75-73fe-481c-ae65-21eff75ec9bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88475bf-19b5-43fb-a380-d2a7bfc743e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd2cc2d-d9d9-4f74-a6aa-6b1f01192d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13045dc8-a1dd-45cc-873b-bfe3dee84ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5dff57-7769-40b7-a1e8-0f9d7eba4b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ec04d2-b104-4c38-8ced-3529b49d8bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf4561c-135e-46bb-a917-6830550f655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9a4df5-c77e-4e62-855e-e6382f7e3923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d89333e-b05b-402b-98d7-45ab18dc5eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9138d0ba-1c68-4c33-9cfa-e9c24b8ee951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4933978-928d-49b1-820d-c88e8046f02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37c0ae6-5426-4e77-b706-a97cc5836e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e29f90d-33ba-43a4-8c0e-9648071c65fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092b84e5-f2d0-49b5-8669-402ea4607906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33d9c12-3c83-4eda-a154-0b3fd367cd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f13e170-ca5e-4314-8185-8b17eaa5eeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fd7140-ce8f-452d-a035-ed4d4e844bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525b54b8-ec7c-4026-873e-aec94c917b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe911ff-e18d-4c6b-b648-78fa905a906d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a72e9c-9f43-4130-8d44-f2e9207ed679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f60c7e-82f0-437f-9702-575f94499335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c72fd4-9e47-4fb0-8888-c90a8aa610a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d17738-8795-4f57-9f6f-79e999f2bd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50561324-fb08-42e2-b4d3-48294597fce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f49308e-a138-44d8-ab69-38116a0c4bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a31f27-5bfd-478a-8f21-d2464b003579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76d6b0f-2e8c-4e51-b230-1a863389e46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c98f29-3cb0-4547-bd8e-1f14ec6f6d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac73e46-78f5-4229-b89b-60158da506b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf303f67-f79a-4020-b5f5-a1f7334f6610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c59cb6-d606-491c-a990-60971036b3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 653fd345-0202-457c-8c1e-1a44c9bf192b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76b8cd4-b0a6-460b-a1d7-6a26fa81434e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edc905f-1c2c-45ac-82c8-74d8bbffea36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ac5c1c-afb0-4766-ba2a-90faceb9bf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ed9460-d620-4974-8da1-f9e1b102de61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e54478e-643a-4125-823c-4d764a023d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf383c0-b57d-48e5-bc0c-d3a9ed2935cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71556b42-7d35-432f-921c-8b73090c82f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caa54e4d-b364-4b09-bae6-a0ee06e5c500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6baca670-8943-4551-8951-467e2ce024a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228e9127-9c9e-4eb9-a60f-2d107efc4fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0f66ee-53a5-4089-b0c0-c90ff30c19ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db9caf8-586e-466b-b3f8-9fe92f41059b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4e2847-125f-4c4b-95f6-e42b60385bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662a0ec0-1fea-4d54-b6a3-fb51a6695c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae2da94-e4ce-47d9-856f-f258c75a7f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3c324c-3a53-425b-b1d8-965d19a9fac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979ae688-c90c-4a1f-a7d3-ed5d403c7cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab54c360-e56f-44f1-b5f8-fbb4a653f41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786f1bae-2666-4354-9ed4-6e4d67136ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7308b0d0-c838-42bd-abbe-108fd84415b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafbf699-0321-4841-9632-7fa3856bc473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ef7808-eec8-4d27-8237-f197652c24a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e148fb81-6266-465b-be3f-b6170f03b0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c740a83-dda5-4e9d-8e1a-2967b25eba56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92acded-0b7f-4a98-b02b-ea34ac4544ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f07a40-33a6-467f-991d-098a33c493a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dba52d4-dce5-408d-bfb8-8062c04478ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fcf4f9-732b-4b82-9258-3b3a604e3546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c300ca15-cb81-420d-8b41-f3e853901ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58510f8-d4a1-422b-bfdd-4454a34c0e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fba8d0-d476-4922-bb29-e3b27e86faa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14aaf1d-89d7-4a2c-a1b6-d95a6cf96098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdaeb3e1-b241-47c1-9e27-f612653d212d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad4112e-7294-4b5e-852e-51c4be85ed6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014ec62d-1f28-4be9-b6ed-f0e50e0c6eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c42082-7408-467f-911c-a92a04108cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0a6d48-2e30-4326-8bc3-80da5b8c58ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1acb5e4b-077a-4eb8-aece-ff49c6c5d7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bdd47b7-c87a-46de-b2c4-873f0c2e2212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79f25a4-3e6c-45f9-b223-0aa4ee45da75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a7a288-622b-4cd9-889f-1de1b007740a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36650acd-0fcf-4014-a10b-c68761264fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974266c8-7228-4a9e-a9c2-2027bacad265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9afc39-9e43-44b3-b681-0c82d1f11023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d9fc7b-2239-4048-a5c3-ae70dc2de618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401a1750-46f7-4b21-b8f3-afe441d93d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bf35ec-65c6-44f2-aa93-1e19e3eeb320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad3a1fbf-4011-4d0a-9372-0bb9fb9ef286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b0cf5a-fd93-455b-a8d2-772ee8274304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed439d9-47ce-4a40-a4ee-c2b7e2a52bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927028e2-0173-4021-91e3-ad3e86bc2f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95f4d6f-8c42-4e6a-bfd9-99763bc091b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664ce8b8-d1c4-40b5-a5bd-a36392d6606e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee44038-9cb6-429d-9a8b-d420a78abaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93839007-a24d-41b2-ab1b-d325afa20da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d879acb1-4800-4883-9d19-45e65432e0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc50cfd-40e2-4798-a66b-6756c4623b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181bea3b-588c-4a40-98e0-e1c17e277197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd189f2-126f-43ac-a472-bd794c9a81b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d394d732-1684-4b52-a3da-9eca319866c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f9d0a2-efc9-4412-b2d1-ccefca9f7637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de168b4-d8c0-45c3-a495-b9be6bc5fd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d24b25f-69c2-4f59-b621-dcaa27d97188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e9900b-9d16-4a9b-a19d-ff3b9d6c9fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3135ddcd-f7a8-4b6c-97a9-ef0499b754ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b9b1c0-0869-4ac8-b689-5ecc39d72737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 156348d4-8f19-4b1f-8571-0113c585480e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1277961d-aa78-4ba4-9da6-827c379c6501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7169f897-ca98-4930-a3ce-b45e0ea6aef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ffb596-252f-44ea-ab0b-36e40b85d27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76137b9-d438-44ea-8aa9-5c89db460b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0bbb9f2-bbd4-4ce6-8101-0302cb61bee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1a1e1b-f096-4b0f-8210-38b97bd419d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e97d4a-7747-4e18-b7c7-a5b3eb4bd488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35198f1b-4efb-4b04-a23d-7f37266184d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510aaaa0-9461-4f94-8b34-d6be34f75d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a6b1ae-d758-4692-bfb4-e8779c78e0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e53ca2-83ef-478e-a609-e44b5f79e926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6dfb828-b578-4978-9062-d197f96d6028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8061227a-08e3-431a-92da-7669f7fb2228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4bfe648-3f34-4fa3-bd3b-a4fd58cdd556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d9a252-0027-416a-b771-1713be8798a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599dbf05-18f8-4bc2-a416-8a2fc50dee61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5378ea2-f147-4b21-93cf-1fd1f61e46f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d70ca78-280b-425e-8088-a1e9975ac2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ba67b3-0632-44c5-826b-38d5d7d35d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a056e983-030b-4eec-a5c7-4f7c3d1a4222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c758ec8-c405-4ddb-84bd-3f93a68c84f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413b7903-f35c-40ac-a09c-6c78a2dbc9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3b0b0a-3c30-43c1-bac8-4e80d04c1714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2513ac25-6756-4c9a-9baf-603bd4d96212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c47269d-c3e1-490f-9ed6-16179da805ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb237b5-90aa-4829-9d52-767f7052352a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bc79bc1-b233-41f5-bca6-f70853bc69ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64de3ed2-1698-40c0-a535-452b314dc058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2452ddc-7d42-4e43-ad67-b788e7f130dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12100adb-1b25-4a8a-8eb7-10e482995d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe044d15-1dfc-4db9-9a64-40348d3fb3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aca8630-3c17-4dc6-b702-0f22f69458d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3906c0-4c78-4495-8ee9-bafa50fcb701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c8e4ecb-e71a-4596-98c8-e297019ed796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4027f8-b0a0-4a54-b488-be9e1fba3995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f0e7a9-7607-4206-b09c-7c0a33b15ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac8a59c-327a-49d4-a4dc-d6baea858fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7825a65e-8cef-4d15-b486-f05045b6153a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449e7eae-304a-4fc2-afa6-18ed435c2ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04de997-483f-4e76-be9c-639bae05f05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e937442c-7c8c-48b6-b7db-4082d568ac20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ac53ff-19cb-4479-93a0-a6051956ebb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b7ba572-3089-4a2f-bb69-f3818f055d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5025efe-8047-44f5-9c46-456717514b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a792efa-07c9-4b75-8f06-04d604bcae41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54d2f3c-dcf6-4c7e-b43d-c94cb0206b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231055bc-20f5-4bf2-aabd-6d5cd0966c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4aad4c1-875d-4aaa-8602-8a7bd684e5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83e3261-1a7f-4c95-b7a9-8839dcb42382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c28ce691-9f99-4d9d-8e59-0032f1f5833f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e81149f-588c-433c-b7ea-4b095f7e42d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e6baa5-9fed-47ed-8c60-3b488c446614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4654209d-4331-4688-ae0a-805b0aea1ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57338981-f354-43d5-a42e-f964eddafd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8df931-ace7-4bd4-b42a-e9413056d284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71c58a8-4639-4c61-85c6-a03029c45334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2ec2fd-7133-44fa-adc5-b79a58b65c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7466042-6299-4fd0-b7e0-32c0c4b4c39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db9ffc9-3b4d-4e96-86f9-dbb509addf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2cb61e-9a3e-44d6-8920-92a27116e995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c4ddae-4331-4333-a8ac-fe4f11f4a40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ccd4cd-3174-4244-a2f8-7a9d08b15753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3360e1-8e35-4688-82a4-f77843e3a8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f70ab47-af69-4805-966b-53b357980721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0582173-d278-4ced-85e1-3288256df8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c30b9d-f9ef-4fa9-a7fb-a5327514c31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af342d6d-aefe-49aa-a788-3b233ddcb0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e803e2d9-a1c6-4deb-abe8-a509064d509d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b70e534-69fe-4aec-a82e-3b2a92afb081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973f1839-1dcf-4b42-92ce-aba36da65995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6cccfa2-ec81-4ca8-aab2-8bcc36119b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efad16f-5c1d-4b65-9b04-ee9637f0d252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a356bb7-ea83-4110-90f3-7a880de4f71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af128bb-3def-40a0-bbcf-e76337b05112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d74d3a-d682-4007-b653-73cf01231ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcad544c-a6a8-4f65-8d56-1a2e1f95d208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc905f69-3773-49a8-a560-b89f47e22941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f3141b-f18f-4845-b88b-b3f8ee9af04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcbcc24-1fde-49ad-816a-da6eabbdc18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e7cdcb-527c-45fd-a3c3-4360a48c6bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b141e705-506c-4194-92c4-fd6f5b443dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d2b9cd-becc-4f6e-abca-b72b010b554b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cac1313-08ae-4543-8380-bf5c618013a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd6f8300-75f6-48d6-84b1-6bc027dad7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6819e60-1930-449b-9f1c-93e2c73266dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd47857-bd7d-4a84-9c18-40d56412f57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976bb353-e71a-4286-b38f-b304017a7010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d62b481-b8fc-426e-a1d8-2be5e197cd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3362cb9a-2039-45b7-93d2-1262c6e78c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b934be-f1fc-49fd-825b-720fc28db5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523503eb-cd8e-4936-8e9d-b56cd45a2880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e7696d-c61e-49b8-b08c-ab6b99edb177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 465f7391-1cb0-499c-940e-17b83129efe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb00730e-855a-44be-af32-be2912c2e56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ce6228-f5bc-4777-bfb5-b6fec9e4baed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea11e28e-9053-48fb-823d-6fabb963cbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60d6294-46af-403f-8c8a-7d8f24b7c2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404cd410-c6de-4dac-9b08-f2347ae76532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38828cb2-83cb-4070-a9be-d0d1bc9956e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbc2b2df-f838-4673-9d3c-586b08eaf6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1115e02f-c8cd-42a0-82d0-eebe0125fbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0cdb5eb-3ecc-46e7-bc8c-3e06b32c3f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a1c6c9-58c7-402e-863a-70f27333b830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5057a9-1978-40bd-b0e4-10578e9cfaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73c31c4-b5eb-4804-b83b-3e7905dcdb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb8a2bb-6de8-49d2-8eef-eaa73ecb405d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1742c115-3dd9-4451-8ce1-35f929d5a539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b2bc51-1741-4ecb-af0d-ede2e455213b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe9231c-4b28-49cc-986b-94cca42fe47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191e86b0-f6d4-426e-a576-191d91372595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da55875a-bf1e-41c7-9168-40872dcbaeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976fdbcc-8a3b-4c79-aafa-dcad11a14dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d7e33f-9fae-4fa8-b50e-11c9b5366b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8f9606-d12c-4893-bff5-3f7ff0f41584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae49d73-7b14-4d83-8132-330d6726520a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91886121-cee9-44fb-83de-d2304b9c04b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 178be965-dbc2-4a72-ad22-95ee38363446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04c8652-58ff-47e4-906c-e21c87e83d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfc3478-5f70-44af-a265-93e2037b94ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23708f95-f279-4636-886c-1e1688f75253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6adf0102-2ed2-4623-b8ea-893f4d53e728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455c9d61-26ce-47d7-b963-825569dba7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f07d990-3f09-4458-a875-dd81d058de07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aea7a5a-a045-41a7-9918-0ba2821749a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a899c52c-39b4-4d30-bb52-d17a0a1f33f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb1b0fb-37f6-4957-9536-9869bf044d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbbde1f0-e922-400a-ae7d-1b572f357e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afd013e-49d5-40dd-9956-26f8a2ebde6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbee77c-3240-46bc-bd6f-eecc8ef0f0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304da790-5149-4434-aad5-cc20a84d6c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24de7082-b11e-47b3-8e3d-7b58a4c5970c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc8fa9c-b554-4e15-849a-e366adcbfa39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a242cd46-5415-4067-8f71-bec98f7e3586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d43d9db6-6374-402e-89b5-4bedc576bdaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0162e4f-0658-4537-bdb3-1f8be58be1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b93fb6-879b-43dd-b690-351adfe69576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86c8c4cf-5eac-4f3a-8f04-7a0c3a912407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9469dfc-7d4a-40a5-a9bc-c085038833d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe6b502-304b-4d7c-a52b-23148f554bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15adf4a-4ff5-4401-a651-70bd685737ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe4ab69-9618-475f-a8ed-31d727d51a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca79d04-5306-42ec-b07f-dcdbde1940bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d612c092-c685-48da-a623-3e1e3f6659e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1b60ab-826e-4c3e-be72-8d3303532cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9d9e87-898a-4f32-a315-c828c1de8312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b74ce1-5cde-4290-b711-da1762de3d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90c60ef-b394-4e7a-8336-72f0e4e8e3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb6259c5-12bb-46ab-846d-b3ba180e53c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094acd09-63d8-4241-95b7-b5249941ad2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b92222-1909-44b0-b2fa-4b931addfadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402b1d94-ae00-4b4d-93cd-dcbf6ef857a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f504fb69-6b9f-4e66-847d-b8e7dc1e5649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c791d1e7-696a-4199-9eca-bfdb7a1361db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40a88cb3-8810-4ad4-b703-9d6fb192f5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42df4c9f-35e8-4b1e-91b9-17f1cf16f2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c017789e-fe6b-4475-9802-4cc26511896a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333c67bb-2da3-4486-87f4-83cf18719901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75793df-2b38-4d4c-b5f6-4c4acc236562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4a1834-620a-4017-97de-f43927bd41cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c24dbc3-c717-4bfc-a3e8-690e507c860c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9dcf168-fc32-4448-b20d-478504459a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f170034-5127-4122-a6e8-6208b8953aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337db292-f33f-4fa5-bc64-788120bc3cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e7d0c3-b767-44b0-80c8-124cbdae74cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510cae0b-e648-4d0f-8b07-bb96db357c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027d8431-9a21-4102-92ea-43d9afa6b23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39772509-3be2-4570-881d-516a5e383885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b190bb5-9876-4e8b-a02f-4aba3e77abac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d793a872-e423-4bfd-bfc3-02d93768c1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163e8102-09c5-4cf6-80e2-426ab8b13329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f52eb0-088b-45eb-b341-00360fd0c434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc7a821-6b0b-42d6-b15d-49e4a7fad308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9258e40c-1988-4226-ad75-984268b5c245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961602e0-6ec6-4cd4-ba25-3ffc657a914a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7268d10-813d-4334-9404-9661bb3d581d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f1ced5-539d-40fd-81aa-5a232d06a7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 866a6000-bd94-4e83-aca8-3dea6d235393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bea21db-943c-4d06-b224-fe56e330a21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dae01d5-8740-4c9a-beb1-8d883419205f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 357cf784-550a-4bca-bd57-a078ebacf3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e512c8-12fe-4b95-89c8-897b15b6edc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf7096c1-727f-40a5-be47-9e008d417dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89220c71-790a-4d5c-8f99-58581cf396a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a89d49d-7c65-4265-99d1-430eb96218e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7956577-ec0e-4bdc-bd36-20991c9bc3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d47ec1d-b214-46d1-8776-f31043be9c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86c09d81-262c-4ee5-8ba9-db3e4a4b0d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec24f5f1-b353-4a20-8797-75e3e43a8453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02aab2e-78d4-44a1-9698-6a3c010fd641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8868b419-5129-4d38-897f-c67f36916d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969d10ff-b2bb-474b-8801-c2c28273080a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d69d23-9100-4353-9936-fbcab26b98b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fd8793-a7e4-456b-b20b-9408bf2a1719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad30ad8f-4952-4877-8490-56d06aaae91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d090b10-fbc7-4285-b39e-fe35954c432b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd39c94d-4062-4cb6-b4a9-b847b0318a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3389dde1-0636-43ef-b812-2c4b19fa0fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c01fa57-ebd9-4267-aaf1-7a3b1f078273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcad40aa-7319-44fe-b1a5-4180bd4724dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754e18cd-f520-48da-89b3-3c0bc5b3c5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a43fe0-b318-49f8-8bed-664f8f6c200a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e240b4d-e426-48a5-bae8-8bdacea02d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e4812d-ac3b-4674-bb04-2eed4c2613bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41081ec8-11cc-4557-9bd9-8389fc059527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7c4088-6640-48d1-9cd3-ab3ea82b54cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6b662e-22a0-4c1c-ace5-157b920d8f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2cfacdb-efff-4f98-9f5c-d5c9d55f4b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0745639-7cf4-4d6a-82a3-221cf495e3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 073422dd-22ae-4c1d-a09d-6b93d43f0b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d9ea6f-5621-41dc-a2fd-37372a9a7524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74834cab-c959-450a-9996-1b6597a13ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f99f67-aad5-4112-9866-82a2250854e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c0ae83-d4de-40f9-ba39-d409ef106d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2e2878-1325-48c4-98b3-b01e02ebcc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a84561-2027-41cc-9f66-3ecb6c4824df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ddcf6f-14b3-42e0-a8fd-3d55526f4d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f9d63d-533f-475a-99e6-5e30b7bce911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714a2e53-5149-4daf-a27e-8b1ad52a1386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e3b6ff-7d20-4a80-992f-17d5cebd8311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e7b697-d4a8-4383-bd6f-feb1b7d09651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b17e13-0d56-4027-95cc-5427d8ea7843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4f9ee5-c329-4b91-b601-f30d9b36baaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9231b1c1-f3a4-4d59-abce-ea0ae9674b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adfc8702-b289-48cc-94a2-b0c06b7c15ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44a5941-afa2-472e-9138-fbdcce0972ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e93353b-6847-4fa3-b654-8ce4f2ee6650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55140855-4bc6-4e66-8158-2dd0ac04efe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7f9eef-f278-42c0-ae70-b07e97379ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac460e3a-2bb6-4613-81fa-c30b0221dd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1129029e-4b99-41cb-a599-a18a6346ddf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97a2ea3-e053-4ae5-a31b-6eac8e378008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11bc97f5-afd6-4fb8-9821-06c9de77bda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de6e298-c2c4-493c-9e33-d9a7321a8374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e341eacd-5436-43e2-9ea6-4a7bc7c4043b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a738ba-70fc-464b-84c7-9346105b0a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e6d9b4-f3f7-4f87-8a23-4df468b92951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baff57b7-405a-4592-b14e-3ca3df1527ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9768f750-666d-42a4-bd6f-5ebdf495f16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d0618b-3fd2-491c-80ac-df0bcd0b4a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f951b8a-6e2f-49dd-b11f-3a5209ef509f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f0a3d89-810a-4ebd-a2e8-89b92b7560a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd3890c0-be80-4b8c-a073-6dbf2c683864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9736d8ab-2e26-4aad-bf42-848380994033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d027bfea-419c-4b89-aecb-2d2434a4af79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f678b9d5-7ad6-4e98-8858-d0368d9fae78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a8fca2-a0c6-47d3-a487-a3f64ebcb598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91365811-449b-4206-9c32-5b345e91a9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9dd5ccb-7f6d-4a6f-8838-0c94025a4d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d096f67-7f92-4f64-9822-f94784b9c90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d816e4-5b06-418a-a10c-868eb120e44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c75c3c-3d21-4f3c-ae2f-a19e2311008c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2c9bf9-2d0a-45a6-813e-ca5cada2d203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bf6632-cefb-458b-afa8-097e08ec2242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d73af6b-f0dc-4d6e-9689-0d6349e994a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30441d28-2672-4965-9923-3c8120f95e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12109377-b2e0-43f5-befe-fef4e959b668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24089e99-6faf-446d-88e7-92c399d74a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd28344-6871-484f-96a7-df986b51063e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c89f11-777a-4530-825c-b924f890d752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1742bc14-aaf9-44d8-87aa-7ba27edf265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071a72fc-b9d6-4f29-ba35-d9b199a3be2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14565aa0-b658-4332-bfe6-73bbebd2f179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306f7cd4-4fa4-4579-b9bd-5d700a4bf0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22913bc0-c433-4198-91f1-a940140f0fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe571de-3ea6-4064-a66e-8b029a12e632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f1346a-fee8-4075-bee0-50be8b53a548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557754fc-a472-42a6-8109-60a84aa3b550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f418fde2-85a5-4559-a2d9-0c6c1d98b5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88039a10-84ed-483b-87f0-6b525f36875a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533eb710-1be2-46ad-abf2-4a47ddd9c6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3222415f-71e8-405b-99ad-a94f0536f2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0c6669-2a30-43ee-be89-c80ba78fe636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe89b56-2d8b-41fa-a39a-4c9e25b43c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03ad3ff-59cd-425e-ba93-ed7b13cc3108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54935221-cea5-4882-a5a5-b0d8d25a0e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3bc0e3-2edc-44b5-b31f-6c6792b4c3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c936de38-bee1-4008-b44a-4bdaf3d454b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df95546-b6f8-4806-90f1-4fd282d9aa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b74f20-f696-4b8f-9bb6-f72f11b99f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d343f2-63ae-4d74-9323-80689b7e8ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642b2bb5-0275-4aa3-bf23-83bb5719ab9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2338ff2-35db-4c18-a393-54807c73b8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56907900-802d-4586-aee3-c0b9a105e107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17bccfd-aad2-4607-b156-6ef9a3ec0bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9110bd-34fa-451b-8cda-0c6570a4415e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d245e0ed-3c34-401b-8203-4870e849b552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df35f760-b3ae-4e69-8e49-8ec65495d208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754193be-a4ad-4d13-8c16-96000602ced4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0ec656-4614-4de0-9b50-6f120a0e2dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642917ce-a502-4bfb-a763-7140be8aff7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c968d2-e039-4f23-838f-33c09b8c1ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a926f82-ccf1-48bd-a94f-78094e981a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52332e03-8d17-4bed-88f4-6990539cd6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b92f9cb-3682-4cb9-97f4-74f031e1af40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d83929-c3fb-4d01-9a4c-702029e99e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d683d05-1964-4a32-a4b1-c2469c4a366d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea0ba08e-28f5-4b74-b9d8-c7338c54cfa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d711e123-04fd-45df-bd93-865ea947a74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cf8ca3-2199-4a35-8292-6ffd66bf91a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c882447e-c2d9-4f52-8307-940320bd738c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce791d5f-2949-4b5c-8923-f496ef25eb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a4ad29-df9a-4b23-8d50-6d87c09549f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7925151-56ce-4a03-b0c0-4168265ba9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72294091-b8e7-456e-93a5-fcbbdf260fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e7846a-707d-4d4e-9ad6-c221012c4135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a674a699-293a-46d3-92f2-ce4a99d83b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 567de62b-76b3-4544-8488-c0071b06ee1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010d5d23-2725-4e6c-aab7-efce192a3e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d2c9fe-3bd2-4ea6-b2c8-20d087d1a049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3f2efc-d2d4-4915-a463-c9e6846656a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847cef32-5b7c-4ed6-be46-a7b0099c9c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2646e34-a1bd-47bc-bf89-3ae18e7c454f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62567360-7151-424d-a163-03b9b32a882a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef119f7-cd44-4272-a555-d679d4a97cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec2725e-1986-4cb3-b02e-eb2b504c0ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4ed876-b5c6-4a29-8952-bf748a7c85b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15dae144-6ce5-41f4-94c0-c9ad91f37300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa17016-d303-44c6-9789-036e57623948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e749623-0968-4611-86bb-8eec967651dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd041d16-7aca-4a0f-973d-f2d004dc365b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ab218c-ac1a-4cc7-bdd2-3d39821d0497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbc7328-b2ae-47a7-bc73-e6b6900ce91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9bb132f-dfea-42ef-9f63-f53fe7a2582c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b012216c-aea9-4b10-9d84-b3d49e6e887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57aca6d1-0454-4b12-988e-6e1b761a169d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca401c4c-47a4-4d67-abd0-816c4fd58618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ceb921-3532-4f9e-b0f5-5668caec1f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5a6618-5728-40fc-b9fe-cedafbb6c12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bbfb23-bf09-46f1-809c-44983c41ce1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a05f61-8cbe-47b1-9d93-91eecd00c201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dcdc7a5-c22c-4a0a-b915-d75b8b4aebf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18dc38fd-1561-4951-87e7-82d642eb9314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0340d48-8762-4c6f-ad88-81410a1bc04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004d3c87-5d86-416f-a1bf-99f051fc2068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a85590-778a-475c-bd17-b4c0f76d2361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a36a88-9e1b-4fc7-b5e9-416d4b731534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206f236d-5a57-4249-94b5-942b642ebdb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64a1313-e038-41df-9550-0e375c3258ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a48950-b40c-4c5f-ad7e-cd29e9e8fb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1240e3-b527-4436-bfdd-bb9cd0e78b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435bd7aa-d170-4f7a-82bf-b074441b35d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75329f6-d615-44e0-9034-7026a4b233da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b796089-7688-43df-9822-24fcebb14e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d29ef0-d9af-44a1-8062-66750576c4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e019128-12a3-4fa0-8c24-385e3e8d3227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f6f1d9-e93e-4005-ba5f-b65a53101e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ec2c72-921d-4db5-95bd-d551fc8475e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a5a8f7-710d-48b8-a1ad-1e4bc1580f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3023de-922b-4629-a97e-daaee388b83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd2402d-0f30-4da0-a8b4-77b2b44f46dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd332af-6430-4220-8aed-9f3ab272a5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a6ff74-36a0-4e81-b907-3cc468e99c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bbac51-973c-4fab-b7ab-5c4ef92ff9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0bee0c5-da32-402c-a06f-08f47eb375c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c65b9f-7325-4a39-9eb1-590efe82278b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8435ad46-6d27-4a93-81f3-9d51481ede72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 764f2684-8f7c-44a5-a23d-eaf1493f897b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f18ca1f6-ada3-425f-ba91-710d0c7f7141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb12d1f-79d6-4121-8882-191149238679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c51ca9c-fd91-4b51-b1c9-974307b3ecc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666e45a7-71e2-48fb-9fcb-a545eca850b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09fcf556-90db-4d97-8842-2fc70cb05ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee38c03-6120-430f-81e1-3886657a8085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35eef053-c546-4aa5-8e74-f026ff400425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3849b8-87b3-4560-bfb4-fd0a93d2570e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c90a41-b5f6-4bec-87f0-c8462f5fbbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581e1c2f-ba9b-4a46-89d3-f83d4018c2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b1c675-6f1e-4bf7-8d4a-01d798b7bba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f61d24-ce32-43bd-a8c7-05b62775e290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b7b592-01e6-4e25-a267-99f1e252f35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8ea12d-7728-4c5e-90d9-5b3ba080d040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbed97b-c852-4471-a8e7-f62f8fcd9fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7861126a-9db9-415c-b59f-beb863d67377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f65c2aa-69d0-439c-ac7c-5513d24997c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adc9bd34-0229-4828-a8b2-4eac13b5336e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e591dc-f4b9-4178-8b67-c216349b5dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cb581c-5947-4ddb-a27c-71d204925741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006f3fee-a1a3-45b2-9000-94f1981bc3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5392bf4d-ae07-4d4f-8a97-d049f539d3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94129c6d-7608-4289-ac6f-3439bdc8135d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4577d9a-7812-4ee2-9014-70b2d879632f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168dd583-bc4e-4f81-bcb0-f0ad53e9951e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455ae943-a4c8-4453-9103-9c03e7cccd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866e3800-f6bb-4346-833f-4b278673c423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2679126f-34bf-4336-9a7b-e3a661158526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9b5534-2116-4765-9a49-f1825ebf4f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd4fc00-dd28-4cbd-bf2f-16c278c1d915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d9a780-9c3c-439d-92ed-d90706c81024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bc714f-d3a5-4d24-bc92-c64ce83813b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd12dd57-9d6f-49c5-a4e9-637f40e8cd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbfbb1a-58cb-4390-af3e-1cee29b80385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60fb13eb-2309-493e-bd75-d60d05b5e551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a45f5a7-42b5-4dd9-b286-2ce04d0a61ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a61a20-25e1-4440-90aa-c85939c0fa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7e2bbf9-1c2a-42e7-95d6-8b5002588e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56ec2dc-7182-4b92-931d-b6bceee39b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a08de8-9aaf-44a4-8e8f-2e71b0aec3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5778e9ac-459b-4f4e-b05a-782e76ce861b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e1494f-000e-4c18-a5a7-5d415c0e73e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adfd8306-232a-4dc4-82f8-05d7006c1017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ca5f7e5-dc47-40a8-81bd-a270aba3e2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ac0238-fd6b-4fb5-a0f3-ce398c3f0c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e344001-5980-415c-a10c-092a960570f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1cd7d4-dc31-43e1-bb96-b5d05cc756de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef6922e-1a39-46cc-ab0e-1147f27254ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89950b81-5d33-4dc2-8335-7627bebdf969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15387f94-7940-47f0-8ada-7b400b524bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be940a6-4037-4b74-a410-a3eea3821328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 095dc778-7fef-4335-9720-a9354647d149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f4e127-c4e7-4c6a-9a1a-1976bcc653d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608a3a48-667d-4391-b6d9-3c730b77f397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02e89e1-0d38-4cec-8159-d53fc0c8c6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8becfa79-7c7c-4e8c-bd76-8d0cf4d4c487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912273f2-85b8-4999-9145-68325aff4f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 990847f6-8e9f-45d3-8d18-4bea14717a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0027621c-30df-42ee-a473-3f53bb33ecc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51851747-6e68-4409-9c16-266f6d4ff9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0edce75-2b31-4ef7-8bb9-9e5d1211feb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c5096d-212e-4dad-b7fb-e19f8a5604f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588f5c22-6cc5-4504-951d-d0f33dd430ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e171c4c0-7ab9-4cd4-9f5e-95bf98525a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d220ef43-89d6-464d-839c-22529161adb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95936e9-cdfa-4af2-b10e-13e3ff56fe31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a673c6f9-a60d-495e-b646-1f9265a94307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49296cc-522d-42e2-8b16-35cd07b4106d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2711b8c2-cbae-4852-878d-787df571ad74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a96fd9-b8a8-451e-850a-084f0dc07c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1215e0b4-9fcd-4843-8dd8-fdfb47650ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036bd3d8-304b-4a71-bd85-e6ce07ee53b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd333e5b-3439-4968-af50-5bb6c8f632a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e947a619-5526-44f8-9f94-1664ed5803ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0736f952-2c87-47f3-a96f-271c1ae6ab86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f7d02b-ed63-427c-babc-ac66c675bb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a91e432-382a-4055-a3e2-891a938fff5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724630ef-112c-47aa-a5fe-bbbc5572dd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c9ce0d-a3d6-4e25-9364-e91aab7e3b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0c9614-4afb-40d8-abda-2b391701c33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e78d32-e42b-4ea1-8e97-1bfc8b0d1d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac67ac4-06e9-4dc8-89b7-aefa06a14173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cc766f-c0c9-4bce-90b6-5fe0a3e85b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1973b62-7565-4bad-b5ce-bf01c7acdab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf13289-6516-4b9c-9942-39adc476ea54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b52f23-1930-4d8d-b765-e1cedecb9e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7513398f-f026-4a1d-8b21-09540becd0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7013464f-8803-41a7-b734-4b7542152e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cde6780-ce86-46aa-8792-63e26a38a28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f614ef8f-4c45-46a4-96b5-d9bab1356c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec306fd-2015-4c16-aadd-880cba61dd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a0e1d3-c375-44d6-967e-4dfddb5deb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1115d5-e7c4-47e8-999a-26164b314fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a053a99-7041-45c7-bd71-414c0c7133af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b33b797-5c04-4d58-91cd-e70b362f8f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce2fea5-5af6-4791-8483-062564af1ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65c26ac-344b-45e6-81bc-2f90f8ecde69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d42a5f-65a9-459b-a4e2-a01bdc189ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49598a29-d221-4b67-a94a-8720c66a5db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87284c0-a676-4f0a-a0c8-7ed9ed639ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e084ee8-4243-4916-b9c1-f96dee615979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076ac0e6-797a-41fb-97e2-f05c3ee2447e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296a74f9-6c9b-441b-99d2-77f28897fa67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ade486-d388-4baa-a797-c52259de177e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ceeb70-b43a-43cf-819f-8c93329766ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5bedc3f-ac4a-46d0-86ce-821812535596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73587602-3826-4c37-af1e-543c9394b15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0015c6fd-bc52-4143-85eb-31675b1968c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79655b87-fb5b-432e-9333-61b033e98f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb661b69-e3ba-4f69-8be8-15534422375d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8084f46a-ecba-45d8-9493-aeee24b722da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7a7b57-ae57-4a94-af79-c12b8061e828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1acdf9-1c8e-4b3f-a895-f509afbbc5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6615aa6e-e8eb-4db2-b1e8-bf2ae03bf5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89acbde-2490-446b-95b1-d7558f0ceb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd36fa1-90ae-48bd-9537-50b238541c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef140120-de74-4937-912c-68d91207c38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8826b3d8-c54f-44d0-a8e1-7e0ba96cdd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beada0ef-4eba-4005-96a5-6e429bd68227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd04f07f-7af8-4797-8ada-f18729b025d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32786907-d8ec-48db-9ef3-4ad9ebadb148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e6c54fd-dc11-47de-ac87-6b61cfca5ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9019e45a-b61b-4189-b3cf-ba0daf63b02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af44b02-f072-4023-ab93-0286a1a3c35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2924cb11-7d42-4cf0-8686-f966f52b0a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ddb208-7397-4738-a6fa-62b127f8e8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1ff5d3-7d49-4a0e-986d-ff7816de1552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933ab1e0-4a70-4ed5-b815-e1872ddae429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a522eb5-c85d-4ef1-9dea-a9cf689dfd10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9afd0a-ff51-4237-8530-cfa5936ccf72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c952743-efd6-4731-b919-7dbf3c2f0531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a360cd-1d85-4468-836e-c05cf42e50ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19dd873c-f729-4ef6-aa33-88820857fd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88393d7e-7eca-45b9-87b7-908bb4c97137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdb1cfa-62dd-4383-afb3-6584d269ded2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527c945f-ce08-4a74-bde5-ef6da1af9f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8997ed1-85c2-4b72-a9b7-fe40076a8d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284d85a9-5119-4387-9bf6-c64eb2a6c3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5637e9c2-6549-4e99-8210-a945eda14927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8a1d17-7a5e-42e0-a978-6c04f9c02f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a864601d-ec1c-4172-8c13-6fbadf40f8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7221ff5a-a95d-4aa4-96f7-77564704f3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a43683-febd-43e9-a575-3a0be974998d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196e7138-ec51-4c02-a53e-bdbfe5d06fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea1f6e3-e39e-4a6f-be64-55e7cd233c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bd4925-2181-44e2-9456-6346f7bbd5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03461ab9-03c9-4ffb-8e6c-266c09d1835d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff0122c8-4b22-4fb1-a8ee-1220f0c68c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963b05d0-4fed-4acf-971a-8f3999660c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f69493-8a63-4ad7-9965-9e56d0ff02e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f6b368-ad02-4dba-9bb8-30ae1a901711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79d26ce-0948-48b4-8158-51a216fa9455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddd2422-195d-41f9-87c7-4af549d14a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbd9daa-0ea7-4214-9e2f-9bd4de202b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6e4c82-39e5-43e5-85fb-9f8d433e29bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b35beec7-c160-4920-b4c5-cb5f9454e82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a40216-b62c-4be1-bbd5-64785560833f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e09f4f4-581e-4c15-b799-c4b10a1be21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c217653-921c-4f91-8889-2b3711b9865a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9631d14-d743-472a-bd4b-8aae6b3cc0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bcfa49-df9d-4bd2-a2b5-2cefaa6a7539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de3b513-4484-45e8-8825-9a6a2faad851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a118c4a-04dd-4d8c-86e7-6f7cc3a2dbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d15d85-8226-4861-8edb-cab12d609a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf62835-1c9e-46be-b8c3-e1a6c96dc609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf4e755-fc64-406e-9ea9-ff914c23d8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f47dbde-a864-40b0-9a16-7dc8c3acf400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ee8136-a6d2-48c3-96b7-d40f7af6d302
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(5643, 24), y=(5643,)
   Test:  X=(1411, 24), y=(1411,)

⚠️  Limiting training data: 5643 → 800 samples
⚠️  Limiting test data: 1411 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1529, val=0.0834 (↓), lr=0.001000
   • Epoch   2/100: train=0.0893, val=0.0829, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0812, val=0.0813 (↓), lr=0.001000
   • Epoch   4/100: train=0.0820, val=0.0812, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0811, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0813, val=0.0809, patience=8/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 1 Summary - Client client_9
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0036
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0012
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: -0.0079

📊 Round 1 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: -0.0001

============================================================
🔄 Round 4 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0852 (↓), lr=0.000500
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0798, val=0.0859, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 4 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0029
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0018
============================================================


============================================================
🔄 Round 6 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0832 (↓), lr=0.000125
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0800, val=0.0834, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0799, val=0.0836, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 6 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0043
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0168
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0063

============================================================
🔄 Round 7 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0932 (↓), lr=0.000031
   • Epoch   2/100: train=0.0775, val=0.0932, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0774, val=0.0933, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0774, val=0.0933, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0773, val=0.0934, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0772, val=0.0936, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 7 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0007
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0082
============================================================


============================================================
🔄 Round 8 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000008
   • Epoch   2/100: train=0.0817, val=0.0772, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0817, val=0.0772, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0816, val=0.0772, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 8 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0013
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0105
============================================================


============================================================
🔄 Round 9 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000004
   • Epoch   2/100: train=0.0818, val=0.0754, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0818, val=0.0754, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0818, val=0.0753, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 9 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0013
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0082
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0754 (↓), lr=0.000004
   • Epoch   2/100: train=0.0818, val=0.0754, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0817, val=0.0754, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0817, val=0.0754, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0817, val=0.0753, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0016
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0013
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2466, R²: 0.0077

📊 Round 10 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0068

============================================================
🔄 Round 15 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 15 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0027
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0024
============================================================


============================================================
🔄 Round 16 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 16 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0026
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0025
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0064

============================================================
🔄 Round 19 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 19 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0020
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0050
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0065

📊 Round 19 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0065

============================================================
🔄 Round 23 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 23 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0029
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0004
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0065

============================================================
🔄 Round 24 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 24 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0023
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0022
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0065

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0021
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0066

============================================================
🔄 Round 27 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 27 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0018
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0028
============================================================


============================================================
🔄 Round 28 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 28 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0018
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0042
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0066

============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0005
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0032
============================================================


============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0038
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0063
============================================================


============================================================
🔄 Round 35 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 35 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0048
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0090
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0067

============================================================
🔄 Round 37 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 37 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0019
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0040
============================================================


============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0044
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0058
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0067

============================================================
🔄 Round 39 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 39 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0035
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0028
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0068

============================================================
🔄 Round 46 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 46 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0022
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0030
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0068

============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0011
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0073
============================================================


============================================================
🔄 Round 48 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 48 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0019
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0028
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0069

📊 Round 48 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0069

============================================================
🔄 Round 51 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 51 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0012
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0022
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2465, R²: 0.0069

============================================================
🔄 Round 52 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 52 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0194
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0069

📊 Round 52 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0069

============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0020
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0031
============================================================


============================================================
🔄 Round 57 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 57 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0030
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0080
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0069

============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0027
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0063
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0069

============================================================
🔄 Round 60 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 60 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0038
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0129
============================================================


============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0052
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0070

📊 Round 61 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0070

============================================================
🔄 Round 65 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 65 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0001
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0022
============================================================


============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0014
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0020
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0070

📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0070

============================================================
🔄 Round 70 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 70 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0005
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0029
============================================================


============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0041
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0063
============================================================


============================================================
🔄 Round 73 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 73 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0006
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0010
============================================================


============================================================
🔄 Round 75 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 75 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0031
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0046
============================================================


============================================================
🔄 Round 76 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 76 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0027
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0008
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

============================================================
🔄 Round 77 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0014
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0015
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

📊 Round 77 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

============================================================
🔄 Round 79 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 79 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0012
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0059
============================================================


============================================================
🔄 Round 80 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 80 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0065
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0173
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

📊 Round 80 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

============================================================
🔄 Round 84 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 84 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0058
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0323
============================================================


============================================================
🔄 Round 85 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 85 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0017
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0004
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0031
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0056
============================================================


============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0004
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0105
============================================================


============================================================
🔄 Round 90 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 90 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0033
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0051
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

📊 Round 90 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0071

============================================================
🔄 Round 92 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 92 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0018
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0075
============================================================


============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0032
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0061
============================================================


============================================================
🔄 Round 94 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 94 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0089
============================================================


============================================================
🔄 Round 96 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 96 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0021
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0017
============================================================


============================================================
🔄 Round 97 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 97 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0023
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0006
============================================================


============================================================
🔄 Round 98 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 98 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0001
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0099
============================================================


============================================================
🔄 Round 100 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 100 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0023
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0233
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 101 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 101 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0036
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0063
============================================================


============================================================
🔄 Round 102 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 102 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0049
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

📊 Round 102 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 106 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 106 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0000
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0078
============================================================


============================================================
🔄 Round 109 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 109 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0034
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0040
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 110 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 110 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0046
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0141
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

📊 Round 110 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 114 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 114 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0007
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0060
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2465, R²: 0.0072

============================================================
🔄 Round 116 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 116 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0024
   Val:   Loss=0.0677, RMSE=0.2603, R²=-0.0005
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 121 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 121 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0042
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0126
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 123 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 123 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0010
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0134
============================================================


============================================================
🔄 Round 125 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 125 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0029
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0051
============================================================


============================================================
🔄 Round 126 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 126 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0021
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0001
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 126 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0028
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0034
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 129 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 129 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 135 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 135 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0027
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0108
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0005
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0007
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0071
============================================================


============================================================
🔄 Round 140 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 140 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0017
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0128
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 141 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 141 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0017
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0017
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 141 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 141 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 145 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 145 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0057
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0181
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 147 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 147 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0003
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0013
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 148 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 148 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0004
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0061
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 148 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 152 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 152 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0001
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0097
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 153 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 153 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0028
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0060
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 156 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 156 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0022
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0006
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 156 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 156 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 167 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 167 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0016
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0035
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 167 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

📊 Round 167 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0072

============================================================
🔄 Round 172 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 172 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0113
============================================================


============================================================
🔄 Round 173 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 173 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0033
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0046
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0009
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 179 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 179 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0068
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0406
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 179 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 181 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 181 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0025
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0041
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 186 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 186 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0036
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0052
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 186 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 186 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 189 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 189 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0048
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0176
============================================================


============================================================
🔄 Round 193 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 193 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0047
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0156
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 194 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 194 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0038
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0081
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 194 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 194 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 199 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 199 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0013
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0010
============================================================


============================================================
🔄 Round 200 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 200 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0015
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0152
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 200 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 200 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 207 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 207 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0008
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0002
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 209 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 209 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0022
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0046
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 210 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 210 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0014
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0010
============================================================


============================================================
🔄 Round 211 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 211 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0001
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0072
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 211 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 215 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 215 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0006
============================================================


============================================================
🔄 Round 216 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 216 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0033
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0157
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 218 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 218 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0034
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0040
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 218 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 220 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 220 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0046
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0086
============================================================


============================================================
🔄 Round 221 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 221 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0021
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0009
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

📊 Round 221 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0073

============================================================
🔄 Round 223 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 223 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0020
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0012
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 224 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 224 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0024
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0467
============================================================


============================================================
🔄 Round 226 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 226 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0044
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0106
============================================================


============================================================
🔄 Round 227 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 227 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0021
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0006
============================================================


============================================================
🔄 Round 229 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 229 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0003
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0065
============================================================


============================================================
🔄 Round 230 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 230 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0022
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0051
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 230 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 230 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 233 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 233 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0105
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 235 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 235 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0033
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0044
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 236 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 236 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0036
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0095
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 236 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 241 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 241 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0020
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0068
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 242 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 242 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0010
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0066
============================================================


============================================================
🔄 Round 243 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 243 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0027
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0015
============================================================


============================================================
🔄 Round 244 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 244 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0037
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0079
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 244 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 248 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 248 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0051
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0504
============================================================


============================================================
🔄 Round 250 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 250 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0007
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0026
============================================================


============================================================
🔄 Round 251 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 251 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0007
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0248
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 253 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 253 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0019
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0120
============================================================


============================================================
🔄 Round 254 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 254 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0029
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0060
============================================================


============================================================
🔄 Round 255 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 255 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0018
============================================================


============================================================
🔄 Round 256 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 256 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0010
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0012
============================================================


============================================================
🔄 Round 257 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 257 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0037
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0093
============================================================


============================================================
🔄 Round 258 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 258 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0012
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0076
============================================================


============================================================
🔄 Round 260 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 260 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0015
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0010
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 261 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 261 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0026
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0061
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 261 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 267 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 267 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0046
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0308
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 267 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 271 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 271 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0112
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 272 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 272 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0003
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0064
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 272 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 277 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 277 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0084
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 280 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 280 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0037
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0093
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 287 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 287 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0034
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0041
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 289 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 289 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0107
============================================================


============================================================
🔄 Round 293 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 293 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0060
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0195
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 293 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 295 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 295 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0001
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0075
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 297 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 297 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0033
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0151
============================================================


============================================================
🔄 Round 298 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 298 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0046
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0581
============================================================


============================================================
🔄 Round 301 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 301 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0017
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0024
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 304 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 304 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0029
   Val:   Loss=0.0714, RMSE=0.2671, R²=0.0058
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 305 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 305 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0054
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0257
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 305 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 305 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 309 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 309 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0042
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0038
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 310 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 310 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0025
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0057
============================================================


============================================================
🔄 Round 311 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 311 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0006
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0096
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 316 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 316 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0038
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0264
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 318 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 318 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0050
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0097
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 324 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 324 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0019
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0023
============================================================


============================================================
🔄 Round 325 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 325 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0024
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0005
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 325 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 328 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 328 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0004
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0026
============================================================


============================================================
🔄 Round 329 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 329 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0031
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0039
============================================================


============================================================
🔄 Round 330 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 330 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0026
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0111
============================================================


============================================================
🔄 Round 331 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 331 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0036
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0111
============================================================


============================================================
🔄 Round 333 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 333 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0004
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0066
============================================================


============================================================
🔄 Round 334 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 334 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0013
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0033
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 337 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 337 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0047
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0109
============================================================


============================================================
🔄 Round 339 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 339 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0049
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0157
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 343 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 343 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0069
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 349 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 349 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0043
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0149
============================================================


============================================================
🔄 Round 350 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 350 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0050
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0089
============================================================


============================================================
🔄 Round 352 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 352 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0011
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0055
============================================================


============================================================
🔄 Round 356 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 356 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0010
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0115
============================================================


============================================================
🔄 Round 357 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 357 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0015
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0013
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 360 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 360 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0032
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0029
============================================================


============================================================
🔄 Round 361 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 361 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0024
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0021
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 362 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 362 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0005
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0100
============================================================


============================================================
🔄 Round 363 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 363 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0043
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0089
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 364 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 364 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0007
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0047
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 372 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 372 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0057
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0216
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 376 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 376 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0024
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0120
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 376 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 380 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 380 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0028
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0077
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 381 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 381 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0015
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0035
============================================================


============================================================
🔄 Round 384 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 384 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0003
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0048
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 385 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 385 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0009
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0025
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 386 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 386 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0059
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0190
============================================================


============================================================
🔄 Round 387 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 387 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0004
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0124
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 388 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 388 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0002
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0116
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 393 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 393 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0037
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0041
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 394 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 394 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0018
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0029
============================================================


============================================================
🔄 Round 395 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 395 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0015
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0054
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 396 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 396 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0030
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0012
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 396 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 398 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 398 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0006
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0078
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 401 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 401 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0056
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0154
============================================================


============================================================
🔄 Round 403 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 403 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0017
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0036
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 404 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 404 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0014
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0059
============================================================


============================================================
🔄 Round 406 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 406 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0025
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0034
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 410 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 410 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0020
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0030
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 411 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 411 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0012
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0022
============================================================


============================================================
🔄 Round 412 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 412 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0029
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0015
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 412 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 416 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 416 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0022
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0187
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 419 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 419 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0015
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0011
============================================================


============================================================
🔄 Round 422 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 422 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0001
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0016
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 423 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 423 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0028
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0001
============================================================


============================================================
🔄 Round 426 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 426 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0002
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0079
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 428 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 428 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0028
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0143
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 428 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 428 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 434 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 434 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0041
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0061
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 436 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 436 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0033
   Val:   Loss=0.0686, RMSE=0.2619, R²=-0.0098
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 439 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 439 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0034
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0098
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 442 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 442 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0024
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0014
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 442 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 446 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 446 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0026
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0007
============================================================


============================================================
🔄 Round 447 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 447 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0000
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0008
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 449 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 449 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0016
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0043
============================================================


============================================================
🔄 Round 452 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 452 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0095
============================================================


============================================================
🔄 Round 454 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 454 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0024
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0012
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 455 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 455 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0022
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0035
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 456 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 456 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0029
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0007
============================================================


============================================================
🔄 Round 457 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 457 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0025
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0010
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 459 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 459 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0027
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0134
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 460 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 460 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0022
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0020
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 460 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 460 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 466 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 466 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0010
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0046
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 466 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 466 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 473 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 473 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0022
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0057
============================================================


============================================================
🔄 Round 474 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 474 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0016
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0104
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 475 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 475 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0015
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0114
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 478 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 478 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0007
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0056
============================================================


============================================================
🔄 Round 479 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 479 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0025
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0039
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 479 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 483 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 483 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0027
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0000
============================================================


============================================================
🔄 Round 484 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 484 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0252
============================================================


============================================================
🔄 Round 485 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 485 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0024
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0016
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 485 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 488 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 488 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0022
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0023
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 489 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 489 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0005
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0031
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 490 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 490 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0025
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0008
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

============================================================
🔄 Round 493 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 493 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0087
============================================================


============================================================
🔄 Round 495 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 495 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0021
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0018
============================================================


============================================================
🔄 Round 496 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 496 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0049
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0255
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

============================================================
🔄 Round 500 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 500 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0015
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0011
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 501 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 501 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0005
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0080
============================================================


============================================================
🔄 Round 503 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 503 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0030
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0059
============================================================


============================================================
🔄 Round 505 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 505 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0004
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0086
============================================================


============================================================
🔄 Round 507 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 507 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0019
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0036
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 509 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 509 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0026
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0001
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 509 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 515 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 515 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0021
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0031
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 515 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 515 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 515 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 525 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 525 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0021
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0004
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 525 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 529 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 529 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0020
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0042
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 529 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 529 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 529 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 529 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 543 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 543 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0033
============================================================


============================================================
🔄 Round 546 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 546 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0020
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0029
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 548 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 548 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0054
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0404
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 549 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 549 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0041
   Val:   Loss=0.0652, RMSE=0.2554, R²=-0.0081
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 551 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 551 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0024
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0019
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 552 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 552 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0015
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0040
============================================================


============================================================
🔄 Round 553 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 553 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0167
============================================================


============================================================
🔄 Round 554 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 554 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0062
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 556 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 556 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0030
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0005
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 558 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 558 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0155
============================================================


============================================================
🔄 Round 559 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 559 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0041
============================================================


============================================================
🔄 Round 560 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 560 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0032
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0027
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 560 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 562 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 562 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0050
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0228
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 564 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 564 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0016
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0050
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 565 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 565 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0015
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0045
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 567 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 567 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0038
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0042
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 567 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 567 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 574 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 574 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0003
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0084
============================================================


============================================================
🔄 Round 576 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 576 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0049
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0135
============================================================


============================================================
🔄 Round 577 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 577 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0031
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0030
============================================================


============================================================
🔄 Round 578 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 578 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0044
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0066
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 579 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 579 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0035
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0033
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 581 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 581 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0041
============================================================


============================================================
🔄 Round 582 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 582 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0028
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0001
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 584 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 584 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0020
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0013
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 587 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 587 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0042
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0058
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 587 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 587 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 587 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

============================================================
🔄 Round 595 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 595 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0025
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0010
============================================================


============================================================
🔄 Round 596 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 596 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0036
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0059
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

📊 Round 596 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

📊 Round 596 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0075

============================================================
🔄 Round 603 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 603 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0012
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0048
============================================================


============================================================
🔄 Round 604 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 604 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0036
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0035
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 607 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 607 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0033
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0241
============================================================


============================================================
🔄 Round 608 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 608 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0030
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0004
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 610 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 610 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0003
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0107
============================================================


============================================================
🔄 Round 611 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 611 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0051
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0179
============================================================


============================================================
🔄 Round 612 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 612 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0042
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0065
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 616 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 616 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0035
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0021
============================================================


============================================================
🔄 Round 617 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 617 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0045
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0069
============================================================


============================================================
🔄 Round 620 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 620 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0204
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 620 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 623 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 623 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0022
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 626 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 626 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0031
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0000
============================================================


============================================================
🔄 Round 629 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 629 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0024
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0108
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 631 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 631 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0000
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0058
============================================================


============================================================
🔄 Round 632 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 632 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0048
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0170
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 633 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 633 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0025
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0012
============================================================


============================================================
🔄 Round 634 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 634 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0030
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 634 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 634 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 634 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 639 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 639 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0035
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0036
============================================================


============================================================
🔄 Round 641 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 641 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0047
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0161
============================================================


============================================================
🔄 Round 644 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 644 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0033
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 647 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 647 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0159
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 649 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 649 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0045
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0068
============================================================


============================================================
🔄 Round 653 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 653 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0011
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0038
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 654 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 654 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0039
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0026
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 655 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 655 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0020
   Val:   Loss=0.0863, RMSE=0.2939, R²=0.0041
============================================================


============================================================
🔄 Round 656 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 656 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0051
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0179
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 656 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 656 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 661 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 661 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0018
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0011
============================================================


============================================================
🔄 Round 662 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 662 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0021
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0044
============================================================


============================================================
🔄 Round 663 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 663 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0023
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0034
============================================================


============================================================
🔄 Round 664 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 664 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0012
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0055
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 664 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 664 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 664 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 671 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 671 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0040
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0040
============================================================


============================================================
🔄 Round 672 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 672 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0021
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0031
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 675 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 675 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0016
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0046
============================================================


============================================================
🔄 Round 679 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 679 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0014
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0021
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 681 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 681 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0008
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0022
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 682 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 682 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0001
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0130
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 682 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 682 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 682 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 689 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 689 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0023
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0021
============================================================


============================================================
🔄 Round 690 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 690 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0014
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0057
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 690 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 700 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 700 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0002
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0125
============================================================


============================================================
🔄 Round 701 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 701 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0017
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0061
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 705 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 705 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0009
   Val:   Loss=0.0912, RMSE=0.3021, R²=0.0076
============================================================


============================================================
🔄 Round 706 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 706 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0055
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 706 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 708 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 708 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0057
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0418
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 708 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 711 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 711 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0013
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0064
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 713 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 713 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0014
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0084
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 717 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 717 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0023
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0008
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 720 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 720 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0045
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0098
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 720 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 723 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 723 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0012
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0071
============================================================


============================================================
🔄 Round 724 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 724 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0022
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0041
============================================================


============================================================
🔄 Round 725 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 725 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0003
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0101
============================================================


============================================================
🔄 Round 726 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 726 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0055
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0152
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 726 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 730 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 730 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0029
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0007
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 730 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 735 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 735 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0022
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0032
============================================================


============================================================
🔄 Round 736 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 736 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0086
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 737 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 737 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0036
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0070
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 742 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 742 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0033
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0013
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 745 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 745 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0033
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0030
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 746 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 746 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0030
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0009
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 747 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 747 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0005
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0032
============================================================


============================================================
🔄 Round 748 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 748 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0007
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0021
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 754 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 754 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0008
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0105
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 757 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 757 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0047
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0108
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 757 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 757 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 762 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 762 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0027
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0020
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 764 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 764 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0043
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0042
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 764 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 767 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 767 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0016
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0060
============================================================


============================================================
🔄 Round 769 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 769 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0004
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 769 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 769 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 769 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 776 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 776 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0088
============================================================


============================================================
🔄 Round 778 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 778 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0048
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0433
============================================================


============================================================
🔄 Round 780 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 780 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0038
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0041
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 780 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 780 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 780 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 784 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 784 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0018
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0043
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 785 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 785 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0035
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0132
============================================================


============================================================
🔄 Round 786 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 786 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0017
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0066
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 786 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 792 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 792 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0029
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0019
============================================================


============================================================
🔄 Round 793 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 793 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0044
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0123
============================================================


============================================================
🔄 Round 794 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 794 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0045
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0303
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 797 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 797 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0039
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0084
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 797 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 799 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 799 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0021
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0008
============================================================


============================================================
🔄 Round 800 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 800 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0072
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0218
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 800 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 800 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 800 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 805 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 805 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0008
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0087
============================================================


============================================================
🔄 Round 807 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 807 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0017
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0130
============================================================


============================================================
🔄 Round 809 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 809 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0027
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0073
============================================================


============================================================
🔄 Round 810 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 810 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0021
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0027
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 812 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 812 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0036
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0015
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 813 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 813 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0021
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0025
============================================================


============================================================
🔄 Round 814 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 814 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0045
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0132
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 814 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 817 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 817 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0011
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0041
============================================================


📊 Round 817 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 819 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 819 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0027
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0023
============================================================


============================================================
🔄 Round 820 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 820 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0018
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0061
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 821 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 821 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0003
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0052
============================================================


============================================================
🔄 Round 822 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 822 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0015
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0059
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 822 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 824 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 824 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0002
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0025
============================================================


============================================================
🔄 Round 825 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 825 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0040
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0183
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 825 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 825 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 829 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 829 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0024
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0041
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 829 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 834 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 834 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0039
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0020
============================================================


📊 Round 834 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 835 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 835 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0002
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0145
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 839 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 839 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0024
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0034
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 839 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 841 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 841 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0017
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0064
============================================================


📊 Round 841 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 843 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 843 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0029
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0017
============================================================


📊 Round 843 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 845 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 845 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0014
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0007
============================================================


📊 Round 845 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 845 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 851 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 851 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0035
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0003
============================================================


📊 Round 851 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 852 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 852 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0004
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0110
============================================================


📊 Round 852 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 852 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 855 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 855 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0019
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0021
============================================================


📊 Round 855 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 855 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 855 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 855 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 855 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 867 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 867 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0008
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0004
============================================================


📊 Round 867 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 869 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 869 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0013
============================================================


============================================================
🔄 Round 870 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 870 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0079
============================================================


============================================================
🔄 Round 871 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 871 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0008
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0100
============================================================


📊 Round 871 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 871 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 871 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 871 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 871 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 883 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 883 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0020
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0142
============================================================


📊 Round 883 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 884 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 884 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0011
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0090
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 885 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 885 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0033
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 888 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 888 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0024
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0020
============================================================


============================================================
🔄 Round 889 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 889 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0048
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0054
============================================================


📊 Round 889 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 891 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 891 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0062
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 892 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 892 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0001
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0102
============================================================


📊 Round 892 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 892 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 892 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 897 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 897 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0028
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0191
============================================================


📊 Round 897 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 899 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 899 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0006
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0105
============================================================


============================================================
🔄 Round 903 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 903 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0018
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0053
============================================================


📊 Round 903 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 903 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 907 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 907 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0022
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0018
============================================================


📊 Round 907 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 909 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 909 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0015
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0076
============================================================


📊 Round 909 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 909 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 912 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 912 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0020
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0048
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 912 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 912 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 917 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 917 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0038
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0055
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 919 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 919 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0034
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0001
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 922 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 922 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0043
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0047
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 923 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 923 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0040
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0024
============================================================


============================================================
🔄 Round 924 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 924 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0045
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0105
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 924 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 929 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 929 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0006
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0054
============================================================


============================================================
🔄 Round 930 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 930 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0057
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0102
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 933 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 933 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0041
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0265
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

📊 Round 933 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 935 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 935 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0055
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0212
============================================================


📊 Round 935 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 938 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 938 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0027
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0017
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 939 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 939 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0018
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0066
============================================================


============================================================
🔄 Round 940 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 940 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0038
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0012
============================================================


============================================================
🔄 Round 941 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 941 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0071
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0513
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 944 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 944 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0016
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0074
============================================================


📊 Round 944 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2466, R²: 0.0074

============================================================
🔄 Round 945 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 945 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0027
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0028
============================================================


============================================================
🔄 Round 946 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 946 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0059
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0116
============================================================


============================================================
🔄 Round 947 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 947 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0029
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0004
============================================================


============================================================
🔄 Round 948 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 948 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0011
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0032
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
