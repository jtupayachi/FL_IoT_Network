[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf0d287-38ed-4e3e-9a58-9f76a395a5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369360c1-5941-4688-bc7a-7508a657231e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 462b42b2-6435-4f54-90ed-bb7a3f590923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b302f9e-5e3d-4c8d-9f9a-6a265ef5a95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5890018d-3ff2-45dc-be62-a3b5e58b2d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3594ea6-a4ce-49de-b1b4-6842ab298021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbde8279-cdba-488f-8c89-1786e77d8b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b3790f-3aed-4ec6-a198-b317d7dc4bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df9b81e-da8c-4316-adbb-35e57c91466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4147e03-2d32-4ce2-b065-5cbf55857447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af47303-a0e9-407f-96ad-ef5281f5c4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b31ff1d-5e51-4e5a-a4ef-9e32afea429e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4aaec7c-726a-470d-a1ff-fe3e2499b59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee30c5e-da20-4396-bedd-065745c1cb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f177ea-ff16-48a1-84cf-addc1848800f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6ea2a0-bdca-44f0-afe1-9469d4581efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c842a58-d844-4836-b4fd-5a4a97c77c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b85b8a2-5247-48ec-8629-b0ea93280724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57dfb4b0-617c-4ca3-b3c1-7cb994eda171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29922c9-4d47-4675-a7ce-7d8ce957daad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a039078-1af4-4bf1-a7e2-3b5fe46f2755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4c793c-b7f4-428d-a9a5-0282f9198255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c35713e-69c6-416a-885a-dfd18195bd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8210fd-0275-4545-bd14-99cb4e5fd0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57dac338-cd1b-4406-91c6-e07b6cde1e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ca2966-5d6e-4abd-b936-53a4acaa0fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de79d612-900e-4363-ad17-c924a3e96fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8318735d-7b2c-4863-b4c0-28faf0fb863c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf925ea-af72-410f-b664-73e580177d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09f8141-18b3-49eb-8bcd-e9e611a1b918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1fdc18-8e31-402f-bd91-1059f394cf8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e09907-1c82-4906-8536-28e9e8f2d1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3477f381-3726-4615-b751-2cf7e938bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6533dc94-555a-467d-b124-84d6fe56ae99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769ac2d9-52e7-4ded-b566-3397fd435c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763722bb-507e-4121-9a20-5df91d0ad02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c2ffcd-3dd6-4fb6-8fee-c4362fad5551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abeacd45-485d-4b43-92b7-35de0954b3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825042ce-1585-4eb3-9120-8b72a28d1800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1293984f-9834-416f-a096-a4e4c32646c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862c796d-d43c-4093-9c0a-5638451fb8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d1985b-b321-46d8-b26f-b8e91028907f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de80fdfa-e9dc-4a7a-9dab-3ba35407ffb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f962c52-723f-40a1-b6ce-f842d8baaf30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9049243-2d17-4257-a934-637e2a0fe84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa8f07f-0e9e-4949-b9d1-19f26eff0059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1daa5ab9-740b-491e-ac76-aa18fd75a319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4158ebb2-a57e-44f2-bcbc-b1bac8046364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf3d74f6-792d-4fda-bd94-3be34929599f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5b813f-e702-4942-99db-6f67e0bfa698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4303ebf-0904-4f6e-92fd-40eedc084a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86cace0f-7610-4228-ac44-66f2e2083095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823ee005-523e-42e9-8d84-23266ea125c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77cc9b51-7007-4e83-b9af-42d0072949f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec4ee37-24cf-46aa-98b3-e5eb4f72ef33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8d67cb-39bd-4657-b857-c312c8f1a1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369d88fb-c5a6-42b9-afc1-00be2eeae457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a18ddff-0768-4850-bbd4-036b32a4d210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480b5695-05e8-425f-8c35-0137e9730acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51181f1-46ef-4dde-86f6-d3a29b1fd483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db0d6614-d39b-4c29-a49c-582ace977f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c82ca1-cf6d-470b-a5a3-a8ced7558988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edbbe363-39f9-4480-89e2-828392c9130e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69376417-cb18-4a50-837c-67818496bd64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46fe1058-26e1-4cc9-a98a-79276b7bda1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc46ac2-5f54-4bc6-800f-be630e4e26a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d76d368-3215-4330-8992-bde41d920561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc13640-1966-4ade-9dd2-3209b78e0292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e697b779-aedc-4666-a06c-185cc0f1159f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69983797-f394-44ab-bf8b-61781d4d7b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5d8fd4-a5c2-4ebf-bee2-43a54feb3934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f041d159-139d-4f93-a48d-0ea4794d5c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5890580-b10e-4e76-a154-f0fe11fc1bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cfdfdb6-9ae3-4934-a429-8ea7f537ef56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1bc71a-e123-4e7e-b4f7-7489a0ca4678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41995464-474b-4e75-947a-e38c1fadd570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2479dd-af5b-45b5-a1be-8a7530b5d773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a850e0-56d4-419a-8503-676528bd1c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a26433d0-a8c6-4e6b-b61d-dbbe9cc5a95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbdd3304-2420-4658-b00b-6a5780eff999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a679f71c-7347-4c3a-ab10-af4b72e07f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423497ec-76b0-4bd9-8968-9d46b7d12f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e09cdd-c0aa-46f1-b4e3-9d5b7bff00e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ed6664-ea80-4291-ab77-df2504f8ae88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b62f00-0840-4704-95e1-70ebc5a1caeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d561da93-c302-4d38-a49e-732e2bc8031a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8938e2-3ef1-4420-8840-ab7a3bf78cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7da3bc-49d1-42a5-baa5-88d11a931171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b13c177-c082-415f-ad0e-def97e970351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f972646-585e-4b22-bd69-b0d7d6b39275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce77543-d2e0-4206-811d-b47ab5ab2c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b1c0edd-5370-4c69-a3ba-a2df6815c7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6346f90e-7538-4cfe-81ed-d2c64837fd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddf2969-ab53-4d76-816e-29d2397986b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08bad23f-7b6b-4778-bacf-4f7bc2448fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae21539-4d4a-4102-8598-900eacbb9780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9877cd7-56f5-43e4-acf1-f1e011efa56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9b7de4-965c-4fef-b1f2-5a5f7fbc299b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26be38c9-3cac-4366-907f-3a78915d6440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4749a1e3-0f09-450b-ab9e-540ab90bfb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9590aed-d8b5-4da7-b2e7-1cfa22c3a527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6606caf0-4d6e-4c85-8583-4119e2e59cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df3a137-3010-4488-a470-3dd82b5c1919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62916e08-be10-4bf6-8d4b-1ccdf295930e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e208a25-e7cc-46f5-84c8-e65b169e9763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24670edc-5dec-455c-bd49-9dc6091a8491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff905f96-f67d-4847-bf12-f6ba34bde386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9feb1d85-48aa-4560-b57c-ade1f6ef7a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ac375f-fc9d-43a0-8493-bd0d2c6b4c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e737dc2e-a8d0-4429-97c1-e9c1a357652d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d208628-ae97-419c-b4b0-a6fe8e8a4c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b536f0e3-afab-4bef-8349-68cdc19e4918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d94ee02-a7c4-4f2f-a1eb-dcae55313158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a23acc-465e-40a1-92af-0895cae4270e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b2d3b5-4565-4c83-bf80-218475d16570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4280e6-f8fc-4360-8f87-7befb662355e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2bfb5a-f893-477a-bd3d-0a473da78cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b33207c8-d704-4ce5-8e4e-ffcafdf7d988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0a072f-89d9-40c1-9223-ce79a26145e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe374092-e25a-4b58-89a3-5aa278d6a980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d10bb0-6086-4956-9d12-7363ff768cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b996f18-c50f-4c33-965d-3412cd30f023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b533780a-61cf-4516-85d9-3af12e7ffe44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8156c5-65d3-4e49-a1a8-df8cbc40d89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be870a4e-8c9c-4638-b10f-67e8c2b1bc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0fe36d-b7c1-48e6-af83-56662bf0595d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8296b66b-8984-411f-8296-b1909c6d27bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8217d1be-77ed-4796-9706-3ddb20d1cac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35481166-d418-49ed-857a-f86ff953cb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520353d1-82bb-405e-a0f3-e085eb8f96ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa526a7a-c827-463b-9ad5-46de6de275e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b2e19b-bb42-4505-8dfa-c84baa7b8a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bf0313-06ff-43bd-89fa-da5d996b6ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6625d9ac-df16-403e-8ea9-89f877ec4ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76479dc3-d4f0-4cd9-9ef3-0824f0a1ecfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ec3923-ea7b-4836-9db2-44ba1139a709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7504b5d-d21d-415b-804f-1bc9e33ccf04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801efd27-ad18-40a3-92ba-fda4b4e97656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05a606e0-8679-42ef-b543-66e14968eb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c199237a-f1a4-4ca3-b028-3c0d90fdbd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06006e0-610e-4a9c-99be-390ae7da08ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26824d6d-cf32-44c9-8e75-9023bac16881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f9a61a-c2b0-4977-abe7-6de8900fcdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66bf217b-3c86-4629-b541-6a5ca603b2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8619d967-d772-4186-a6b1-9e92569e6959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102a49b1-3c1b-4f47-83fd-776b1907bd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5103c060-4b5c-4e57-8a80-59f3f25d62cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f840ca-686e-49ec-9771-8b7c6955c33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a4d5ea-e357-45a6-9040-e4d7f5052182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af63bd6-630a-45cc-af89-3e05393048b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665d7b92-1657-47e7-95ad-c4a69ba80bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5f92c4-de6f-47a6-8d2a-50d438834043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cefdef-2a28-42e3-9da4-6a96a8741234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c9aec5-fd3a-479e-9202-50472ea36a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba6f6e5-c7fe-4b90-8591-f89cef534ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fae9d79-36ff-46c6-9341-e4a572cce6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d6337b-85b8-4990-b693-5b6444989802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8581a74-be44-4e92-94f5-903f32a3a43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf1bcc30-678f-4532-9396-e5eb3cb49d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38625f7e-d40f-4fe7-9e98-b69ce2cf785f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e860383a-2b03-4e3a-a472-09f3665d6287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346c827f-3475-4592-a801-b25cda7e9abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5afaa2ec-4eea-42c4-96bd-0b6d755d2679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a90c316-c8ba-498f-9003-7ce9099e9767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df733e8f-e2c8-43b5-b9cf-5a02b13ad6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ede0031-2eef-4ed8-a994-544706db994a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b766b2-730a-4559-9c06-6b1ffa7f4359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665670ad-d5df-48ca-8ce9-42532dc0a146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77c87b3-3f00-4ac6-a63f-49a189206fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84183e51-6d0c-4475-9ded-930050cbedf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e33fbc7-6579-47b2-a4f6-2cf222ecce84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23644a6-4954-4e4f-845c-2eb7518e7109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5271a20-410f-4b91-939d-85c4ff0de030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f8fab9-96f1-4c06-8572-2e4d40cc4ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda4f71d-a030-483f-8662-d91f6bdda8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6bc8d82-1a82-493a-953d-080664064160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a278d1-696c-486e-94f7-c7a88550c835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945e97dd-1ebf-4fca-88ea-2df93a237815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0144555c-93dd-4b47-9591-bb5ad92030ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8c32b4-98c4-4417-affb-b0b1a17bb310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160ec3d3-db69-40be-b6ee-9d2e24639519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7306bc4e-aeb9-4364-a905-6b9b43219be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c1daffd-1e36-4ef6-a2b2-d645e2ef5e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b9aa10-e165-41a6-b4f6-8756308b4737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc99ddd-9f91-4fd3-9459-86955987aa6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c541e81f-54e9-4206-a495-286b061b0240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f0c112-4b14-44b5-9a26-0772852a08ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0563cb-6644-4477-acc6-e10046f5ff9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d4f9d9-2db6-4d61-a11c-47f54ce80edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1b3e9d-eac1-42df-8e5f-b2875ab36dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ec55cc-1e3a-4b80-afe8-32f8f6dd3b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc8d119-12d9-4824-9b90-ade69d145418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27fcd48-c6b8-42b5-b640-de379280663b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2205b23e-0430-4133-b265-f7003483c92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf863ac-1055-48a6-8c07-d245c32d0e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ec1ae8-9e04-42d3-8282-3999975e1d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55eacf61-5477-499a-a909-591590eedfee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591c8861-6b95-4d4d-bb86-286014b0619f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03238359-e134-421e-a325-8f6df88a51c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467f0bb1-e277-4121-a94e-526a4c306f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcec490f-9d81-4931-a9cb-7d4b8e94c589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da550f4-0f47-4515-b21d-6a1058ef8bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bae46cd-39c8-40a6-9fa7-bc3667a5fed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e3afcd-e668-48bb-9adc-855e25c52688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa45dae-0081-4812-beeb-b23cb30830fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f8a69a-3511-43c3-9d48-6c8e5863f551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1884325c-e24d-40f6-a989-a8a93a29db52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d79d2f5-8374-4f46-bb81-6619f1d3ea6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a84d4d1-c109-400c-9294-eca192401de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e069c9-0d65-42de-8ace-4bc5e6a538f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fea4e18-c26e-472b-8808-34c2c987f9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8d9dca-3ceb-4166-9646-24976a8a893a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecf05eb-3b0d-4e0a-a7c3-67ccde32db0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c891bf-939d-4e3c-a54e-90b72f60ca30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9dcaf2-d90c-4f55-a238-49c75ebaea44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b9198d-e595-411e-9dc7-43c2ae907ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43f13f2-8160-4f8c-a5cb-4e930374f422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba96035-ce03-4584-996f-d23fd8eb7e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19baff6a-648c-4fcc-94d1-07468e2de99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bc76d2-418c-4e7a-9606-0981c2ffc2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7893bae-85d3-4ac8-8a87-5c034e9ba3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbd445d-2447-4b25-9265-f8c88223efa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f678d26b-040c-4ab2-83e7-6c9e9e184506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23a55c77-339b-4fe0-a7c5-c8d521c3c37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dc0f12-1d5f-42ed-a48a-04e1308a2805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5234cf7-9a37-4fa4-9653-cbde0772da78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408efa44-2c5e-46c1-b7ac-48ecd0bdefea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9318ef-0324-4c03-b016-07c270ec6887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111b20d2-1afe-4b6e-9961-dce838d74fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e7c88d-db62-458f-b22a-dd057047a5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fcf4a43-3b2b-47c8-a7fb-d2af9bfcd3f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf08a23-2957-4aa7-8261-ababd6564684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0914b1-f35b-49bd-b14c-12932610f5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c48d225-5e93-4465-980c-87cf4bc60ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 678fd3c7-d023-4353-876a-12cb9260b22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d97eac2-e124-4ecb-8e66-b433d33c4f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eda5ce1-df76-4087-b2ec-369497d76876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a95517-7f17-40a4-b9ec-b00a965e5487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed559a1-88d5-4620-8c63-cd25a960d72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e972b23-086f-46c5-8b19-0c40387e5dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcba8b3e-b44f-4da5-9661-98ee0be1c15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0301f658-4e20-4dc6-a1b0-cac8c36d1071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b7d078-a776-44d0-b689-6d6d80f4c928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34115e3-251e-4df6-beed-11c3879c91a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f540988a-eb41-4bff-96a2-4fb25851e6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79da3d05-ca38-4fc0-8835-a3b551eced43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e904627-f58d-4789-8ffb-f804d945b2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2520f6be-924a-4fbc-967e-18f3ee9e0bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a968c4-77c6-4d0e-8700-a430d52017e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f65276-8cbf-4470-a5c4-9c09dcc43ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76cc9d72-7562-4860-910d-beca6e15b740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb3e3e7-4ebb-42d9-beea-acfb3d44a8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a11aa8-bb9d-482c-ae1e-b8436fea17d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067b3dde-d52f-4c90-877b-1602d79791bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f4dccb-509a-4d50-aefe-009ded884d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab37d01e-2290-45ac-b83d-4e20fd527edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317a45cd-8530-40b3-b21a-b8433e0633a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331539b6-1472-4c24-b1ba-6f097db668d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf9d0d7-29dd-4bb7-bc85-ce3d74b400cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1102b034-ec6c-42ae-a007-3eeab57cc3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc976f2b-8bb7-4cbc-8579-728bb0f2b0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73857e1-8946-41ab-ac8e-4272f60332e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b061aaf7-85df-4635-a91b-2f5ef614efe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb662ad7-3b36-4664-98fc-13fbed8d57ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48948431-b11a-431f-807f-f17801f55b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65af6050-6300-40ca-b6be-aca086c9d4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78bc9d4-01c3-447b-bd68-158e106aa288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 703b33ee-2eba-4b82-8dcc-bf0d0ae02739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c698fef-1263-4401-8d29-545e7792d5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf58293d-b8ab-4e9a-a98d-eeb45dae7e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04de28d0-ebc7-456d-8688-67e7af4eeaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b68f6c5-2d77-4f04-9782-a3c42cd76121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb23d9e-6cca-43f3-93c9-37de7e80fda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2121de9-2e47-4dd5-b31b-e23c62fd6571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef247d46-ed48-44f0-8a6e-4739a0295a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af2d891-6b46-483d-b17c-4d92b411e2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56fa61d-41f4-48ae-99db-b4c7ae084284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77589cae-7858-4cd2-995f-6206b26bb5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e141fc6-86ad-4409-9196-620450624c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec6bced-1b02-437c-974e-d6523c98216f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd6b83e-c4c0-4db3-8170-f6658812fb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5487896b-c517-4774-8860-84927e249b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa63ade-98e4-4c03-b1e5-a7b1318bbe29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890d6021-ca02-4d3e-941d-123b330cee6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8887036e-f6c7-4618-b59b-732ee44a9237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a3b6c1-840d-4e73-8c37-d7a70e7d18f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df73a1c8-358f-4946-8b8b-d56fe27f8efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57951437-bffc-473d-afae-f8dc571415c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7284d1bc-9aee-4c19-b93f-1cdeae443732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470808e4-6d1d-4149-a4a2-09eb9789ac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46b7499-2e2f-4651-92a2-90138911784d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 289fa311-c994-414c-9905-cb8ac5915496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df1fff7-fd2c-4bb2-8117-bb26a6579125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365297e3-d3d8-466e-b28e-755e6e7f8fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c4d832-0315-4c01-96b8-7b5b70217d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa6e2d0-1fab-4d9b-a190-0f4af5cb37c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c9d77-d8b1-4efa-b0c7-5fa55931347c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e42e672-5565-4df4-b044-50e89e54556c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47f4975-8636-495d-813b-be10f95f0fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a738500-c8df-4999-ba9a-3b40b7923a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7f90dd-6a27-46a2-9648-814ce2ba928f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6195768-fbdf-4e18-8615-f3f1b51c49ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87bc0b27-6ef1-466c-8875-b09c7091c2fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 659448ed-26d0-4b17-a72f-51a28747b29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a9816f-8fc1-46c3-9925-23941255150b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7428c842-f3ff-429e-a8a0-db960aad8c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6211b1d0-332c-4389-bbde-79e7cb814207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274b9de1-4c9e-4f8b-8e8d-48131d176482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54af5fdc-0d06-494f-9753-54c736e4841e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683325ab-eab6-4cea-a6da-7cf2e02be27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d240a7-9541-48c0-ad2b-5fe725c7d7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e5032d-6d80-4afa-8b71-0fe578e9ba25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759af4b5-fcf1-4d4d-8bf5-39c51ebabb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446a23e6-3115-4dcc-a56c-f99279474fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3528ab99-5aab-44bd-92da-946cea87b6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beeed364-09e6-463c-b083-03ed9f1f4292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee0aca1-3299-462d-b4c9-7178c9cf2bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1078b3a0-6e80-41f2-9a45-b98eab394330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14dd0352-a037-421c-8788-e136cbbb9b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07975aa8-03d7-4b8b-b977-668e4deb754e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b4ab20a-c99f-43ba-aca2-43cc3d920caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46788ef0-e9b9-4e47-af93-2bacfeb4c738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9ee7dd-c20c-4b1d-b4fe-e473b6195267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a32245e-ba4c-4303-992a-95f5807b9848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb358a3-38d8-4a3c-87da-86d4f90acdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c89cef-ebd0-49dc-a1f3-ea9a90fec4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78e8188-a1df-4593-b6ba-7ba977ed4eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22bf561d-cd27-4e13-826e-b98f5bf34221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8339ac45-ca57-4fac-a99e-1b3d23896794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94fc9eb-1bf8-46f3-a0c5-3940b91b7638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a687f38-a9fe-42d5-a1c5-8e58684acb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf68058b-ca7f-4e1f-af5c-45436d586f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcacafad-b4c7-413b-8138-c0583fc9626e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f17a48-fa6f-4ee7-a794-90d26563f4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e5143c-ad8d-43db-afe0-9bd383356f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2842b67-96ff-47fa-b565-f2de63f74498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43298f53-c43c-45d2-8a7f-0e177452ad28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969c2d93-f797-4f28-bc13-363416e694e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed74dfb-8bcd-4bcd-abee-c87e4e5269ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b680354-7613-4f65-b41f-09c9e825a082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d9bbfe-3732-4dde-83c6-2f6a8af63ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f25c293-57bc-4960-b72e-8efeb4bf4f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8377fd6e-2ff9-41c7-aaa0-b95b3ccbda21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e38aa10-2bc1-4da4-90b6-fbf036319986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f0671a-b488-4131-b926-d958f636a44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025f987c-0e02-43c8-bc3c-c28b349112ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4edfd79-af8a-4157-a40a-3e13a8ea7152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d978db-7a50-4e70-9ad0-fde5aa659c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaea2120-60f2-463e-a633-6603405f06cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6273c255-a8c0-4228-8265-bfa79fe8d212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6eb6eab-3f85-4245-bf2a-1b4716449fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e871e5b0-9315-4740-9e98-99173c348814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aaa57b5-4fd6-4a4c-a6cd-a98404a97786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf9e879-98bb-43b3-b641-2a9426515a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb47d9a6-15cd-46a2-aa69-8d566d61128a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc0f0ef-ef7b-4390-8db1-a68ab6d859f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2950c382-02c3-4426-ab68-2c0bc5c68d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055623ba-b881-4a29-95d9-6c9e7274bf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629d38d8-0e12-4f30-9d6f-f145252e947d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ea39a1-645a-4493-996d-36f0dfeb299b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3138fe17-83ca-46b7-ba79-575af6679eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1aa29fd-0727-4376-a0a5-d444b241843a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc01816e-4dbe-4a7f-9506-373759c2c026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f08a1cd-3068-43b4-bedb-28f2a414dd8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d1cab1-e49e-48c6-ac55-47c36c9c4031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d6d761-a154-4aea-aa7e-7f623fd49df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ff1ee2-f369-470d-8e3f-ffc7e7821e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c839a24-2b5b-4c56-bca1-f606e1513caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352b6503-d57f-491a-8353-a453232c9c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9c1db4-fb25-429e-940c-3e48840daf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492d022c-4620-4171-8c00-4819b52f36b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db070690-194d-4524-96ea-0cecd3f2677a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bc13f1-6d42-49dc-8116-2abe1c72dd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8415739d-641c-43c2-9d4a-07fde081713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5fb6fe-5a07-48ab-a8b5-a34ab488d890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d23fc13-66b9-4d0f-adff-9e8550307309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e2f6b0-25e3-493c-b920-6881edfb114a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739ea8df-9cfc-41e8-a105-10f455e78dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686e4622-d9de-4664-ba30-6b0995e5e4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdec4060-c30b-4190-987f-3b59d52cce6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e6bfa0c-32ca-4752-9f43-56b4d79d5b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c5fa4c0-beac-442a-9585-4a1515a1f72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a89cdcf-f75f-465d-a664-57f45124f6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175774ca-0914-4ae5-ba3d-b915ce0245da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb030df-4630-4b18-823f-12de7649326c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de91dbd-74af-4153-9503-6e82e6949ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91bc06ff-bd2d-4528-bb57-0a527463cd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ccf42e-54bf-4ce2-a0d7-e86e3fe9f526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a4dfb4-9671-481f-8088-c0bcbfa61700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe46c99-5877-4513-8e1a-f22ac8214f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6d9323-d9bd-45be-b8d0-20d895cb7c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5dc4775-a680-4e68-b46c-ca068473c691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59581df-27fc-40f5-94b6-29f3ffd02e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e338dd-690e-4665-a47d-75a1692f0099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a01851d-5a66-4235-9dfa-356f5ead133f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456aeba7-89b1-463b-88bc-6d6e3483ee95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1121d0f7-9bcd-4326-a687-9a98e045f699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3728d94-894a-452a-b2ed-1a7d10887cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 357b1b48-f232-44ed-a497-395d539e6cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07084146-4624-4e08-9cfb-7c48608d94be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c43929-79ad-47ae-b07d-bcd4e82e2c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0e56b9-ff7f-42a5-81fe-299dccfb0ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d43c5a5-9c80-46ee-ba61-efc655d86f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc0df1b-54fa-47fb-87de-678e0450206e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ab3ebf-81b9-49b0-9903-1cbf507115bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d773cc9-590a-4b2c-a691-92451e050d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a598b19-1af5-4c74-945d-32497e2e5a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec9731f-c1e1-4943-9da0-0a84f807d3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490acb3a-8f2c-4cca-9885-0ea07f6c72e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b69205c-5be7-4c64-bd52-5d4122005161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47f3ce5-6ee8-4d5a-85aa-152bcef68a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a597862-7d2f-48fe-83d8-31c7a95258d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3a3247-4e09-41d9-91d6-9c7564e9bdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 659d92d2-4b3c-499c-9109-62a9a6dd4969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50344a24-96d0-4b68-8cec-8f81e777917d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0137e0-61ed-45ae-8c18-55d9228beec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b3abc6-dda7-43fa-89e4-b4e45bad2057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1eb52c1-4808-485e-88be-95eb18d7aaa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47d22a8-8921-432c-af59-5810dabc6258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b314f5e9-1cbf-4b8c-aa9b-ba3c928eb758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e95357-f9f9-48c0-a026-4b8d13c97f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd22e038-857b-430e-bc8f-efb1c838b7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aece692b-049e-43c5-ba1c-5407d3050bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c761270e-b1d1-489c-8685-8e4426f129f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80113ac4-c567-49ad-a710-195dcdc1795f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b313b2b-e90c-4c20-9817-6f8bdde651ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c41327-0ea0-4605-9ad3-fb65fd816cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa63f2d4-043c-4290-bca6-210631a16d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345853c4-70e7-4637-b1b9-6917954736be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd150d83-9906-4e27-9a26-7b724154eb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f104267f-749f-4b39-822b-7b68d5c3d768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbd6427-677c-4b77-9bfb-d72621f332db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b895a3e-be3f-49da-8ebe-674ca776f790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bb785dd-1276-4cd8-89c7-c30ae3390886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eace43a-85ee-46ca-88c3-367441c6d278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa7cbbae-2582-4350-b347-f29fdf03cd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b50d0db-71fd-4ed4-b92f-e7a111c019b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699afc8f-0b1f-48c3-87ef-2ab10e86a8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7afe9b02-d4e3-42f7-94aa-8225b7883010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4488450-cb86-492b-82e0-8b1dd3067c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204e8590-558f-4632-ad8e-449310c3af86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe704176-3d80-44c2-bf97-49168f93b8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99d170b-37a0-4c5f-9d8f-684748d7403a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e131511-78f0-4e7b-8641-256b1a318ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e413fa-4b9d-4fc5-9928-5d19940afe31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3bec8e-d496-4b71-b445-29fafc446358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f460a4-74a8-4e32-a9cc-c8021c50cb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8937e0-1862-4dc4-8677-3a7781a5e8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 232997a4-d778-451b-8f40-fd0d625f5045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa97dc0-13f7-445d-a572-9fa096dc6f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abee88b-a7ac-4542-a780-ef2d46f5c9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409062e2-56b4-45e5-b95d-88918b09eb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c68883-d667-47df-ad03-153bada3d909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff511ed6-fde7-4400-91fa-c6d5b5cced79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482be336-2402-486e-ab9b-c714c4ad96bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8baffd-c313-410a-a5e0-338b9fcb9ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2531400-faa2-4e6d-a40e-6d62fa332aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a49790a-71d3-40cd-8653-e390f5210014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cc438e-2dc0-4043-b5b6-9e8c33f1234d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367b9099-ace8-4957-afdc-6fa9bb9d8b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f165a9c6-b31d-4d63-a1e0-082c3ee0cef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da96400-cde8-4dc1-aa54-d481b0db388a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861dc2af-ccad-4681-902f-df47175ac922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5090d71-2186-4dc5-82ee-67c0038c48ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7417022-a9be-4b90-865e-15c58e25c5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7bf6241-5168-44a7-9692-17924b126331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911cf5d2-d9ba-4ddd-9182-70f399da2731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977805dc-dcba-44a7-8cc2-c8d41964a8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b53f549-ae58-4f1e-8132-1818814757d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88d6e56-d467-4a2e-8381-e3b64f03f69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e9997a-d58c-4219-b771-6a3ee5a0caba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 173f314a-1f71-42e8-b010-1248405316fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fc1640-a927-49d9-9603-e24b6e4b33d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e253aa89-b88f-497c-9862-b0c65bb7aabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a25cad9-035b-4938-bf4f-1f78647e8a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8b791e-e896-4a72-a652-e04bcd67b7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638fdc98-e067-49fe-b91e-27df0d9e55c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835236ba-c97f-456a-a12a-138bffc3f92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b5f7b5-9e50-480d-b773-1dab9e09a1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688e6e9f-8666-46ef-ad85-8776c27ca23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98fe0adc-697e-4e23-8df5-f821871358af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63da75b-bf97-4357-9c89-eb2c00dc2f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa2536d-3c22-4359-8b8b-adcbacb935d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c26f3ca-ee0c-4479-ad9e-651154eb12af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0338abae-ee64-4dd7-ba71-ca7fbe3a17e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0da7e2-9f36-4d4e-9e37-d894e7211b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c1a496-569e-4d67-b7d9-29f1ecae3698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4af929-712c-4e52-bab9-101331074760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43234fe-90d9-4bdc-828a-f3ea7441939d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47ff757-f3b1-4f14-bb77-82a3c51b66ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a9c806-9df7-4dd5-8ee0-b112e6819c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28c5eea-bcac-439c-825f-112186b64e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122a92c0-fd7f-4e61-90dc-cce6a3d58543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a26d33c-2844-4d9a-83dd-8e1bbb10f4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2834cc24-76e5-4d25-acbd-c50a891ac75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e6bc5d-8aa9-4aca-a163-9dd6034f0c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce09a02-fda6-4b34-80f8-e30ee7175939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cab94cb-2168-4d20-9f36-86e330ddf9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c10546e-a917-4baf-bd59-609c6cf758f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2636db-fe0b-410f-9bd8-514aa8b0d62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dbf51e4-2266-43de-b66f-966412443699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213122e0-83bc-4212-a7d3-dee0afed57fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8592ddae-ef2b-4208-800d-a955b8406832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80bc5dad-ede3-452f-bf89-5b5f9de71f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 127ab768-73aa-438f-8bd3-8057b822f393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14d6911a-ad2b-49bc-8b5d-86ac13912559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53961822-45a6-4a93-8716-81da23863eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4810e0fa-6bc2-40ee-9e9b-e97cb5931190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec79419d-d091-4f91-94b0-43f51eff1d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d761197-191d-4603-9bee-565f3495c855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7466f8b4-df18-44cd-bf6f-7578f9fe7e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec59f88-b0bd-42c6-a6ae-e52ec567c688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d20ed5-f668-46b0-b04a-6ec012e7106b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b75bef0c-5c7c-47dd-9aa6-4ebe0e724f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c71b4cf-d0c8-4564-a52b-25e7f44f0b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f038e8b3-9e0a-4996-b511-dd98db2ec8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b395cd-5c4f-4545-bd90-8125046a412f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 880b003a-e171-41a5-9e28-a79ca5c9fe9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131ea204-6184-4748-91e0-27fa1fdcedf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4b8e84-6346-4164-a190-3575688b5e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6591bb-5cf5-414a-8fed-4b33fa215bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03e8ab9-adff-44f1-abfe-080dc261608c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f65f21-7e3d-4763-a5e3-b272f56d6778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7a0799-a11b-49ec-9551-5dc2e4c4bfa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f61fc8b-8982-40d5-9b28-9d3fc09786d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a24c03-e622-4b26-bb87-2022d784d8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e6d03c-afa1-456c-86ca-4f8600f0090d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cdda9d6-e4e4-4f86-a7e6-6e39e04ef31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef411f83-eb66-496d-97e4-dd5f6a8a5a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f53c236-af69-4816-9fb3-ee04437f6708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f48455-8d4a-41a2-918c-d3077814b2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f2c894-b9f5-4133-bf7e-f1713edac588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629c48e4-67bd-4bc0-826f-2c9e6efd596b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b39616-d258-445c-ae9f-c1239549f590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6396830a-e88b-45a6-aa91-1df26a200559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130dd46c-1bb5-46e1-ae7d-e8c64079ff28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8282a1ab-85d7-4d98-83d7-dc69307c9753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0029956-e89c-49ee-b5c6-79300878d54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b93a99-b195-42ba-b482-0616758b5624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd7cb26-1ecf-4f4b-ac83-599ae55af1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cd4310-3517-42f0-8d15-f57f2b922a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d71ea80-3db3-4763-98fc-dff2dc257a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5ebe0c-0203-48ed-a374-7e1257af4368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21aa752-b96c-4dbd-af35-06ff3c7d4e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a5fcaf-da09-4d59-b4a5-6260275cf399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fe2bba-ecb9-4ecc-84ac-216880eee7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d660ac1d-212a-4182-82ea-8b442391dbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b09ad85-b9fc-472c-940b-7c45547a0585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6407f403-8744-4a35-857e-ca8e50e283b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84188e0f-5635-4b42-85cb-29636a0b3cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca2ac77-c95b-4649-b8ef-6ab42a10ff2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f7ec0a-373d-48a0-98af-3ddb954c93cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1f3c8f-f1ac-402f-9e4c-dbe11c7c8775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25301494-882a-4743-ac25-91e21b4e5cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf520d8-d3a5-4001-8be2-456f074194a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54f3811-0995-4609-a092-d1f63930f136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce382374-7a3f-410d-b55d-dfa82218f1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52624695-5c74-4bc4-96f0-87c6cfe98072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b391a44-e2cc-47e5-99f0-15b8566bd303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3254953-f810-45aa-9fff-05ce3496088f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b741198-e707-440c-b987-2ddbb300e5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24d0220-97ca-45c9-b3c2-26ecb810259c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2974810b-8ac3-40c8-97ef-45ba59cabce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1959ca4b-c086-4594-9164-0dc484ec8338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38523cc5-1ebd-4ec6-a71c-01c5f1a3dd01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d8aa0c-9866-4abc-aba8-96c7e08ecef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d746b473-975a-4701-af20-85c3a87148d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00b8df0-05ed-41b0-98bd-104a89cd0cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f14775-42d4-4eec-bedb-8db49c3e547c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b1b18f-d24e-4063-8b1a-c1f3c5a4feec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb8ba39-356a-40c4-909c-3603ab939cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210349c6-30f9-43ae-96d6-2e0035e1b25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab48c4b0-3b92-4b49-a8ee-5e37870844a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39eced79-0d4a-47cd-b729-2363649b8e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658eb94c-5f56-423e-b49d-0c3a346d8935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa55e8a-d39a-4001-a713-230c6afc25ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2574cb15-7d03-41b5-85b6-c9749e140b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3515ef-da44-421d-a1d4-e9ea2b055cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63259ad-3b98-405a-a86b-a49e78779a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2724d72d-1af6-44b8-a351-6db2f23114d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed5042a-881c-4769-8993-b38d4e3e84f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bccb0269-c97b-489b-8e58-e3a673d6512a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389382b1-9482-4511-914f-32c7e09a754c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a150872-57dd-4667-a1db-8cd7ad3c92bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb72550-564d-4bc6-be06-8d74d3da6f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a011dafd-d0f8-47d3-82e6-c8108db8fdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3eaa50-a9e2-47c5-8d22-0e575860a54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f92b434-6d12-4baa-bb60-a0d66649fa96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a750a131-e9d3-4766-9900-9084b98a146f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 332e57aa-ebea-408a-98a1-2c9630d6cd35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e920384-e5ed-41ad-b67c-fda64551f374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d9b0d0-e9d2-43c4-8d64-770b8cb1364f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96152e29-a074-438e-88e1-2c1ee37be2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6939aa-6c69-420c-ab00-39ae55d01fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80951be6-bfba-49f2-a73e-19daadbcb66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3c9e0d-9001-434c-90e1-184657aa3c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637c42ec-ac28-47b2-ad33-7cf2fa3194d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62be352a-90e5-41d5-822b-7b971ed9cc89
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(4872, 24), y=(4872,)
   Test:  X=(1218, 24), y=(1218,)

⚠️  Limiting training data: 4872 → 800 samples
⚠️  Limiting test data: 1218 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3437, val=0.1678 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0941, val=0.0925 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0822, val=0.0832 (↓), lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0850, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0845, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0847, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 2 Summary - Client client_10
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0133
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0010
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.4789, RMSE: 0.6920, MAE: 0.6286, R²: -4.7131

============================================================
🔄 Round 4 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4331, val=0.3980 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3314, val=0.2919 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2027, val=0.1166 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0890, val=0.0729 (↓), lr=0.000250
   • Epoch   5/100: train=0.0845, val=0.0734, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0828, val=0.0725, patience=4/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125
   📉 Epoch 21: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0826, val=0.0726, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 4 Summary - Client client_10
   Epochs: 22/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0022
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0062
============================================================


============================================================
🔄 Round 6 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4566, val=0.4599 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4149, val=0.4207 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3805, val=0.3886 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3501, val=0.3580 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3201, val=0.3256 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1284, val=0.1315 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0798, val=0.0870, patience=1/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000004
   📉 Epoch 39: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.0796, val=0.0866, patience=14/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 6 Summary - Client client_10
   Epochs: 42/100 (early stopped)
   LR: 0.000063 → 0.000002 (5 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0005
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0096
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.4565, RMSE: 0.6757, MAE: 0.6105, R²: -4.4461

📊 Round 6 Test Metrics:
   Loss: 0.4335, RMSE: 0.6584, MAE: 0.5913, R²: -4.1720

============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4295, val=0.4667 (↓), lr=0.000002
   ✓ Epoch   2/100: train=0.4279, val=0.4648 (↓), lr=0.000002
   ✓ Epoch   3/100: train=0.4262, val=0.4630 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.4246, val=0.4614 (↓), lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   ✓ Epoch   5/100: train=0.4231, val=0.4599 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4189, val=0.4559 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4138, val=0.4505 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4094, val=0.4458 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4053, val=0.4414 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4013, val=0.4373 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3975, val=0.4332 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3938, val=0.4292 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3900, val=0.4252 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3863, val=0.4213 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.3826, RMSE=0.6186, R²=-3.6549
   Val:   Loss=0.4177, RMSE=0.6463, R²=-4.5489
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.3809, RMSE: 0.6172, MAE: 0.5449, R²: -3.5441

============================================================
🔄 Round 14 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3912, val=0.4010 (↓), lr=0.000001
   • Epoch   2/100: train=0.3908, val=0.4005, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3903, val=0.4001 (↓), lr=0.000001
   • Epoch   4/100: train=0.3899, val=0.3996, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3895, val=0.3992 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3868, val=0.3965 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3825, val=0.3921 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3782, val=0.3877 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3738, val=0.3833 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3695, val=0.3789 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3652, val=0.3745 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3608, val=0.3700 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3564, val=0.3655 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3520, val=0.3610 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3479, RMSE=0.5899, R²=-3.2714
   Val:   Loss=0.3569, RMSE=0.5974, R²=-3.5049
============================================================


============================================================
🔄 Round 15 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3561, val=0.4090 (↓), lr=0.000001
   • Epoch   2/100: train=0.3557, val=0.4086, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3553, val=0.4081 (↓), lr=0.000001
   • Epoch   4/100: train=0.3549, val=0.4077, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3545, val=0.4073 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3520, val=0.4046 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3480, val=0.4001 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3438, val=0.3956 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3397, val=0.3910 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3354, val=0.3864 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3311, val=0.3817 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3268, val=0.3769 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3224, val=0.3720 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3179, val=0.3671 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3128, RMSE=0.5593, R²=-2.8691
   Val:   Loss=0.3626, RMSE=0.6022, R²=-3.5474
============================================================


============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3367, val=0.3501 (↓), lr=0.000001
   • Epoch   2/100: train=0.3362, val=0.3497, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3358, val=0.3493 (↓), lr=0.000001
   • Epoch   4/100: train=0.3353, val=0.3488, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3349, val=0.3484 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3322, val=0.3457 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3278, val=0.3413 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3233, val=0.3368 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3188, val=0.3322 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3142, val=0.3276 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3095, val=0.3229 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3047, val=0.3182 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2999, val=0.3134 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2950, val=0.3085 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2908, RMSE=0.5393, R²=-2.6875
   Val:   Loss=0.3039, RMSE=0.5513, R²=-2.3877
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.3018, RMSE: 0.5494, MAE: 0.4666, R²: -2.6008

📊 Round 16 Test Metrics:
   Loss: 0.2827, RMSE: 0.5317, MAE: 0.4462, R²: -2.3722

📊 Round 16 Test Metrics:
   Loss: 0.2568, RMSE: 0.5068, MAE: 0.4189, R²: -2.0638

============================================================
🔄 Round 19 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2653, val=0.2673 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2646, val=0.2667 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2640, val=0.2660 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2633, val=0.2653 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2626, val=0.2647 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2585, val=0.2607 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2518, val=0.2541 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2450, val=0.2475 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2383, val=0.2408 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2315, val=0.2342 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2247, val=0.2276 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2179, val=0.2209 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2111, val=0.2142 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2043, val=0.2075 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1970, RMSE=0.4439, R²=-1.4754
   Val:   Loss=0.2015, RMSE=0.4489, R²=-1.3228
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.1894, RMSE: 0.4351, MAE: 0.3502, R²: -1.2589

📊 Round 19 Test Metrics:
   Loss: 0.1617, RMSE: 0.4021, MAE: 0.3233, R²: -0.9293

📊 Round 19 Test Metrics:
   Loss: 0.1336, RMSE: 0.3655, MAE: 0.2963, R²: -0.5940

============================================================
🔄 Round 24 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1105, val=0.1082 (↓), lr=0.000001
   • Epoch   2/100: train=0.1101, val=0.1077, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1097, val=0.1073 (↓), lr=0.000001
   • Epoch   4/100: train=0.1093, val=0.1068, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1089, val=0.1063 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1067, val=0.1037 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1032, val=0.0996 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1002, val=0.0959 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0974, val=0.0926 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0950, val=0.0896 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0929, val=0.0869 (↓), lr=0.000001
   • Epoch  71/100: train=0.0911, val=0.0845, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0895, val=0.0824 (↓), lr=0.000001
   • Epoch  91/100: train=0.0882, val=0.0806, patience=1/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0480
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.1111
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0924, RMSE: 0.3040, MAE: 0.2560, R²: -0.1023

============================================================
🔄 Round 25 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0864, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.0918, val=0.0861 (↓), lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0856, patience=2/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0843, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0884, val=0.0823 (↓), lr=0.000001
   • Epoch  31/100: train=0.0870, val=0.0807, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0859, val=0.0793, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0850, val=0.0783, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0843, val=0.0774, patience=5/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0838, val=0.0768 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0834, val=0.0763 (↓), lr=0.000001
   • Epoch  91/100: train=0.0831, val=0.0759, patience=10/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0069
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0109
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2499, R²: -0.0108

📊 Round 25 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2499, R²: -0.0094

============================================================
🔄 Round 28 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 28 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0077
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0090
============================================================


============================================================
🔄 Round 30 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 30 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0088
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0012
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2501, R²: -0.0081

============================================================
🔄 Round 31 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 31 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0073
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0046
============================================================


============================================================
🔄 Round 33 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 33 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0042
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0022
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2501, R²: -0.0083

============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0041
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0252
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2501, R²: -0.0083

============================================================
🔄 Round 36 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 36 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0030
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0001
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2502, R²: -0.0084

============================================================
🔄 Round 37 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 37 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0044
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0040
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2502, R²: -0.0084

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2502, R²: -0.0084

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2502, R²: -0.0085

============================================================
🔄 Round 45 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 45 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0015
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0053
============================================================


============================================================
🔄 Round 46 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 46 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0047
============================================================


============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0028
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0074
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2503, R²: -0.0091

============================================================
🔄 Round 49 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 49 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0009
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0048
============================================================


============================================================
🔄 Round 50 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 50 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0003
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0136
============================================================


============================================================
🔄 Round 54 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 54 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0035
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0194
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2505, R²: -0.0099

============================================================
🔄 Round 58 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 58 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0011
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0429
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0108

📊 Round 58 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0109

============================================================
🔄 Round 61 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 61 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0032
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0009
============================================================


============================================================
🔄 Round 65 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 65 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0025
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0043
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2507, R²: -0.0112

📊 Round 65 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2507, R²: -0.0112

============================================================
🔄 Round 68 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 68 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0066
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0019
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2507, R²: -0.0112

============================================================
🔄 Round 70 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 70 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0015
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0037
============================================================


============================================================
🔄 Round 77 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 77 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0293
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0109

============================================================
🔄 Round 78 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 78 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0017
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0027
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0108

============================================================
🔄 Round 81 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 81 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0003
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0120
============================================================


============================================================
🔄 Round 83 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 83 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0011
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0083
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2507, R²: -0.0109

📊 Round 83 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2507, R²: -0.0109

============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0678, RMSE=0.2604, R²=-0.0118
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2507, R²: -0.0112

============================================================
🔄 Round 90 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 90 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0023
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0038
============================================================


============================================================
🔄 Round 92 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 92 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0044
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0545
============================================================


============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0021
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0010
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0106

============================================================
🔄 Round 95 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 95 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0020
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0060
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0106

============================================================
🔄 Round 100 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 100 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0002
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0077
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2505, R²: -0.0099

📊 Round 100 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0096

============================================================
🔄 Round 105 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 105 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0136
============================================================


============================================================
🔄 Round 107 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 107 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0029
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0032
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0097

============================================================
🔄 Round 108 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 108 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0006
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0055
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0097

📊 Round 108 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0097

📊 Round 108 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0097

============================================================
🔄 Round 111 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 111 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0018
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2505, R²: -0.0101

============================================================
🔄 Round 113 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 113 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0001
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0106
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2505, R²: -0.0101

============================================================
🔄 Round 116 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 116 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0024
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0023
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0104

📊 Round 116 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0107

============================================================
🔄 Round 122 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 122 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0030
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0028
============================================================


============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0024
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0004
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0103

============================================================
🔄 Round 127 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 127 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0029
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0001
============================================================


============================================================
🔄 Round 128 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 128 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0700, RMSE=0.2647, R²=-0.0078
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2507, R²: -0.0109

============================================================
🔄 Round 129 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 129 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0118
============================================================


============================================================
🔄 Round 130 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 130 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0018
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0072
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2507, R²: -0.0110

============================================================
🔄 Round 131 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 131 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0023
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0012
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2507, R²: -0.0110

📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0106

============================================================
🔄 Round 136 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 136 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0028
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0014
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0104

📊 Round 136 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2506, R²: -0.0106

============================================================
🔄 Round 139 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 139 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0018
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0023
============================================================


============================================================
🔄 Round 140 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 140 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0050
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0028
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0106

============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0018
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0024
============================================================


============================================================
🔄 Round 146 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 146 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0040
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0057
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0102

============================================================
🔄 Round 150 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 150 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0022
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0004
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0103

📊 Round 150 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0102

============================================================
🔄 Round 152 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 152 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0023
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0059
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0102

============================================================
🔄 Round 154 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 154 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0006
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0075
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0102

📊 Round 154 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0104

📊 Round 154 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0096

📊 Round 154 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0097

📊 Round 154 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2504, R²: -0.0093

============================================================
🔄 Round 166 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 166 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0016
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0039
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0096

📊 Round 166 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0096

📊 Round 166 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 169 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 169 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0010
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0049
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2506, R²: -0.0101

📊 Round 169 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 173 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 173 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0048
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0094

============================================================
🔄 Round 175 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 175 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0025
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0120
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0094

============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0007
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0257
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0094

📊 Round 176 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

============================================================
🔄 Round 179 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 179 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0033
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0005
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

📊 Round 179 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 186 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 186 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0019
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0001
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0100
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

📊 Round 190 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 194 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 194 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0019
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0011
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0098

============================================================
🔄 Round 196 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 196 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0055
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

============================================================
🔄 Round 198 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 198 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0019
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0004
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0094

============================================================
🔄 Round 199 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 199 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0007
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0112
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

============================================================
🔄 Round 201 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 201 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0034
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0053
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

============================================================
🔄 Round 203 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 203 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0009
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0110
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0092

📊 Round 203 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 203 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0092

============================================================
🔄 Round 207 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 207 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0046
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0256
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2504, R²: -0.0092

📊 Round 207 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0088

============================================================
🔄 Round 212 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 212 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0008
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0048
============================================================


============================================================
🔄 Round 214 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 214 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0006
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0132
============================================================


============================================================
🔄 Round 215 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 215 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0024
   Val:   Loss=0.0650, RMSE=0.2549, R²=-0.0138
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0088

📊 Round 215 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2503, R²: -0.0086

============================================================
🔄 Round 219 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 219 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0019
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.0010
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2503, R²: -0.0085

============================================================
🔄 Round 220 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 220 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0017
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0022
============================================================


============================================================
🔄 Round 222 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 222 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0155
============================================================


============================================================
🔄 Round 224 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 224 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0115
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 224 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

============================================================
🔄 Round 227 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 227 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0032
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0017
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0087

📊 Round 227 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 227 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0093

============================================================
🔄 Round 236 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 236 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0027
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0058
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0093

📊 Round 236 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0095

============================================================
🔄 Round 240 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 240 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0016
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0022
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0091

============================================================
🔄 Round 241 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 241 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0048
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0534
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

📊 Round 241 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

📊 Round 241 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0091

============================================================
🔄 Round 246 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 246 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0013
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0116
============================================================


============================================================
🔄 Round 247 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 247 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0015
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0152
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0093

📊 Round 247 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

============================================================
🔄 Round 249 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 249 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0012
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0023
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 249 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 249 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

============================================================
🔄 Round 252 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 252 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0031
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0036
============================================================


============================================================
🔄 Round 253 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 253 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0045
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

============================================================
🔄 Round 254 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 254 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0169
============================================================


============================================================
🔄 Round 255 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 255 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0152
============================================================


============================================================
🔄 Round 257 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 257 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0002
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0073
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0084

============================================================
🔄 Round 258 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 258 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0034
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0078
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0084

📊 Round 258 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0087

============================================================
🔄 Round 261 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 261 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0022
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0087

📊 Round 261 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0089

📊 Round 261 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0085

============================================================
🔄 Round 267 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 267 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0003
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0059
============================================================


============================================================
🔄 Round 268 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 268 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0020
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0012
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

============================================================
🔄 Round 270 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 270 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0004
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0057
============================================================


============================================================
🔄 Round 274 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 274 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0023
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0012
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0084

============================================================
🔄 Round 277 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 277 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0025
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0020
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

============================================================
🔄 Round 279 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 279 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0015
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0002
============================================================


============================================================
🔄 Round 280 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 280 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0009
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0040
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0087

📊 Round 280 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0088

============================================================
🔄 Round 283 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 283 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0015
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0028
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0088

============================================================
🔄 Round 286 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 286 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0150
============================================================


============================================================
🔄 Round 289 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 289 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0039
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0191
============================================================


============================================================
🔄 Round 293 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 293 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0666, RMSE=0.2581, R²=-0.0053
============================================================


============================================================
🔄 Round 295 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 295 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0059
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0163
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2505, R²: -0.0096

📊 Round 295 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

============================================================
🔄 Round 299 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 299 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0025
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0013
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

📊 Round 299 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

============================================================
🔄 Round 301 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 301 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0043
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0022
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0085

============================================================
🔄 Round 302 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 302 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0013
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0130
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0084

📊 Round 302 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0085

📊 Round 302 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0085

============================================================
🔄 Round 306 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 306 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0061
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0085

============================================================
🔄 Round 308 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 308 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0005
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0056
============================================================


============================================================
🔄 Round 309 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 309 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0009
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0029
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0084

📊 Round 309 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2504, R²: -0.0084

============================================================
🔄 Round 312 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 312 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0003
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0290
============================================================


============================================================
🔄 Round 313 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 313 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0002
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0115
============================================================


============================================================
🔄 Round 314 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 314 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0014
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0019
============================================================


============================================================
🔄 Round 315 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 315 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0008
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0053
============================================================


============================================================
🔄 Round 316 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 316 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0026
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0021
============================================================


============================================================
🔄 Round 320 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 320 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0014
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0119
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

📊 Round 320 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

📊 Round 320 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

============================================================
🔄 Round 326 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 326 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0020
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0020
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

📊 Round 326 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2504, R²: -0.0086

============================================================
🔄 Round 328 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 328 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0013
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0021
============================================================


============================================================
🔄 Round 329 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 329 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0020
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0013
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2504, R²: -0.0086

============================================================
🔄 Round 331 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 331 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0000
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0199
============================================================


============================================================
🔄 Round 332 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 332 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0020
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0006
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2504, R²: -0.0086

============================================================
🔄 Round 333 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 333 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0001
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0069
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2504, R²: -0.0086

📊 Round 333 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0087

============================================================
🔄 Round 335 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 335 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0042
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0080
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

📊 Round 335 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

============================================================
🔄 Round 337 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 337 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0013
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0027
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0090

============================================================
🔄 Round 339 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 339 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0014
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0021
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2504, R²: -0.0088

============================================================
🔄 Round 343 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 343 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0024
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0005
============================================================


============================================================
🔄 Round 344 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 344 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0026
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0256
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0078

============================================================
🔄 Round 345 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 345 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0093
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

📊 Round 345 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

📊 Round 345 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

📊 Round 345 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

📊 Round 345 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

============================================================
🔄 Round 352 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 352 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0007
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0259
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

============================================================
🔄 Round 353 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 353 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0063
============================================================


============================================================
🔄 Round 354 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 354 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0028
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0035
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

============================================================
🔄 Round 355 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 355 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0523
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0082

📊 Round 355 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0083

============================================================
🔄 Round 357 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 357 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0004
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0106
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2503, R²: -0.0081

============================================================
🔄 Round 360 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 360 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0085
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2503, R²: -0.0078

📊 Round 360 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2503, R²: -0.0078

📊 Round 360 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0074

============================================================
🔄 Round 364 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 364 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0006
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0027
============================================================


============================================================
🔄 Round 366 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 366 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0028
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0124
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0071

📊 Round 366 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0071

============================================================
🔄 Round 371 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 371 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0035
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0077
============================================================


============================================================
🔄 Round 372 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 372 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0140
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0068

============================================================
🔄 Round 375 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 375 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0003
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0097
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

============================================================
🔄 Round 377 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 377 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0004
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

============================================================
🔄 Round 380 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 380 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0023
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0069

📊 Round 380 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0069

📊 Round 380 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

📊 Round 380 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 387 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 387 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0000
   Val:   Loss=0.0659, RMSE=0.2568, R²=-0.0169
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

============================================================
🔄 Round 388 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 388 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0024
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0016
============================================================


============================================================
🔄 Round 389 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 389 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0012
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0136
============================================================


============================================================
🔄 Round 390 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 390 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0030
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0035
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

============================================================
🔄 Round 393 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 393 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0024
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0027
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 396 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 396 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0003
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0095
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 397 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 397 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0005
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0050
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

📊 Round 397 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 404 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 404 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0017
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0043
============================================================


============================================================
🔄 Round 405 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 405 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0000
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0135
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0072

============================================================
🔄 Round 406 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 406 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=-0.0004
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0036
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0071

📊 Round 406 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0072

📊 Round 406 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0072

============================================================
🔄 Round 412 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 412 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0086
============================================================


============================================================
🔄 Round 415 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 415 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0009
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0018
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2502, R²: -0.0072

============================================================
🔄 Round 416 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 416 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0011
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0013
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

📊 Round 416 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0068

============================================================
🔄 Round 423 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 423 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0094
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 423 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 429 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 429 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0018
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0018
============================================================


============================================================
🔄 Round 430 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 430 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0021
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0018
============================================================


============================================================
🔄 Round 431 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 431 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0015
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0019
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0071

============================================================
🔄 Round 432 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 432 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0019
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0196
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

📊 Round 432 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

📊 Round 432 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

============================================================
🔄 Round 437 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 437 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0015
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0232
============================================================


============================================================
🔄 Round 439 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 439 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0006
   Val:   Loss=0.0685, RMSE=0.2618, R²=-0.0036
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0071

📊 Round 439 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 439 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 444 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 444 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0004
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0117
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

============================================================
🔄 Round 446 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 446 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0022
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0027
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 449 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 449 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0026
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

📊 Round 449 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 454 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 454 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0031
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0009
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 456 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 456 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0327
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

============================================================
🔄 Round 458 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 458 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0025
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0001
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0067

📊 Round 458 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 463 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 463 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0035
============================================================


============================================================
🔄 Round 464 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 464 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0019
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0023
============================================================


============================================================
🔄 Round 465 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 465 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0027
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0062
============================================================


============================================================
🔄 Round 467 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 467 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0028
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0037
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

📊 Round 467 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0069

============================================================
🔄 Round 470 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 470 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0027
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 470 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 470 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 470 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 474 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 474 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0008
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0020
============================================================


============================================================
🔄 Round 475 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 475 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0023
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0037
============================================================


============================================================
🔄 Round 477 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 477 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0011
   Val:   Loss=0.0689, RMSE=0.2625, R²=-0.0045
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

📊 Round 477 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

============================================================
🔄 Round 484 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 484 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0042
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0076
============================================================


============================================================
🔄 Round 486 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 486 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0036
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0096
============================================================


============================================================
🔄 Round 487 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 487 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0000
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0058
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0067

============================================================
🔄 Round 489 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 489 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0015
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0053
============================================================


============================================================
🔄 Round 490 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 490 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0026
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0131
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 491 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 491 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0005
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0392
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

📊 Round 491 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 500 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 500 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0014
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0002
============================================================


============================================================
🔄 Round 501 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 501 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0022
============================================================


============================================================
🔄 Round 502 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 502 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0010
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0014
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 503 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 503 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0010
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0035
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 504 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 504 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0001
============================================================


============================================================
🔄 Round 505 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 505 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0014
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0095
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

============================================================
🔄 Round 506 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 506 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0011
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0065
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 507 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 507 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0007
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0052
============================================================


============================================================
🔄 Round 508 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 508 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0017
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0021
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0066

============================================================
🔄 Round 509 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 509 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0009
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0018
============================================================


============================================================
🔄 Round 510 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 510 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0026
============================================================


============================================================
🔄 Round 513 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 513 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0001
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0049
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

📊 Round 513 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0067

============================================================
🔄 Round 517 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 517 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0008
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0034
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0067

📊 Round 517 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0067

============================================================
🔄 Round 520 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 520 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0000
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0118
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 520 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

📊 Round 520 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 524 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 524 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0021
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0103
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

📊 Round 524 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0071

============================================================
🔄 Round 527 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 527 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0025
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0026
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

📊 Round 527 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0070

============================================================
🔄 Round 530 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 530 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0003
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0075
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

📊 Round 530 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

============================================================
🔄 Round 534 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 534 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0015
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0001
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

📊 Round 534 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

📊 Round 534 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

📊 Round 534 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

============================================================
🔄 Round 542 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 542 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0006
============================================================


============================================================
🔄 Round 544 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 544 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0011
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0047
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

============================================================
🔄 Round 545 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 545 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0012
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0120
============================================================


============================================================
🔄 Round 546 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 546 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0016
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0056
============================================================


============================================================
🔄 Round 547 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 547 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0094
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

📊 Round 547 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 549 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 549 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0003
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0076
============================================================


============================================================
🔄 Round 550 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 550 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0001
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0067
============================================================


============================================================
🔄 Round 551 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 551 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0008
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0042
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 552 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 552 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0018
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0051
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2501, R²: -0.0065

📊 Round 552 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

📊 Round 552 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 563 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 563 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0010
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0016
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0061

============================================================
🔄 Round 571 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 571 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0002
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0168
============================================================


============================================================
🔄 Round 573 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 573 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0016
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0079
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0063

============================================================
🔄 Round 575 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 575 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0019
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0141
============================================================


============================================================
🔄 Round 576 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 576 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0007
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0019
============================================================


============================================================
🔄 Round 577 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 577 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0020
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0035
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 581 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 581 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0004
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0253
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0063

============================================================
🔄 Round 583 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 583 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0023
============================================================


============================================================
🔄 Round 585 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 585 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0090
============================================================


============================================================
🔄 Round 586 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 586 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0004
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0089
============================================================


============================================================
🔄 Round 589 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 589 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0006
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0114
============================================================


============================================================
🔄 Round 591 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 591 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0005
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0081
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

============================================================
🔄 Round 592 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 592 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0002
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0156
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

📊 Round 592 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0066

============================================================
🔄 Round 595 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 595 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0001
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0062
============================================================


============================================================
🔄 Round 596 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 596 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0008
   Val:   Loss=0.0686, RMSE=0.2619, R²=-0.0029
============================================================


============================================================
🔄 Round 597 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 597 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0019
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0024
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0068

============================================================
🔄 Round 599 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 599 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0020
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0020
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0063

📊 Round 599 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2501, R²: -0.0064

============================================================
🔄 Round 604 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 604 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0014
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0001
============================================================


============================================================
🔄 Round 608 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 608 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0008
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0196
============================================================


============================================================
🔄 Round 610 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 610 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0001
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 616 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 616 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0047
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 618 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 618 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0003
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0231
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 619 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 619 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0020
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0041
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 622 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 622 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0005
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0192
============================================================


============================================================
🔄 Round 623 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 623 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0307
============================================================


============================================================
🔄 Round 626 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 626 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0019
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0051
============================================================


============================================================
🔄 Round 627 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 627 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0035
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0037
============================================================


============================================================
🔄 Round 629 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 629 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0102
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 631 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 631 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0024
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0002
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 632 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 632 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0019
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0023
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 635 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 635 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0004
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0041
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 637 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 637 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0016
============================================================


============================================================
🔄 Round 638 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 638 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0006
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0033
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

📊 Round 638 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 641 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 641 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0019
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0021
============================================================


============================================================
🔄 Round 643 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 643 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0011
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0482
============================================================


============================================================
🔄 Round 644 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 644 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0031
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0022
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 646 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 646 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0035
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0170
============================================================


============================================================
🔄 Round 648 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 648 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0008
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0018
============================================================


============================================================
🔄 Round 650 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 650 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0032
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0030
============================================================


============================================================
🔄 Round 653 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 653 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0004
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0186
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0065

📊 Round 653 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2502, R²: -0.0065

============================================================
🔄 Round 655 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 655 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0022
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0028
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0061

============================================================
🔄 Round 657 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 657 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0019
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0004
============================================================


============================================================
🔄 Round 663 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 663 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0028
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0111
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0057

📊 Round 663 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

============================================================
🔄 Round 666 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 666 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0001
============================================================


============================================================
🔄 Round 667 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 667 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0004
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0056

📊 Round 667 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0056

============================================================
🔄 Round 669 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 669 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0017
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0009
============================================================


============================================================
🔄 Round 670 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 670 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0010
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0128
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0057

============================================================
🔄 Round 672 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 672 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=-0.0014
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0012
============================================================


============================================================
🔄 Round 673 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 673 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0013
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0009
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

📊 Round 673 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 676 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 676 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0002
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0065
============================================================


============================================================
🔄 Round 677 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 677 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0018
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0021
============================================================


============================================================
🔄 Round 681 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 681 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0012
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0090
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

============================================================
🔄 Round 682 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 682 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0016
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0008
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0060

📊 Round 682 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

📊 Round 682 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

📊 Round 682 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

📊 Round 682 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0062

============================================================
🔄 Round 693 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 693 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0014
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0001
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0058

📊 Round 693 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

📊 Round 693 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0055

============================================================
🔄 Round 698 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 698 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0036
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0054
============================================================


============================================================
🔄 Round 700 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 700 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0002
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0042
============================================================


============================================================
🔄 Round 701 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 701 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0010
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0001
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

============================================================
🔄 Round 704 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 704 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0017
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0024
============================================================


============================================================
🔄 Round 709 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 709 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0003
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0262
============================================================


============================================================
🔄 Round 711 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 711 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0030
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0016
============================================================


============================================================
🔄 Round 712 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 712 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0003
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0030
============================================================


============================================================
🔄 Round 713 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 713 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0000
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0042
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

============================================================
🔄 Round 715 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 715 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0002
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0054
============================================================


============================================================
🔄 Round 717 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 717 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0016
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0042
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2499, R²: -0.0048

📊 Round 717 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0051

📊 Round 717 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0051

============================================================
🔄 Round 721 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 721 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0015
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0060
============================================================


============================================================
🔄 Round 722 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 722 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0008
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0078
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

============================================================
🔄 Round 723 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 723 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0006
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0165
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0053

============================================================
🔄 Round 726 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 726 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0023
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0191
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

============================================================
🔄 Round 729 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 729 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0034
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0058

📊 Round 729 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

============================================================
🔄 Round 735 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 735 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0046
============================================================


============================================================
🔄 Round 736 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 736 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0022
   Val:   Loss=0.0652, RMSE=0.2553, R²=-0.0123
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0056

============================================================
🔄 Round 741 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 741 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0009
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0059
============================================================


============================================================
🔄 Round 746 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 746 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0018
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0020
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0059

============================================================
🔄 Round 748 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 748 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0033
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0121
============================================================


============================================================
🔄 Round 749 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 749 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0034
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0010
============================================================


============================================================
🔄 Round 751 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 751 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0017
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0008
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2501, R²: -0.0058

============================================================
🔄 Round 753 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 753 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0016
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0003
============================================================


============================================================
🔄 Round 754 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 754 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0008
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0156
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

============================================================
🔄 Round 756 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 756 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0004
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0097
============================================================


============================================================
🔄 Round 758 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 758 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0007
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0023
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2499, R²: -0.0046

============================================================
🔄 Round 766 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 766 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0002
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0032
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2499, R²: -0.0046

============================================================
🔄 Round 770 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 770 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0030
============================================================


============================================================
🔄 Round 771 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 771 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0014
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0035
============================================================


============================================================
🔄 Round 773 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 773 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0002
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0058
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

============================================================
🔄 Round 774 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 774 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0004
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0083
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

📊 Round 774 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

============================================================
🔄 Round 777 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 777 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0022
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0052

============================================================
🔄 Round 779 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 779 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0007
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0019
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0055

============================================================
🔄 Round 780 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 780 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0302
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2500, R²: -0.0054

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
