[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 408188f7-b6aa-4dd8-9d89-76dfb8331ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731c0b9c-8015-4cf3-813b-a9cfa3dd7648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a7838b-07ea-4c3b-8781-a97e11a26236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337019bd-f1b2-49f9-a26a-1fef7b2ee918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5356f8a6-d1df-45f1-87b8-fab6c2203434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fea8314-8249-42a7-b6df-69b831d5f164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e4824c-4f3d-4feb-a817-d1dc669abb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa0fae4c-69b4-48b1-b73d-ef270d89180f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41792062-9a7d-498d-83e5-366aca229ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaaa930c-5808-4895-83f1-9743bd0f7830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668c3eb6-cfa1-4f3d-8860-60ff0ad2586d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8d3da7-00fa-4eb3-b9a4-0a040a63633a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504c5459-aa8e-4661-8cf5-e4d7c3e886bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802c100a-1a22-4ec4-a3a1-f8ab6ee28661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d5b4e1-15df-47fe-aa65-e7d99d6c7040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288d7403-26b3-4dff-9bf5-00e98f17793b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1b8d03-ee86-4fcb-b65c-53d61acc7b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3778d425-e88c-4145-9e87-82ec9e0d2dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda936f3-74d8-423c-9b61-2b9d1dbc8a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9f7006-b62b-4a28-8e74-341170099d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39796e6-6de0-4095-88fd-72cb6ef04a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54cd0fa-ee56-4ca7-8205-78c4d850be1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf530e2e-52c6-43ce-b335-184001c0f884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf5617e-17c4-4346-a7d2-49a0b6cdb414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c24e21-b6a1-4d36-9f65-acca0e640d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881ad185-6e66-4676-9197-a45134d92e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d5b4ee-c33f-4882-8075-ab84bfeb369c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5017b301-5cf7-4f0f-9880-80a4407603c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fef809-a277-44b8-975a-f410e7d9d74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1bb89dc-4d44-49ad-be42-959413925fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8a5de6-3d9b-4cd3-881d-c539b580befa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac711f94-db57-49be-9cfd-1448f4a8ab45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e834db0-2438-4eb3-80fc-35c301a6f9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c53cca2-fd18-4708-8b5d-033ff8504359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c2eba4-b6e7-4623-9c83-f73f69d58e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f446ed-4d9f-47f5-8521-4660385bd18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e278ca2-64f8-4673-a902-a549c83cf050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09cb185d-749c-444f-a511-9818efb68609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e09469f-c116-460a-b114-a357e49f39a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b749a9-b4fb-4be5-adb4-4712cff27089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd9b614-feee-4c01-9930-29e9c574b7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ea3e69-8e8a-4073-a944-76ca85c07864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c2877a-c048-4c4e-b512-832c2919ac5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1ed6a5-7bdb-48a9-a6dd-5718ac18df43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ab5749-04ef-4d10-95f5-d78dbfab2753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958d0bb1-20df-4c15-af2a-dfa4315225f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90efe80-bc27-4f9e-969b-18240012ea10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d0ac9bd-1be6-4aa7-97c6-ff31150d18f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dad9a29-b653-4e25-a0be-7903e0a79a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1caa5345-3e64-453f-a73b-460ccb917f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48304e9-8b37-4cdd-a8b1-40f1aacc6777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce11d54-84dd-411e-a507-91de987c1a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22099f08-d782-4afb-b240-cb1208d81ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8256e9a-da63-4b91-b5d5-d7d9267333af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e929ac5d-c022-4637-8e86-0a647e0bc072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc58a52-c075-4264-85d4-b8011a478859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c7863f-9923-4611-b308-dbad9c6725c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090f29e2-936e-455a-82e7-80a379cbf6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd893873-a7be-4d39-bb60-472c754fbcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039b600a-b9d6-4bec-a376-bba4aaa30963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc57a08b-d2bf-4bf4-a161-bcb0c2e30a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6171b9-fe60-4681-9856-3db908095d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6612ab17-1670-4d87-9718-492e0a4bfa09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1523d3-ce03-488a-bc63-2585389cad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62722762-4bec-4070-a60a-27624d55f600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a15bf8-4285-40fd-9d0d-49fa0d282d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c872f016-c7f2-4ff9-b845-0fcc8a96fdc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd388d3-594d-4a93-8997-7680f9106564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f963257-911e-4f2d-9613-c8cf11d80149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4544d95c-e54e-4866-b016-5fb198a55814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f382ace-be68-4b8c-be5c-633d7f5404d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae310b8c-ea85-4378-acd5-8191242f562d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ac2471-2fd6-4fc4-8162-f12414ed0350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990757f7-15f3-4b61-b523-4579c029c90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53fd5a13-bed2-45d5-a395-f1e2c4a58f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f630a0f8-167e-4a13-806e-2ea6dd9f489c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecde0eae-10ad-48c1-964a-3214a06148a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa38747-3c2e-4bd6-b34b-112c6a8ccd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5cf54b-84ca-4c83-b898-64529e94c3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4066c25-3f05-464b-a713-5c4188177de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7db373c-85db-4aa9-9016-41541150065e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1e8ea4-bc57-40ca-bec2-f75f6c20aae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7807d4-cdd8-44c2-817e-9ed89beaca68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957efa94-e262-485f-8350-e59ea1e58e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2453e395-58c8-4610-ae15-a886d39817b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4348d89b-57da-483e-8d7b-b7b5a9733c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a0facf-75e0-42d9-9cb0-ea707047831e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28279dd7-94e8-494f-892a-5822170192de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b523e32-9cd6-48c9-a886-521c5293c4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbba7873-30a3-4f55-9a27-5cb7c5498c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7753a1-3cb9-483a-8572-9bb65ff6bf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e4d191-1900-4b42-884c-829daa9ed611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e039583-0928-4046-afc0-bda66c869e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f0e585-b30f-401f-b8fe-102f04003528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963a321c-e421-4422-b395-c9ae2aa699fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e76cf01-db97-4829-8ac9-f14373d4e5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4461d2-55da-451f-be54-47a890cdc976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f99a7362-4578-441d-acde-5de9959585ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036b3628-5e79-4388-8037-017aa615cedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31bca37d-28f6-4418-bec3-ff586d47fe75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b556e89e-a3db-4745-b37d-20cb531edf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cb9262e-1bfc-4c75-a0c0-e1709d62192e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4949dfa9-71f4-4908-994f-2e4515d4be28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e3b8f5-b7be-4712-bd5e-1cbb028cfe33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea825b8-8e4c-44d3-9f69-c1b2d2b18e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7a007b-9f41-46d1-8318-a4a231cd5733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a20c22-d031-4464-a898-93c3bf2b9900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83358a9-1c36-47b4-9ff2-f4d6e316f2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a494ec8-22a3-4ea6-aa50-bb3ec3764b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb312420-27c4-47a2-bfb3-2c29a1f18365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f26421-409f-465f-9235-c6c04d061db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0745b64b-a810-4ccc-b95c-60ecc27ddb29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81943a38-5b64-413d-86a9-0deed4e2d16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b1cb6d-7ac9-4a5a-aa37-d517c0b91f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5268997e-8058-40ae-9b39-7265ace8b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24d5f51-e771-4b1d-8cbc-2a9aa24bdb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a6f3ac-e76b-4a10-8997-b9ce9e1844e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf62fa1-ea91-4a1b-8cbb-9764e9bbaa9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1617558-f9c4-4e8e-bdd9-7256d824e0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8b4bd7-18dc-413e-bbea-558d5697c5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb64bf79-6d09-4d53-b6a0-594dcf03ac11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58396c98-af5e-413f-a9e0-7911c3e541ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86a88e0-474b-4b37-a452-ae9f981a2826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c9132cb-0c63-48a5-a6bb-f60a480c09ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba3c2c1e-0aa6-453b-9dcd-00bc81e24a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11787891-de59-43f6-af45-87e915b42e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 209bd51d-8f9d-4bb4-8a68-9633bf76d99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addcc82f-95c4-49b5-912a-e1b15a98bd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64787fe7-953d-4d0b-b057-02ae9b8ce8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ffea55-8f7a-4262-89b3-4ffa8df5719d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772d8a0c-e09f-4a01-96ff-f5b3920e6221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d5272d-d41b-4401-b46b-892a14bc86aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8bfaca-a6f1-4efd-a518-3e3cd3d1cb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 095e6f74-54a6-4ba1-a543-edf04d8a072e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf2a801-c622-4e12-944e-c8768f1e4064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962de975-837d-442b-862a-c405054ffdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42912eb0-f3da-4aca-9326-ae1c41eead5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc5b267-6f0e-4440-a484-d5e06f7d5b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e0717b-b27e-42af-95e6-bdb4e8cfa429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049282a9-8b00-49a3-af1f-8afc3cd34030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e430f41-5de5-4c42-a0f4-6a03877de062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a7a422-849b-4038-a38b-0bacf1a38ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfce7789-8af7-4868-ab21-2bc971abc149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70506fe2-6be3-4baa-ba0b-04ae75c10678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e2cf91-4f94-4f73-bb17-f974ac025d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03ef57f-beaa-4469-9195-a4d2e80f026b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a3bcb7-5be2-43e1-92b3-f7260e975ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b16758-039a-4cb4-ab56-ea14aee2f8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd8bd9d-00f6-4e9e-8553-d0df6da836b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3381318-9efd-4d43-8cb6-6b89d19fc01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef78b0b7-81ca-4f8b-8f0c-09d3336dc560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb64ac5d-7774-4731-9063-bcdbb6b9cbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ed2ea5-1335-4ee8-b9ee-f67e6c3503a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb90617b-ccfc-405b-9e39-83ccefc78da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e9cab6-2c3e-471b-83e7-f3aba4a469b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e786e62-947e-4759-89fe-3be20458e8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f4f2e67-e5c4-49d0-b8e9-718617ababe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359cbbbe-1c6e-4693-b156-f6dfd6fccb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1e76a1-8141-41a1-adbc-05c03221248b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573d2e09-97f4-49cb-a74c-46e35878d353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6d726c-6e81-448f-b93b-247427c50f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd55b9e-9d00-4f5a-b699-8549c66e0618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5eb745-bbdc-4c64-ba6a-7da2cd752883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80b8612e-497e-428f-9007-e001c27af853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bd4258-e8e6-4d38-94cc-7cd938003403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89911b4-a4f6-4a12-b423-f804c4b3ade3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92dd6258-06c5-4be5-a2e6-e8d725e436f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc5779e-380e-4f3c-9b26-03a305fd5a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85dae9ce-45a4-496f-b345-bcd7a7bdaccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a138e0e0-9bf9-4045-87cd-01bfa26506f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e2b8ed-29af-47f8-bc2e-37695c58e192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c26428-9a4b-47f0-8bb0-6ca93597b67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ed0080-a956-4d6f-ae4c-f2e621cf2196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6053ff4-79ef-4131-85a7-b0804c7feff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32c2d57-cfd2-4d08-9b72-968598f177c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd9843b-f7e1-45eb-b200-5e13a6838f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7863f3-f759-422f-9305-36d4fdaeaec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db304038-4425-4885-8ca9-95ea3fb0b881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed52d8a-1431-4225-b351-94767c2ce54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f93bb350-3594-4d40-9259-f39ea6bc4c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed4ac9b-caad-4444-8736-93f22e1f1f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65673654-354a-4ac9-924a-9a025bebc7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df819c72-b34e-423f-a5f2-28e653f4d355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34398b5-5878-44df-81eb-ea873dcdb314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e027abc-2536-43f6-b9fa-af7081b3d19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626f28d1-cd78-4e18-b21e-a0418999b211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd42ed3-4b9e-4d66-9c5e-8d787fefbd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a4ac96c-19d3-4f6f-8311-fae1cf709d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4c6a38-12ff-4e27-be6b-e9835ec373b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868a1153-4b8d-4713-b518-09c559a5429c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a81842-64af-4c60-a0e7-cdd480a3ff8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6a4752-8929-4f3e-b4a4-8084f2f406c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b151f9-19c0-40ea-979a-98fb1eac94a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef01a9a-278f-45b2-a29f-ed7287e3a0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 013269a6-990b-4233-b028-6708094e1773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b7eef07-61fd-4843-aaf0-d263b568096c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f64962-8c0b-4b84-b25f-7f1ce53de889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3f3292-5419-42de-b3fc-bc6c8e42d2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fb4def-7acd-47ca-b59c-48f6762b8df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc25e08-623b-48dc-ad99-ae6be23a3acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a04dd1c-36e7-46c1-b182-c15c270efe72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef616f9-7e84-4986-9672-b489b49b444f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89590938-a3ff-420c-a0bf-91af72f053f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b4d006-dd85-4552-9993-6c3618bf1f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3b814d-90bb-4fbd-aa31-299e3f12184a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53512a9-84a0-4b69-9224-35a49e20daed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a7d219-9556-4eb9-9d4a-4ae85a20976c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cadfad1f-beb4-463d-b1ba-b471bd764275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631a4749-738b-4fe6-9504-ebf2d3d0e68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8522c595-1348-4c51-af4a-319e679ff332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7db6f65-58d5-49e1-89d9-9159f441abdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564e6ab4-ce60-4d39-918c-e744ac8bfab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4be8be8-5ca5-4b79-9903-ce7930a720b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da2af32-0dd8-4668-af75-98c572876347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3464369a-ff5e-40b2-b100-516217378795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a516cf-d867-4f48-bbbb-f29b06360762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8be848-d7b0-4c7d-8574-f95ada8dedde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07926b37-46e1-49fe-a56b-ccefad4c244e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a782091-8166-4440-974e-55293bd99402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dafbce9-6933-4247-a979-1417edad8524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e9349a-2bcb-4e92-8c54-49eebd60f769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5180234a-f0b9-460d-a189-c3a48106fbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9055de2d-6e49-42ef-873e-c77807d999d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae28b70-cbf5-4ac1-8022-b1fecf67aa12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d646839-738d-43dc-a39e-23a6313c5d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429954b5-cf83-49cc-b24f-f154476ea34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8c8a95-1893-4f36-828a-3165ebba7b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9068c8be-d221-4822-b9a8-9abc3eea75aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d858402a-4107-4aef-a6ee-1af24a257123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae4314b-4321-4826-85e7-d02dcde4fd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 851da22a-140a-4073-9b4d-9ef4217c47c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb28a9f-07fa-4024-b571-9ae2a2b95890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9888cf9-17ff-4c69-955b-d5ad6119e550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bd2db1-9047-4bb7-a11f-175ee18002c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092f2a6b-a13b-4784-b715-42b69f38d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e3641d-53a4-4292-849f-083253222c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8091c95c-ca18-475d-86f6-9a2fbcd380d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90465ad7-9948-4fb8-b239-4ba3392d8b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ce7686-6cbe-417e-87a1-644be106ecaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97980dd1-6d37-42eb-b9d1-e71ce9d6905a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35274018-72a2-4836-aabc-e17ae0ff4863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bebf79-9b1e-4459-b316-878230c9077a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87176cae-91cd-414f-8753-56fa16fd8f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9f6dd8-fb48-4577-a38e-5f683465473d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e18308b-f1af-4a30-9dc2-2c3f2585f61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d24789c6-34c4-449f-82f9-0c68d5e9fb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c125ee-28cb-48f3-8e79-cd63ea1d716b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0da3c35-eece-4cdb-b0b4-8f0a72b20aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a379b36-76b6-47e6-b781-2c2c9eb73438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93a7e13-4c1a-4da8-9afa-a857c1424a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f083996-8d6c-44b4-90e4-b530d9b716c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b99efa-fac2-4989-bb56-b6c14467f0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be752f9-fb02-4e94-8118-dcaac5995962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e62011b-d910-4723-b31a-7bf5f14a31cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd17faf7-7974-429e-bf53-49fc08a305d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3c8c3b-a9b6-4c25-a1b6-0592f2730c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115a5551-5ced-441a-a691-bc7447e8b6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54456cd5-9355-4bd5-844a-ee1f07aa5a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5695d9b5-9918-465e-ac98-6c6495c5cb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed42e5c-b7f2-4228-8673-39f0850f842c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1029ba86-8708-4258-894b-428070231a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34eb322-722c-4170-b381-cc33429d6435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f574f21c-1f66-4234-bc25-7af779176567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc702ad-0d01-4d00-930a-1e5e5a3fb95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b70de2c-5e7c-4e75-8db1-a7121ab60da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c727fd-10c2-48fb-bd9c-fbd674123e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e76825-62b5-4660-ade4-94b727f77547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b350043-e270-4a0e-9dbf-0e484874273e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a492ef-b620-4d1a-a66b-49367485ef3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d670f0d6-37c2-44ae-8ca1-2583cbc86282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b37b06-04d3-4204-bde4-41c1fa194289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d2b5e9-060a-40b5-8f0b-0a4e2c9596f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f047c270-87da-460f-9610-17b83d92a1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622f145d-45fd-457c-a1c6-5d5a5fa35d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd973500-d08d-4902-aa5c-5f7419e3e68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5febf0a4-b644-4699-9193-532e3bd0a573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491522f2-bff1-441a-90fe-3e9d901e3d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db9a8cc-33a1-4238-a7dc-e4543ed7e2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7637c6cb-7bb7-4f05-aa07-d55c54ffa9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391e2a1f-3c0d-48d6-a3c5-5457ab2a5f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbdb8cc8-3f0c-4ddc-bbbd-06699be408c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507b4148-2d52-408b-ad48-e658b87348e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a299bc4e-5c2c-42ad-9266-92f075fd4ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 755466de-b937-40cc-a341-9af925583a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3380c6b6-f28a-49b4-8a22-009041cbe880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de315034-7ad7-46fd-82ee-3e2f0444d3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda1a475-73ba-4508-bb14-759bc2009255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09565ef-2eae-41e8-86be-4cdaecc7505d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50c0a40-3b00-41f5-b230-50b9da2ddacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070a977d-90da-4f9f-aa0c-f15d061fad5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68798453-ed0d-4c1d-849a-a0b962ed2dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6619c71f-d232-45f5-947a-095b6f360164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388f074e-c764-4068-bebb-cf8042999e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39ba1cb-202e-4dcc-8d71-52839f473134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0f5306-8fcc-4958-9e39-0ec78361f292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17defeca-38b0-4e97-b1d8-b2aae864da81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080ef68e-4327-4e15-999c-7190c017f70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc62712e-6659-4fcc-8c80-46a0cd08eeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be1bb4a-02d4-45f4-936c-7b13c037d21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c39d6da-491a-4570-8f47-46112926fffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f66dbc3-2b5a-4cee-8867-fbb027ad5f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea99f15-d082-4db2-a7f0-e9fe2adf29df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc1ce46-ae50-48ff-92e5-105c9198fbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0df353-3328-451d-b06e-ead247bfdd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d478c05-1b69-4c40-bfed-5438fe909f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f95046f-c62a-4be9-ac61-373c179b1dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a455d770-b1c1-4d0a-85c0-50d5286f5ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d637311-800e-4b91-bdd7-95a9a6d5bf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2395c1-2209-4d04-bed9-3532a728c723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef35506e-cf94-40b9-8fc2-4d125a2f96c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3cc35a8-c1bc-48a2-9111-16f1dad3b96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d69f3861-2349-4680-bdba-85150fbc156d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf09c940-4e29-4821-b60c-bc07d03efa2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d680a8-5c3f-4690-84e0-0e088aa107a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ff1d29-51f8-4e45-8223-fa8ad3c75775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb616f4c-80d2-471c-9f4a-7d0b5703d1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c137160d-8dfe-4b4d-9c72-db093a89a33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12e6241-b020-4275-9f07-4c8a6b93cd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2edf06d7-3344-4f0e-9502-76556d5500b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4867d2f-a4f9-4d5b-901d-a260d7384956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a184fc1b-e9d5-4e77-b187-252d172a9c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2d49de-9dd3-437d-879d-096ff25f65d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607316be-4508-4302-9b1c-b25c5b9d0c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb81b12-328b-4430-9d32-43442d60a55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fce883e-4480-499f-9c59-134830ec0466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea80487-5d06-4d7e-870a-e3cfbf389cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406f9f86-0108-41e7-a21d-7bf19cdde21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b28c8b-2e6d-4a59-b8b3-55994c45cde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4560f494-b4fa-4eb3-92b7-3d34952d83e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef37972-7c62-4d1a-8329-62baeac0873c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7130eac5-ef5a-4a70-8917-3f69d37f96d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83c43e5-5a86-4256-9170-8222c3a7a8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c328bcd-3a75-4548-8833-57a09b3ca30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a4dde7-21e4-4fe2-a31c-67a5b9d2088e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3288093-13b9-47e0-9dbf-9a4a7be36316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a2373c-5405-413a-a244-c28f3aaad4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4161ff-6df6-4255-a0e4-bfda41429b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b3cc98-1621-4131-8723-babd950a7305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddeb3df-9566-46b0-8fbb-3c93be1dfa68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192ce935-527d-44da-b582-50fbe8e7c269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1b5443-b876-45fe-afdb-f99baed2b7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0e4e45-3dc1-4ce6-98dc-9c5b71907175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d63a5d-2ec9-423f-a0b3-ef1e476b88b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993bb860-199e-42e1-8db2-132b3e6a972b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bda93e6-4745-4a66-8bdb-1014583a0478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a578c280-415a-4aeb-a40e-0fb2b24ccf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f60b36a-25e3-49df-b484-66a6ebb12237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611f2243-94db-41eb-ab1d-4a4563f88a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd97e03f-23d6-4ea5-82ca-ab9bfd6ae651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277e343c-7303-4a5b-a1c4-bf14dd547c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f53dc49-8ab8-4143-a4e2-07175e0b5574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8ec349-84d8-4e0c-ada7-6651dc52c5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d71f24-5152-4e04-a79a-7c6ad1806d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9db0c8-a25c-4ca6-8efe-5703f20c2a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07126cf4-c930-4b31-96f8-13f8d4b5d7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406250b9-3c2b-499e-a612-e813d811dd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ae9070-74db-42b1-b65d-1849154b26ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585cc37c-e055-4f42-84e0-7afab117c3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9d2c1b-f030-4c7c-acc2-59d997d7462b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e069bca5-4299-44a1-ad8e-500b93867b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d669381-53e5-4b23-8c73-31d151e71652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6725b73-a936-4ad7-b3d5-f48464e57c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad7cc87b-f530-462f-9f4d-1e6998d32ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb2de87-67b9-4e56-9b64-2e216c100517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b57a71e-217a-4542-9444-e8550cb9eeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 081414d8-5af2-42d6-9204-9bc14b30d037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38242346-1aac-464a-8a02-435476021949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733bbd89-d402-472a-8c22-f45278ce2e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 211de95d-676b-4aa7-8ffb-8c9116a511d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee03bf8-9cfd-4b37-8c22-acedb3f4988e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cb2132-d8ad-41e5-b297-9a77fcfba02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c15d16d-5312-47a8-aa5c-d03b83d222bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b56e17-081d-4c84-8093-35717272eeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ea77c2-2d85-4d19-9b1a-a9f69f55ff1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93502f41-b7f6-4caf-a4cc-48e925f4a015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c577d88b-d21f-4656-b44d-6291979450c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7931be8b-5981-4c66-91d1-8efcde960f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf81415-94a4-46c3-8cd9-edf4506f8cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166b4cb8-71cd-4399-b77d-38102fa5fd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e813f8dc-7df4-499f-b2f7-b090096359a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80bf8b1-9b82-4455-9f6c-96e3226db4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f297b12-0e4c-4fdf-b533-5d1b953a8749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c120a2d-c753-4e85-9cc8-3d356b8ca694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70408950-b9cd-497c-b3fb-19fc884d6938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85114b8d-b14e-4279-8d66-3bc49bf6f89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd29bde-a872-486d-ab24-2f8fa40c8740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c26f06-c2a1-4945-8abb-1b29dd372ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5239714-c26d-4430-9a48-fa03e0093dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0484ab-13a4-49ac-a52b-7e8e2e35dfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522e4fa1-6bd7-40de-b07d-5407c963df89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d7c4db-bcab-4f68-ae37-b00b68949a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c7633e-f0eb-4762-abd5-02d4e81b9b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbac419f-acf2-461d-87b9-89f7c5be0333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5809f7-85e4-4a05-aba4-ff79c45cbd02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc1d7c4-0b78-4ffe-be36-364456e0ecd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3608fdfb-2a0f-4639-848b-daa1a671520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7920b5d-0e97-43d9-ad8a-d2bead7b1c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9a9103-ee0c-4a48-b952-f20bbda7e89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4046fb69-7a6c-4f4f-b187-bdc0cb6a54e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1dd945c-1f84-4516-9bf7-9a4c87099d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38019ec9-f202-4e39-a3c2-4a61703c773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8818dd-dfa4-4270-8c30-614edcad0b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace1b558-c7f7-4470-83d4-88748a6b92d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd90109-05a5-42d2-bce1-10dcb5957763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38086a3f-f6fe-4cb3-8d0b-b03f4fb02c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dde663db-ccce-4360-bbdb-7edd4926d3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee238cd-fc17-4409-ab23-4d5cd0dda11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33803665-ad14-4b74-8ef9-6bd7f38531cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d6c595-75fc-40ae-bf86-a5a685040ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216ed7ef-7d17-482f-a247-96900e57c27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b404ad8b-f0d0-44d9-9cd3-5a5d4e240f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1159f4-3a29-4ff2-8b5a-7360e2524fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc2f96e-8f55-481a-8708-5f46480b0f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a101f04f-e3d5-4f87-97f7-6cec2ea71a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2387e26-7cff-44c9-8bb4-6318e3c40d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f24029-ebf9-4040-a739-f7ebfc3147d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65ee6f9-a89b-4776-9755-c063be879237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2591cc1-6ca1-4af8-904b-493be89d6947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc48d481-d764-4253-bae3-567469c1687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934e02c5-527a-4da5-97ae-8883fbc12d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5ba81a-a45d-4963-b198-606d799ae28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70dfe18a-541e-455e-a359-a2ccb316d332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5a4e9f-0118-491f-a25c-5b9b2e8bfb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1370c1-5763-4338-ad53-85127229b584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aedc54d8-477a-452c-b8db-124b3893c4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1234afa8-a21c-4d20-ab00-a08dd0989239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366f54e4-677c-4792-844d-7a1822d5a382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633735cf-3b4e-48f6-80c0-b7324d156130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab439156-a156-4936-9163-cd19e132ac73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140100aa-8647-4ce3-9307-d172192827c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc172f2-777f-40ab-a386-56de7401a9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8cb97d-1b77-4054-a46e-44e8431efe63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dae3efc-8065-4250-bb7a-45b9f16e48f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66553370-4a5b-4f24-87d2-8aba9c88cfd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eca2d39-7ad3-4541-86df-a8f72f16a77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567c54f4-b5ae-4c4c-9b1f-994fbb96c5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09b1055-e1ef-40d6-950c-80d957bebd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6a4c95-7c7f-49dd-a629-7df4b42accaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e96dab6-e141-4fb7-a4de-c628761715b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d084712-05a4-4211-b093-b8cf70728a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b92ffe-4cbd-4773-84ea-b973f767a630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21130c66-ba14-452f-8989-9c7e1feb7207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c338fb79-dcef-48df-be25-848c13c2a82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3fa6a1-f18f-4549-a8aa-dcb8f177514f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67569353-e974-41ad-9129-dc9098fa3a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56dda8e-280d-408b-9df7-44cddb7c9fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac05b336-dc02-48ff-b5fb-d93667796bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa237773-b0d4-4f6f-b182-af1274235f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce3889d-847d-4944-8861-6903320e6333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aab46c5-1672-47f0-8c2f-c936e1531e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 579e915c-0c33-417b-9344-9af9c0fa273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29aeb109-5310-4f02-b575-bb6753f1097e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa2de00-4d8e-45d6-bf22-c830991e6f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50dc89e3-0b75-45ac-977f-5253122569cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1463611-06cb-4f34-b179-7b62e90f77d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc1d3881-34ea-4099-bd97-d8059cb0b802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b5d9db-b68d-414a-b3cf-a1c188b829a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56d8cd4-272b-4ff0-bd55-e0eacc730c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94072286-4e7c-4949-94c2-fb9baff0c4d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d48881-3503-4261-9118-f004ebd3bbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c3d1cd-abf7-4004-a92a-e2f71c350601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b85b84-3792-476d-be52-f28a90062265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0758a5bb-0bb0-4461-a995-08a94bd72504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e995140a-501a-41dc-97ea-68deca702998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa8fa65-6470-4f99-bbbb-4cf926f8e147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a465397-16a8-4a8c-b58a-c8ac75a8aa86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c237072c-a309-4f3c-879a-2761b6465a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97cb72d-5a84-4786-9b41-e52251907d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bda6163-bc04-4ecf-b0a5-73492710d9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2235d1f8-7142-4db1-bad4-dcbb3be3c38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a16453-3ba5-4832-9e45-d4b62ccc0d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3109593e-76cf-41d6-885c-85b336aa8dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1aee8c-2f59-4f95-a75b-cb84c7bac85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf86e7c-2f50-46fc-99f9-88badace7d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227aba72-b2f0-410b-a428-2e5b41ee1412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2ea375-d315-4a3b-845f-ed96a131897c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6894af-0b2b-4979-8cbf-9c9387ef3bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd440086-f898-4ab3-bb23-a27e82aad827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6547d0-fbbd-4cca-b5ab-602efe36da15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23190e5-051c-4e5f-93b0-f04541eb2dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd62601-d1c7-4269-954a-3e45acd0f2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc748c50-d45b-499b-a4a3-501afc1c86b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d478c960-c283-4c22-97c3-e46a75ea60e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0438a0-cf7c-4357-b06e-4380275ebabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee9a39c-10ba-42ef-afbb-6e2ddb1e59a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4234b0b1-dd26-4589-a55b-ecb2c5902d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e416e4b4-1d1e-468f-b875-754fc783d58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3278dc27-dc1c-449f-954c-30457aed5a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 691d92f5-816c-4297-a067-aa7518ca59dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b6cbb0-0042-4025-8299-75156c25a22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6147f4cf-eec7-4a28-98aa-b0feca1313be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20801106-93ba-4e22-8a6b-b21faa94dffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296c1068-133c-4267-8a06-80eb75889aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a294a14-e907-40f2-af21-0587d1c0c369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd1efbd-b2a3-4a5d-a43a-d2083814edfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbab4c44-9604-427d-99c3-7a612dac67b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2e9b70-e0e6-4086-bef2-df7ab8398902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59402e51-01dc-47f1-a417-bb6e60b8d8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684f969c-1969-4a26-a81e-d65f5511c162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63bb038d-df15-4c8c-9c56-135e437710fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5784c93a-2fdf-41e0-94ff-5fd0bc11a3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8bbd547-1307-457a-aa4b-7376da937426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2a1fc1-35f2-488e-9a5d-71a7bcf6eb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c9247b-e68a-47d9-8105-a081dac44c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3023f5-04b0-4fed-9452-21f41d366ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5935cf-681c-4e0c-85dd-9a8e1b278c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9787861d-2107-49aa-98c3-844e2e307406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7dddbc5-7d6d-4fd5-9422-21a23946147d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52193090-5739-4efd-9a4f-2b4ccb3955b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852b74da-c837-4580-b671-a9b50d17158f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e6c8d5-49e4-41dd-8715-6304b18eecd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29029b54-f886-4f3a-aa78-93699dacd5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03de0240-b11f-4c80-aed0-edfa0f9dba9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5856ddce-3fe2-405e-8d0c-1a78ce5421d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870a8dc1-a491-43f4-b9ae-3e7e88142cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688093d7-1287-4286-82bb-6e04b55a5722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b5e397-5368-4baa-a159-fb0d81c77131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe77c8d-049d-4dae-89ae-d1a8511332b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92506fff-c4e4-4c60-8ab5-e7c20817dabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb8a3ec-1603-4a94-bc45-3606368cc342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4be1c31-ba6c-4308-915a-bb9ac4b273e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422541bc-7c7d-4b8a-8f7e-6b765900c33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1023ef1b-5f19-4a8c-ae0d-f396d86f2a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21606574-9733-4f05-97e1-11ba21acd315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94aeaa56-e636-43c0-8332-e17fa2134ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e43b5f-59b2-4d88-91dc-07b33b9e622a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a1e1d2-7667-4961-8b0b-67c1384f3a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e83200-fd91-40fc-ab96-d8e806d65a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808b46bc-19fa-40d4-867a-50aa3085c858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9bd6d1e-a8d1-4928-af38-a17247a595be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5599334e-4e62-43c5-bd03-5d1df1b3ba27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d05af61-c2ac-4ff1-b0b3-bc27bdc713b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dde9abb-7806-46ab-b13e-759e19b76181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f029ec-0178-4248-b32c-47409cea27a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98891291-c5d1-4f6d-83f0-f6110685d2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29e9d17-1774-4999-9cd4-4e0dca626bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285471bf-41c7-4ead-8beb-01adf5ba8f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc78507d-b9ee-4eb5-9c72-a3082013e9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb06af07-87b7-4601-817d-3d94027804b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 256a0d7d-cc31-4eec-8327-c18eae4be677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94d7322-705f-46ed-a002-8ebb87d489da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a91b51c-1980-4300-882a-c2c4922f13bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d693be-c569-44eb-bdd3-9c65eed3bed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c210d7df-7fef-4d10-afbc-19033c4f20d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4333a328-99b9-4b15-94bd-8c6d286e2551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb010eb7-165c-4395-80b2-3461c28a8e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1127caac-2a6a-4d46-9bfa-43fa0e2e4c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3949fb6e-08f8-442c-9393-dcf715242fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6902ca9a-4540-443e-bbbe-ebc14176dae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8a7444-f0c0-48a0-bf4a-90dda5dabe93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cc86ca-2170-48ac-a4ec-66b8279cafac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba976131-e749-4c47-8c5d-4b56bf743a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9776b8-6862-4efa-89d4-dffd8529e9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd92e9e-14ea-4b4a-a331-4fea85edf353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67017885-15a1-436c-a971-fd464f1b2809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa68440b-b4ba-475b-8eb4-0276250336d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f3096a-542d-4e7e-b4b8-39d5818b0f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b0b3e3-5c48-4b90-b20e-78b44d8b6678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6b796a-f655-496e-b4d3-72434b5960f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b491aa45-e396-4c50-a596-a861cb1ce5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d634d7a2-75b1-422e-9f7b-efb0000b8818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcb39a4-e0e8-4df0-9408-5ddbed1b82e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b57ce5-9923-47b5-9b6d-a9dee9cb0f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eadfa8e-b4a0-4637-8171-60263cfefdb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47616879-76fc-45e1-8ece-6ed08cd284f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df42f9c6-844f-48aa-bf78-f32920b68aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c3d8a7-44ac-453a-9fd9-b3c22d677e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec9f20c-2879-4cbf-a816-5c087ca9a7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f26cb6c-aa76-4b41-bd4c-b524ec848b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf805c3-1be7-428b-94ef-c096736d7282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d998a402-4ea5-4d6b-9ae6-d33d976e0857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8095d63e-ee41-4ed9-b9f0-14623e2d81a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96390850-2be2-4538-af5f-d4164bcb6d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af878dfe-a866-44c9-8a7c-b3f98625f025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d944ec7a-8ca6-4062-af56-885146a9abad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f01255-ccfb-4bb9-8946-12ba8fdc0544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd5ac91-6369-4cc3-8deb-0860221bd575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d2119ed-bd38-4df0-859e-b21b4107de40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec6a27c-6c96-4640-a37c-fe376de6ebe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec80bf9-21f3-4ac7-9153-ef797e82bb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6b2c87-faca-441f-b9ef-fa97c215d86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7705ca8-a176-4d26-ae53-ed51c3a6a8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d9c5e5-52af-4e95-8286-8696dfde0316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f14073b-04f1-4e9d-99be-45423fd0121c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b146d552-4c02-4e32-bb56-95c59ff5e4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ca1151-cbd7-46d1-a5b1-badbba8d5740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7058900b-07e0-4a2e-9b73-bffcb1186710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2337429d-751f-4277-8f3b-29f080838ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e31a78f-3ce1-489d-8cf0-d07bb7499bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c59237-76d1-41cf-bf31-aaf648742bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0373c6f-16b4-4534-b95f-9ce551b5a2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa64917d-e43b-40fa-9ffd-dd356a920c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce7fc2a-c9f0-401a-abe8-6655c77e1bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48246b88-7cc0-457f-9591-84bf3b457995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72de78f5-98d1-4a64-b295-593e660e5fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7830d5d5-01a5-4976-9188-5176fe64c1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c041f55d-1bdd-433c-a80a-8c1449302888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509ebc6f-168e-4469-bcd7-a1c193df225c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df1391b-01b8-47ac-99a6-86f00a4eabc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0efe5a-308b-4756-b543-d6d03bfba341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71da35b-ac7c-4e80-9248-7247996cd46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62fd41d6-e738-4f6d-b2cb-de6658614e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988ce942-1698-43d2-a745-1d44570f6d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245a1c4b-ab5f-430f-8b83-f03c986be653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 835525e3-d6a1-4ec0-bb2b-e8a650cda640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5eafa0-cd70-47bc-b08e-1a650f168754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4198a82-0699-4513-86ea-7b085fe36ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cd7b37-5c8d-44d0-b3fc-4ea59593f237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6e2e1e-d6cb-40d2-9d53-1237f96f03c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee27aa16-5390-4251-a198-2ae88fd24667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4413b96-0855-4a8f-a53b-0be883976b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab77e68-04de-4953-90fd-1a2cd2f9c559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ded346-1334-4e01-ac2b-87aea0182080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b29500d-dd76-46c2-8422-b2ef9503e7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc2e937-cff2-4568-a320-95bf06bcdd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f1d8db-d79b-47b8-bcf6-36a115bc95a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7756d9b-9127-47e5-8806-8d416ff135c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a42187a-8950-4261-8214-50ec9167804d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c7a262-60ae-4d6e-8779-e6937d64b7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d76e512-94ed-4939-bcdd-0f5205f082c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c531f58-cb8a-4694-b822-7c74c47e7da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02fd76c5-279e-43e4-9b8b-cebfa799df73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70cffd6b-8677-42eb-a257-c60cacf78b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c450d9d8-95e3-47f2-b26a-15fc8329c02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b68d7e-0ab2-482e-9a83-d0ed21e88ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f754b34c-f8a1-4da6-aa78-a8f8b975e451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76af29f2-85c6-46c4-a620-5241f5f872a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af12236-f45a-422e-9b06-8ec268c197c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85504e4-e906-4ff3-b91a-39b7fe0af4f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e95d95-1ecb-487f-a61c-7106f48c2782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164a3552-f8cd-415c-a75c-0da09fda9017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6667af-e4b2-426b-9e8f-e45db8144a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7069c5d-e820-4d8b-b207-481e5df7ebe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f9d07a-c759-4cc7-860f-64f453fb7517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c58385c-94df-427b-90b0-e8238b82cb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593c7e5d-65a4-43a7-89d6-752d5cf59384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0076fe32-e274-48be-933e-e5349682710a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b317ed-451d-4479-9de5-5c23804f2665
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(6688, 24), y=(6688,)
   Test:  X=(1673, 24), y=(1673,)

⚠️  Limiting training data: 6688 → 800 samples
⚠️  Limiting test data: 1673 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5027, RMSE: 0.7090, MAE: 0.6501, R²: -5.2726

============================================================
🔄 Round 3 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3499, val=0.1215 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0985, val=0.0828 (↓), lr=0.001000
   • Epoch   3/100: train=0.0832, val=0.0848, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0816, val=0.0817 (↓), lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0823, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0804, val=0.0826, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 3 Summary - Client client_11
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0005
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0076
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4942, RMSE: 0.7030, MAE: 0.6435, R²: -5.1667

📊 Round 3 Test Metrics:
   Loss: 0.4837, RMSE: 0.6955, MAE: 0.6353, R²: -5.0358

============================================================
🔄 Round 7 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4260, val=0.3107 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3001, val=0.1786 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1304, val=0.0725 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0873, val=0.0714 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0846, val=0.0700 (↓), lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0841, val=0.0707, patience=6/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 7 Summary - Client client_11
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0006
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0106
============================================================


============================================================
🔄 Round 8 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4482, val=0.4095 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4043, val=0.3692 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3664, val=0.3347 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3317, val=0.3007 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2942, val=0.2605 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0917, val=0.0861 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0813, val=0.0814, patience=8/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 8 Summary - Client client_11
   Epochs: 28/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0109
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0109
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4621, RMSE: 0.6798, MAE: 0.6181, R²: -4.7662

============================================================
🔄 Round 9 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4470, val=0.4663 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4410, val=0.4599 (↓), lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   ✓ Epoch   3/100: train=0.4351, val=0.4542 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.4310, val=0.4516 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.4286, val=0.4491 (↓), lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.4162, val=0.4367 (↓), lr=0.000002
   📉 Epoch 19: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.4079, val=0.4288 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4040, val=0.4248 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4003, val=0.4210 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3968, val=0.4174 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3934, val=0.4138 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3899, val=0.4103 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3866, val=0.4068 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3832, val=0.4033 (↓), lr=0.000001

============================================================
📊 Round 9 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3789, RMSE=0.6155, R²=-3.6463
   Val:   Loss=0.4002, RMSE=0.6326, R²=-4.0166
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.4531, RMSE: 0.6731, MAE: 0.6107, R²: -4.6533

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4268, val=0.4112 (↓), lr=0.000001
   • Epoch   2/100: train=0.4263, val=0.4108, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4258, val=0.4103 (↓), lr=0.000001
   • Epoch   4/100: train=0.4254, val=0.4099, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4249, val=0.4094 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4224, val=0.4069 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4183, val=0.4029 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4144, val=0.3990 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4106, val=0.3952 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4068, val=0.3915 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4030, val=0.3877 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3991, val=0.3839 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3953, val=0.3801 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3914, val=0.3763 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3883, RMSE=0.6232, R²=-3.7196
   Val:   Loss=0.3728, RMSE=0.6106, R²=-3.8357
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4142, RMSE: 0.6436, MAE: 0.5780, R²: -4.1679

============================================================
🔄 Round 15 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3609, val=0.3620 (↓), lr=0.000001
   • Epoch   2/100: train=0.3604, val=0.3615, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3599, val=0.3610 (↓), lr=0.000001
   • Epoch   4/100: train=0.3595, val=0.3605, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3590, val=0.3600 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3561, val=0.3571 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3513, val=0.3524 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3465, val=0.3476 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3418, val=0.3429 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3370, val=0.3382 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3323, val=0.3335 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3276, val=0.3287 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3228, val=0.3240 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3180, val=0.3192 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3139, RMSE=0.5603, R²=-2.9089
   Val:   Loss=0.3148, RMSE=0.5611, R²=-2.7017
============================================================


============================================================
🔄 Round 16 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3375, val=0.3292 (↓), lr=0.000001
   • Epoch   2/100: train=0.3371, val=0.3287, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3367, val=0.3283 (↓), lr=0.000001
   • Epoch   4/100: train=0.3362, val=0.3279, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3358, val=0.3274 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3332, val=0.3249 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3288, val=0.3206 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3243, val=0.3162 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3198, val=0.3118 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3152, val=0.3073 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3105, val=0.3028 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3058, val=0.2982 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3010, val=0.2935 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2961, val=0.2887 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2910, RMSE=0.5395, R²=-2.6097
   Val:   Loss=0.2843, RMSE=0.5332, R²=-2.3961
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.3138, RMSE: 0.5602, MAE: 0.4836, R²: -2.9154

📊 Round 16 Test Metrics:
   Loss: 0.2659, RMSE: 0.5157, MAE: 0.4341, R²: -2.3180

📊 Round 16 Test Metrics:
   Loss: 0.1941, RMSE: 0.4406, MAE: 0.3614, R²: -1.4223

============================================================
🔄 Round 21 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1851, val=0.2127 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1841, val=0.2116 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1831, val=0.2106 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1822, val=0.2095 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1813, val=0.2085 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1760, val=0.2025 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1680, val=0.1935 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1606, val=0.1850 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1537, val=0.1770 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1471, val=0.1694 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1409, val=0.1622 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1350, val=0.1553 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1294, val=0.1487 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1241, val=0.1424 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1196, RMSE=0.3459, R²=-0.4753
   Val:   Loss=0.1371, RMSE=0.3702, R²=-0.7037
============================================================


============================================================
🔄 Round 23 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1332, val=0.1305 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1327, val=0.1300 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1321, val=0.1294 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1315, val=0.1289 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1309, val=0.1284 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1276, val=0.1254 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1223, val=0.1208 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1173, val=0.1165 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1127, val=0.1125 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1085, val=0.1089 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1046, val=0.1056 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1011, val=0.1027 (↓), lr=0.000001
   • Epoch  81/100: train=0.0979, val=0.1000, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0950, val=0.0977 (↓), lr=0.000001

============================================================
📊 Round 23 Summary - Client client_11
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3045, R²=-0.1684
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0857
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2459, R²: -0.0040

============================================================
🔄 Round 29 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 29 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0035
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0034
============================================================


============================================================
🔄 Round 30 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 30 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0077
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0180
============================================================


============================================================
🔄 Round 32 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 32 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0022
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0255
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0028
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0036
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 35 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

📊 Round 35 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 39 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 39 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0011
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0054
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 40 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 40 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0004
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0068
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 42 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 42 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0007
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0176
============================================================


============================================================
🔄 Round 43 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 43 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0004
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0071
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0003

============================================================
🔄 Round 44 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 44 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0000
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0116
============================================================


============================================================
🔄 Round 45 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 45 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0005
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0107
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0002

============================================================
🔄 Round 47 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 47 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0032
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0073
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0002

📊 Round 47 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0002

📊 Round 47 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0002

============================================================
🔄 Round 55 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 55 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0031
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0000
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2452, R²: -0.0002

📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0005

📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0005

============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0007
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0261
============================================================


============================================================
🔄 Round 67 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 67 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0009
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0118
============================================================


============================================================
🔄 Round 68 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 68 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0047
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0050
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0007

📊 Round 68 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0006

============================================================
🔄 Round 73 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 73 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0042
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0014
============================================================


============================================================
🔄 Round 75 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 75 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0051
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0056
============================================================


============================================================
🔄 Round 76 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 76 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0007
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0107
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0007

📊 Round 76 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0005

============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0010
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0094
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0006

📊 Round 82 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0006

📊 Round 82 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2452, R²: -0.0007

============================================================
🔄 Round 88 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 88 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0045
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0037
============================================================


============================================================
🔄 Round 92 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 92 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0029
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0017
============================================================


============================================================
🔄 Round 94 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 94 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0060
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0058
============================================================


============================================================
🔄 Round 95 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 95 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0047
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0016
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

📊 Round 95 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

📊 Round 95 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0004

============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0024
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0018
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0003

============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0035
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0025
============================================================


============================================================
🔄 Round 104 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 104 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0043
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0067
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0002

============================================================
🔄 Round 107 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 107 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0008
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0103
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0003

============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0013
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0052
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0003

📊 Round 108 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2453, R²: -0.0003

============================================================
🔄 Round 112 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 112 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0039
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0035
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0004

============================================================
🔄 Round 113 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 113 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0103
============================================================


============================================================
🔄 Round 116 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 116 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0019
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0041
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0004

============================================================
🔄 Round 117 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 117 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0007
   Val:   Loss=0.0995, RMSE=0.3154, R²=-0.0124
============================================================


============================================================
🔄 Round 118 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 118 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0009
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0095
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

📊 Round 118 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 122 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 122 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0015
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0081
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0042
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0005
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

📊 Round 124 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

============================================================
🔄 Round 127 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 127 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0056
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0037
============================================================


============================================================
🔄 Round 128 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 128 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0034
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0021
============================================================


============================================================
🔄 Round 130 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 130 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0046
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0020
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0009

============================================================
🔄 Round 131 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 131 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0042
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0006
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0009

============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0089
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0033
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 134 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 134 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0130
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

📊 Round 134 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 138 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 138 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0036
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0016
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 141 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 141 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0058
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0048
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 143 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 143 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0043
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0008
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

📊 Round 143 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0008

📊 Round 143 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0008

📊 Round 143 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0008

============================================================
🔄 Round 151 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 151 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0365
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

============================================================
🔄 Round 153 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 153 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0059
============================================================


============================================================
🔄 Round 154 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 154 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0089
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0147
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 156 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 156 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0069
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0037
============================================================


============================================================
🔄 Round 158 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 158 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0019
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0177
============================================================


============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0009
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0113
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0055
============================================================


============================================================
🔄 Round 168 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 168 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0063
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0235
============================================================


============================================================
🔄 Round 170 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 170 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0062
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0075
============================================================


============================================================
🔄 Round 171 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 171 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0007
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0145
============================================================


============================================================
🔄 Round 174 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 174 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0034
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0008
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0012
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0077
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

📊 Round 175 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0027
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0021
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 179 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 179 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0022
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0106
============================================================


============================================================
🔄 Round 180 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 180 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0036
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0008
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

📊 Round 180 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

============================================================
🔄 Round 185 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 185 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0035
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0003
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

============================================================
🔄 Round 191 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 191 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0243
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0007

============================================================
🔄 Round 196 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 196 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0029
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0027
============================================================


============================================================
🔄 Round 197 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 197 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0032
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0001
============================================================


============================================================
🔄 Round 198 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 198 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0173
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0006

============================================================
🔄 Round 201 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 201 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0025
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0053
============================================================


============================================================
🔄 Round 202 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 202 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0245
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 204 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 204 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0013
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0162
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2453, R²: -0.0005

============================================================
🔄 Round 209 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 209 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0070
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0014
============================================================


============================================================
🔄 Round 212 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 212 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0022
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0031
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 213 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 213 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0019
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0058
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 214 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 214 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0049
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0075
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 216 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 216 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0003
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0157
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 217 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 217 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0013
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0103
============================================================


============================================================
🔄 Round 218 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 218 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0013
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0075
============================================================


============================================================
🔄 Round 219 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 219 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0034
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0085
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 220 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 220 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0023
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0008
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

📊 Round 220 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 228 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 228 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0008
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0079
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 229 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 229 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0012
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0132
============================================================


============================================================
🔄 Round 230 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 230 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0020
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0270
============================================================


============================================================
🔄 Round 232 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 232 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0308
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 232 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 237 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 237 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0020
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0061
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 239 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 239 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0033
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0040
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 239 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 241 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 241 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0033
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0002
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 241 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 241 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 244 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 244 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0048
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0066
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 246 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 246 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0083
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0133
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 250 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 250 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0009
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0088
============================================================


============================================================
🔄 Round 251 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 251 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0033
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0004
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 254 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 254 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0053
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0067
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 255 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 255 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0034
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0003
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 256 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 256 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0033
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0000
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

📊 Round 256 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

============================================================
🔄 Round 258 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 258 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0065
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0048
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

📊 Round 258 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 261 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 261 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0007
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0233
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 263 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 263 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0092
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0277
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 264 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 264 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0038
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0011
============================================================


============================================================
🔄 Round 268 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 268 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0033
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0008
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 269 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 269 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0038
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0042
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0004

📊 Round 269 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

📊 Round 269 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 277 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 277 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0024
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0027
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 282 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 282 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0020
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0133
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 283 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 283 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0057
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0073
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 286 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 286 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0008
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0613
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 287 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 287 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0034
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0026
============================================================


============================================================
🔄 Round 288 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 288 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0062
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0079
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 289 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 289 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0001
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0190
============================================================


============================================================
🔄 Round 290 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 290 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0036
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0006
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0009

============================================================
🔄 Round 292 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 292 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0112
============================================================


============================================================
🔄 Round 294 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 294 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0044
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0012
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0010

📊 Round 294 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0010

============================================================
🔄 Round 298 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 298 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0033
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0011
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0008

============================================================
🔄 Round 299 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 299 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0034
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0024
============================================================


============================================================
🔄 Round 300 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 300 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0025
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0043
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 301 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 301 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0041
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0004
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 301 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 303 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 303 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0067
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0111
============================================================


============================================================
🔄 Round 304 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 304 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0021
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0044
============================================================


============================================================
🔄 Round 305 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 305 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0009
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0128
============================================================


============================================================
🔄 Round 306 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 306 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0029
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0048
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 306 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 314 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 314 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0015
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0079
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 316 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 316 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0047
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0113
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 317 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 317 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0006
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0090
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 317 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 321 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 321 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0041
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0032
============================================================


============================================================
🔄 Round 322 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 322 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0021
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0048
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 324 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 324 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0017
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0061
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

============================================================
🔄 Round 325 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 325 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0031
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0047
============================================================


============================================================
🔄 Round 327 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 327 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0024
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0041
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 331 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 331 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0037
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0015
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

📊 Round 331 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0008

📊 Round 331 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0009

============================================================
🔄 Round 336 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 336 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0053
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0000
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0009

============================================================
🔄 Round 341 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 341 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0055
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0055
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0008

📊 Round 341 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 341 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0005

============================================================
🔄 Round 345 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 345 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0018
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0041
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 345 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 348 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 348 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0006
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0224
============================================================


============================================================
🔄 Round 349 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 349 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0012
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0089
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 350 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 350 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0043
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0002
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

📊 Round 350 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0006

📊 Round 350 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 355 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 355 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0002
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0118
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2454, R²: -0.0007

============================================================
🔄 Round 358 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 358 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0088
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0030
============================================================


============================================================
🔄 Round 359 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 359 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0040
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0077
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 359 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 362 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 362 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0047
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0017
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 364 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 364 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0011
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0052
============================================================


============================================================
🔄 Round 366 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 366 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0171
============================================================


============================================================
🔄 Round 367 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 367 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0055
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0003
============================================================


============================================================
🔄 Round 372 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 372 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0002
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0097
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

📊 Round 372 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

============================================================
🔄 Round 377 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 377 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0038
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

============================================================
🔄 Round 379 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 379 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0007
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0345
============================================================


============================================================
🔄 Round 380 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 380 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0004
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0242
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

============================================================
🔄 Round 383 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 383 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0320
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

============================================================
🔄 Round 384 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 384 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0125
============================================================


============================================================
🔄 Round 385 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 385 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0030
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0043
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

============================================================
🔄 Round 387 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 387 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0352
============================================================


============================================================
🔄 Round 390 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 390 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0005
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0421
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 391 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 391 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0016
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0206
============================================================


============================================================
🔄 Round 393 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 393 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0011
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0043
============================================================


============================================================
🔄 Round 394 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 394 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0012
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0241
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

📊 Round 394 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0004

📊 Round 394 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 399 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 399 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0005
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0077
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 400 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 400 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0046
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0075
============================================================


============================================================
🔄 Round 401 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 401 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0002
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0117
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

📊 Round 401 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

📊 Round 401 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 401 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 401 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 411 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 411 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0012
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0058
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 413 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 413 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0013
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0066
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 415 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 415 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0030
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0014
============================================================


============================================================
🔄 Round 417 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 417 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0037
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0057
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 418 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 418 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0024
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0008
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 419 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 419 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0190
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 422 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 422 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0039
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0009
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 427 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 427 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0004
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0160
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 427 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 427 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 427 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 427 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 433 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 433 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0002
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0346
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 433 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 433 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 436 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 436 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0005
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0658
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 436 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 436 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 441 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 441 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0020
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0080
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 442 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 442 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0013
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0049
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 445 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 445 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0009
============================================================


============================================================
🔄 Round 447 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 447 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0025
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0032
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0005

============================================================
🔄 Round 449 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 449 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0054
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0056
============================================================


============================================================
🔄 Round 451 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 451 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0024
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0015
============================================================


============================================================
🔄 Round 452 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 452 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0032
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0037
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 452 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 457 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 457 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0012
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0051
============================================================


============================================================
🔄 Round 458 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 458 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0011
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0072
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 459 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 459 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0018
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0025
============================================================


============================================================
🔄 Round 461 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 461 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0040
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0048
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 463 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 463 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0000
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0298
============================================================


============================================================
🔄 Round 464 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 464 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0214
============================================================


============================================================
🔄 Round 465 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 465 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0003
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0102
============================================================


============================================================
🔄 Round 467 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 467 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0018
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0030
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 470 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 470 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0030
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0004
============================================================


============================================================
🔄 Round 471 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 471 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0016
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0244
============================================================


============================================================
🔄 Round 473 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 473 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0015
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0138
============================================================


============================================================
🔄 Round 475 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 475 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0096
============================================================


============================================================
🔄 Round 476 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 476 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0156
============================================================


============================================================
🔄 Round 477 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 477 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0015
   Val:   Loss=0.0863, RMSE=0.2939, R²=-0.0031
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 479 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 479 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0084
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 482 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 482 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0047
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0019
============================================================


============================================================
🔄 Round 483 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 483 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0266
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 483 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 485 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 485 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=-0.0020
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0022
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 492 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 492 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0036
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0045
============================================================


============================================================
🔄 Round 494 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 494 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0021
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0018
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 494 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 503 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 503 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0124
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 503 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

============================================================
🔄 Round 508 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 508 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0010
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0087
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

============================================================
🔄 Round 510 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 510 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0003
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0146
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

============================================================
🔄 Round 512 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 512 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0085
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

📊 Round 512 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

============================================================
🔄 Round 515 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 515 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0004
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0126
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

============================================================
🔄 Round 518 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 518 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0061
   Val:   Loss=0.0896, RMSE=0.2992, R²=0.0042
============================================================


============================================================
🔄 Round 519 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 519 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0016
   Val:   Loss=0.0720, RMSE=0.2682, R²=-0.0229
============================================================


============================================================
🔄 Round 521 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 521 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0037
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0028
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

📊 Round 521 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

📊 Round 521 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0008

============================================================
🔄 Round 527 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 527 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0104
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0139
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0008

📊 Round 527 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0008

============================================================
🔄 Round 530 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 530 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0055
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0029
============================================================


============================================================
🔄 Round 531 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 531 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0018
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0086
============================================================


============================================================
🔄 Round 532 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 532 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0024
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0043
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0006

📊 Round 532 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0006

============================================================
🔄 Round 535 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 535 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0022
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0037
============================================================


============================================================
🔄 Round 536 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 536 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0035
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0004
============================================================


============================================================
🔄 Round 540 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 540 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0023
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0012
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2455, R²: -0.0007

============================================================
🔄 Round 542 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 542 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0027
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0001
============================================================


============================================================
🔄 Round 543 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 543 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0057
============================================================


============================================================
🔄 Round 545 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 545 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0013
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0046
============================================================


============================================================
🔄 Round 548 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 548 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0031
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0042
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 549 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 549 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0031
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0014
============================================================


============================================================
🔄 Round 550 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 550 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0168
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 551 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 551 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0018
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0075
============================================================


============================================================
🔄 Round 552 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 552 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0027
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0009
============================================================


============================================================
🔄 Round 553 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 553 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0000
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0251
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 554 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 554 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0001
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0676
============================================================


============================================================
🔄 Round 556 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 556 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0007
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0423
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 559 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 559 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0015
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0039
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

📊 Round 559 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 561 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 561 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0017
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0046
============================================================


============================================================
🔄 Round 563 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 563 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0054
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0009
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 565 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 565 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0062
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0043
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 566 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 566 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0017
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0034
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

📊 Round 566 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 570 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 570 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0001
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0103
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 571 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 571 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0013
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0061
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

📊 Round 571 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 574 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 574 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0030
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0005
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 575 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 575 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0013
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0075
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

📊 Round 575 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 577 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 577 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0034
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0012
============================================================


============================================================
🔄 Round 578 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 578 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0007
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0111
============================================================


============================================================
🔄 Round 579 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 579 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0305
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 580 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 580 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0049
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0065
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 584 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 584 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0007
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0390
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 586 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 586 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0038
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0027
============================================================


============================================================
🔄 Round 588 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 588 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0042
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0031
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 588 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 588 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 588 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 593 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 593 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0016
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0053
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 596 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 596 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0009
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0229
============================================================


============================================================
🔄 Round 598 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 598 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0085
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 598 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 601 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 601 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0040
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0018
============================================================


============================================================
🔄 Round 602 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 602 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0002
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0119
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 603 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 603 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0006
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0233
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 603 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 603 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 609 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 609 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0026
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0066
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 610 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 610 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0183
============================================================


============================================================
🔄 Round 611 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 611 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0002
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0150
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 614 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 614 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0007
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0178
============================================================


============================================================
🔄 Round 615 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 615 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0028
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0009
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

📊 Round 615 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 615 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 615 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 621 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 621 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0014
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0050
============================================================


============================================================
🔄 Round 622 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 622 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0019
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0040
============================================================


============================================================
🔄 Round 623 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 623 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0063
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0024
============================================================


============================================================
🔄 Round 624 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 624 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0018
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0121
============================================================


============================================================
🔄 Round 625 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 625 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0009
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0133
============================================================


============================================================
🔄 Round 626 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 626 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0052
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 627 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 627 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0020
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0010
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 627 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 630 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 630 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0004
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0319
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 630 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 633 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 633 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0038
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0042
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 633 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 644 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 644 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0098
============================================================


============================================================
🔄 Round 645 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 645 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0027
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0001
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 646 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 646 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0080
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0146
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 647 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 647 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0022
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0196
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 650 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 650 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0009
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0271
============================================================


============================================================
🔄 Round 651 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 651 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0163
============================================================


============================================================
🔄 Round 652 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 652 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0031
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0037
============================================================


============================================================
🔄 Round 653 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 653 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0044
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0013
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 653 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 657 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 657 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0036
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0022
============================================================


============================================================
🔄 Round 658 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 658 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0001
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0249
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 658 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 658 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 662 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 662 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0031
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0025
============================================================


============================================================
🔄 Round 664 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 664 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0361
============================================================


============================================================
🔄 Round 665 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 665 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0006
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0413
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 666 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 666 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0044
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0047
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 667 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 667 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0041
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0079
============================================================


============================================================
🔄 Round 668 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 668 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0048
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0033
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 670 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 670 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0062
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 672 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 672 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0008
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0116
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 672 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 672 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 676 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 676 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0016
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0104
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 676 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 679 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 679 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0028
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0010
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 679 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 681 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 681 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0030
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0009
============================================================


============================================================
🔄 Round 682 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 682 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0071
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 686 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 686 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0003
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0316
============================================================


============================================================
🔄 Round 687 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 687 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0016
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0041
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 692 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 692 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0019
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 693 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 693 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0036
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0001
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 694 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 694 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0133
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 697 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 697 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0000
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0089
============================================================


============================================================
🔄 Round 698 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 698 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0018
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0074
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 699 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 699 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0033
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0004
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 700 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 700 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0605
============================================================


============================================================
🔄 Round 704 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 704 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0011
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0049
============================================================


============================================================
🔄 Round 705 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 705 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0016
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 707 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 707 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0009
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0055
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 708 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 708 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0019
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0025
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

📊 Round 708 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0007

📊 Round 708 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 715 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 715 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0047
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0046
============================================================


============================================================
🔄 Round 716 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 716 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0019
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0001
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

📊 Round 716 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0007

📊 Round 716 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

============================================================
🔄 Round 719 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 719 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0003
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0200
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

============================================================
🔄 Round 722 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 722 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0147
============================================================


============================================================
🔄 Round 724 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 724 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0021
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0029
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0008

============================================================
🔄 Round 727 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 727 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0130
============================================================


============================================================
🔄 Round 728 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 728 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0019
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0015
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 735 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 735 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0006
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0235
============================================================


============================================================
🔄 Round 736 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 736 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0025
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0020
============================================================


============================================================
🔄 Round 737 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 737 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0022
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0026
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 738 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 738 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0012
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0067
============================================================


============================================================
🔄 Round 740 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 740 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0007
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0247
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 743 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 743 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0016
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

📊 Round 743 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 746 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 746 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0014
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0068
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0010

📊 Round 746 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2456, R²: -0.0011

============================================================
🔄 Round 750 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 750 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0033
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0001
============================================================


============================================================
🔄 Round 753 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 753 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0028
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0005
============================================================


============================================================
🔄 Round 754 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 754 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0055
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0079
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

============================================================
🔄 Round 756 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 756 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0001
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0137
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

============================================================
🔄 Round 757 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 757 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0031
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0011
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

============================================================
🔄 Round 758 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 758 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0037
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0003
============================================================


============================================================
🔄 Round 759 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 759 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0228
============================================================


============================================================
🔄 Round 762 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 762 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0038
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0008
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

============================================================
🔄 Round 763 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 763 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0025
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0013
============================================================


============================================================
🔄 Round 766 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 766 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0015
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0032
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0008

📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

📊 Round 766 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

============================================================
🔄 Round 775 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 775 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0089
============================================================


============================================================
🔄 Round 776 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 776 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0004
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0091
============================================================


============================================================
🔄 Round 778 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 778 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0029
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0009
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0010

📊 Round 778 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0010

📊 Round 778 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0010

📊 Round 778 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0010

📊 Round 778 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2457, R²: -0.0009

============================================================
🔄 Round 784 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 784 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0083
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0208
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
