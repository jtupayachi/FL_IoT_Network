[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597f99b5-6f1c-432e-a185-12d4c3f08266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcc7788-2cca-4e75-a123-7661f989b7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150d4773-e046-47de-8dd9-7b0f6697c7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01745108-0b27-414e-8a64-23960a107abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2c38c5-313c-40b9-8a7d-984d48f834fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c80fc5-de98-44ee-9751-dba1727a9502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4976e725-290c-47f7-910d-61fa7de39a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204b98f6-36b4-41b0-8f36-f3c650aed7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a17d87-04a0-4afb-b938-704e99b6ab51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16bc9e6-2d23-450d-a72e-8e4b0ed5134c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60229704-8906-486e-a9a1-88a16e510604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a38a15-d778-4f35-aec1-3e2495360c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f4fe21-7856-41a3-a258-6e00725350f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d53d9d-90e0-4960-b03f-46088163df3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d89090-aa94-4df4-b4d6-9158415a0be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 804d0066-637e-4535-aed6-74b63a260fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97e14a6-a117-470a-97b0-39da9dd311bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea797427-044a-491e-aac2-412db03a14e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66fffad3-6ea9-4494-a8a6-7780d535f9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf27d009-07f4-4583-b080-1e9af24614aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd36a7e-ab8d-47fe-92f1-9fa8d7290cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415bb546-ef5e-4cb5-9c1b-d6ea73b91e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef8dcf4f-bff2-44e6-a986-273d7148fa40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e189fc89-4499-46d0-9ef0-5bb48941804b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bc8e18-48ff-4645-98ce-f341b23ea559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54fa115c-f24b-43fe-89b5-ca376c08223b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491fa6e0-eecb-4ae0-bc6e-9cb404e244a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa000878-681a-4289-b9bc-809ff47a9963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d404d04-b41c-42d1-a67a-e0652fc9bec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6a07b0-f822-4306-bd32-7b1f123db5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf0551f-aeda-4559-9399-2ed8ad6979e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0f97af-483c-4be6-a9bb-fbb0eff5b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1fce90-0b72-4deb-a104-59e5e1d70a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771f0f2a-2286-4368-a93a-f8309a5992d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e685da19-2c62-4845-808a-b11333cde2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f841547-d4c7-4fb3-8dd1-86f4d052be15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982f237f-bb2c-4e4f-899c-9b19bfd39310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5a2c33-3e9b-440e-8277-3432baad70b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd3c63f-916a-4596-88eb-0ae7955dd910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9403fa2-dcf4-4563-8776-d573a01e81cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b3c215-5638-442b-88e4-d1e1ba5e77ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24a3bd2-971c-43a2-aec7-adcc34e5b961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d7b8e3-a4d4-4cf9-ab9a-183957cd2113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7b700f-1cbf-415b-b9c8-79ff27097232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca55bd09-c8b1-45e8-a599-22d6e18a994b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f814a7-2141-46c2-a1a8-825cbdcaf308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936859a5-cb3c-4d13-84ca-c663f7d7f17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55526e97-e1bd-44ff-aa2b-bcaf4241cda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fea9af-18b4-4874-99bd-7a5c7deaf3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666386dd-faa2-4c4c-b768-0409ddac6542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a441f985-b9ff-479f-ac12-7bc9d355b2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88016987-7e92-4086-af53-dc66a697ab96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37a77898-cf0f-45a6-95df-4a05b6264738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56576700-327b-4fbd-ad08-375d25c4cf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1349b8-a280-4f6b-ade1-17610d4b84a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb4dc7d-8254-4837-9102-7d1dce7192e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c433ea-14b6-4e8f-9eee-b40fadac6bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabde679-f237-4707-a0b1-53bf09a33b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8380f6a2-d6a9-4a73-a31f-bd3d2fd747e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9d684ba-034d-456f-a63d-d15d4a3ce1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da34050c-11f8-4e08-82dc-f896a9809619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849e5e76-5eca-471b-a805-dccdd6da0791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a440d96-c9b9-47ea-8fb5-306953802714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33cbb82e-3712-450a-a336-ea1e46d58742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff0e83d-3230-4b65-ab83-ea164b6d4627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e7fc36-d1ce-488a-98f5-5159e933f782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97981bd8-432d-4d5f-902f-71f65e0da215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82428937-d65e-40ee-86a0-b37ab4c86c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004e253a-ed84-459d-897b-74e9a49047b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210aac26-4fc3-45cc-a2fd-24af6529c195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0d19cc-b007-42a1-9cb5-3856e3da1507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ab26e7-9073-4935-a1b0-585788fd7a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6723cf-dd59-4d96-ab20-69a67c43d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a92e316-8c07-471c-bda9-e34b75eaa252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24a799a-12ad-46f0-af9a-905f2c12ef31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cabf8c14-8ff2-45df-bf63-536bc332dbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8154047c-0689-48fe-8fc9-3c0d404f04f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78d1db7-9af4-494f-bb3a-ae9dfc502032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a93e7251-c433-465b-8682-0b64762e734e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee1136d6-6901-4058-8e07-28f0275b70ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0516f8-6428-4608-aeb9-baaf849f43a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88fee74f-6619-47c9-8c02-24078059feae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd19a46-fef8-4e18-b820-c23bef284fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd713b5-a0e6-4aac-9f53-58412f919c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 312d2288-24f9-4bba-aee9-a8860da0845b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af2df74-566a-4fd1-b865-c378ff62de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb78516-9afd-451b-8b4b-5932acdecf1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66f4385-52f5-406c-8d16-34585849914c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a050de93-2aa2-4d34-bbf0-5e51d3989e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99fb4826-613d-4201-9968-854b28e785d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d5f82b-3f0b-4126-818c-f467d0715d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65d240a-1856-450c-b506-8f460f8ac3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8600574-ea21-4145-bd92-3570521efdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9cfcd3-c6db-442e-9511-dd635b4cb081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2492e7c8-0079-4b26-925f-a9433f6bfcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e977362-d624-4e00-b334-ccd96ca5d9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1dcff8-a07a-4fa7-a4fe-102db9452a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79838d93-f8e9-4323-8d63-217de31ed784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcfd6955-1aed-40db-9345-7c61aa47aeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f384fb-c3a4-46f9-bddf-be9cd1185b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a314e3-2359-4e3c-86a0-e659f3f052a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2f8b3c-65f5-4598-89cb-e440ae0e42a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4675194a-4398-4481-8b92-a93896886055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3022f4b4-d1a1-47c6-8a82-c79cc3153738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d135ee89-3adb-4526-adba-7a19845e1172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 634caac5-8ddc-4a0b-b47c-feae3304a600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460e5652-9564-432b-84e6-f82fe2beccc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabfe56c-baff-4e3a-8870-28b8801fc821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd9704c-75ae-4fba-8fad-55ca310d3f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e57645c-58a7-4106-9843-f0aa134bf3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62dc833-4a7e-4877-a222-c40fcc375d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fddecfc-7d3e-4eb0-a979-3f79908980af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcac3b9a-1110-4797-9926-ae4b7ccd15f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47920895-c920-4695-8e54-c28e439bfeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79e406f-e429-4adc-8340-cf159ea9d342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ec9ecb-cd25-4055-b6ee-537487e90b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571011a5-fb85-4fe8-aa78-85e5200673a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4513539c-f505-4275-ad99-a684688f636e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cafa5bad-b33a-447c-b18c-04d718d609e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e581b07-ed1f-46e2-b7a5-849709c4a9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da90f952-886a-4876-be1d-dd3add9c486e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67bc289d-973f-4517-957f-514d130b039e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5b11b7-328f-48eb-853b-ec563fa813f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11565a09-8293-429a-88d7-73005336fbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f471e5-f29b-4714-bd08-6e1a3538ff5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c73927-6233-49dc-87b1-89c1e2805962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3a10c3-26d0-4daa-873e-1a76a4878ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ee5829-49a2-41f7-9f87-224757c92023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cecc3182-2340-4262-96bb-dc71bb95a7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e7ce1d-dd40-4f96-8b19-aaa1f25ed8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14cf4d6-6ebe-42be-988e-b32e337b4b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e9573c-eb94-46a3-8c0f-5ac7c861b264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32319e0-8039-4f77-8714-4dc3f0ac5e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caca983a-9e6f-41ba-b8ce-587c41153bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21cc7673-a0db-423b-8524-a29983a9e29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85d92e5-a2b6-4635-82e5-f32a864c3bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51eef425-7b09-4dc2-9895-c0edc44f901b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9041d29-af00-4822-aa26-c076983983ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d58aeeb-676c-4707-ab43-176a9276f638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a9f09b-c8a9-4311-a4ec-abdf0c94f0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267da162-13cf-439b-9cb3-76dedbe571b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091e60d8-4df2-48af-80d8-ea8fd45a9428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663c8997-fb8f-46da-bbf5-e155311970eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8489ee2b-19b1-4a3f-a01a-205c84f8633d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a94e8e-98a4-476c-8534-2c831d27c719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e448917-9ee2-40e8-97e8-1f85d49b2ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b44aa8d-4eeb-4209-8cf6-0436af957ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b6cda8-0b65-4e2f-992a-0f90a2b75df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6146b3-88b9-4a82-8c87-3ec36cabc05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116bde98-1567-4d50-ae33-84cdda3d1c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea9140d1-4bc6-44d1-801d-3a10b79e9937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0499d8c1-cd94-43b0-8501-5b826fa8a4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524e9e4f-6c82-4125-8b9d-1cc7f549a5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce67f46c-15f2-48cb-867d-741032bd6bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfb9c345-b9dd-49ca-86cb-09040db81b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 877b9664-480d-451e-a774-f9941930dbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f2c48c-8b1d-4c5b-b1ae-af0abed8408e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28af64d-aee0-4011-ae94-c11d7597b465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3226afcc-a5c2-4a23-9e1e-3525763aeb9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0120af4f-2524-4f87-ac83-85f873fee62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a15603a-c98c-43ba-94d3-570e8451adbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5b4e2a-7525-4411-8bb7-6a777bc53101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26be8a02-d0d5-4e4c-84d9-56984e2c072f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc512f7-9744-4cf6-92d3-31dc64f9d3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385ad1d2-da48-4b4f-88e8-40774858208e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b56cca4-de78-401f-906e-478f024046e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739f7846-477e-4a6e-9531-ccfd6840b1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b483e9-10d1-4bfc-9e5d-3803083de074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48cdcb7-67cf-4b35-bc76-5db0907e98f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5753f68-529e-4867-aa46-fa3f6b2cba44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c16975b8-3798-4c8a-8296-1dbf2925671c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad31c37-45d8-455a-a1e5-5d47c8c3085a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300085db-dd04-41ce-add4-242670eae83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecaa37e4-a713-44b4-a4f5-68d113123a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d0eac6-a9d6-4417-a9ff-1fca6d19f673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d54608-dbf7-4823-a720-616bc284c685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cd2a18-f2d4-4d31-b653-f65a48858464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3ddf81-08b3-45b3-9499-29555c062665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97c0ac0-3508-4597-abaf-a568164a7953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a69b6cad-ed7d-4687-9781-74836caa5e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ed4490-152d-47bc-bd70-56048f2ab3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69cda99c-0fd4-42b1-ad79-9c8bb6d7532b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00239ffb-2998-4ad2-9420-098b52597fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644948c3-4c17-4748-9672-f2bbd3e8d049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7553502b-9288-417a-a860-d02480fec733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 985c33c4-e6f4-4c40-b133-63699dc254ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096b5689-ff92-4db5-a98d-244094eed683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938cd970-d33b-4984-b2c0-8e3b4ac2e38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ca1149-3cde-435e-bcc3-6bc4ee3b9cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7407777a-e4b8-4861-8682-17437a36f851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1b39dc-cabb-4b5a-86c6-74c34388e6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53f1389-08c3-48b4-bce0-9b8b7372578c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184d3dc9-7f37-476b-8bf2-2afaa5853a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342f4c67-6f01-433b-bb95-85776d3405a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9de89c-a58d-4220-aed4-351d850b3672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cca853-a9bd-44cc-b21a-8c94615fe7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f4d1ee-7309-4a05-9d14-3ccee66148ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74ba98f-c908-4b09-a6fd-e79059a5f0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edf91cc3-e94f-4a29-8fe7-8c5a8964cf2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48fcf3dd-7e50-4060-ac29-b69f4918d395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e842dc6-9dd3-4aa3-a5e2-c27b0c3b2dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c741687-dcdd-480e-9f91-390a0da9fb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819d7c0b-bbd9-47dc-97b9-d451139d21c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2dc663-6961-4dcf-bfd6-9638e8353356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a50eca-8a87-473a-9cc2-4d95756962e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2d7170-d887-4eb9-8c78-20855ab961f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6491c454-c123-4a48-aafd-0dda4baba5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c393023f-2625-4417-92f9-6f4ef8e0396a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51bae843-9eed-4c08-b405-9201654b5165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c39d585-392e-4429-9230-34e4b823f788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6befc11d-062c-44bc-b544-1b8a353ea4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc43a1f2-9612-4e4e-aced-160295ae0f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55966243-3d97-471c-a533-7aaff2ed7f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543e7515-9d19-4428-a24a-0aa010dfadc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a2d522-6eb3-4b7b-853f-ce33fdb3da14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e29fd4-2c3c-45c6-bb4f-6ba4086e5c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 017c38bf-c798-4194-9cf3-577b299b0ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce6cc8b-852f-4362-905e-c7ee0c3dd00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0ad80f-b6ba-4db9-8be6-425a8caff9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89832485-58d6-4738-9970-03685b07cb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b25f22-7d20-4468-a202-cfe6cd65e489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 374aa294-246f-405b-9165-78e46d8f7e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221ad25f-1e8f-4aa3-a56f-203e681fc7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6196ca-56d9-48a7-90bc-eed85299a11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6431ab-57ad-4ee9-b0ef-0f3b89c1bca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8918333-1180-4a14-b394-6143266615d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0541b686-6ac5-4e30-b5fb-8451f4634141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3080a7d8-2784-4e59-9e21-b0fb7df701b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1104c271-224e-45be-9aa8-dbdc78508d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b75e2c4-4daa-446d-adf2-53fbbbf0b6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab3e78a-16ac-4ef0-a7c8-77387f3de110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bec7fc-8004-4c8f-8711-78c85a9c7968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb8510a-97e6-4aa0-b7a3-0e3fe740bbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee6cf98-2a78-4206-8f82-2e0f58d2b27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 553f7e53-76dc-4d8b-b958-27c36845702c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e96d551-416f-4623-a77e-b968a6080734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97620161-4a29-4207-a7c7-9dd07022b2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79361c45-cd0b-4bee-a95c-3d0af6b9fc40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd3bf84-c59d-49c4-ba9e-d7b1c7a64968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf883c4-04b3-438e-a8ab-48f713625b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf520978-99e6-4377-9ba3-238fd01803e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d68f1e9-a379-420a-8962-b09cd3d0cbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac16b0c-178f-4f83-a6c9-5eca96df68f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402b97ef-356a-49b7-92d8-a854c296a37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a0e7194-e4e2-44da-8861-9e2bc3e8dc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43320e21-1924-4a5d-8ddc-6ea2ecf1149d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23456e9-4fb7-48c6-9708-ca9a68b53907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507203bb-1ebe-4af2-9065-df4603f0c0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fed4ff7-ca8b-47f1-a455-7112d986a8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ef429f-6b6b-4930-aab4-f478cc8a6f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539b9d74-84d9-4a3e-97c2-afae67f80b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876a8771-3b65-4e56-ab2d-9929617e6aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa240c7-9a27-4b49-85b7-4e951328fe73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ecfdd8-d63c-4880-bf0e-a445e185258f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfba2bfe-c451-4eea-a670-025c79cd2fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419a302a-62b5-4b89-9839-1c72d90fb10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17b630d-a494-4bf8-8de4-bd3002f95aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33014fca-e8c7-4ed8-a38f-57267c48615e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8813e4f3-53f6-49ad-b322-afaf48310bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690858fd-557d-4fba-84be-11f45e89496d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aebb93c5-37e5-4970-8c22-d03efd5a4b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672b8615-9b59-40f9-a817-c7e1694c3106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4c28c9-853b-457d-aea3-c48fd442f605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b0fe81-1ddf-4ac7-bfc7-f6419f5198e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b60a1adc-50e4-444a-aae4-e1476d4b84e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80392a05-f900-4771-a1f8-b2676081e411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25db0bec-1534-4289-8cd6-86dcdd35f930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f064fa-4759-450d-b336-f2750d58bebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667d7531-a2f3-4f82-971f-5602f59c9966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7908dbe-7462-488c-bef3-fa5db14a0ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c1f181-7cfc-409c-a940-3fdfbe3e28f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c23638-a24e-4547-a5de-70f46f2d52f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df655234-2d15-46aa-8e7a-357712f95640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a8c6bf-63ac-4b38-a175-f0a7d7a58122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe2c3b6-9f0f-4cbf-9079-454f4aa10630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8720c543-9beb-46c0-bad0-081b64434f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba86938-2214-4a03-9b63-7342475dfcce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f44b85d7-bf41-4db2-b267-23c3cc196e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e3a674d-fb8e-453f-a46a-239f61be8cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb51e97-7d94-43e7-a421-a83578ee05f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd840e4-6ea4-491d-8146-5b1e599da3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94944a7d-76f9-439d-ad54-b658aa9f201d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e712623-263d-4920-8692-dca620af0523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c914a3f-a172-4b1d-82d7-7e46602c13cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee72e6b-962c-459f-8b6a-c4481c1b3040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25945c6e-12df-4aca-a82a-4cf72bb0da0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f402bd54-d851-427c-83d4-465869b15799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5c2885-2198-46bd-a780-7616c7af9ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1046a5e8-f204-4cb5-aae9-5a2323402917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfb1fd5f-24e7-462f-a7cb-94acd50c4be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be921ed3-0082-44f7-ac51-57ec0e4658bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1765fc65-64a1-4ce1-a7f4-9af6ac9713bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef490ac1-fdd8-472b-a56d-0d6f85431bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56dd3e5-95bf-4a8e-b885-107e30fee8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f16d865-26cf-4f8c-b5e4-4f00988614e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda78886-0520-42a7-8b0a-20d72d77dffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0a465c-61f6-4b5e-a8d8-ae9e0b659775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6504204-d145-4333-9bb7-cf78b108ced3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb803fa-8e99-4bef-8a05-356eab43346b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d34943-48a7-4632-9e57-1e47a71e21a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4953741-d0ed-4fef-b199-4f6a82325ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1b1343-75b0-4348-9a9c-20add243f041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b161cc-0c98-4953-a494-2ed5662854b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63dfd18f-75e4-4993-9787-bf9cba87764a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17bef6b-fd40-49f8-83a7-de21a3e2d149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6713e06f-a4a2-4222-a347-47a027a2a345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e6ab42-c1ea-4594-8535-491ad93e1ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787b05e6-8c1d-48ee-8c19-384e80e6b9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ff91f5e-3076-4c7c-8e9f-8d5287ccac7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1e252b-a6d9-4d11-9150-53cbdf640910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16fb5a2-ca5a-45cb-b47f-607912c3b8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111d96aa-ee90-4a51-a4ef-c8fd49ae537f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f9b282-2561-423a-9cc0-e9892c6479ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e441fd84-19ce-41c8-b74f-e2327d36a777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfae5c3e-391c-48b5-8e73-e0b3863c7d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f2da97-f0fd-41cf-9c70-e082ce84e178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ff76ee-f46c-44ab-93e4-68df8af46efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262b1a02-546b-43b2-82e1-48bccf2f20ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96107b5a-8535-4ca8-bd29-526a34857a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0195e5ec-8faa-4ac2-8205-922c80ae0a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182b1bca-93b5-4f70-8c48-2deff7941e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc24e4e-6130-4de2-9c39-966350875d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524314e0-f8d0-486c-9bb0-c8de983c4a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b05f5a-5dc8-40e9-a178-b3efdf377d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72f422d-23a2-4bdd-8823-cfa6e2846e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1df90b-b113-4380-bf3c-309d022b45c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ccbc1e-7a71-49b8-a552-4bcabc535e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba78e4c6-450b-4e63-8e5b-03e0e365c7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31a8663-0342-4864-bf7e-271c301ddc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9074ca7-a6f4-454b-b273-70c7e341ba0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf1fbc4-6bb4-40b0-8d95-a14ac74d2769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0360d49-2ac8-4854-a15c-431df6c503d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c3f971-0cf4-4052-ace3-70b4c3945d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45bf85a4-7d5d-437c-90e3-dabde78b04ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f13df3-3a82-40b8-9634-ebfa32a6a357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60a2af8-1698-4963-ba81-2d732f217ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af24071-6781-4914-b2fa-a0f6b82b1c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90644a95-eaaf-4249-9b35-9569e9c826be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fca2ef8-2924-4861-a19c-268a9f4ab87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65581677-fea9-4e58-ad66-a987c45bfa97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755b47bc-5949-45cd-9af3-c7527a8206fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318a86a6-6c1e-45e2-be15-3a6839efd38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b92ef3a-e404-43af-9b45-b84a5a1bf0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40edeb86-c736-4f68-8ab3-30744ff444dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4043cb8-ec8c-4777-a691-4373569462bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4625de41-f37e-4102-a634-bb804146902d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d68f99-34cb-44bb-8917-4a0f8659d18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5460bc65-e880-4c5c-8dad-9aa3fc8d98e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b80c0f-ca80-4ac9-b6e6-e52722831e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01d0375-e696-4716-9185-65eee4430c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5b6eae2-f300-49fa-b665-245b17a41da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381ed7a8-3686-47a6-8cef-6b5da1143373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d705177-56e0-4c35-af25-49550d757d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cd4657-17ba-4915-824e-c020a16ac986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35f07f4-3a73-4585-9aea-ab212d8123ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565f0896-f2c3-4672-a195-1ab3268f34c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdba2a4a-ea76-4bb6-8c53-ef450c3f8f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3f4278-8c24-4c13-bd91-bb57ec2f1e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca9ea1f-ca6d-4e68-9cc0-df2be53e669e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a0e27c-304a-4bec-a684-e77b55b6d417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdff5f90-018a-4b52-a57a-5804692c4c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99fe778-3dbd-4742-92ad-1333fc48620a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a893321b-1203-45b8-b2cb-145a6942b6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79138689-1151-4609-878b-748ffa89e726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251d9040-197d-4515-b24c-14de9f40bfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7166cf5a-c614-4c85-8d34-1039777ac0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169b2975-dc89-4b15-ba04-8c31fb6ed28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912ba65d-bb67-4c34-a56c-2e8e01e175f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7b2d1a-8632-4eff-814d-a61c977933f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261a56c3-0e15-4472-bdbe-904c79284791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0045b749-ad2c-4fdf-9690-c7fa83bead2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77705509-db48-4742-b341-d289e75f1e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9610709-254d-44d2-8266-d7e0dcd0a8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081a2c89-c38d-4ced-b006-47dc57e80082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 056a09ec-9263-4378-88f3-40d78f4a90b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc78e07-af08-4585-bf8d-02edae8f2168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa186f5f-fe70-4bfa-9579-7726b5b3b0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf416f3-be1f-4cd0-a6e4-fcf26869ab4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d963746e-f0cc-42b4-ad34-3e9f24e5f280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990da91a-e6e2-4cef-8d01-c2c27cbb1cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb5e3ce-e73d-4bbd-948c-0cdbbb5443be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc02b952-3a46-469c-9845-283101b5ad77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a55cd5-60d2-445f-a5c0-48af42cf3c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6338bb3-b3b2-4647-b5b2-65ac22b36655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4860f7-e70b-432e-b498-2922c014345d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132bf032-4367-4b41-8ee5-d7637a3b09ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b74fd5c-880c-4309-86b9-6f0f8737c594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0460f9-d822-4941-9c93-b24fd09c57fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea488b4d-bf0b-44b2-9edc-46e35c84426c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5662bbfe-eeff-4f3f-bbf3-3e107eca7deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b68b66-5538-4926-9422-6dbe90808618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12668e39-59d0-4ec3-bd96-1452c7df6429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f2da1c-469d-4752-a513-376202571c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7d8735-b756-4673-b99d-bee5656d215d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac37ad52-e33d-4cb1-9315-7b10e781390c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abeb726c-f727-4e4f-9e90-047d91041acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f042b70a-4f0a-4c44-b596-167659d71877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c99d2b04-5761-40e7-9a98-190e4b713b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f9ae86-374f-4f3c-a15e-30573e451122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71683873-e7a5-436d-aeb3-0d139ab6018b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1c7e36-8e50-4f1b-bb29-8088a656b9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14115acc-684f-45a8-9857-6e23322397fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95554890-ceff-41c3-b11f-f877a7226838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fa8be1-bb31-432d-acef-0a1f0e99864a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab826d7-72a8-4d67-9ca6-c9f9d97de379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36d7b9b8-022d-41d7-81d2-04476d5f2d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5b5b1e-9115-4ed9-9c90-4f8dfe9f61b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb6f926-7f52-4db0-bb6f-25222c6be673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91395be9-e202-4845-8e53-7e1257fa6807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450a5e3f-9a37-40fa-bba8-2f1cf77a914a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9acfbd69-34e7-4781-8020-ca381a9a5c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb89e9a3-fc7a-4876-a7e8-b9146b8ebd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f1c19c-c6f1-4376-b03b-ff69fdd85052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0536e595-d968-4fd5-9ea2-b074855e69e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca59ff8-6d39-4f5d-b59e-0cdf2aa8b4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351e2ca6-7a44-4966-b9b1-e2412f20ba80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a308af84-edcf-4ead-bdc8-bbf493205d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf99d33-3662-4ce1-8e01-20cdb5110647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec364a8-f37e-4ef8-8f25-9a9d94b3ee8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd87575f-bc34-44ab-a50f-4d9df1df135a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad17f20a-c706-4674-855b-6068d745699f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea25889-a758-4182-a822-53c8aedd163c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9845af6a-43c7-47fb-9b49-b2bafb08b94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dda4f76-6145-4651-9c68-4a1429e5ad60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d935ae-2f55-4c27-b361-3faccf8f36b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fdbd29-430f-4f73-bca3-517826b97ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd40c5a1-768c-4b16-83ef-ab86145229d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfff0b9f-6d7a-4e09-bc23-7a0594d532d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e355e90-43b4-4b98-9994-96593e344dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e5cffe-5f56-44ab-9f13-6bb569ebe952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1a4cdb-a163-4245-8afb-3739df095cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912aa2c0-4f0a-478f-9126-c0dedf127866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720e79f4-2cd5-47aa-98e9-a81edeb0a0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7295e194-dc69-4be8-8936-b849fc43d95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52141d06-51c8-429f-b296-6ba1ed6eb60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7b15d2-2cb2-4f4a-b1c1-3518d220edc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b14abce-1cdb-4416-9ad3-3e03c9f0e4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5451e8d-3eb8-4e26-89df-e791fd4b103a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b9289f-4cce-4868-a72c-96d14c943f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf8e00d9-78f1-44e8-a33a-385b9b8c4068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43bfd71c-f617-49a4-a701-60823ec733a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981bcf7a-54c7-4782-b010-2ce6e12b4a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4924f36a-1db7-460a-93d2-5519afbb6ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d2eade2-fa7d-460f-8f5f-66d3bd87f4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb44772-4b26-48e9-b782-710b846a2dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7625599-cb70-4713-a07f-96086a365652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 678cefb5-ea4c-4c48-ad25-d3d67df9a3ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e3043e-3c88-4e79-9afa-6578249b5a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b07eec-9245-4103-9709-49d2f0b58415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfabcae7-6349-4290-b724-47718b815dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d40505-ed1e-4cba-913e-668fe652091c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690d05ae-d8f5-436e-9943-2bc3d31faded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1145fd66-ec86-44ba-9f85-283e5ce48378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9333aa61-50ef-4816-bb35-2981b99a6bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a72d51d-c58b-41d4-9647-e2104f08e961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af30b2a-977d-4197-b930-c803853a062c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e77cfcd-f337-42a6-b6d9-3b3ca80d0f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ae7e23-4dc9-40de-938e-65682c9e6e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ff99a6-e206-440c-9d70-92848de78df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f629b43-e39b-4086-90da-2d949be436dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480a0897-329e-4fe4-ae89-9e318adb54c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac06430-2bd1-47c8-b87f-50f61d9a9bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9337d533-3e79-4c0a-83c9-c18127d16670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b0a89cb-1fe7-452f-8d09-4ce8d0f9e8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1625e1a-a5ed-4cde-8430-e9072ca1a685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed80b413-cf99-4034-a244-178d500579e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38252b7-9b08-436e-88f7-ea5651c71a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ae2a73-7d3e-4876-b63d-77f89ec4a71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864a47f7-c1b5-477d-a4e9-84492a992306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d7d248-9628-4046-8cc5-0c7c8791e067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f39c98c0-fb00-439b-9a69-357bcedb05cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383a369d-a68b-4ed1-9bb7-a81fc5074b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6ae401-9081-4862-8f34-cff8ccef7edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6bb0ad3-b5fd-4487-ac1c-cbb594c5b530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0d79aa-2bd1-442c-963a-48cff282b250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4fbbec-df16-411f-a83c-db3880a0f80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc334fc-2a0a-41c8-94ea-8708f8395c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb32bc7-f4b8-414b-a326-1906e070b883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57ad815-90f1-4f14-a112-de8876c465c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d7c9b5-a409-4853-b6ce-6381e7dc3130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc74d461-409b-4f9a-99c2-9a2039d716a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6ebc57-0c54-46ca-b92a-dc7884a0237e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20ec061-6072-4ea0-906c-7d8932288bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c17a6f-8195-4a1b-9452-ea033e15d177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4673fd-25ff-4667-b36b-966e3b09cc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7a83cc-1103-4de1-b565-d7e117000709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80a87dd-8862-48f3-92fc-522a3a358bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f88c4109-9f1a-4629-86a7-d29a82619765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbc8d1b-1b87-4334-965b-2a43a15ef218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df837de1-ab3d-4935-beee-000da6cb62ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e021c87-00db-41e7-93fa-07ee1c3f5427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71a1afa-50a0-41e0-ba69-39f3da11d62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c77e4d6-dcda-48e6-88ff-d255c17f2ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea869ae-c66b-47e6-84d8-a24c3b500d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bc3f1c-0275-4bfe-b910-0913d362d0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44388327-3085-4199-ba5a-e19633cf056b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09490d63-f2fd-4622-99e9-4f698e4efed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3900efc3-a078-49b8-99a3-1251c2e8d654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0ded82-8760-45c1-ba93-4ac997fb093c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c136469-5ab4-48d8-8e89-33573b015d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9267871-effe-462d-9945-6bcbf5c4ea0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f00ee0-b223-4013-be07-acab9d45c046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0725ec40-fa2d-4bfb-9e9c-0186d5d6e4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d0a82f-bfeb-48c0-b1be-79aaf9d14f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1720cbd4-3d84-44b6-8603-216825451499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ead2c8-8778-4455-bd2f-e58a044f2c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e778ce5c-baf9-4512-8c95-7c616f385102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b373d931-807f-45e2-9409-fe975003dade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4acd2541-e7f5-4bf3-9f5a-bba466008551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a21a96-385e-4480-b9be-d5b60a9b68ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945f4c69-0e07-4b25-a45c-54850c9c734e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb51c4bd-98e2-4353-9ecd-f39dff91855e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07034ef7-b378-4070-8e2b-14c8330e6052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415bf3a5-9854-416b-a901-59b7468f9ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03fecf73-b7b8-4759-80b6-a28ce4690e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08e1670-0613-471a-90c0-3ffdd454a09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ca8375-9075-4037-bf95-32fd4e6453fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2ce390-ad3d-478e-bac6-cde41a42dc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da7301c-23a8-4a3b-8d8a-cbba475a89cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61eb9722-0aac-4ff9-b090-9d17573777a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ba00c3-7936-4bf2-97f5-9ed36b9ef9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692d1ed8-86fb-48a3-951b-708e841eb905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c8d5d3-233b-4126-9596-c2055df47723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b75dfcc-b4b9-4f53-bdf4-5eaaed96beb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f4fed3-7da1-4e3c-add8-f42917b447e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa8a2d8-30b6-4a96-9268-5a002618811a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40e0db4-b1e7-4521-ad32-994d6105549e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce27016-4ab0-4277-9bb3-83a5583e6722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13bb9e34-6ce8-4cda-af49-ef0924c48705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c617e4c-9c21-4baf-81ef-dbe79c56cd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62cc3508-ad2c-4388-b15b-09e11a55a687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6137fe1-ca0e-4c7e-b1db-68d94a37be54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f1b72a8-77f1-499f-aee7-54f0293caf4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce03b0aa-772f-420a-aa35-724c50fb378e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9381dfa7-ef57-462a-8c67-c7154463d6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 716ca204-adc6-4904-ba8f-4f58937aa94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6b96c5-d38a-418d-954d-45b163bdddcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874c6d97-c70b-4585-82b9-370bd442f891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4fc916a-5eb2-4a29-999c-155746352e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca552aad-5619-4ae0-9465-4569238ec516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb0920d-5ae3-44d4-92f7-7b809909cb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 726c35e6-321d-425e-975a-dcf1e9faae92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6e24c1-1626-40dc-95db-32741093286a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06aa8db0-7af6-4ee3-839a-af768e60d85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e337e4-7a12-4cb5-8728-dd556f066f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a54b48-f277-4b90-a1fa-4e6d5f0f3b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4d6b7a-10a0-43e8-bd4f-e0f43915f505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ddd136-8c1b-4d51-b519-2c5fd08ef4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bc7627-b850-4f40-bbb2-a02974b9317c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb633f75-eba7-4af5-bd75-14dcd73fecc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26528f01-78a7-4d63-a471-b723505730dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e20fc0-7b7d-43b9-9273-1227c28e1580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8368b13e-58e2-4637-b06a-2386f7330641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4bc5a91-3830-432b-854d-ced04dbfab78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102f5341-ffca-451c-8224-7af64e12da11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd507cf-3401-411e-ae20-251f3e7dd891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34096f6-65e8-4d0b-a288-94e0d5473d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194d5671-3e12-49db-a337-0d506750f996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a27ae37-cfec-4d4d-9ed4-bda1d3036b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcedeafc-17b4-4d6d-b8fc-0a7b218c5cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4bdc264-761e-45d8-9d90-67f2a13515d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268bfbfb-bc9d-4b7c-a2cd-9d1123481c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdd8a0a-0aee-440c-a72f-a24686862d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25f4238-d1c0-4e17-9b21-a62476efe803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b257bc-9056-461e-9b85-ed8d5749e7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd3a770-d27a-469b-b337-545a5cb54f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea1b9e8-2a7a-4c6e-b16c-70b9a99e6f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f50b9c80-b4d4-4b24-a573-42f6e4e7a94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c73195d-9e50-4f3a-acd5-f93ab3d13b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8ad7d1-6338-488b-97df-bad7da740057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a740db97-9a5f-42e4-a85a-5204f9bc72b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068f5e02-04b3-412e-9b35-e83b511dbafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94abfbbc-b6da-4651-a55a-dd5b68ffa749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f81246-08b1-4756-98be-d81a9d2690ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb776a1-644d-4729-b5d3-3def6b39d69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fd7a4e-260f-4daf-a318-ee5d65dbef12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b43c8c-0c30-4eec-8e3d-1b6125d1b5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91717bc5-d316-429c-b20f-7c4c6391b2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd3fc00-7129-4e7e-a1e0-46b59f97af5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f77bf24-90b1-49a8-adff-31ca00c4ebe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dee61f2-7239-458e-9c3b-a1352663bcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dadf01f-26e8-492c-8d78-52298767631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112973ac-d391-4031-bb70-6fede32d66e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 315e3000-b775-4921-b6b3-62747543ed63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de7d45f9-a126-401c-8586-74358860d65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf0e3bb-23a5-407b-a40e-e42cf7f0d845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80c42c5-166c-4bd9-ba6d-964d82c8e819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69735511-94f6-4c2a-ab99-495e5a9222e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481b08d4-6cd0-4601-bee0-fda850b277f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56413cd-1d65-4963-b897-a38bb46d03b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831f98a6-7d88-47de-b4ff-100bfd3c7a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99da5a56-bd3b-43c2-b040-afc96ea07944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f61c17-04fd-4976-ac57-3398a4099577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 726e092c-5dfa-44ad-b12e-92b9e4ae704f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef5c7ad-00eb-48ce-b14a-f842a6b8f42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89341efc-5853-4231-88a8-24d7bb56c93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d67a85f-03d0-4256-90bb-396b5328e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011f6ebb-8c07-49f7-a9dd-dda9b94ac52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c4cec2-e1a3-4ec9-b5fb-df0a84be3f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecaeb145-0f54-4698-ad68-3d5c1500cbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b19b03f-bb41-418d-8b87-8309df3c6f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c1c517-87a0-4b83-87d5-a41b57cae5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a549ee-89b7-4039-8a5f-97f1f1ff93a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ad648f-71ad-41c7-b5e8-97779b5fb938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09365d0-aa89-4a8e-98a7-f15341e2ce5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f2a826-7e51-46c2-a500-5b19e347e06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58f3ed6-d269-467a-94ad-6406b54dae9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2598ebb-e4b0-4f8c-8359-5cf56faf4412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b81ae56-831f-4eed-8c49-a49166dd080d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9518375-4eb1-4abf-80e1-2bf3a30d96c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4977a38e-d339-4b40-bfd2-02c4badc125c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535d4754-040c-4f91-8d4e-3c2f70d9d6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba1657d-cea4-46c8-aadc-8bbf78e04687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97cecd2d-4024-483d-aacc-5c8c4b60cfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e199afb0-edca-49d4-867f-2a83c5706063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1699f7c1-f2bf-4d92-9d90-5be2798bacc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8dd04c5-6321-4b91-804c-2697446b603f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b37a89-e028-4c07-82f5-7311cc788020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f3f1a4-e222-47ec-995d-3dc6d883441a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f396a0c-bcd1-445e-8e0a-baf2b5a7f4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39756563-62a5-4d2d-b2fb-07e82653e26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41604c25-a3c6-4ca6-bc84-ef6564f513a7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(5148, 24), y=(5148,)
   Test:  X=(1287, 24), y=(1287,)

⚠️  Limiting training data: 5148 → 800 samples
⚠️  Limiting test data: 1287 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3691, val=0.1692 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1033, val=0.0936 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0860, val=0.0864 (↓), lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0876, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0828, val=0.0874, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0885, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 1 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0036
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0144
============================================================


============================================================
🔄 Round 5 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4403, val=0.4404 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3340, val=0.3240 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1966, val=0.1337 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0877, val=0.0907 (↓), lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0940, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0807, val=0.0925, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 5 Summary - Client client_12
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0318
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0010
============================================================


============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4734, val=0.4866 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4325, val=0.4469 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3981, val=0.4140 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.3678, val=0.3826 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.3454, val=0.3669 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.2259, val=0.2329 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.1016, val=0.1064 (↓), lr=0.000008
   📉 Epoch 28: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.0883, val=0.0898 (↓), lr=0.000004
   📉 Epoch 36: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.0860, val=0.0863, patience=1/15, lr=0.000002
   • Epoch  51/100: train=0.0851, val=0.0847, patience=1/15, lr=0.000002
   • Epoch  61/100: train=0.0844, val=0.0835, patience=2/15, lr=0.000002
   • Epoch  71/100: train=0.0841, val=0.0827, patience=6/15, lr=0.000002
   ✓ Epoch  81/100: train=0.0838, val=0.0821 (↓), lr=0.000002
   • Epoch  91/100: train=0.0837, val=0.0816, patience=10/15, lr=0.000002

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000063 → 0.000002 (5 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0044
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0143
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.4845, RMSE: 0.6960, MAE: 0.6336, R²: -4.8318

============================================================
🔄 Round 9 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4801, val=0.4379 (↓), lr=0.000002
   ✓ Epoch   2/100: train=0.4780, val=0.4358 (↓), lr=0.000002
   ✓ Epoch   3/100: train=0.4758, val=0.4339 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.4740, val=0.4322 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.4723, val=0.4306 (↓), lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   ✓ Epoch  11/100: train=0.4669, val=0.4260 (↓), lr=0.000001
   • Epoch  21/100: train=0.4615, val=0.4208, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4569, val=0.4165, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4528, val=0.4125, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4489, val=0.4088, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4451, val=0.4052, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4414, val=0.4017, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4378, val=0.3982, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4342, val=0.3947, patience=1/15, lr=0.000001

============================================================
📊 Round 9 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.4328, RMSE=0.6579, R²=-4.0358
   Val:   Loss=0.3917, RMSE=0.6258, R²=-4.3356
============================================================


============================================================
🔄 Round 10 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4689, val=0.4538 (↓), lr=0.000001
   • Epoch   2/100: train=0.4685, val=0.4534, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4681, val=0.4530 (↓), lr=0.000001
   • Epoch   4/100: train=0.4677, val=0.4526, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4672, val=0.4522 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4648, val=0.4499 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4610, val=0.4462 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4573, val=0.4426 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4537, val=0.4392 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4501, val=0.4357 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4465, val=0.4323 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4429, val=0.4288 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4393, val=0.4253 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4357, val=0.4218 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4313, RMSE=0.6567, R²=-4.3091
   Val:   Loss=0.4186, RMSE=0.6470, R²=-3.5260
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4474, RMSE: 0.6689, MAE: 0.6037, R²: -4.3859

============================================================
🔄 Round 12 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4551, val=0.4093 (↓), lr=0.000001
   • Epoch   2/100: train=0.4547, val=0.4090, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4543, val=0.4086 (↓), lr=0.000001
   • Epoch   4/100: train=0.4539, val=0.4082, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4535, val=0.4078 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4511, val=0.4056 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4471, val=0.4019 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4432, val=0.3982 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4393, val=0.3946 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4354, val=0.3909 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4315, val=0.3871 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4275, val=0.3834 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4234, val=0.3796 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4194, val=0.3757 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4151, RMSE=0.6442, R²=-3.8716
   Val:   Loss=0.3723, RMSE=0.6101, R²=-3.8858
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4284, RMSE: 0.6545, MAE: 0.5877, R²: -4.1572

============================================================
🔄 Round 13 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4261, val=0.4216 (↓), lr=0.000001
   • Epoch   2/100: train=0.4257, val=0.4212, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4253, val=0.4208 (↓), lr=0.000001
   • Epoch   4/100: train=0.4249, val=0.4205, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4246, val=0.4201 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4223, val=0.4178 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4185, val=0.4140 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4146, val=0.4101 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4107, val=0.4062 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4068, val=0.4023 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4027, val=0.3983 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3987, val=0.3943 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3945, val=0.3901 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3903, val=0.3860 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3879, RMSE=0.6228, R²=-3.6514
   Val:   Loss=0.3822, RMSE=0.6182, R²=-3.5419
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.4117, RMSE: 0.6417, MAE: 0.5734, R²: -3.9561

📊 Round 13 Test Metrics:
   Loss: 0.3290, RMSE: 0.5736, MAE: 0.4961, R²: -2.9609

============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3266, val=0.3300 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3259, val=0.3293 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3253, val=0.3286 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3246, val=0.3279 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3239, val=0.3272 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3200, val=0.3233 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3137, val=0.3171 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3076, val=0.3110 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3016, val=0.3049 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2956, val=0.2988 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2895, val=0.2927 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2833, val=0.2865 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2771, val=0.2802 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2707, val=0.2738 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2640, RMSE=0.5138, R²=-2.1597
   Val:   Loss=0.2680, RMSE=0.5177, R²=-2.2078
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.2454, RMSE: 0.4953, MAE: 0.4119, R²: -1.9535

============================================================
🔄 Round 20 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2374, val=0.2642 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2367, val=0.2634 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2360, val=0.2627 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2353, val=0.2619 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2346, val=0.2611 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2303, val=0.2565 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2233, val=0.2489 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2164, val=0.2412 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2094, val=0.2336 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2024, val=0.2260 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1955, val=0.2184 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1887, val=0.2108 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1819, val=0.2033 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1753, val=0.1959 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1690, RMSE=0.4111, R²=-1.0143
   Val:   Loss=0.1893, RMSE=0.4351, R²=-1.3356
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.1784, RMSE: 0.4224, MAE: 0.3436, R²: -1.1476

============================================================
🔄 Round 22 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1817, val=0.1545 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1809, val=0.1539 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1802, val=0.1532 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1795, val=0.1526 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1788, val=0.1520 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1747, val=0.1483 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1678, val=0.1422 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1612, val=0.1364 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1548, val=0.1308 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1486, val=0.1254 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1427, val=0.1202 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1370, val=0.1154 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1316, val=0.1108 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1265, val=0.1065 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1220, RMSE=0.3493, R²=-0.4396
   Val:   Loss=0.1029, RMSE=0.3208, R²=-0.3202
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.1468, RMSE: 0.3832, MAE: 0.3114, R²: -0.7674

📊 Round 22 Test Metrics:
   Loss: 0.1189, RMSE: 0.3448, MAE: 0.2823, R²: -0.4313

📊 Round 22 Test Metrics:
   Loss: 0.0971, RMSE: 0.3116, MAE: 0.2618, R²: -0.1691

============================================================
🔄 Round 25 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0960, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0958, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0956, val=0.0995, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0954, val=0.0993 (↓), lr=0.000001
   • Epoch   5/100: train=0.0952, val=0.0991, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0941, val=0.0978, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0924, val=0.0958, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0908, val=0.0940 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0894, val=0.0923 (↓), lr=0.000001
   • Epoch  51/100: train=0.0882, val=0.0908, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0872, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0863, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0856, val=0.0874, patience=3/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0850, val=0.0866 (↓), lr=0.000001

============================================================
📊 Round 25 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0105
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0353
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2531, R²: -0.0314

📊 Round 25 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2521, R²: -0.0119

============================================================
🔄 Round 29 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0862, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0858, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0833, val=0.0853, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 29 Summary - Client client_12
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0189
============================================================


============================================================
🔄 Round 30 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0833, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0839, val=0.0830, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 30 Summary - Client client_12
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0019
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0117
============================================================


============================================================
🔄 Round 31 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 31 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0044
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0118
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2518, R²: -0.0043

============================================================
🔄 Round 33 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 33 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0056
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0031
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2517, R²: -0.0031

📊 Round 33 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2517, R²: -0.0029

============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0007
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0308
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2517, R²: -0.0027

============================================================
🔄 Round 36 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 36 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0070
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0025
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2517, R²: -0.0025

📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2517, R²: -0.0021

============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0017
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0232
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2516, R²: -0.0002

============================================================
🔄 Round 46 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 46 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0006
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0123
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2516, R²: 0.0001

============================================================
🔄 Round 49 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 49 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0043
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0089
============================================================


============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0045
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0022
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2516, R²: 0.0010

============================================================
🔄 Round 53 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 53 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0044
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0047
============================================================


============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0001
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0011
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0016

============================================================
🔄 Round 57 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 57 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0006
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0162
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

============================================================
🔄 Round 58 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 58 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0023
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0173
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0028

============================================================
🔄 Round 61 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 61 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0011
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0052
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0028

============================================================
🔄 Round 64 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 64 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0000
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0036
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0031

📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0031

📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0031

📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0032

📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0032

============================================================
🔄 Round 72 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 72 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0012
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0079
============================================================


============================================================
🔄 Round 73 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 73 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0002
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0053
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0032

============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0034
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0079
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0032

============================================================
🔄 Round 77 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 77 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0039
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0099
============================================================


============================================================
🔄 Round 78 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 78 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0018
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0029

============================================================
🔄 Round 81 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 81 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0026
============================================================


============================================================
🔄 Round 83 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 83 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0009
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0011
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0030

============================================================
🔄 Round 84 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 84 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0003
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0062
============================================================


============================================================
🔄 Round 85 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 85 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0005
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0034
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0032

============================================================
🔄 Round 88 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 88 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0005
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0038
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0029

📊 Round 88 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0028

============================================================
🔄 Round 91 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 91 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0045
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0139
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0028

============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0023
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0129
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2515, R²: 0.0029

============================================================
🔄 Round 98 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 98 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0000
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0036
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

📊 Round 98 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

============================================================
🔄 Round 103 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 103 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0027
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0131
============================================================


============================================================
🔄 Round 106 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 106 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0014
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0036
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0021

📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

📊 Round 106 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

============================================================
🔄 Round 113 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 113 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0002
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 115 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 115 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0051
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 119 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 119 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0036
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 121 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 121 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0021
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 123 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 123 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0018
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0022
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

📊 Round 123 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0034

============================================================
🔄 Round 129 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0003
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0049
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0034

📊 Round 129 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0035

============================================================
🔄 Round 132 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 132 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0028
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0111
============================================================


============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0036
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0023
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0032

📊 Round 133 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0016
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0018
============================================================


============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0016
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0018
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0033

============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0029
============================================================


============================================================
🔄 Round 141 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 141 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0013
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0015
============================================================


============================================================
🔄 Round 142 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 142 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0007
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0056
============================================================


============================================================
🔄 Round 143 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 143 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0018
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0120
============================================================


============================================================
🔄 Round 145 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 145 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0031
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0029
============================================================


============================================================
🔄 Round 146 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 146 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0034
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0025
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0034

============================================================
🔄 Round 147 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 147 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0001
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0055
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0033

📊 Round 147 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0017
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0102
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 154 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 154 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0022
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0078
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0032

📊 Round 154 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

📊 Round 154 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0013
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0048
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 159 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 159 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

📊 Round 159 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0015
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0010
============================================================


============================================================
🔄 Round 167 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 167 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0006
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0041
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

============================================================
🔄 Round 169 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 169 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0000
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0024
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0032

📊 Round 169 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 174 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 174 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0023
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0090
============================================================


============================================================
🔄 Round 177 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 177 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0031
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0034
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

📊 Round 177 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

============================================================
🔄 Round 180 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 180 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0020
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0072
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0006
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0025
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 182 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 182 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0014
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0039
============================================================


============================================================
🔄 Round 183 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 183 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0020
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0057
============================================================


============================================================
🔄 Round 184 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 184 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0030
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0074
============================================================


============================================================
🔄 Round 185 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 185 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0017
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0025
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 189 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 189 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0029
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0112
============================================================


============================================================
🔄 Round 190 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 190 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0029
============================================================


============================================================
🔄 Round 191 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 191 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0008
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0003
============================================================


============================================================
🔄 Round 192 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 192 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0026
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0250
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 195 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 195 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0024
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0068
============================================================


============================================================
🔄 Round 196 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 196 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0008
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0070
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 198 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 198 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0012
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0007
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 200 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 200 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0021
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 206 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 206 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0007
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0014
============================================================


============================================================
🔄 Round 207 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 207 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0025
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0075
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 208 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 208 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0044
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0163
============================================================


============================================================
🔄 Round 210 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 210 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0005
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

📊 Round 210 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

============================================================
🔄 Round 213 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 213 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0017
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0098
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

============================================================
🔄 Round 218 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 218 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0008
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0181
============================================================


============================================================
🔄 Round 219 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 219 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0013
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0060
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

============================================================
🔄 Round 221 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 221 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0138
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

============================================================
🔄 Round 222 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 222 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0009
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0062
============================================================


============================================================
🔄 Round 223 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 223 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0017
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0066
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

============================================================
🔄 Round 225 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 225 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0057
============================================================


============================================================
🔄 Round 226 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 226 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0041
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

📊 Round 226 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

📊 Round 226 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

============================================================
🔄 Round 230 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 230 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0006
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 232 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 232 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0012
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0101
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 245 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 245 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0000
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0000
============================================================


============================================================
🔄 Round 246 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 246 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0018
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0093
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0030

============================================================
🔄 Round 249 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 249 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0011
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0068
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

============================================================
🔄 Round 250 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 250 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0011
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0023
============================================================


============================================================
🔄 Round 252 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 252 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0013
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 252 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

============================================================
🔄 Round 258 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 258 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0018
============================================================


============================================================
🔄 Round 259 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 259 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0030
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0202
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

📊 Round 259 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

📊 Round 259 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 259 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 266 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 266 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0058
============================================================


============================================================
🔄 Round 267 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 267 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0001
============================================================


============================================================
🔄 Round 268 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 268 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0015
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0018
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0025

📊 Round 268 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0023

📊 Round 268 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

📊 Round 268 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

============================================================
🔄 Round 274 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 274 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0042
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0058
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

============================================================
🔄 Round 276 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 276 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0005
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0017
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

📊 Round 276 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 281 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 281 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0032
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 281 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

📊 Round 281 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0030

📊 Round 281 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 281 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 288 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 288 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0027
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0117
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

📊 Round 288 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 293 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 293 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0004
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0009
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2516, R²: 0.0033

📊 Round 293 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 300 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 300 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0008
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0053
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0030

📊 Round 300 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 300 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 305 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 305 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0006
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0026
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 307 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 307 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0015
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0056
============================================================


============================================================
🔄 Round 308 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 308 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0002
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0007
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 308 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 308 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

📊 Round 308 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 318 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 318 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0009
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0036
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0027

============================================================
🔄 Round 319 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 319 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0008
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0083
============================================================


============================================================
🔄 Round 320 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 320 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0020
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0078
============================================================


============================================================
🔄 Round 321 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 321 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0027
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0201
============================================================


============================================================
🔄 Round 322 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 322 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0010
   Val:   Loss=0.0956, RMSE=0.3093, R²=-0.0038
============================================================


============================================================
🔄 Round 323 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 323 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0015
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0152
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 325 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 325 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0002
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0007
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 327 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 327 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0018
============================================================


============================================================
🔄 Round 329 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 329 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0002
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0003
============================================================


============================================================
🔄 Round 330 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 330 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0052
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

📊 Round 330 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

📊 Round 330 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0028

============================================================
🔄 Round 334 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 334 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0001
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0007
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 336 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 336 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0002
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0008
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

📊 Round 336 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0030

============================================================
🔄 Round 338 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 338 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0005
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0031

============================================================
🔄 Round 339 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 339 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0006
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0074
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0030

============================================================
🔄 Round 340 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 340 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0004
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0023
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2516, R²: 0.0029

============================================================
🔄 Round 342 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 342 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0008
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0022
============================================================


============================================================
🔄 Round 343 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 343 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0017
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0069
============================================================


============================================================
🔄 Round 344 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 344 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0012
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0054
============================================================


============================================================
🔄 Round 346 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 346 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0038
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

📊 Round 346 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 350 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 350 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0005
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0024
============================================================


============================================================
🔄 Round 352 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 352 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0011
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0048
============================================================


============================================================
🔄 Round 355 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 355 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0009
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0037
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 356 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 356 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0028
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0081
============================================================


============================================================
🔄 Round 359 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 359 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0005
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0016
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2516, R²: 0.0026

============================================================
🔄 Round 360 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 360 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0024
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0024

📊 Round 360 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

📊 Round 360 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0019

============================================================
🔄 Round 364 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 364 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0001
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0049
============================================================


============================================================
🔄 Round 365 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 365 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0011
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0139
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0019

📊 Round 365 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0019

============================================================
🔄 Round 368 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 368 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0006
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0310
============================================================


============================================================
🔄 Round 369 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 369 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0004
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0056
============================================================


============================================================
🔄 Round 370 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 370 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0053
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0026
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

============================================================
🔄 Round 371 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 371 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0021
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0049
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 373 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 373 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0011
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0005
============================================================


============================================================
🔄 Round 374 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 374 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0010
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0284
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2516, R²: 0.0014

============================================================
🔄 Round 375 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 375 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0149
============================================================


============================================================
🔄 Round 376 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 376 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0002
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0056
============================================================


============================================================
🔄 Round 377 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 377 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0031
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0043
============================================================


============================================================
🔄 Round 378 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 378 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0051
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0016

📊 Round 378 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 384 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 384 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0014
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0025
============================================================


============================================================
🔄 Round 387 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 387 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0032
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0045
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2516, R²: 0.0013

============================================================
🔄 Round 388 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 388 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0008
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0147
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0017

📊 Round 388 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0017

============================================================
🔄 Round 394 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 394 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0006
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0074
============================================================


============================================================
🔄 Round 395 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 395 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0009
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0157
============================================================


============================================================
🔄 Round 397 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 397 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0009
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 398 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 398 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0033
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0050
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 400 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 400 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0019
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0029
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 401 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 401 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0018
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0032
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

============================================================
🔄 Round 403 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 403 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0010
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0021

📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0021

============================================================
🔄 Round 410 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 410 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0047
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0040
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

📊 Round 410 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

============================================================
🔄 Round 413 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 413 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0012
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0145
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0021

📊 Round 413 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0022

============================================================
🔄 Round 417 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 417 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0041
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0009
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

📊 Round 417 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0018

============================================================
🔄 Round 419 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 419 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0021
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0236
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0019

============================================================
🔄 Round 422 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 422 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0022
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0040
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2516, R²: 0.0019

============================================================
🔄 Round 423 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 423 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0022
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0019

📊 Round 423 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

============================================================
🔄 Round 427 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 427 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0013
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0004
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2516, R²: 0.0020

============================================================
🔄 Round 428 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 428 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0031
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0070
============================================================


============================================================
🔄 Round 431 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 431 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0002
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0073
============================================================


============================================================
🔄 Round 433 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 433 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0010
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0067
============================================================


============================================================
🔄 Round 434 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 434 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0023
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0122
============================================================


============================================================
🔄 Round 435 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 435 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0008
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0065
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

============================================================
🔄 Round 436 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 436 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0011
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0083
============================================================


============================================================
🔄 Round 437 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 437 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0017
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0034
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

📊 Round 437 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

============================================================
🔄 Round 443 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 443 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0015
============================================================


============================================================
🔄 Round 444 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 444 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0006
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0071
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 446 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 446 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0005
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0070
============================================================


============================================================
🔄 Round 451 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 451 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0010
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0146
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 453 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 453 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0015
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0004
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 453 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 455 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 455 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0002
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0053
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 458 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 458 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0031
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0074
============================================================


============================================================
🔄 Round 459 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 459 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0020
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0159
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 461 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 461 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0063
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 462 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 462 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0006
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0075
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 465 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 465 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0010
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0066
============================================================


============================================================
🔄 Round 467 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 467 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0011
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0097
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

📊 Round 467 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 474 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 474 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0002
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0055
============================================================


============================================================
🔄 Round 476 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 476 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0001
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0041
============================================================


============================================================
🔄 Round 477 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 477 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0052
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0098
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 479 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 479 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0026
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0022
============================================================


============================================================
🔄 Round 482 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 482 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0275
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 487 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 487 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0017
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0233
============================================================


============================================================
🔄 Round 488 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 488 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0035
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0014
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 489 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 489 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0013
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0099
============================================================


============================================================
🔄 Round 491 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 491 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0156
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 493 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 493 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0020
============================================================


============================================================
🔄 Round 494 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 494 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0031
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0082
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 494 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 496 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 496 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0108
============================================================


============================================================
🔄 Round 497 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 497 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0025
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

📊 Round 497 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

📊 Round 497 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 504 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 504 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0150
============================================================


============================================================
🔄 Round 505 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 505 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0022
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0052
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 506 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 506 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0006
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0212
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 508 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 508 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0039
============================================================


============================================================
🔄 Round 509 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 509 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0039
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0006
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

📊 Round 509 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 509 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 509 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 509 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 515 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 515 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0011
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0016
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 515 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 517 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 517 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0056
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 517 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 523 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 523 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0000
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0028
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 523 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 526 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 526 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0006
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0101
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0022

============================================================
🔄 Round 527 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 527 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0020
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0013
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0022

📊 Round 527 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0022

============================================================
🔄 Round 530 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 530 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0015
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0039
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 530 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 536 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 536 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0022
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0060
============================================================


============================================================
🔄 Round 537 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 537 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0002
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0101
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0014

📊 Round 537 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 537 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 544 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 544 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0011
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0010
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 544 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 547 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 547 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0007
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0089
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 552 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 552 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0003
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0203
============================================================


============================================================
🔄 Round 555 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 555 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0047
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0035
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 559 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 559 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0007
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0026
============================================================


============================================================
🔄 Round 563 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 563 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0063
============================================================


============================================================
🔄 Round 564 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 564 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0037
   Val:   Loss=0.0964, RMSE=0.3105, R²=0.0016
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 567 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 567 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0094
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0306
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 568 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 568 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0007
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0071
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 569 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 569 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0007
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0037
============================================================


============================================================
🔄 Round 570 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 570 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0027
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0056
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 572 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 572 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0127
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 572 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 572 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 572 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0016

============================================================
🔄 Round 576 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 576 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0027
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

📊 Round 576 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 576 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 576 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 576 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 584 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 584 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0237
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 584 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 586 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 586 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0010
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0004
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

📊 Round 586 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 588 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 588 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0004
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0217
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0020

============================================================
🔄 Round 596 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 596 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0008
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0071
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

📊 Round 596 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0021

📊 Round 596 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

📊 Round 596 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 602 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 602 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0067
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 606 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 606 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0004
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0049
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 607 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 607 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0036
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0066
============================================================


============================================================
🔄 Round 611 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 611 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0165
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 613 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 613 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0009
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0166
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 614 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 614 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0024
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0366
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0014

============================================================
🔄 Round 615 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 615 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0053
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0053
============================================================


============================================================
🔄 Round 616 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 616 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0257
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 616 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 621 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 621 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0022
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0042
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 622 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 622 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0001
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0110
============================================================


============================================================
🔄 Round 624 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 624 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0025
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0002
============================================================


============================================================
🔄 Round 625 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 625 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0122
============================================================


============================================================
🔄 Round 626 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 626 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0266
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 627 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 627 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0001
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0249
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 627 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 627 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 636 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 636 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0011
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0178
============================================================


============================================================
🔄 Round 637 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 637 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0008
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0101
============================================================


============================================================
🔄 Round 639 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 639 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0015
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0018
============================================================


============================================================
🔄 Round 640 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 640 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0016
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0009
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 642 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 642 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0012
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0170
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 643 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 643 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0021
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

📊 Round 643 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 647 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 647 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0018
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0379
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 649 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 649 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0011
============================================================


============================================================
🔄 Round 650 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 650 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0001
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0056
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 653 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 653 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0027
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0007
============================================================


============================================================
🔄 Round 654 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 654 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0018
   Val:   Loss=0.0940, RMSE=0.3067, R²=0.0028
============================================================


============================================================
🔄 Round 656 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 656 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0001
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0039
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 657 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 657 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0003
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0269
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 657 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 657 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 662 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 662 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0010
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0023
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 665 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 665 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0020
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0013
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 669 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 669 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0018
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0003
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 671 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 671 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0046
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

📊 Round 671 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 676 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 676 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0262
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0019

============================================================
🔄 Round 678 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 678 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0011
   Val:   Loss=0.1003, RMSE=0.3167, R²=-0.0084
============================================================


============================================================
🔄 Round 679 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 679 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0030
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 679 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 679 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 687 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 687 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0015
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0015
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 687 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

📊 Round 687 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0018

============================================================
🔄 Round 690 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 690 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0043
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0016

============================================================
🔄 Round 694 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 694 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0004
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0071
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 697 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 697 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0015
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0014

============================================================
🔄 Round 698 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 698 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0021
   Val:   Loss=0.0971, RMSE=0.3117, R²=0.0007
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0014

============================================================
🔄 Round 701 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 701 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0065
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0185
============================================================


============================================================
🔄 Round 702 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 702 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0005
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0159
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

📊 Round 702 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 705 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 705 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0053
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0113
============================================================


============================================================
🔄 Round 706 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 706 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0008
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0031
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

📊 Round 706 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0010

============================================================
🔄 Round 712 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 712 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0041
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0006
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 713 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 713 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0023
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0028
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 715 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 715 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0011
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0018
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0011

📊 Round 715 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0009

📊 Round 715 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0011

📊 Round 715 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0012

============================================================
🔄 Round 721 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 721 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0025
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0012
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2517, R²: 0.0012

============================================================
🔄 Round 722 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 722 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0193
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0012

============================================================
🔄 Round 723 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 723 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0032
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0010
============================================================


============================================================
🔄 Round 725 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 725 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0563
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 726 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 726 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0164
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

📊 Round 726 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 734 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 734 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0020
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0005
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0017

============================================================
🔄 Round 736 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 736 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0004
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

📊 Round 736 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2517, R²: 0.0013

============================================================
🔄 Round 740 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 740 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0037
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0034
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

📊 Round 740 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 742 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 742 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0015
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0003
============================================================


============================================================
🔄 Round 743 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 743 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0017
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0185
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2517, R²: 0.0015

============================================================
🔄 Round 744 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 744 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0086
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2518, R²: 0.0016

============================================================
🔄 Round 747 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 747 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0001
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0103
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2518, R²: 0.0017

============================================================
🔄 Round 748 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 748 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0000
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0145
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2518, R²: 0.0018

============================================================
🔄 Round 753 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 753 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0367
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2518, R²: 0.0013

============================================================
🔄 Round 758 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 758 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0018
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0001
============================================================


============================================================
🔄 Round 759 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 759 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0002
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0185
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0008

============================================================
🔄 Round 762 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 762 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0027
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0042
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0008

============================================================
🔄 Round 764 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 764 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0011
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0078
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0009

============================================================
🔄 Round 767 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 767 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0058
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0031
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0010

📊 Round 767 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0008

============================================================
🔄 Round 769 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 769 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0030
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2518, R²: 0.0011

============================================================
🔄 Round 773 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 773 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0032
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0016
============================================================


============================================================
🔄 Round 774 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 774 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0002
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0096
============================================================


============================================================
🔄 Round 775 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 775 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0008
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0355
============================================================


============================================================
🔄 Round 776 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 776 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0005
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2518, R²: 0.0013

============================================================
🔄 Round 778 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 778 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0004
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0111
============================================================


============================================================
🔄 Round 779 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 779 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0000
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0079
============================================================


============================================================
🔄 Round 781 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 781 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0011
============================================================


============================================================
🔄 Round 782 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 782 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0036
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0052
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2518, R²: 0.0015

📊 Round 782 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2518, R²: 0.0012

============================================================
🔄 Round 785 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 785 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0054
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0108
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
