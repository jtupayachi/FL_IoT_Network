[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ea4b88-2a67-4c56-8658-2155fbe9ef9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b62a890-790f-4ad6-b08f-5176f6d16577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6214806-93ca-4d25-b233-3d60a6b69687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcde08b-9b43-4245-bfcc-4244026fc3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc661deb-94ad-406f-b6f4-9ee7f256f765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8509f8e-b3d5-40d7-9259-cdc84182dd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f197f088-f7a9-4a14-abfe-1513cb138fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b651b7-2572-466e-8a75-37b48f4cdddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12aee67-f6cd-408f-909b-82fb837c8bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac083362-d75e-49ba-9e4b-5ed824063f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15de8ec-73db-48f8-83d5-ad8c90dcc3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ead9b64-17b5-48e5-82f5-9cb99d8e3bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b57fb7-73d1-452c-9cb4-c4c240f99158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88e5d1c-a148-4862-a3a3-10099ae25a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fde1020-976b-48d1-b21e-88252ae992f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf3652d-15a0-4ff7-b2f1-fa9c24c029ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29a3aa3-97ef-4334-96b4-4a97c4dd1b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a23f90c-f9ce-402f-9c09-8582df95a7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b95cc18f-f0b6-4fa4-bd17-86ebf68ac0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08d3f907-5095-440a-a931-df584ed1998e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29eea9c0-d9bf-4650-ba8e-f4a2921f1d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8580cfc-0032-4cb8-8cba-8d1da786c944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18af9c1-218a-403c-a954-d4f963b7d94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87daf52-e196-4597-aa0f-bcc621ca2bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71200691-7fe4-4056-8873-54534f5153af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae8b5c4-35c0-4a62-baf3-4a904c663be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09984597-fcca-474e-bd88-44747b4d22b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98dca10a-b1f2-4926-a9fd-db57b0e4bb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac711379-af8c-4c2d-9328-a0ebc3d0aea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3380f7d-20af-4fdf-823d-487a79f55358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81aa4372-d4e0-4ebc-be1d-f4398542eb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072439c6-05fa-4cec-9881-02124c7f2fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d78c438-efdd-45ef-97d4-aa4956eaee62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152717be-cfcd-4379-8ff6-7f9c33756ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26ed759-a892-424f-bb25-d28b74046e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e5ed54-7794-496b-8113-2f5b6235fc49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1590f6e-8ef8-4ef7-bf18-762eb03a006b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2a5bd0-d09c-4aaa-9aad-68edb46d986f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 229edff3-fed5-425f-a598-a1285f5fb677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08b5f8c-ab39-4f8c-9acf-c4f1ba1286e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15d6d5c-09e0-4f8c-9a4b-5ab726c44a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bee7580-435b-46e6-8cb1-d19e2b4d43de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b22d0e-082c-4554-96a6-ce58d15b7907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ea7aad-d9f9-4b59-a6d2-aff421caa515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab852f72-e668-43aa-90d8-dfe3b71c22c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b134e76-6995-4231-bdf6-e9a2956ff7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 734630de-9b8b-49b0-bea2-5ad3aaf5599a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55acac4-2905-4469-aa89-a15a58984bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e688b480-f898-496b-8f02-e6c25721ffcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e96deebc-49f1-4134-8326-9849762eaaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad7f543-0e94-4692-bda5-3ddcaf7fe4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a853d5-d004-4d56-af3e-6034914be449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcad742a-84a9-4d46-a80a-d00ef66530bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f874ff-0e40-4135-9b39-c68cac30e35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea9a0041-4663-4a75-9137-db4f4eb88f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be356311-efac-4f4b-862c-b7e0063fa69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15dd0016-367f-4025-b4a5-0c8ea68ffa71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3372fb6-2002-4bff-b8c4-2fb72fd8ac0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd6c9c9-0a02-4fae-9b59-a7c297fd4678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669dbf08-7965-4965-aad6-8dda57256e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47857c1-e027-494b-88a3-ab185de9e8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67728f8f-f721-4e47-8d4b-9f0748190a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1642cf1-551f-49e1-ae31-8991ef009421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51d2d9d-7073-4b9d-9b64-31aefdba3350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c426e3-867f-43ca-8881-d4c824b5f80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff57e42c-c7b2-4dbc-8c67-5e769631b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a208446-75db-471f-be9c-867b7bcf67ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971ea6ae-448b-4714-8f99-9f3754c59ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06b45ed-c3f8-4467-be0b-462c1fa29b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db757b97-4e05-4b38-af85-062ea7624702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b367972-6c73-4078-968d-9141fc389e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edaea03-263a-4b85-84fe-bf633bdb82fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecf785d-081d-4b25-88f1-afcff8bc98a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efff62f-6b20-42ee-b712-f472cc14c99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f92413-3c9b-4b62-a0b8-d3bf12673e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ec913b-7eb7-4f97-8897-3c772e459857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81b0269-5de5-4f32-881a-68e61cc8b4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33253c7-5f10-43b8-a482-0c8783926171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7009b1e2-b9f4-4859-a37e-d5068efc1d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4730e1-69f0-4466-b47c-2f9e613ab0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf29416-8245-4f8b-a8cc-16e73c39ba5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01eb75ef-603e-42ad-b16f-a24839e4b0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f414938-2e2e-4639-ab9f-246cb1b1f99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3639214a-7a37-42ce-b4d7-c3a38a194b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf09435-7f99-4010-b5ea-a51da1afac3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e82f71c9-41a7-4f35-b4dc-7d41675eeaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac21d68-fbda-4b2e-958d-831b6315c527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62af3e13-c5ec-4f05-a477-829039c55f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea762a9c-52ac-486f-a518-880d2b7004a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf93892-6a62-4e0b-909b-fd66a862b8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e88c01b-d901-4479-bd53-5b73e392c5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c57f31-9270-4fa3-ba2c-1c620d53923b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2cc70e-f99b-4bb7-bcd1-4aed81679337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1741ab41-897c-4c54-8475-4c31b8c20b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 350ced39-137c-4d04-85a4-972611a8a952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af49e85-9980-4c77-b314-0283e0877bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908f913d-05ec-42df-979c-e8f4b157e7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35367ad9-1492-41b4-b143-209eb26149a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a66245-ecab-46bf-9b39-217c25dc2e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30cedcc0-0a4f-4632-aeeb-437f1cc8226c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd2654d-e721-4b56-b159-26ef2d59aad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba2e7bc-a3d2-4d5f-bda1-7e7d39d5ea57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1536860c-2b4a-4246-9fc7-4013d1ff1070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32387b6f-07a9-4936-95df-735aa213bc0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4025dcf-2214-48f1-b051-593fd828a347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0429286-b96f-488e-9855-d1787c308d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df73d325-0702-4a8b-803d-241b69dba906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f59494a-fdac-4870-ad42-f4325f6680b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7d0bed-68ea-48cc-ab3a-572db725afc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be4fad9-955a-4656-96fc-ccb90130c6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a1f187e-30a3-44e0-81e8-d34b34a5af8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece172e2-641b-4335-a1c7-0439e13fa4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c0007e-8123-4f89-9840-a4f817df7732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c881a60c-d361-4084-891e-7750baf95959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb95f68e-601f-46ea-8887-fc28b800c28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78514e59-7f41-40f1-b49b-ade5c334ad52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1af7d7a-0c2d-4845-acfe-56daee92a23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10faaed2-7e94-4144-9b9f-cd166cad5ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d848153-fbd0-429d-ba15-4cb2502f3467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b6de3e-42e3-4f4a-ace0-3cebe316956c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5994d790-6472-4146-be93-f10b8d2106df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad49cc6-e18a-4b28-a82e-2bd9ba072c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6396f6f5-85e8-4b3f-9a7e-b53c6c16a2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28be67d1-bda3-48c1-9f96-a70201af46dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425e0fd4-1570-426f-9a16-4b4a4f8c1652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b3a5b5-2352-4712-8c15-cd9442910802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72a0fb0-327c-48a2-967a-6a1e232f0b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731d89a5-404f-44c2-ae6b-0fb0cac0b0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d7af71-1180-4506-80ed-3fd1e217ed4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd59342-bf07-481f-aa37-0ba1198552e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ced027b-b717-4e94-afc9-d2234479e495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0c9685-45c1-4466-bb31-5ebad586ee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9135f5ac-486c-41a9-aa65-3d29516866c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932b8f27-2287-4b86-9c54-60dac53bf244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d804152d-d1e5-439e-99de-ecc09b7ffc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa0e836-e8b9-4e62-92e0-be1ba0f618a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2277bd7-eb7e-4602-9f1c-d7cb095b56cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43684cd0-65a5-4efb-87bc-bcdc56b95c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4d31473-c2f1-4862-9230-428136362780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284309b7-2409-4de1-a361-d4722453bd61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef866ab7-52aa-43fb-819d-b1f460cc2876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e442c90-4391-4b48-95ed-ec12aab8fe3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56adff2c-5fe3-4a5c-87aa-f5d4b3396b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d8872c-39c8-422c-92d5-85e48394ba88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7045b79-ebd7-4787-b6ca-72198547bcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bd2c7a-c456-4293-a456-857e1a13b6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41aba93-506c-4379-9b55-a9d76c9f9c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70b256d-bb0b-462f-a3c4-9fb74713cbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96670949-0b45-4a81-9bdf-63ce5eb3932e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f51770-de6c-4542-beb7-ddcc6d76b79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b677c0-8c48-4137-92ec-a6392ab71949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba6d2b4-7b32-4914-a0a6-49f450860939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df2bae3-71d9-4037-9a0c-dd7e451d67fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46db4856-5c9b-49e0-8490-7fab35a31978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ccbc62-d9a8-495d-a0a0-3b56ac628e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f7724d-55c7-48fc-9d1a-beecbd41b718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66092835-3dfc-44b3-83f5-599081913050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbbe26ae-9e88-4489-935d-5252b121213c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e57e99-af46-420d-b3b2-2f66a052aa0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec01e54-c344-4dca-898b-09ce9aaf629b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd566aa1-a048-4eb0-bb4f-054786e29e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f76347e-b089-4c89-8da0-e094cc6d8db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7e6006-4fbf-4ab9-a8bd-ae89b61ce378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787f0214-d9a2-4a13-8770-49151ef477be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8090be5-bcb9-4564-9a2d-9b4149e48f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837720bc-a46c-414b-a7cf-d3e4b5504f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b931c995-873e-45e1-9967-733c334c1ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50578c4d-a209-42e7-8dc3-4b30d16a22fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc102a6b-502a-4088-9596-63f413c96f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ed7624-773d-485a-bdd1-4f3e2a6b803c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b378e02-1455-46f6-98d8-c37f362aa916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e573e5-2571-463a-b106-79d270a7792c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46e79f9-f13a-4c19-8b0f-f5ba60af8496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a94475-15bf-42cf-aa00-6ce17261f4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45893ee-4277-40ad-957d-c5e9c53b32d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c27457-ac29-4e07-b82d-f67e6b6e2dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10b07c5-a92a-4847-b92f-31a534532c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d002d373-f0ff-4ac2-a326-d1a811919b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6d9b342-055e-47ac-80e8-5c4f4ff1dd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25f6cf1-5d64-4184-9d61-890f4fed62e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a67f728-bdc6-460d-a85d-9ab153946a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64e421d-4a31-4025-bb8c-8e05ecd89727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8047a908-1290-4818-b92b-b31ddd2f48f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86b48cd-7fbd-49d9-9c48-a31d54610fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d62a3e-546d-4192-8706-825f8f6ef6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9945c3b1-d763-472c-a416-7ff94d984309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddabe953-3e7d-42a4-8038-e40ce036bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c18d9cc-974a-436e-a5b3-f22665b72f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c296cc-aa02-4acf-8bc9-60040c27639a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecf3b3c-bca1-4477-8124-917df93b9dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2b30bd-1bf5-490b-9350-2db41cdc3ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d2d983-3129-4952-b426-91c80f59922b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6af5d0-9a85-4856-bf36-b7340b8b5ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ae66e5b-609f-4ac8-a05e-eb64b6b4d101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21455f80-b89b-472e-ae9d-e809328f712d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d083a0e9-d4e2-4c74-810f-e57b79538500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f693a81-81cb-4582-8af8-a6cfe817257b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9418da87-25ab-4784-a83f-e8f589abc328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a720b87-7c7b-41ed-9fad-fc6ff65522a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f08992be-1a1c-44ba-a8f5-49dcac02d3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb1b58b-c17f-4884-8cfb-6810b58aa984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f501ddc0-a1e3-4c3e-8d28-161339bf8f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cc14c8-2635-46ba-a844-31214bd9e888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6699e67d-8ad3-497d-b533-46893d7f7fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bacadd3b-f482-4c86-a62d-1dccee880ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9f4aef-77d5-43c5-bf18-2a0c8aebf7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4da32d-3ff8-46ec-aaa8-4f14f6928c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ccc341c-9c55-472b-85cd-d0486a0aedac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8cb07f6-1e3e-46a6-96e0-83007406edf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e393c562-9262-4a34-8b41-83704fb27466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ebbbb4-ba91-4c2f-aead-94701e1b6726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a751b5-9993-4979-82f8-f7a61097ce71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e29a45-5450-4e00-ab0d-867028d85646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12741561-7212-44e3-bbdd-05f3d455f8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9b073c-190e-4d7f-b66d-5f06067cb96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd2c4ef-66da-471a-b1a8-806373a32535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be203d99-6606-4362-93aa-8b163ae0ce0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8673cd9f-8c42-4192-9578-5e4aa6592d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bfc64c7-2bc7-4d7a-8270-83a1bb39e49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4ed97f-5448-4e31-9ec8-3cad277cef7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0dfdc1-a8db-41fe-8504-20e54facc5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0de81cd-407a-437d-abf5-e188b038a879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317d6659-1c97-438c-b4f5-0b7aba1d17b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d161ea-0ef7-4eba-9a2f-416ef13d543e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f1d9a8-11d6-4cb6-9076-db594c37a17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b82685-513a-47e1-9a45-dde8c2870b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd6abb7-4220-4d27-a614-1789f39d1d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de5966b-8c7a-47d1-985b-4cad0abd35d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6f9747-bed3-4619-ac7c-fab3cf094983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63836922-250b-4131-aea2-d53cf3f3f708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90d90ef-82ed-4a52-afad-a28321007ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b7d6884-2692-426f-8c5e-b66988c60189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80e3bc2-fcaa-4d22-8ed1-1f79ffd84e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3726bc4d-ba3f-403f-991d-7d52364da790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af237f4-a6d4-417b-8617-8d0e2e9def50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4714f9d2-b19d-47cf-8586-56cdfc097635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0932c6-19c1-4442-b144-ecdf84fc8ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6dbc51-3ce4-444e-b40c-d436c2b418e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248ee77b-ee24-4dd6-b73f-90b837491bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447e9f00-3948-48df-8834-ab4d42520ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eeddd71-c506-4495-984a-95c7d93ed80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4b6502-8fca-42fd-8913-0f39b5d4fe88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63d3d52-e188-436a-8c7b-8844613338c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ceea07-0093-418c-8ae8-551f7188eedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7691386e-41e3-480d-bc6c-10ce471bb311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0cf04ac-ae79-48b5-8a18-2cd5dc636ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba4f0c6-4ced-45d6-8fd4-0e352b521722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2538587-9e90-4571-a92a-881c075270c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0327da18-afa2-4d62-a279-1d84dbb0427d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7964c4-3509-41a0-95ab-b89ea3af2163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507062d4-f43e-4501-a307-1bb14c88ccea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77ebcaa-9070-4d5c-8df4-2bf8b9ad5be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db92380-2ab2-4056-918a-669259a15f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb9660f-031e-4ac5-b01f-e6e94d2ba32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e492cd3-92da-456d-986b-0f806255dd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0cbd7b-e768-4244-8453-471874355a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7af0e6f-9bd4-4bb0-8813-12cd1a0da5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ea3e7b-e4f3-45e4-b659-f29b401685d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362e5b85-e1d7-4982-8334-c5d4d585d723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591b5476-32be-4bfc-a4c6-8f59c58827e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ccfa85-f874-47da-b9ca-1213050d96ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b2051b-1cff-4a5e-af3c-61c52a94197c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63eef024-1457-4a18-87e1-7242d30b77de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a90c88-2c75-412a-a56c-5b40a60c946c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e96888e-8138-4014-8af3-45c7d69640d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bd0f47-7c15-4824-9b6a-298b05079d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ffdab25-4005-4401-8dd1-32d1ae6fff84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad1b268-c7f2-40ed-80af-3551916447ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ec2296-6822-4038-847f-320d45630154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ff0f2b-34a5-4b4c-9a93-6a09d50eee2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d95b82-fbf1-4102-be0f-8a61561b52a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1b475b-f403-45ae-8e57-2831d5540be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda3774e-9ee3-4ecb-97e9-ddaa0c9bca57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e400f4-8fa9-4f20-bee1-49f467cca2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a15f73f-fd2e-438e-927e-26b30a40200f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547e7d2c-c472-4f66-95d2-19b58ef7c25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554e0b20-5bf9-4880-8c01-fe65038503ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17dd67fa-b33e-43e2-9dff-2a116b5dc873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e407a7-8e63-4188-9176-e012a9a89acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9efa064-976e-481f-887d-b92ad48b3f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99a25f2-028f-407e-b7cc-7732d52ed6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a40a67-5264-4670-827e-15881e67cd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f651b45-84d3-4cb0-b07c-1b6655d9e5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aaa477d-e676-49c2-aa00-94196a99fad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dea53f8-f6a0-4697-8048-e1f410feefad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19ad2fa-df36-47ab-b844-717c2b71bc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91fe717-5877-4da7-88ba-d1218015b10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8adf920-a5e8-49f6-9fcd-f87a1b1c203e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f341def9-01e0-4cdd-84c6-9b48bd108145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e1815a-ce73-4c6b-bf2f-d2525104e0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9801ea8-eefd-4988-9657-8e8fd63b6d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8359ae6c-fb26-48b1-a584-72a4bc27b713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598fc685-c8d0-48d8-9833-fd1e88a3cc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f25aec-7e7e-4a07-91ac-b559dd2c4757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e41874c-ea55-4632-9b42-f80b2e580312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe28210-9f76-466f-871f-566437e3221d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a5f550-3bdd-4eef-a471-7311a93cf530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdf4c6f-cb0a-4292-b495-fd1b52eb470e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f5ce38-5846-4afb-ab0a-b63a9ae50a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84575ff1-53af-4a93-b616-eb98713efb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385a9ff7-db3d-4400-860a-10751299d44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1367bc-4d5c-4ef2-bb10-f7b688e88bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e7feef0-e17c-4215-9c47-117349ae6400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6f79da-9e28-4343-a133-c9d5b3f72818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b7d1e7-dd2e-4779-81ad-5995d2f11878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f9670d-3d96-4cec-a206-388a291b54a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7968df9-7ddd-4909-b97a-040384323371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f4462b-0976-4de6-ad9c-3549f070021c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d630312-47f2-431b-9691-7e88efc0e9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5597a4db-721f-423c-883a-a086e26989c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fe6069-92cd-4914-a0ca-3abbda825fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b96d84b-3a6d-41f5-91f9-c35c945bca90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2e9aa6-3c37-4e89-be74-39fb535037e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4abc0a0-f7d2-4726-85a4-b68d3fb77c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb2a804-7adc-4e8a-b73f-fdafb8afc277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b6699e-f05d-4780-868b-f70aeac7f14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9b70ff-e237-4b57-9175-c2adf8d8125d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140fdd09-aa6a-4769-bd69-65ee60d57e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49935507-633a-4430-a0c8-240df9ce81ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb5293d-648e-400e-bf10-3b00e90d09f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c800af1d-36d7-4a6c-b1e3-8c9b6f45ebed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f245b37d-6d37-4511-8b9e-cabb2e832083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b4685b-141e-4cde-945a-0fd11c7cc33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 753487ab-cd7a-48d9-be80-66561851e964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6a61be-754f-4ab7-8646-9eeddeef6d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef7cbea-9b76-41f9-9b54-cf2e88bcfc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee3a3a3-5e24-4c6e-b948-9014b5106049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5568a021-888e-4613-b290-96627c812a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeaf380a-2a83-448d-a676-72b7f0253810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1edb43b-1c38-48b7-845e-c2ca693bb0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d3b551-c2f7-4b54-99db-96b3e66f362f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be91324e-5277-4952-80a9-ee793781829d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bd4aa4-8bc3-4ea9-ac0a-3f7fd56668ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4796e0-609e-4a73-8636-9b918a591bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9ca135-b1c5-47b1-b74c-18ee88ef8292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2579bd-4fb8-4abd-a0a0-cae759d47ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11825d1-a6b0-42f9-9014-ce6669e0813c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e98fc99-5a03-45fb-899a-8648eedcd7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098c79fc-f958-4fae-ab8a-321a572fb867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc987ae7-d1d0-4170-a6b3-0750759b34bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9b12d1-9667-46a5-8f95-ab84c6580c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e7f394-f556-4325-be9f-111d2d087302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da7af74-2579-4320-8a93-12e3ce28da93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab30938-dbb3-4a24-b77d-46eaece9833f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8229a0-798b-41c6-8016-6a15d961cd1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a206ce2-7340-4a19-a7eb-2a5bc1bf339a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c25ee57-58c3-4729-a0fe-5473afeae650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d913b7-3824-4b74-a586-1993a979277e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d09572f-33d7-4df5-984d-97bc558b6f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b52fdf5-1f06-4e77-9371-8751fe475eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb7a7df-f4b9-4440-aa82-28f3f2f91353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955d3f2e-634a-49f4-9375-d854e3dff809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9169ebd-6293-4c89-b126-e8695b04dd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de55dfd8-dd3b-42bd-953f-63ed115e414d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315d1bde-397d-4964-9f4b-39d23d4879fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd800a2-876d-445d-8bbc-66888273d860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c896e9-8ad4-402d-9304-37e507296da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2fedc1-d48f-433e-b5d7-5fcef2dcd126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7401b928-b051-425f-b1f6-6dcb2ca7e5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d4df6d-2688-4d88-826e-a3debc5ab21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a5a033-5c6e-4fcb-badd-81811ee178ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f91878ae-1d68-41c7-af76-4b715e0ffe2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f98f5c-91fd-458f-891d-ee89ae67a34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77034117-47eb-4f81-8707-56eedf7ee357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf382cd-a06e-4bc7-94be-05ecadea8eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452d4b0a-7527-44ee-a43a-c9b63167184f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad05861f-b2c7-4108-a97d-d68d305bc035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01181f6-a6b3-4a20-86fb-e132e2feebe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5471245b-d469-4b5e-99d4-330a6c9275fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f3930d-5267-4529-883a-2aea0d904b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0162c3ba-2d5c-4749-b993-0461e885c641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be257be9-fffe-4f31-9fc5-a812387fd90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57fbcfad-5768-4963-86be-2d7a95f49988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592f9b6d-d182-4b9c-9606-a1c6f5c9b244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab6e299-7ea7-4659-9605-27156e2ebca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f56292-59f7-4477-a322-5b58d813a8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c0ac2b-b033-4059-bb6d-930fe1e819ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4649f7a-5698-46c2-9eea-d76a237cd23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f62ea8-ce80-4e82-a242-cb6ae8e90f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8bb5558-0d89-4e2e-9497-07b74df6e828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c108f0d3-9f36-4f8f-9696-6585d570df0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65adfd01-1b39-400a-91ae-1a4eced8c411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2749b1ab-88ba-4226-bf3b-5b8f616d91c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d682ec-8901-4f50-944c-69bdf9b34f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cbdd6c-0367-4e28-b9bf-b96eafeaef83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ccd49db-4d0e-411b-a43c-e09d47e0dd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdfe09e-8b2f-4a43-95eb-a9d39f57c14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1a7d26-8305-403f-9b21-78ad55933f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c7eb2e-823f-48a6-be9f-d90fd2a2108c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9b12a1-dfe0-4e6a-81d0-ef05e71931c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884542a2-ab33-4063-9e71-b08af261270a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4621df4f-529a-45ad-9345-3f20c06dc261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5dd96a-cd85-4295-84e6-774c045c8b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4b7858-c432-4bdc-b171-53369efa7e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0ace44-250f-41e5-bdf2-3704c83a88a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c812115-6a26-4252-8f2d-189aded63f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc191f80-b915-482c-b229-c2a3314f9633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604a35d1-1e0b-44c8-ad0d-9e4a44d6bd8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e076e89-2d61-4355-bad0-f854423069d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a05c1a87-4360-4f10-a9cf-9514137522d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f497cc31-f879-4c20-a6e7-03cd20f6a1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc43002e-e31d-4cdd-9657-c23a101d145d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67dab01a-2f38-4817-9a1c-400b192ad86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c7dfa7-1ce2-49ea-9091-1bf4431b992c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1df6a1f-d893-4a60-8869-8490ae375218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9323b62-ce02-424f-8370-d6711f4e9927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd199550-f1b5-4d4e-b969-97320613f437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a49ff6-9696-4f9c-9c06-5c5e6c778218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e560ca5c-3791-4400-950d-6f3542c7b409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54e6753-9b6b-4985-b938-5393bc0da05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5746d8b9-1e6b-43a3-b005-87a83d926f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad487a8-731b-42be-bae6-f6a1b645b4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a73a720-2e46-4971-b503-6c6a19a09037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58c63f2-7a1a-4ef1-8f64-79dd07f35bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd317beb-141f-4f9a-9839-38689febd136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2659aad4-e798-4d93-829b-41819059b67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15a7219-3077-4e0b-a600-86b9be887428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea2df02-e905-40b6-886e-b2e31c9ecc38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f524ac8f-f577-4e85-9945-c59e2ceed3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870f77a4-6f3d-44b6-ad72-b2ae7b815e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b1b6b7-da86-4520-aaa4-9337695abad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b33ad928-6736-4ee6-8d3c-60cee0e85957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe23d88d-2a04-483a-ba64-465b45549e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304af264-8ad6-4b90-852d-ac5b1710a424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c91c8d-7213-4084-8f23-e75da5ab9d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b534e41-8217-4979-9c84-f840b1e6b9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fda4f74-f4ef-4ca9-8cc9-9de88d82e2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 266817a3-21f4-473a-b403-fd949ec23fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0a6f4b-29b2-45b7-9030-c754ec675917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9966de-adab-4e0e-be71-7d46d05e8f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26427c46-9e3c-410a-855b-3647aebd0f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d652b6c-c93d-4d69-9b92-b03dc2e72535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8aea032-ac57-4021-9ed9-baa0e0a4a6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd21e94a-fd9b-4e16-b1d5-4731c8af4478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d029b940-9b18-43f1-8ef3-94e553f61de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82743b30-9cec-42aa-9021-95d29808d9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07f0f45-8ca0-4634-9136-35f919d759d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94519cd2-5412-4bbb-963b-cee743a7ee25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3df980d-2f9d-4e4b-9c48-c202c8451ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee54c868-6510-4756-8403-0c355b425e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7baa4fa1-387f-4900-901f-3696f3f4589a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8055bcb-b540-4299-9957-269c3704a9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7fb4ce6-3588-43d5-b8c4-7532f0be8d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9426e86-82e9-4925-b214-1355c291ceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecd6c50-a87a-4c59-b98e-4009c6fca9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fbc08c9-adf3-4c7d-9183-eebc74cdbb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2141f89-4997-4b5c-b541-c76a9a67d068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c3cb178-678b-4c3d-b413-a47d526e6ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06b6f822-5260-4373-8415-a9d77c891135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d17944d-d347-4bea-9a00-cb8071cf024e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa6d956-ebec-4561-880b-5197703cec7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e49db7-fbc6-4c32-b294-e47eb5706bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa47376-d472-49d6-8f76-7a1b465f236d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24265b20-5a04-40f3-8ae0-29325bbb7c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d963d7-ae6c-49a5-bc10-7b3ef54575b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3475ca40-b46c-4bcf-b2df-8bd0b014fe04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa73bbe5-d9ac-4e11-921e-e44986659ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4f5d86-e5c0-420a-bbc6-893c35f4d6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b8aa83-6497-48c3-a5f0-b1965f7c6e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 209e924b-ac7c-4b84-a50e-21a7d2df2abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a2011c-196b-420c-aec1-97a99d8320eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e4264f-da27-49b2-a0d7-858e351831be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85daaf5-1d42-4a5c-adbc-a430e223a3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b03304-98ed-4c02-8205-de6f070c3572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4401752f-74b3-4ce7-accc-68d54d269400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72591d54-d0b4-4b43-b7c7-a46b2a97b826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403a3d93-88bd-42ec-809d-e50ebe466118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c02205-481f-4673-a81b-c1f732dd6579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f629ec7-7259-4636-9281-35614ee5719d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af114370-7b32-4c4f-9a98-5e6303d8a493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cac9f19-1603-460b-a809-69120e677653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680b77bd-ffad-47de-84d4-9fdd91890c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d7745a-5668-43d2-955d-468764668999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05bd7815-29b7-4f30-911f-91ba8cd868c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be29d39a-9008-4511-b207-40d654890bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d830a3-c821-4563-b72c-05a8b22bd0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724d1f20-aa07-4ea9-a8a7-d45777c1598c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a149e1-fd61-4947-95c2-5e5a289c8500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13f62c97-c0c4-4444-817b-2042ad55f2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e6f7a0-f7a8-4f77-808b-fe5096b2e898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e61e63d-31df-416f-baf6-5dff35605371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83608618-66af-43ce-ba13-f0a70e9eeac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd532955-a200-4fc5-8edd-cd9ecca49a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb259fc-b79a-4716-af16-f85e6f054f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61239481-2cd9-4602-b03d-53457c321001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3959e498-1665-4cc4-a74c-4704915ce2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 183bb73d-08b9-4826-90a4-daa7b480773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75ff2e3-b87c-4415-8a99-f45f76da1ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e51cc39-e69e-490d-8174-97a2e68d06a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bbff21f-afb2-4186-8e83-55d6537d518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bdd8f42-20c5-4690-9ced-341cf60e66fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e4873fc-d62b-432a-86b0-ae566c9a8dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 805a1288-ad89-4c35-9a9d-1885c7c946f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d097c14d-0970-41f7-b49a-e8ac231712ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a216e0dd-f07b-40d9-a8ac-4565a1cfe0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58cfa1c2-e434-4944-b7fb-a891488e7e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e5ea2e-50cb-4140-9454-c1e62f3b3c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5d4c5e-6fdd-404a-875c-cdc93cad68d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 948b1cca-f7fc-4ac0-95c8-b775762dbcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e8dfb3-f2c4-4691-8bf6-c4d14238e79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bb563a-29ba-4d9f-91a0-4a2b5a35a766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a7f5f8-c99c-4bb2-b127-a89c5b77fa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcb6531-8019-498d-972a-5bdd320174de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4ad5b99-72bc-4e1e-a813-219b6cb030ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7606ac3d-ff9b-4cd6-9a36-9a04dab4a805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9feb7ce5-5bd3-45af-945f-507e3b148b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc1137d-9882-4f75-bff9-929ef3fa421e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6087c101-8667-4ea5-8e66-9199ea80cdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d5559e-dacf-4f53-8639-711661599fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bdec8f-50a2-488c-9de6-4105dd11ef80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8cda75-e6da-4dca-b223-2fefa5afec4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9a6d76-7eab-49e3-971f-6342e32eb9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2911e117-69f2-42be-bda7-b5de73aa6b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b85c9f-0563-45fc-842d-c1a4bf7e93a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95aed81-d7c1-43c7-9a62-9a8424617756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80c969a-4f22-4631-9cd1-1555446f0c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bb6ca2-0d64-47b6-8c29-92fd8a5d391f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71a46d5-f729-4446-a496-40b3c78d24db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4d47a6-1e34-42b6-ab01-8c99733840b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8187767-db48-4d02-a101-8b59951c2985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2520fdfb-602d-4bb0-82bc-14317b95663e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d258147a-ba99-4c8d-8760-78d40cb577c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcab4d42-36f5-4062-9cde-0c27ff7854ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f4549a-97e6-47c6-bdf8-d65646144709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f42788-4258-4e3c-a056-5590c09d1f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3c6bdb-9925-46e6-b46e-7a5aac032d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cac95a-4c22-4925-aff6-0533972ddb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa03b49-77b6-41ca-858d-4eae35520262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163cffc6-0af1-4c4d-b954-8da81efcfdc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34550c69-49b6-4dba-a151-5250a2b27024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a91586-466f-4dd1-b51d-9f8130d8aed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbf7322b-66ae-4f59-8f21-b4dd1c99751f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495286b1-a862-4883-a96a-a2d9af774840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317a6bf2-5881-4302-95bc-f1a13bd6253b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879c7d5e-fd25-4238-9520-c53360c2487d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b2736a-2602-419d-9cd2-3326f410f455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded8b353-03c3-44c0-8ac1-218d73a9882e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a0102e0-896b-49de-bf28-fa48157f2acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e79c1194-ae3e-4e21-8879-5a1ac534247f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50670ad5-b8a0-4734-8ea4-79b8c8c86ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0875c43-4c72-47f2-a7d7-3ca9239392d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e3746a-a9e4-44f7-9a29-65d651e53c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199caaff-b9c8-4878-9197-528f0b1390d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02074df4-9707-41f9-89c7-66d29ceb0ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb1696b-5d45-487a-bb7f-02a7a0dc9d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbae2674-28a2-4e6b-9811-1c3ef73b8dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104ffcb2-99e2-4de7-bef4-3637d94c02bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e056aaa0-7a6f-41df-9860-3c2bb5b1d257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1994353-bb85-43db-8e29-44938f37a50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720b7ded-0a32-49a1-ac36-6ce81bc3b145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bea34b3-e4fe-4a9f-b6e4-6e9ce130c972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7431bc01-6012-4d66-aa1a-5292415fa7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f61366-aa93-406b-b289-98c3adf9f277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6a92dd-a90a-48e7-bdc3-9270d0d9d069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60ed7e9-024b-43c6-8e46-14f42b591ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5a5820-e13c-4f7d-8944-88f8488b18a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3473520d-9662-4097-af4f-efc8f92bf37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e1e6631-a4f4-48db-b2f5-7c466a70f2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803bffd7-daa7-4db7-8b57-ea812f6c893b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31d63b9-d472-45a7-84e7-ac24de2cb8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d198f70-2df7-4f03-b200-80278ea3216d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5dbbca-5435-49f4-ba44-6b3856307ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 832aeab8-580f-48c8-ba28-2dea00b991d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d92608e-a209-4a0e-9107-f8b4887318be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50713f33-9c25-4390-8d7b-fb6240ef7621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57cbb93-bc55-483e-800f-e0f5fdd92d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881e85fa-4be4-43ae-a9cd-eb5759ef8423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3250e832-82c1-406f-aa01-0d44b195c9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ce75c5-6077-41b4-93c8-44f0fe335450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ddc6f5-6f82-4c17-bda1-b8881d40e221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ac0800-7405-4567-ad80-670b0ff01d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a17f27f-bd83-4e6c-809a-ab945a330a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9323106-0c8d-4af9-9663-8b253d53c364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47066c1-9e29-40d5-ae2f-16b7d4e85a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c0fa6e-dcfd-4764-b273-2a9b84b719a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521f2ce7-9d46-4c42-99bf-d6a18d1377ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbd1043-109a-4dda-8481-48810d947358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8900b38d-eec0-45e3-9672-220a6a457d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566e8a04-d596-448d-9754-5e2dd5b770cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c756de-2c50-4348-9b3d-382dd28c040c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f901c4f-e33c-4554-b614-fc51f418bc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1355ec6b-f419-4415-8fc6-aea95522831c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55527e23-2497-477a-b3cd-1208e0da20d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e243127-32bf-4850-8f45-a4aae1484dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f87616d-dcc0-45d3-a74d-d3a81621114d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38826bf0-816e-421e-93ec-e3aea5eca3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5001866-b092-40b5-9854-0fdbb75a8d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd6a256-1a22-471a-8855-917c6b26e67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc3c88f-af30-448e-91b8-b12d07793d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376a990e-2ca1-4d2a-b13a-b0ff5de973f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602adfc8-b771-4b70-a6f6-e67cce986980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b46b4b-4c89-4e6f-b9a6-842e7d34cda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e83ed39-ff99-41b3-a296-774c56005027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2074f83-ce41-4c56-88da-a92ea67413d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06394ab4-6626-44a7-9698-af111f0d3863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21328e02-21e1-4198-9a6f-47d1a0139a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae3aaf43-6e46-47ab-af16-32c690f5b96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b319241-0bee-402f-8854-be7285bbfbef
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(3174, 24), y=(3174,)
   Test:  X=(794, 24), y=(794,)

⚠️  Limiting training data: 3174 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  785 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3416, val=0.1234 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0948, val=0.0926 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0862, val=0.0876 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0831, val=0.0869 (↓), lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0869, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0873, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 5 Summary - Client client_13
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0118
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0055
============================================================


============================================================
🔄 Round 6 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4350, val=0.3906 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3205, val=0.2634 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1643, val=0.0925 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0857, val=0.0860 (↓), lr=0.000250
   • Epoch   5/100: train=0.0850, val=0.0856, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0836, val=0.0845, patience=5/15, lr=0.000250
   📉 Epoch 20: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0832, val=0.0845, patience=15/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 6 Summary - Client client_13
   Epochs: 21/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0033
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0049
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.4816, RMSE: 0.6940, MAE: 0.6314, R²: -4.8217

📊 Round 6 Test Metrics:
   Loss: 0.4728, RMSE: 0.6876, MAE: 0.6244, R²: -4.7149

📊 Round 6 Test Metrics:
   Loss: 0.4531, RMSE: 0.6731, MAE: 0.6084, R²: -4.4766

============================================================
🔄 Round 11 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4115, val=0.3956 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.3260, val=0.3031 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.2208, val=0.1732 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.1106, val=0.0954 (↓), lr=0.000125
   ✓ Epoch   5/100: train=0.0827, val=0.0925 (↓), lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0815, val=0.0929, patience=6/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 11 Summary - Client client_13
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0048
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0088
============================================================


============================================================
🔄 Round 12 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4254, val=0.4468 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.4001, val=0.4202 (↓), lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.3759, val=0.3968 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.3592, val=0.3858 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.3488, val=0.3752 (↓), lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.2872, val=0.3101 (↓), lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.2266, val=0.2514 (↓), lr=0.000004
   📉 Epoch 27: LR reduced 0.000004 → 0.000002
   ✓ Epoch  31/100: train=0.2009, val=0.2253 (↓), lr=0.000002
   📉 Epoch 35: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.1906, val=0.2149 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1840, val=0.2080 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1779, val=0.2015 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1720, val=0.1952 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1664, val=0.1893 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1609, val=0.1835 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.1560, RMSE=0.3950, R²=-0.8961
   Val:   Loss=0.1784, RMSE=0.4224, R²=-0.9392
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4252, RMSE: 0.6520, MAE: 0.5850, R²: -4.1389

============================================================
🔄 Round 14 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4051, val=0.3981 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4045, val=0.3974 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4038, val=0.3968 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4032, val=0.3962 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4026, val=0.3957 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3996, val=0.3927 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3953, val=0.3884 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3913, val=0.3845 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3875, val=0.3808 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3838, val=0.3771 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3802, val=0.3735 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3766, val=0.3699 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3730, val=0.3663 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3694, val=0.3627 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3675, RMSE=0.6062, R²=-3.3453
   Val:   Loss=0.3594, RMSE=0.5995, R²=-3.3239
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3542, RMSE: 0.5951, MAE: 0.5209, R²: -3.2811

📊 Round 14 Test Metrics:
   Loss: 0.2776, RMSE: 0.5269, MAE: 0.4444, R²: -2.3557

📊 Round 14 Test Metrics:
   Loss: 0.2055, RMSE: 0.4533, MAE: 0.3724, R²: -1.4835

📊 Round 14 Test Metrics:
   Loss: 0.1755, RMSE: 0.4189, MAE: 0.3425, R²: -1.1207

============================================================
🔄 Round 24 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1212, val=0.1033 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1204, val=0.1026 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1195, val=0.1019 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1186, val=0.1012 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1178, val=0.1005 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1135, val=0.0972 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1079, val=0.0929 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1034, val=0.0896 (↓), lr=0.000001
   • Epoch  41/100: train=0.0998, val=0.0870, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0968, val=0.0849, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0943, val=0.0833, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0923, val=0.0821, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0906, val=0.0812, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0893, val=0.0806, patience=5/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0348
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0147
============================================================


============================================================
🔄 Round 25 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0973, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0970, val=0.0965, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.0966, val=0.0962 (↓), lr=0.000001
   • Epoch   4/100: train=0.0963, val=0.0959, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0960, val=0.0955 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.0944, val=0.0938 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0921, val=0.0914 (↓), lr=0.000001
   • Epoch  31/100: train=0.0903, val=0.0894, patience=1/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0889, val=0.0879 (↓), lr=0.000001
   • Epoch  51/100: train=0.0879, val=0.0867, patience=1/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0870, val=0.0858 (↓), lr=0.000001
   • Epoch  71/100: train=0.0864, val=0.0850, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0859, val=0.0845, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0856, val=0.0840, patience=4/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_13
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0056
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0177
============================================================


============================================================
🔄 Round 26 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0852, val=0.0865, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0848, val=0.0860, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0846, val=0.0857, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0844, val=0.0855, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 26 Summary - Client client_13
   Epochs: 51/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0064
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0149
============================================================


============================================================
🔄 Round 27 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 27 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0236
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0077
============================================================


============================================================
🔄 Round 28 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0910, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0907, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 28 Summary - Client client_13
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0077
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0130
============================================================


============================================================
🔄 Round 31 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 31 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0039
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0246
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2488, R²: -0.0090

============================================================
🔄 Round 37 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 37 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0058
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0057
============================================================


============================================================
🔄 Round 38 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 38 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0063
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0031
============================================================


============================================================
🔄 Round 39 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 39 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0055
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0059
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2487, R²: -0.0081

📊 Round 39 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2487, R²: -0.0080

📊 Round 39 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2487, R²: -0.0072

📊 Round 39 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2486, R²: -0.0068

📊 Round 39 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2486, R²: -0.0067

📊 Round 39 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2486, R²: -0.0066

📊 Round 39 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2486, R²: -0.0065

============================================================
🔄 Round 49 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 49 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0032
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0091
============================================================


============================================================
🔄 Round 51 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 51 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0036
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0065
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2486, R²: -0.0058

📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2485, R²: -0.0056

📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2485, R²: -0.0052

📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2485, R²: -0.0052

============================================================
🔄 Round 57 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 57 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0037
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0116
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 59 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 59 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0033
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0018
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2484, R²: -0.0043

============================================================
🔄 Round 60 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 60 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0053
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0077
============================================================


============================================================
🔄 Round 61 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 61 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0048
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0091
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0043

============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0017
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0037
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 65 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 65 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0020
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0062
============================================================


============================================================
🔄 Round 66 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 66 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0004
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0077
============================================================


============================================================
🔄 Round 68 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 68 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0018
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0185
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 71 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 71 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0032
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0032
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 73 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 73 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0084
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0048
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 74 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 74 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0052
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0114
============================================================


============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0014
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0068
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

📊 Round 75 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 81 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 81 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0028
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0005
============================================================


============================================================
🔄 Round 82 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 82 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0026
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0018
============================================================


============================================================
🔄 Round 83 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 83 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0011
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0073
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 85 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 85 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0018
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0021
============================================================


============================================================
🔄 Round 87 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0052
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0121
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 88 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 88 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0007
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0052
============================================================


============================================================
🔄 Round 89 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 89 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0032
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0051
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 91 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 91 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0008
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0136
============================================================


============================================================
🔄 Round 92 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 92 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0059
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0065
============================================================


============================================================
🔄 Round 93 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 93 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0009
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0116
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

============================================================
🔄 Round 95 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 95 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0021
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0085
============================================================


============================================================
🔄 Round 96 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 96 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0003
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0081
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0039

📊 Round 96 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0041

📊 Round 96 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0043

============================================================
🔄 Round 102 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 102 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0029
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0000
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2484, R²: -0.0045

📊 Round 102 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2484, R²: -0.0045

============================================================
🔄 Round 104 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 104 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0013
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0150
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 106 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 106 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0058
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0042
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 107 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 107 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0067
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0131
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2484, R²: -0.0043

============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0024
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0322
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 112 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 112 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0043
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0088
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 118 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 118 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0024
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0252
============================================================


============================================================
🔄 Round 119 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 119 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0054
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0086
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2484, R²: -0.0037

============================================================
🔄 Round 120 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 120 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0021
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0029
============================================================


============================================================
🔄 Round 121 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 121 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0042
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0105
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2484, R²: -0.0036

============================================================
🔄 Round 125 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 125 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0005
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0085
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0035

============================================================
🔄 Round 126 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 126 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0000
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0495
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

============================================================
🔄 Round 128 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 128 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0003
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0098
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 131 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 131 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0011
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0053
============================================================


============================================================
🔄 Round 132 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 132 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0023
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0144
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 141 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 141 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0022
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0035
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0031

============================================================
🔄 Round 143 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 143 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0007
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0071
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 144 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 144 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0019
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0109
============================================================


============================================================
🔄 Round 145 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 145 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0017
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0034
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

📊 Round 145 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

============================================================
🔄 Round 148 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 148 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0032
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0082
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 151 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 151 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0011
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0005
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 152 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 152 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0139
============================================================


============================================================
🔄 Round 153 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 153 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0009
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0074
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 158 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 158 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0081
============================================================


============================================================
🔄 Round 159 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 159 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0011
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0350
============================================================


============================================================
🔄 Round 160 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 160 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0007
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0076
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

============================================================
🔄 Round 163 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 163 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0054
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0005
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0035

============================================================
🔄 Round 165 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 165 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0181
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

============================================================
🔄 Round 167 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 167 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0210
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

============================================================
🔄 Round 168 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 168 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0059
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0011
============================================================


============================================================
🔄 Round 169 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 169 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0022
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0016
============================================================


============================================================
🔄 Round 171 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 171 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0004
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0093
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 171 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 171 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0031

📊 Round 171 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

============================================================
🔄 Round 179 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 179 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0024
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0136
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0031

📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

============================================================
🔄 Round 183 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 183 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0001
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0101
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

📊 Round 183 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

============================================================
🔄 Round 185 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 185 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0018
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0089
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

============================================================
🔄 Round 187 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 187 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0005
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0065
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2483, R²: -0.0028

============================================================
🔄 Round 191 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 191 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0019
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0053
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2483, R²: -0.0028

============================================================
🔄 Round 193 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 193 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0011
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0009
============================================================


============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0026
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0070
============================================================


============================================================
🔄 Round 195 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 195 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0074
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

📊 Round 195 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

============================================================
🔄 Round 198 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 198 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0025
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0146
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

📊 Round 198 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0029

============================================================
🔄 Round 202 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 202 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0005
============================================================


============================================================
🔄 Round 203 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 203 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0007
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0203
============================================================


============================================================
🔄 Round 204 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 204 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0023
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0026
============================================================


============================================================
🔄 Round 205 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 205 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0203
============================================================


============================================================
🔄 Round 208 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 208 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0006
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0002
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

📊 Round 208 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

============================================================
🔄 Round 210 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 210 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0019
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0133
============================================================


============================================================
🔄 Round 211 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 211 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0002
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0050
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 211 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 211 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0032

📊 Round 211 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0031

============================================================
🔄 Round 218 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 218 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0289
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

============================================================
🔄 Round 221 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 221 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0014
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0025
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0033

📊 Round 221 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

============================================================
🔄 Round 225 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 225 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0032
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0195
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: -0.0030

============================================================
🔄 Round 227 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 227 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0007
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0040
============================================================


============================================================
🔄 Round 228 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 228 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0019
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0068
============================================================


============================================================
🔄 Round 229 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 229 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0022
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0058
============================================================


============================================================
🔄 Round 231 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 231 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0018
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0098
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

============================================================
🔄 Round 233 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 233 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0018
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0130
============================================================


============================================================
🔄 Round 235 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 235 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0006
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0028
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

📊 Round 235 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 238 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 238 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0029
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0085
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 239 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 239 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0005
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0040
============================================================


============================================================
🔄 Round 240 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 240 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0011
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0053
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 241 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 241 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0011
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0044
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 243 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 243 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0304
============================================================


============================================================
🔄 Round 244 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 244 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0000
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0051
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

📊 Round 244 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 252 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 252 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0017
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0138
============================================================


============================================================
🔄 Round 253 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 253 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0004
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0105
============================================================


============================================================
🔄 Round 260 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 260 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0015
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0049
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 262 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 262 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0006
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0028
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0026

============================================================
🔄 Round 265 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 265 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0045
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

📊 Round 265 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 268 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 268 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0005
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0006
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

============================================================
🔄 Round 271 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 271 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0009
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0038
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

============================================================
🔄 Round 274 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 274 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0001
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0001
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0028

============================================================
🔄 Round 277 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 277 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0005
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0041
============================================================


============================================================
🔄 Round 278 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 278 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0022
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0000
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 282 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 282 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0013
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0074
============================================================


============================================================
🔄 Round 283 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 283 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0018
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0099
============================================================


============================================================
🔄 Round 284 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 284 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0021
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0087
============================================================


============================================================
🔄 Round 285 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 285 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0060
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

📊 Round 285 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0024

📊 Round 285 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 289 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 289 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0012
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0172
============================================================


============================================================
🔄 Round 290 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 290 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0003
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0019
============================================================


============================================================
🔄 Round 293 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 293 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0011
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0027
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0020

📊 Round 293 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0019

============================================================
🔄 Round 295 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 295 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0011
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0020
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0019

📊 Round 295 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0021

📊 Round 295 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0021

============================================================
🔄 Round 299 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 299 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0004
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0102
============================================================


============================================================
🔄 Round 301 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 301 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0013
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0059
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

📊 Round 301 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 304 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 304 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0021
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0080
============================================================


============================================================
🔄 Round 305 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 305 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0017
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 306 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 306 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0088
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

📊 Round 306 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 308 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 308 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0025
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0147
============================================================


============================================================
🔄 Round 310 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 310 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0008
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 313 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 313 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0003
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0189
============================================================


============================================================
🔄 Round 314 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 314 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0002
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0042
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

📊 Round 314 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 319 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 319 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0006
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0022

============================================================
🔄 Round 321 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 321 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0016
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0063
============================================================


============================================================
🔄 Round 322 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 322 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0125
============================================================


============================================================
🔄 Round 323 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 323 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0013
============================================================


============================================================
🔄 Round 324 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 324 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0011
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

📊 Round 324 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 326 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 326 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0001
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0009
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0023

============================================================
🔄 Round 327 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 327 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0009
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0045
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0021

============================================================
🔄 Round 329 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 329 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0001
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0019
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0021

============================================================
🔄 Round 332 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 332 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0023
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0086
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2482, R²: -0.0021

============================================================
🔄 Round 333 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 333 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0037
============================================================


============================================================
🔄 Round 334 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 334 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0022
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0078
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 335 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 335 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0057
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 338 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 338 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0110
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 341 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 341 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0004
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0005
============================================================


============================================================
🔄 Round 345 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 345 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0006
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0022
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 348 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 348 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0006
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

📊 Round 348 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

📊 Round 348 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 356 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 356 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0002
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0023
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 359 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 359 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0035
============================================================


============================================================
🔄 Round 361 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 361 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0003
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0012
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 363 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 363 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0026
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0136
============================================================


============================================================
🔄 Round 364 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 364 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0001
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0009
============================================================


============================================================
🔄 Round 365 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 365 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0000
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0052
============================================================


============================================================
🔄 Round 366 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 366 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0005
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0013
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0026

============================================================
🔄 Round 368 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 368 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0021
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0039
============================================================


============================================================
🔄 Round 369 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 369 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0022
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

📊 Round 369 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0024

============================================================
🔄 Round 371 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 371 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0020
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0163
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0026

============================================================
🔄 Round 373 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 373 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0002
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0022
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2482, R²: -0.0029

============================================================
🔄 Round 377 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 377 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0043
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0049
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0029

📊 Round 377 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

============================================================
🔄 Round 380 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 380 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0035
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0023
============================================================


============================================================
🔄 Round 381 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 381 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0003
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0004
============================================================


============================================================
🔄 Round 382 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 382 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0002
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0070
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0027

📊 Round 382 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2482, R²: -0.0029

📊 Round 382 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0026

============================================================
🔄 Round 389 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 389 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0018
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0079
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

📊 Round 389 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 399 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 399 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0006
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0002
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2482, R²: -0.0025

============================================================
🔄 Round 401 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 401 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0022
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0095
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 403 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 403 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0008
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0263
============================================================


============================================================
🔄 Round 404 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 404 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0001
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 405 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 405 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0002
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0006
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0021

============================================================
🔄 Round 409 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 409 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0115
============================================================


============================================================
🔄 Round 415 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 415 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0005
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0059
============================================================


============================================================
🔄 Round 420 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 420 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0010
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0029
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 422 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 422 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0045
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0106
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 423 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 423 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0000
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0029
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 425 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 425 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0022
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0085
============================================================


============================================================
🔄 Round 427 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 427 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0018
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0048
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

📊 Round 427 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 434 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 434 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0043
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0046
============================================================


============================================================
🔄 Round 435 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 435 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0004
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0021
============================================================


============================================================
🔄 Round 436 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 436 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0037
============================================================


============================================================
🔄 Round 438 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 438 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0015
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0042
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 442 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 442 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0023
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0079
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 444 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 444 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0053
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0023

============================================================
🔄 Round 447 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 447 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0029
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0216
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0023

📊 Round 447 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 452 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 452 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0025
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0285
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 453 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 453 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0008
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0011
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

📊 Round 453 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 455 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 455 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0002
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0008
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 456 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 456 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0011
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0044
============================================================


============================================================
🔄 Round 457 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 457 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0010
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0021

📊 Round 457 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0021

============================================================
🔄 Round 465 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 465 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0018
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0031
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

📊 Round 465 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 468 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 468 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0004
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0003
============================================================


============================================================
🔄 Round 471 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 471 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0054
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0236
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

📊 Round 471 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 475 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 475 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0012
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0011
============================================================


============================================================
🔄 Round 476 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 476 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0009
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0029
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 478 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 478 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0019
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0004
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0022

============================================================
🔄 Round 480 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 480 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0002
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0050
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 481 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 481 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0020
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0046
============================================================


============================================================
🔄 Round 483 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 483 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0022
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0044
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 485 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 485 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0028
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0071
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 488 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 488 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0023
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0059
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

📊 Round 488 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 491 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 491 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0012
   Val:   Loss=0.0835, RMSE=0.2891, R²=-0.0299
============================================================


============================================================
🔄 Round 492 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 492 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0036
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0183
============================================================


============================================================
🔄 Round 493 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 493 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0002
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0000
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 494 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 494 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0027
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0152
============================================================


============================================================
🔄 Round 495 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 495 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0014
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0131
============================================================


============================================================
🔄 Round 496 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 496 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0014
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0037
============================================================


============================================================
🔄 Round 497 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 497 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0001
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0045
============================================================


============================================================
🔄 Round 500 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 500 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0019
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0041
============================================================


============================================================
🔄 Round 502 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 502 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0009
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0024
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 507 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 507 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0012
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0026
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

📊 Round 507 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 512 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 512 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0021
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0343
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 513 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 513 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0023
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0228
============================================================


============================================================
🔄 Round 514 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 514 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0021
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0088
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 515 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 515 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0018
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0043
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 516 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 516 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0006
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0011
============================================================


============================================================
🔄 Round 517 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 517 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0001
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0040
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 517 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 517 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 522 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 522 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0005
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0036
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

📊 Round 522 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 532 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 532 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0039
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0077
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 533 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 533 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0022
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0077
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0023

📊 Round 533 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 539 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 539 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0005
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0012
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 543 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 543 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0031
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 547 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 547 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0200
============================================================


============================================================
🔄 Round 548 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 548 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0005
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0115
============================================================


============================================================
🔄 Round 550 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 550 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0033
============================================================


============================================================
🔄 Round 551 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 551 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0004
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0059
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

📊 Round 551 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

📊 Round 551 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 556 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 556 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0026
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0047
============================================================


============================================================
🔄 Round 558 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 558 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0031
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0222
============================================================


============================================================
🔄 Round 559 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 559 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0053
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 560 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 560 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0192
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 560 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 563 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 563 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0012
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0050
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

📊 Round 563 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 574 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 574 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0045
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 575 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 575 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0021
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0278
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 579 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 579 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0002
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0011
============================================================


============================================================
🔄 Round 583 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 583 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0003
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0004
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 583 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 583 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 587 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 587 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0008
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0035
============================================================


============================================================
🔄 Round 588 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 588 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0021
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0014
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 588 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 590 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 590 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0053
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0014

============================================================
🔄 Round 595 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 595 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0048
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2481, R²: -0.0014

============================================================
🔄 Round 597 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 597 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0010
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0030
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2481, R²: -0.0014

📊 Round 597 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 602 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 602 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0100
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0015

📊 Round 602 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 604 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 604 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0025
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0038
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 604 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0014

📊 Round 604 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 612 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 612 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0023
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0032
============================================================


============================================================
🔄 Round 613 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 613 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0009
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0005
============================================================


============================================================
🔄 Round 616 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 616 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0005
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0077
============================================================


============================================================
🔄 Round 617 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 617 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0013
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0015
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 626 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 626 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0023
   Val:   Loss=0.0813, RMSE=0.2850, R²=-0.0025
============================================================


============================================================
🔄 Round 628 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 628 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0022
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0070
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 630 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 630 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0020
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0103
============================================================


============================================================
🔄 Round 631 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 631 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0000
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0067
============================================================


============================================================
🔄 Round 633 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 633 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0043
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0376
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

📊 Round 633 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0014

📊 Round 633 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 649 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 649 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0019
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0000
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 650 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 650 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0005
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0020
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 650 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

📊 Round 650 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

============================================================
🔄 Round 655 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 655 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0026
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0046
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 658 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 658 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0007
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0046
============================================================


============================================================
🔄 Round 660 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 660 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0006
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0007
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2481, R²: -0.0015

============================================================
🔄 Round 661 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 661 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0018
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0037
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 662 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 662 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0168
============================================================


============================================================
🔄 Round 663 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 663 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0004
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0022
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 665 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 665 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0042
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0127
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 665 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 668 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 668 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0003
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0009
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 671 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 671 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0016
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0001
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 673 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 673 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0011
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0027
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

📊 Round 673 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

📊 Round 673 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 679 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 679 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0011
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 682 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 682 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0008
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0042
============================================================


============================================================
🔄 Round 683 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 683 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0011
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0005
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

📊 Round 683 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

📊 Round 683 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

📊 Round 683 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 687 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 687 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0015
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0017
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 690 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 690 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0015
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0021
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

📊 Round 690 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

============================================================
🔄 Round 693 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 693 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0065
============================================================


============================================================
🔄 Round 694 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 694 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0107
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 696 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 696 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0004
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0086
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

============================================================
🔄 Round 700 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 700 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0060
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0016

📊 Round 700 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 708 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 708 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0006
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0011
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0019

============================================================
🔄 Round 711 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 711 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0003
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0065
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 715 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 715 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0003
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0058
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0020

============================================================
🔄 Round 719 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 719 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0007
============================================================


============================================================
🔄 Round 720 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 720 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0013
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0324
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0017

============================================================
🔄 Round 721 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 721 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0009
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0003
============================================================


============================================================
🔄 Round 724 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 724 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0018
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0005
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0016

============================================================
🔄 Round 725 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 725 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0024
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0186
============================================================


============================================================
🔄 Round 727 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 727 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0005
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0077
============================================================


============================================================
🔄 Round 728 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 728 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0009
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


============================================================
🔄 Round 729 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 729 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0016
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0019
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0016

📊 Round 729 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0015

📊 Round 729 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

============================================================
🔄 Round 732 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 732 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0059
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

============================================================
🔄 Round 733 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 733 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0001
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0075
============================================================


============================================================
🔄 Round 736 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 736 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0012
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0031
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

============================================================
🔄 Round 737 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 737 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0013
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0015
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0016

📊 Round 737 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

📊 Round 737 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

📊 Round 737 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

📊 Round 737 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

📊 Round 737 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0013

============================================================
🔄 Round 745 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 745 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0026
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0013
============================================================


============================================================
🔄 Round 746 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 746 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0032
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0011

============================================================
🔄 Round 749 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 749 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0015
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0010

============================================================
🔄 Round 753 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 753 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0019
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0012
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 755 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 755 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0023
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0064
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0017

============================================================
🔄 Round 760 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 760 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0019
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0109
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 762 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 762 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0010
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0027
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

📊 Round 762 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 766 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 766 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0019
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0060
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0018

============================================================
🔄 Round 769 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 769 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0022
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0045
============================================================


============================================================
🔄 Round 771 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 771 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0024
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0241
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0016

============================================================
🔄 Round 772 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 772 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0004
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0023
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0016

📊 Round 772 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 774 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 774 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0018
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0010
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 775 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 775 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0004
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0132
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

============================================================
🔄 Round 781 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 781 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0013
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0021
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

============================================================
🔄 Round 783 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 783 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0028
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0051
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0014

============================================================
🔄 Round 784 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 784 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0020
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0240
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0012

============================================================
🔄 Round 785 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 785 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0021
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0003
============================================================


❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
