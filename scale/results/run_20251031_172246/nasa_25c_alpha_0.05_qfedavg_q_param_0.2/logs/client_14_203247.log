[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e5b3401-7a25-48d2-8b0c-d6bd162abab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519bdc26-a873-4d9d-a628-b76ac4f0f47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00e2bb1-0b21-4083-b9f0-38180f8f1a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ca3388-0a10-44a3-966e-c510f830d55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a3ce5c-9c1c-460e-baed-0399ff7bb6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125e9a09-6136-4db1-a7b7-736c920a9ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8971e7d4-ff15-464b-b359-a307227f9e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf029d1-9698-4f07-8161-e832b53a895e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f066801-d9d5-4415-81f5-df433a078a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eaae2f2-b68d-4e58-8b1e-3c8865c5ff92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d59bf6-8140-405d-8285-2eef6ea296e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cfad0ea-5384-42b2-9e80-098f068c13fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb7878c-500f-4f53-b51c-ddae542dbd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81388c68-8c2c-4795-ab75-3872c14ad559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cbc1a9c-feeb-4d21-ae58-6c36185fb4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d87ce0-77a7-4436-946e-779b5b0e54fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6867353-74c0-417c-9bc6-283c45923c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19272880-c58b-4d3f-9e3d-14ced3341bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca394f1d-1d87-4566-a962-4c5796ff330f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc393b86-d62e-436b-ad51-05ea107aed5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db9243e-bae1-4795-bfcf-de2adaa39208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39b6b39-ca34-4ba0-9d9e-77833441755d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e9d307-b24b-44ac-ace6-50a8acf235e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae9d85c-4f48-481d-a2b5-b0ccefe3a6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5772af67-ccc1-4490-b2bc-dad07c0f00c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4111dde6-086a-4842-8f97-5f60e9af2fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18468d7-bcb4-4ae0-afca-7b28436511c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f73e77e-e73a-4b5d-b2f7-a84268b76de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704f02a0-192b-4682-a58d-3ac1efc12747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1b3b74-3550-4d2a-a8ec-9cdc1f936f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0393a4-72b8-4c16-8013-5f99f9036e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82cf1f5-fc80-4845-8879-cf3021a12605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0b463e-3c3c-4457-8a25-afd0cc3aa379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6f3a91-8194-41fb-9631-d85878f5a6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dafa4d4-48e9-449a-ae59-b089406a8cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887a5f96-c8a9-43ad-828a-7bc48597d920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e36e9f5-f53c-4d2c-a1a5-39e042335b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32974dc8-8b55-48ce-b1ff-985eeb7c9064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13d6a73-c0e7-4052-87aa-b820d5f0732e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e05efb-32f3-4a7e-a841-423f19170f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174cba74-bb54-421d-baf3-40eb9167401d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7409bbeb-469d-4c15-bdb0-6488a31c50b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 799a31eb-965c-4ad3-b018-5756a22be887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ed73d9-8e6b-457d-81d4-765eb4fa93fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc59cc67-e5b7-45d3-a5eb-5d586131e19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b4a624-1789-4fbd-beff-f5aa731312c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3280d6d0-c653-4731-a140-b9dcdee942c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f58e1af-7a1c-4a31-a29f-bc396d8cfa86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d7abd9-1612-48d1-af92-704f70683d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1a10ed-0d1b-47b1-bd9b-0843682843e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988591e7-4521-45ce-8baa-c49282c82619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c740d7d-5f17-4577-b51d-87ff0bc67668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18434667-8c32-4ba2-992f-a6030184bb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d8203d-00d6-4482-bb9a-534bc8ce080c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cb9af9-2dbf-48af-9049-f067d4a82350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9637615b-765f-4c6c-a92b-e1be6ea5ae77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5e0f26-2592-423e-945b-6c1593840b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b1fa54-8ed8-4b00-8988-4ec6c97ceb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cc7cf6-f88a-4cd0-8220-d32910fb3efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56fc8cd-2637-45e9-ac71-dad74e6e991e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297e172b-2271-4554-98a7-721c2984f129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d01110a-3a2d-444a-bad3-aeb301156f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e1896e-8c7b-4bd8-b45d-c6977e1efc3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7590add7-6070-467b-88a6-65bfe89be1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a42bdf-c37e-465a-8578-bfac8f1a1708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9f7d53-c1cf-4bc3-afc1-a0774ac851ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693bef24-a751-4c40-87fd-ed3d942bcf37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfedd816-b763-4b15-8342-645ab744cf4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6214dea1-c76c-4b2e-aa88-1ee5e37cf9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105cb912-775b-42e3-a99a-92904132f67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 798769a7-136f-47c0-b8a6-8715e98fb524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f569746-e75b-49e5-8b5b-a0a6d6d49cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d35996-9c0a-4fff-8776-e372113b0194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2884d0fc-28fe-4243-bc22-1e95ef4be3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc071f82-9cec-4396-b6c5-86279ade7d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1acef0-de43-4122-a267-2d0669a152a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ed3d3f-b9df-4f04-a535-e01f3dd897ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5beb99-c506-4638-a47c-a152b57db52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32420fb-aba1-4152-9eb9-5da044f54095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d1e192-e0a5-4586-bacf-d732c778d380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87de0ea-cea8-437f-a3b3-80aee7042397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78b27c0-87c8-4657-94f9-22df9c056986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2951f1-c488-4468-9cb0-748d4dbd386c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53452f1-caf8-4f2b-a681-da796a021c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683d8159-4c2a-48f7-9564-ff8820a4cd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b894dc-76e5-4ca7-8457-4afc11cfd9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72b0bfb-2135-4f27-aaaf-7039bf618474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 933209a7-55e4-44e2-a7c7-a732f4fb0fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0b5e3a-3ab0-4725-a438-4e4b706f5e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb6f50c-f909-46f1-974c-45ca803fa733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767c3974-8086-4e37-a20b-84fffa53dba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef83ab94-da8d-4ccd-ae65-15d7ea9bd8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca09e903-4025-436f-b848-661158cb821c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e2561d-5827-4088-b2b0-67d0ba88efe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31433085-6c6d-4a73-b59f-1586078c17e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c418c7-6066-476a-8fcf-4e2c70c4f79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc060a42-cfa0-41fa-9584-b96bda495cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a512de-950f-47b9-9d33-ac2a1cb834e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4bcb90-3eaa-4745-8784-ba8dfbe7121f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d14b371-45a8-4cb0-b775-d574696a9188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b795266-318b-4a34-b40c-66a351113c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dad33b5-8c24-4876-b6f7-8e5230690a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901da158-2bce-4251-8230-6c05a665bb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322984b5-0b5a-4a82-bb6d-769ca7094b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779a744d-5ca3-4861-be8d-8324f5c8f2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6185c481-5b0e-4d2c-ba94-dfd947f93770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b4700c-db15-4922-acd9-b04de4b1b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40edbe4d-d65c-454b-892a-0bafb9ed078c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46911828-fe16-4c2b-86bb-8ca05401d255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c7456e0-ac61-471d-a567-e46ccf58ef2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f36669a-d61d-4c7b-b47c-7c12664430f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb9134f-96f7-40f0-be06-5ce1a53a22f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9a2264-1189-4705-86e8-eb9018362dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da5de78-4720-418a-ade2-c95913edfcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5caf56-806c-4c7d-b615-d0cf4001f9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 243b6069-2259-4616-9e46-976a7c8dfa2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06878064-5c5e-4e8b-8f90-07232a552d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d669ed4-0c2d-482e-8023-91aad63e7d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd211c7-07f7-43df-a298-d0decaa7251e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff3148e-1d08-4218-8314-cde8050b1076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daafa6c9-ac41-43fb-ae13-561a21a46bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72f5a97-d0b6-4022-8978-787043322434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6bbe98-8061-40a9-92f0-378520d6abd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712e33ff-d979-42a7-8406-d5e42badea11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac08a29-7468-4d6b-b998-167d4d038d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f660b12e-e033-420b-a0b4-1f94547e0698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72801052-298f-4537-872d-3c1d9b7511ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c0064f-c539-4554-ae59-72ea92e49527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c14e42d-8841-442b-88fc-964e5788c0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4f8913-ad8e-4ce6-a653-f5c59e1178c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634f985b-1615-4d5a-bd55-e2cd53e6eee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a84e79c-8fd1-47f5-8e03-4d87421819ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78ea9c9-a253-4593-9caa-ed81b1c0f498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf154d53-5b31-477c-ba68-f0d0f6ab0bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39cfcd1-371b-42cc-9ee6-bd2cbadc5b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df18e28-a027-460d-882d-06c12d55a2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31fd0b6-fee6-439f-898d-a7f37d31a6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39ce553-74b5-4a8e-9361-8e57f0b158c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aec156f-9dda-4f10-a051-5264ceccbca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ead15c0-9c3d-46ec-8a8e-167ed720d98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83878007-be29-4dc5-8a4a-281347381f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7bf433-509d-4274-8240-6c8a088cdd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9a022d-3471-48da-843e-c8ac4a1183d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98959f86-5a20-40a4-a491-06a9e633650b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406b3cec-8f08-4d19-94fb-49fcc393c790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866aa1e5-59c0-4572-81a8-f8bc5ef0afcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637bfb28-2465-45a5-a17b-e877f7f62238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d165a8ff-9c95-4dd6-b821-1ebe6945be41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a8d42f6-a607-4b8f-b83a-86addd778650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b608b610-c7e8-48e5-8e9a-3459067e42d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca52c477-b7ec-472c-81e8-6ae6ca21989b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0d53c6-67bc-4fc7-a848-626a92ad109e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88382e1-4e19-4430-8360-d14123a9ec4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0226d52e-4f47-4f6d-a981-d84e6cc2c8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844fffd5-65f9-4658-a1b6-7b36149fe312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e6293e-8963-47a3-a04d-d5ab9188648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa9b26b-bf76-40d8-852d-14fea5139c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c279d48-2e6b-4edb-b47f-d67a8dd3d5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e4567c-066a-48ba-84c5-7e52de81fd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bfbe8c3-e1ec-4f87-97fa-3e9b14c561ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c797add3-4e1a-4c12-9bc9-bb79ee81d74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5b88c8-d22e-4d5a-a43b-bb476770a289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c39160-5286-4531-b762-211af1cef7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0f2213-cb0a-4cf5-9f13-f12473207256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1b5e350-f5e9-4d64-8324-ecb4a512bf3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75837a74-3cf8-4215-ab16-c390d788dae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87761df6-d704-4d92-9b90-371776810a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 038cbcb4-fd6a-4f58-8dc2-e1f39000c1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf91ad1-be54-45ee-b50f-e29d960b211c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5c3c6e-b419-46c0-a3c1-0a3130c694a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b6ed6a-cfde-4189-9e96-651531af2a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340dd58d-b128-41e3-b96c-74c8bae4c0de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3fe397-7a96-4386-89a0-4f32a04fdb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4591eaf9-ece3-4c6f-9e40-8767ea18d912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e16ca7b-0ac6-4805-a82d-d142b6a2036b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36cf16b5-fa01-40ab-a0b7-fed4eb762d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea239b76-408b-4518-9034-f443ad07a100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6caf5a-a5ae-48d1-bb10-388f337d4ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2771d7d4-ade9-4387-9703-f07dee1e9088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5c43d6-9f9f-4d66-9fd1-812923f680c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97e2745-9bda-4ea5-9f94-493ac8793ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5778814-c8bb-422b-8cf2-c19af5b0d7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dcb6e7e-f9ad-449d-9d47-8e5a3ae3f43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222d5071-b84e-4ba6-a2a4-8d7dd4f1fa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1af05dd-1823-46bb-91d4-fceaa84d586c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798b1395-d864-444f-91a6-0890d9afd4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02fc06ca-b1e6-4e8e-bee0-948db7d54337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee8a885-a740-4405-803e-a4b004265066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81337306-490a-466d-a577-5a4a5c3e23f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796e71de-9119-4b40-a054-aa62248ca043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad931b1-f214-4bd2-9569-978e2f647a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704642e5-d26e-4404-8abb-88e6f41715d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95fe1519-b641-4f65-a3f0-0b0416c5fc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359e8f5f-064a-4f2a-a67f-e68281043cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57818730-8e53-450e-86c7-8c355a4b56c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7364b9c1-658d-4ff1-859a-513e09440d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d79d4b2-a9f0-4c4b-bee3-90ecc193fded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff24b90-5777-4e0c-a00a-ae2f74d777e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd910021-e51e-491c-b6c5-e02ddefb36a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55248e7-d287-4a03-b135-0bd4ba5d44dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c71e0e3d-0dce-4172-b0de-feb4d42b9752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8e37f81-e60d-4b24-964e-a01cc9318266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a1428b-bfc7-4dfa-bf63-cc6cea50f711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515c494f-f174-42eb-8798-f076b97d9385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e68833-bb3f-47d0-a7ae-2dd550076484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5a43a9-aa1e-4809-903d-0021ca8c6522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93280d4e-5c54-4eb9-b52f-ac04b285828c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d79c70a-dd6e-4780-ba53-3a8fdea04aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e28fb5-7989-45c3-8c09-c769993c7a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0984915a-9489-40da-bf6b-db50b8163e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5d9dac-95a2-4643-a2dd-98830d19a2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59eced67-5835-4138-a887-9ba1ad68ab75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0a29cd-1557-473b-bcac-a6dfe7eef1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2519b4c-08f1-4d15-956e-3a2793e22294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c6bbba-3677-4c19-97e7-5fc52a5283d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd375e1e-6d48-444b-8f78-b32585b001dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd96e6f1-31a1-4cee-8e8c-aaaa766e47f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795f9e31-9143-4936-a10d-d3b6796ef034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105c8eeb-1873-42f0-b160-d9025ecd8a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc37ca34-573d-4634-9220-701f281ee059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b718d3d5-f2e3-4893-bea7-e7d64d284dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c431d46c-9d91-451e-9c76-b2e67297e488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c36b78-807a-49e7-8cc1-2feb5919b526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7c0f22-f608-4f72-b307-177046bfe807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0018fead-18de-4020-bf7a-5d4ec43d117e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1a48d5-a8ab-41ea-963b-cedeb427eec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cce12e6-1a00-4d7f-8587-2ea699e5ed20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a30830-4d07-441c-9e3d-85a7ca0e508c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff16ba3b-7945-47e6-a662-b49ba9ad99a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ae7655-d6d3-4233-9c06-25a260667f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f82eca9-e83c-4398-a8a4-6939963bf859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c23af2-bce4-4b07-b5f4-e4b1a63aa2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdaf5e65-e5c4-4536-84b3-517bc31fafc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05ef69d-29bb-4339-bf3c-bd244b4b13c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3193264c-d82a-4008-9152-e30916f51217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd102a2-1acb-4149-9c4b-670d1aef8d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeae86a2-14a2-4147-bf29-5dca878c42de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49a4a8b-3394-4e54-aeab-6fac38d5b839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b11529-45a5-4098-9340-e0eab93a47bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97f9a1a-78ce-4aae-9fa4-20822117a6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd19872-123e-443b-bbc5-e91754a1fb8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f61d68d-0efd-49f6-978d-c7b16f87e029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b43b21-f8a1-4e80-9126-521ad358911e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44f3224-9560-40f2-8caf-c5c801e53692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b9e69d-04fa-4a4d-ac4b-f8b2e6a98bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8e9866-f6ea-49d9-9b97-b5bece16b3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a96cb6e7-4111-41fc-9090-0961dde3ce8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb31e07-2d4c-4d99-ad6d-badc9adb3803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0299ed7-137e-4f8a-89e6-fceb8e825d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ade2511-b58d-4fa5-b273-30b8e60b5c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71821f64-aec4-4e06-985d-899964b64f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46952fa6-b767-47bc-b947-4b010740dbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6583681-9772-4556-b1b0-4f2ab1b84c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce969bf9-49c4-4241-90ce-495b8cc7110e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3ea31c-10ad-4b8e-aa15-931cbd330bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c086138-c4fb-4d2c-9afc-e25340d57fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1800949c-b607-4fdd-909d-dd27b326bdfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f555a4-26f4-4ffc-bdfd-9ca5c4ed1e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1227fdfb-bb8b-4a02-9d2e-4764cebba1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf94214-a4bf-400a-931d-7f2d7e0f0999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefbbed4-d982-4f0e-a9f4-ad40edaf0323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a683df8-944e-40f6-b2ca-998020689b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4492c0-5f57-4368-b213-1fb19815c13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e079830-33be-4a3f-b36f-6d2663515f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018846d6-608e-497d-a8a5-9d6e35e39d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0b91a8-a557-4da2-85ac-896ff309f213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d2c155-5628-4d69-9e5a-5156cbe790cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039bd742-6d36-41fa-bda6-a1f05e53cbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d80e25-1b1d-47c5-9cfb-ecdc883622ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4cce640-13cb-4b1f-9328-7a0e6c111bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1efdf74-419a-48e3-beba-e35f3a4c6cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f12ede-4758-4f53-b7cd-d80d197cef5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9aede4-05ac-46b5-ac4f-a6651ac4e4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23fc940-35f3-48b5-b4ff-3cff1d642c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886bd614-b59b-4087-ac03-4f097dfc752c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1cc2ce-1e75-4a84-90cd-1528d274bddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd9a7a4-bc22-43ee-950f-48085ef11fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babac743-f895-4ef8-b90d-5bb0aef704ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be3dafa-19c3-4a88-94f2-6fe101a3642b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3719a56f-7fa2-4750-811d-8f15b6dc0c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cba2ee9-b034-4c6f-9504-534e3fbd3f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054394a3-e2ff-4c05-b512-c7bd3205770b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7945fe9-4cdb-41f5-9658-17349945e398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e299709e-b2dc-4e47-bb5e-35cecf767709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d5456c-d9c8-4251-8caf-a1c52eb48e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c800229-522f-4177-bcdf-8391577bf8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e772c13-db4d-4210-8b85-63c54c03f5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31cd468-dff0-472b-8863-03ba1eed8860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859971b0-57b7-49ca-8029-7d1afbd2b017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d171437b-7d66-44e0-9218-32e9554671ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbcab0de-e605-4a25-9499-bbe2889836d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d35f6d5a-a4ec-4df9-bf68-4858fb0255b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6cd2f7-f940-433f-8cd7-272d58cfd71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 533ea339-839c-4069-9ebf-ea778932b692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ed876b-72fd-408c-bb73-2eddd5e7965e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c3b771-3b57-445f-953f-f8a126631006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd2efd2-08de-4ed1-8ef0-6341b5689318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac98b83-8a0b-4015-a2c9-f42bd0dfb6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f2c575-c838-4eab-96cc-3c76d40da85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7860811-7704-40b5-961c-03807c39a2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43dd031e-e728-4aaf-8f35-baf95347a339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40ff93f-2d44-44e7-aca4-33dbb6ad284c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484d884e-5380-4c8f-877a-453f516aefca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0407debf-1228-4958-8897-57818c9a83ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bae3eae-73ec-43c7-b027-95239f878de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01592098-1d1d-417f-a5d0-2b2d53b55787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924534fb-6665-4258-bb62-da657bde11f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54684af7-9ef0-4df6-8d92-1ed6db9f6afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32011a8b-5f8f-486c-8fe5-5505617f6c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f45417-321e-4fdd-a550-9a9744f59009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06bc991f-3f46-4ba4-b2c1-e8dbfffce872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64edc4b3-fb37-44b0-811b-df9181fa5bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f6f779-ad3f-4297-88f1-2eba4501f7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d5056f-25ee-4587-88f7-aa5b98920979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa43e06-bd5d-40e6-90ed-0e3f48ec0c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d36aff-85e3-4213-8942-8a48768484c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15634cef-04d6-43db-a6d5-028fdf01c79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b17c35-67af-4d86-bd38-c5785dc406d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ea58b8-099b-4ddb-9277-e43f8b31341c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb19cb6-1e1f-418e-8225-e5d099ba3d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20964e5-3fe0-4bc6-a92d-5e2b0d0295be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1562e1a-40bb-44d2-9b92-de4a26d410bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eda0134-eae7-4939-9887-9840091a7705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f70865-cc1c-4fec-8c9a-257de36be15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc480f7-5b14-4fe3-b4af-4e3a5a03a0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0121cd-7df5-4916-9c91-cd8630c5ecf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbfd4e3-b8ff-433e-bc20-bb3b722eaaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb254646-d1f2-43d4-913c-65958c3cd0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c28fb37d-200d-4d3d-838b-00003d4c35fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c803f998-2de2-4329-a0ec-801715f5bed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee73819-6e1f-4d20-90e4-38ebb7408ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34853db0-bb60-4d19-9115-7d7cc1dce775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bbd8e2-dab9-40f1-b58a-aa3907764dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2efe83a-1c12-4954-b972-f8d9417a629e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74fcb570-5fab-4554-8ffa-47a8aa99ef5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f75fae-0c13-4921-9c46-61c48a27229b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee51b529-a01b-4aac-864d-cad0eb6aa8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd1a8d8-48dc-4a43-a19d-503c8cd9c1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d64bd43-9ed7-4aef-8bad-9aff653a7e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a44d12-3ccf-4162-bcff-e5176c32da11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1029c5ef-d600-4754-8321-501eac4dedd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47a3cbf-ffdd-4dbc-8856-a6b354866fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1573d9bd-c2a0-4896-95d3-e95e271ed8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 021ec04c-b663-473b-a701-8a3422257ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c8e444-31a9-4cff-97eb-a5c818776d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5155747d-712e-41aa-a249-dc52ebc16649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a20e1e-4f40-4ae9-a7ff-c71522e99483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1a5310d-ba4e-4934-86b1-1634d15377bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfdc5f6a-4873-4cac-a92a-9c849cc847b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5652a217-a077-4c16-b90b-15b358cdc093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f9de96-3b09-4ee9-98e0-15d4a9472355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcd3f49-d53a-4aaf-b123-86b1b821405f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99e43f4-2509-4200-a511-a3b7db4bcfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cffaf439-87d5-4aac-8d5a-ebc5420f186d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ba76e3-4615-4a08-a837-9e6bcbdb178a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a310551-be2d-4364-a702-33f98bb8a08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4c3ec9-96f2-42d6-8fd9-9c62cd23a67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf1d96b-c068-43ac-96ce-b1144c99527b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd9336f-8476-4e50-b85d-9815468ff67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c94f15-d388-4657-acef-5dcb30dc2f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975e9a95-d66d-4873-ab74-35bfa71db144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69afa3bb-aabc-427c-aedc-a52c1c25dace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00354624-51f8-4c1b-a874-78bbfe8d6c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15bd65bf-77d2-4d25-8103-d397df698d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d76df9e-d225-49ac-bf91-ca984c9c8f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c4c5f3-b1cc-414d-9beb-a7b46c2ddd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631d1557-999a-4b71-b938-63fb8755dd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55bb9149-3d17-4898-8471-61b07abbfd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd389ee-f2c2-47bc-9981-ad55c0a47fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822c2cc8-a848-4490-ac78-5d9accc73d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75208fed-b451-4cd2-bee9-0308a4503fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371e70c9-a704-4c93-8090-11182b2db89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f594f3-8a1b-4476-ac2f-2e1a9088af71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3380fb1f-fb6e-4fcf-b330-722ec581228c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2339b14-49a2-4576-9d26-b8513bf4b941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641793d9-d6e6-49b5-9934-9636729503f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d11aff-bbfb-4dc2-8fd8-cb04609bcbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133b9bdd-a159-48c8-8689-98f97a1a1c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1645ef-aa39-48d8-927f-b97af707c620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa55ea2e-6275-4f69-958c-81d842068c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318a9bca-ce74-4a59-b654-0ca788ce6c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030f5a34-6281-4dbb-8c9d-82fb4cc4893f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6bb1949-886d-4125-ae91-afd14a1cb59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f1bc26-0b2e-493c-8435-a9f53460e8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3a77a6-37d8-4229-8a14-fd0e751fe9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ef81ac-9390-45f1-bd33-f63dc2e323b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d53a69-5abc-4baa-9149-1fab905ef4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 138cf37f-d5fa-44c9-b27b-59b669821317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbba78a-ef4f-4b1d-bb92-3d6194fe0dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6854c1-b647-4b71-b3d6-f4e822a4f4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2655fb75-fe3f-4432-9c70-48269096bf85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d384e17-7897-48d1-b821-33462a9a6983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d17151a-934a-49a9-9d7c-42d41129d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f402ce07-328d-48df-83b4-6d98ed08ea53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f87127-5063-4cbb-99d7-bbbe9e13045a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6d024e-0f11-41a7-8b2f-978262010d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fbf531-c54a-457e-a506-993ae950def9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ff6e47-19c9-4ecd-a0a7-f8bed504e7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6062c5-d7f6-44f0-ac51-85811db0c42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfb566c6-6a84-4457-8da9-47976b689750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b5add72-9f16-4679-bf49-21725161c88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485c6d19-cc27-44a1-a179-ce1ecd618a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b224f003-a745-4d70-918f-3d83b9ab97cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a91c9f-4ca5-448c-8ce3-cbb7a5a4054a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb39795-83f6-4e53-a1fa-3a41c5c622d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955e52d7-dae9-4b6c-9ec6-e38cf5ee4f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b2985f-8a20-425d-96c2-c11a2ac99a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02746398-6b9f-4668-b0c9-f1b675702e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c3d43e-acc2-4c91-88d8-15b56edfe169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c76aec-206e-46b0-9fe8-7db121fb19b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 511293f7-9879-4bbd-b186-8d34b58860c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd33dee-8b24-427f-83e7-616af1026cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54e5222-c057-42fc-8618-6860139bc81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea0fbf5-6f1c-456f-a902-623078f6f52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66da8102-2551-481a-b90b-cada3352edda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376be896-fbbe-4457-bb37-a648cf2b9276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f0bc37-d8e6-4665-9f11-15ba6d0060d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0c07fa-343e-4f90-8fdc-39c4af991d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b180c5f8-8120-4898-903a-7ec8fe3585dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a3ce27-9777-486c-9121-13674100f3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f51c217-b5bb-4be9-a160-a9b343ff3df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e1c259-7a3f-4815-9bb4-1995ff27a32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239239f5-7511-4002-a317-cd46e06f3ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c89f40-91fb-448b-891f-cc48ae7ed519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03146ce-cf0b-4fdf-a63b-5631cf0f43d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82489736-d3bd-45a0-ab43-221d89d34ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3c966f-8882-4362-8cd9-75ccc3c76ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f78b8b-2b62-4c72-ba67-b46d0d4b577e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b388f23a-154d-4916-93f9-10ec40eefc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 760d4a73-3603-4578-bed3-dab8acfabcbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9eba8c8-3de3-4c2e-bae7-07b58f564765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aca8043-7b1d-417e-9dbe-fe26b8dab10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45698ca-9b97-47ce-904a-d94b851f646d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606a8e51-ee1d-4676-ae06-750d681c15b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116c96e0-8453-43eb-9b5f-673d5552df3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a50fbfca-050e-4906-b5a5-a35b06f462a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9e3206-be4d-4e03-8e38-291d2acca255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f9cabb1-9a75-4142-9667-4581622c4649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9683568-46a9-4b56-ac24-1b48f61f91a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f1818f-6ca3-42e9-a98a-97c7bcaa5138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc8e3fd-02f4-44b0-86a4-ce8ad0cd174c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbee554e-9842-4fd9-9ae9-dd2b23e025db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5de26ee-496f-47f2-b63a-cf0eea85228d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0b0df8-0e80-406f-80e5-fd43e37f1f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6abd72c0-584b-4ee3-ba3f-3970b373edd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9159bf-35d2-424a-82bd-683439eeb75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bad9626-59c4-4f3d-9dc7-bf398f2c7901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded8ef27-e804-4491-94b5-7ca901c3d6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb12b5ed-b6c8-4784-8422-988b05ebf2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899166e7-7698-4faf-ad82-f34ac19bebfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124e84e1-2b9f-4e57-9c79-b42fd600d135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a1f260-6cff-4559-b1dd-77be56f26501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3106de-5b39-4d75-b97b-03cb30c422c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42c5e8c-b093-4ed8-8710-4d7d5bf06494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93908b7-4263-4f11-a985-f32fe0d26767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14bc1577-ffcd-4892-936b-04f4ad7249cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963f2f31-070b-4a7f-843c-b8342b5724bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d20c383d-2e1c-4306-b156-b289deb30b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a5ae20-44b5-4c77-8c7f-f0aa35ce32da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2b939a-0117-47cb-b133-a61e9b45de1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f3f3ca-71ff-476e-be33-ac5c24cd0974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5881b33a-435b-4165-940e-e3b7c0b619e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21179f6f-4517-4d0c-a5e5-3914b3d999b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d58ccbc-17b2-4da7-9938-01c9b4cbac53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f69b9fa-6faa-4dd0-9085-a1855b32e7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e226ef-ffdf-40c6-8b54-b2735b2c46cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581863aa-6ee6-44cc-9301-27dd9462340c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a15def-99e4-4454-a1f9-c1bca28da34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13159b42-96fe-46e9-bfb8-e46cea37e87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a760012b-8438-4bb8-96b1-ae39131ca1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e70444-fe0d-484e-9975-9a13676364ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b5afe1-144e-40e5-8c4e-af95d8b64a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00becca2-ec20-4d7f-903f-8350f42f43bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b99078a-ffcf-4158-8b64-857017dcae39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57554c42-8ac0-4024-b4d9-244a25385b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d72d32-b28d-4268-9c7d-019cf5abdc0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02035ab2-92eb-40c3-baad-45c2cbb58638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a68103-cca7-4393-ba1b-4b4189011639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d179d7-16ba-497a-9fa6-c198594d2317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a5d45a-51f6-4096-a5fe-26a5e26c0584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a0196f-88f6-4898-b53b-125226c8dc5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be937be3-c281-402d-a5d9-da294537523e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb13a144-e187-4b8a-85be-e772c58ecad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a75bd51-148b-4f58-883b-2a806371feb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6290609-6ebe-47f6-9d0e-f26dbc7961de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13ea19c-f46e-4ef4-b8d5-7b8d6e486d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abbcab94-3076-4ae0-ab48-528223a8e280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e76316-749a-401e-ba1a-b3adfc3c3b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69dc159-4789-4b51-a092-5fdc7b463308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e116abec-fd52-4205-88d0-fbae48ad6a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335259f2-cf9f-4634-b59d-2cb0b27a2a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ccf4c6-e49d-4a38-b052-5f2f879f848a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5073bc-0a7d-421b-bd6e-dea30b68bf05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81efbc9e-a6e9-4d56-973e-df22fc810200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e563a0f-cc26-42af-accd-c3b3ea55af6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0c8ed4-8e48-42f9-b45e-1cb2f03effae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79f95c0-e82e-4512-bc1c-5e0b67cc3535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c271c3-03f2-4261-af3f-99ed3ce32649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4045c74-32ab-463d-b0d2-a688437b0504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb06268-89a8-4223-90e4-c1747320b0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1608fa66-cd6a-4715-9515-1de7fd6cf23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5feb6bde-0090-443c-9c01-37cd21926de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cf0e5b-e366-4335-b99b-fdaae67db238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da23f9ef-c0d8-44ff-b6c9-9faf6fc9cab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e3916b-7a23-473d-9964-2b4529fa4d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138e54b1-edd6-4558-8367-37d1a2ab9814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6536086-b61b-4f99-b0d3-25bec848075a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c654af7-7b53-4cba-a85a-d2246888de32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e22ed8-ac90-48f6-8a4b-414d06a8d61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ab1dfd-d926-480c-9f16-22bfbaf21ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319988a4-f134-4937-83dd-d86ce6fa7af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a66700-6080-4745-9511-d920bf987945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe22b6c-b8d8-4e26-98c0-aad37c380681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ece35ee-ebf8-4076-8731-74dc0469b6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ebe97e-9b05-4a65-9bfa-b7eff6e4cb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56667a2-2135-4d3d-8fb3-f7a52dc39dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b66920b-4fc4-4874-a9a6-644b90f39b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d69e628-9330-4fc2-b885-550d9f09317b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065ada3c-deb3-4d28-b953-aaed4c4bc388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17eee956-5d46-4b79-9056-e5c5b9f9c96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6eea3e1-f3b1-4762-a31e-7b3a1d6f37eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9ab7e6-c2cd-40fe-9e16-2be22a091192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986e2272-7d70-4e2a-8385-30977c283df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfef82db-f859-4a22-a968-2907ec217fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd6e3a7-8425-4e59-afda-354964044e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ec38a4-5523-4212-b6cb-e71d934cf1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7285d4-5147-401f-adf0-8e4b025f2bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ba6186-ac57-42e7-bf8c-f7e2a2b103ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238f553a-8348-4b0a-8f92-23f847bd5f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1120f091-6204-4141-a350-7b997a456673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d995f75-e74d-4a5d-9052-fe98a7b37f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d29f2d-93b8-4d8f-a181-a92673a99167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf6c496-8735-40ec-be44-ba2f0380c391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084f4feb-6b3e-4b24-8c31-ef85a1565913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5949b8ad-f29e-4ce4-91ce-52102da11c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9bee08-cbc6-4957-b6be-b28544fd20f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65f8dec-1587-4209-8cfc-5ec2d21cac08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10b1902-19cb-4134-b3fc-b1279d0f73c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8c986e-6ec2-4d1a-b747-674bd366591e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1ccc9f-2528-4b80-96f0-2413d5d04701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daacb43b-a7f1-4ba3-95fa-2e9801a6115a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ceac0cd-4152-4b80-9111-a26702e96575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45fbc993-6440-41ed-9169-870d74b3487c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2f28f9-708b-4781-90b3-209b0386665f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a0773f-0670-4d94-9811-b2caf7728d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a15444d-a36a-4a56-ad6f-ea784e45cbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b8ab79-2a6a-4133-94ee-f91816337300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4582f4-0250-4910-b076-344e6c029446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f3b39b-2014-4215-9f56-c77797c448eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050fc9c3-68c8-4fe7-8385-2359ef55312b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc4f0a8-c3ac-4b2f-8959-0b7eaae020d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deadfc9e-3afc-45cb-8552-65d82c516b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3cc5ea-a32b-48d1-bf72-2b10ac1cd582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6322969-7b44-4cfb-a446-b1fc628d4199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5762d97f-be14-43cc-ad8f-0482f689c6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34bb2c1-7d77-44ab-8baf-c13a8e614f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e500345-e9af-4b2f-a918-64b953aeb41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ccb23e-3fc3-48eb-be51-3d5e264e8ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72fb96ba-0db9-4c12-9129-2d74bade96bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4a84cc-b53b-49e1-b8ec-c23472bc0812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f98d30d-f86e-4652-a894-5d666d6af076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2879637-6d41-4e5f-932f-0ee577d85728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95501379-d467-4db2-b406-c8350b4ff806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e45830-c295-482e-9645-87e04b8b2bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c71ec6-c10b-40b8-b3a7-94ba2b865451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a52e3de-c033-4e90-99e3-b0ac19b2909e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acf4508-5018-4f9b-89c7-fa5e6e6129f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf1c1a5c-db57-41d4-b6ea-86036588f19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027fbb4e-3aea-48c5-8262-88d213ba4cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aed72b7-41e2-4cd9-9927-d2fa13c96e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4ed97d-98cb-4e94-b5ce-d25952fb2a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840b1574-35d2-4a79-b2b3-b0ac559552f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5efa62f-eaca-441e-8b8e-08fef9fcecdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a5a757-c911-4a84-8140-66356b445326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b1d580-4650-4649-9702-d1b575aa5c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62251ac3-ebeb-4804-9958-0475e4c1c74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e40fd630-c51b-4744-a3a2-5f733369f408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d0cf388-ed06-4903-bb0d-4f20a52fb734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b594bc5a-e55c-4732-bc49-3b5e9bf70c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead10e96-de2c-4b72-9343-3c116a04c2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ab638c-7f30-4c2a-be7e-ae0844de50cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8322bfbe-e191-4350-97e0-85f000915b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac609d48-40b3-45be-8cdf-e60451a9aa40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6217b45e-0082-4235-b23c-0ef3a3f353dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921b245a-79dd-45fb-8de4-c43d9516747f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cdeeb5-d543-4b56-af34-f24547b9b295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c3061b-8c7d-4401-9174-f8fc5ed1ace0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b34a14-46a0-40d4-bb94-72aae829bcaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c014ad4-cab3-4434-913c-84c9ce0a05ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1772d9e0-e076-4bdb-9e3b-28dc24ed39f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dfb7b84-6298-459c-93d5-cdfda323430b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac1f0e0-a6bc-4341-bf5b-418dd62f5e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da604ecd-d0e0-4acd-89bc-606d2f891202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18b6d62-e9a6-4a06-ad47-7763917fdcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac91d2e5-6646-416b-b185-68d3a57be0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d75642-98fd-4ade-a267-693fb2ac41e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf80088-f51f-438e-ae65-c8537dfdba80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5489fb-539c-471d-9e26-1de1b9db9c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab645f1-f062-4e10-a83d-c6bf9d987034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b456ef76-c585-48b5-9520-c440a6471ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9fdd60-4468-496c-9f92-3d37ce06b4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c9a073-9a6a-499f-b581-245863a91fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d87c94e-a18e-4878-afbb-31acc0bf6266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844bd7bb-dfb7-479b-a2c5-a0b607591258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3b8d6f-10f1-415f-a1a3-3c75eee25b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d071df7-d1cc-47e6-8ec1-24b07ed0b033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e211edf-369b-40f3-b046-3413e10e3e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e7bd54-1857-40b4-b3b5-a981ee2d846d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1b6e61-b8c5-4814-ae76-4f02c607c3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bfb4c5-24c7-474e-aa60-a9cca9294613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0145d2-5eaa-453a-b07c-d560602657a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1c96b6-bad1-48ef-b0d4-01a83c80087b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf3bd84e-a99b-49bd-8acd-723c18a20db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c96eb0-63d9-4f48-9263-f3c5148e9f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b386ee-6314-413b-a56f-eb6ae3145133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324df49e-15c2-4259-bd55-5200c637c698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bed9fd6-c819-49d3-bfbb-98fe5c8c1acc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(5733, 24), y=(5733,)
   Test:  X=(1434, 24), y=(1434,)

⚠️  Limiting training data: 5733 → 800 samples
⚠️  Limiting test data: 1434 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3676, val=0.1616 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1054, val=0.1013 (↓), lr=0.001000
   • Epoch   3/100: train=0.0865, val=0.1010, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0835, val=0.0984 (↓), lr=0.001000
   • Epoch   5/100: train=0.0838, val=0.0985, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0834, val=0.0977, patience=2/15, lr=0.001000
   • Epoch  21/100: train=0.0825, val=0.0974, patience=4/15, lr=0.001000
   📉 Epoch 24: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0796, val=0.0975, patience=14/15, lr=0.000500
   📉 Epoch 32: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 1 Summary - Client client_14
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0084
   Val:   Loss=0.0974, RMSE=0.3121, R²=0.0153
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.5016, RMSE: 0.7082, MAE: 0.6472, R²: -5.0643

📊 Round 1 Test Metrics:
   Loss: 0.4932, RMSE: 0.7023, MAE: 0.6407, R²: -4.9627

📊 Round 1 Test Metrics:
   Loss: 0.4898, RMSE: 0.6998, MAE: 0.6380, R²: -4.9210

============================================================
🔄 Round 6 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4185, val=0.3691 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2857, val=0.2046 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1221, val=0.0842 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0896, val=0.0831 (↓), lr=0.000250
   • Epoch   5/100: train=0.0879, val=0.0835, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0873, val=0.0833, patience=7/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 6 Summary - Client client_14
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0045
============================================================


============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.4512, val=0.3840 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.3911, val=0.3497 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3567, val=0.3180 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3223, val=0.2832 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2819, val=0.2408 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0875, val=0.0891 (↓), lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0859, val=0.0893, patience=10/15, lr=0.000016
   📉 Epoch 25: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 26/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0099
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0069
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4705, RMSE: 0.6859, MAE: 0.6227, R²: -4.6876

============================================================
🔄 Round 8 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4752, val=0.4417 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4686, val=0.4351 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4621, val=0.4293 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4563, val=0.4241 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4512, val=0.4195 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.4329, val=0.4034 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.4202, val=0.3919 (↓), lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.4153, val=0.3874 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4117, val=0.3839 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4082, val=0.3806 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4047, val=0.3773 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4014, val=0.3741 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3981, val=0.3709 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3948, val=0.3678 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3914, RMSE=0.6256, R²=-3.5198
   Val:   Loss=0.3649, RMSE=0.6041, R²=-3.2299
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4617, RMSE: 0.6795, MAE: 0.6156, R²: -4.5820

📊 Round 8 Test Metrics:
   Loss: 0.4529, RMSE: 0.6730, MAE: 0.6084, R²: -4.4749

📊 Round 8 Test Metrics:
   Loss: 0.4423, RMSE: 0.6650, MAE: 0.5996, R²: -4.3468

============================================================
🔄 Round 12 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4358, val=0.4239 (↓), lr=0.000001
   • Epoch   2/100: train=0.4353, val=0.4234, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4348, val=0.4229 (↓), lr=0.000001
   • Epoch   4/100: train=0.4344, val=0.4225, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4339, val=0.4220 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4312, val=0.4194 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4272, val=0.4153 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4233, val=0.4114 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4195, val=0.4076 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4157, val=0.4038 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4119, val=0.4001 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4081, val=0.3963 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4043, val=0.3925 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4005, val=0.3887 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3977, RMSE=0.6306, R²=-3.4975
   Val:   Loss=0.3852, RMSE=0.6207, R²=-3.8504
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.3707, RMSE: 0.6088, MAE: 0.5366, R²: -3.4811

============================================================
🔄 Round 16 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3435, val=0.3549 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3430, val=0.3543 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3424, val=0.3537 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3418, val=0.3532 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3412, val=0.3526 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3378, val=0.3492 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3324, val=0.3437 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3271, val=0.3383 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3218, val=0.3331 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3166, val=0.3279 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3115, val=0.3227 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3063, val=0.3174 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3010, val=0.3121 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2957, val=0.3068 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2904, RMSE=0.5389, R²=-2.3931
   Val:   Loss=0.3019, RMSE=0.5494, R²=-2.3258
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.2960, RMSE: 0.5441, MAE: 0.4629, R²: -2.5790

============================================================
🔄 Round 18 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2971, val=0.2952 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2965, val=0.2946 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2960, val=0.2941 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2955, val=0.2936 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2950, val=0.2931 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2918, val=0.2900 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2864, val=0.2846 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2808, val=0.2792 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2751, val=0.2736 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2693, val=0.2679 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2634, val=0.2621 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2573, val=0.2561 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2511, val=0.2500 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2448, val=0.2438 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2398, RMSE=0.4897, R²=-1.8072
   Val:   Loss=0.2382, RMSE=0.4881, R²=-1.6077
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2336, RMSE: 0.4834, MAE: 0.4010, R²: -1.8246

============================================================
🔄 Round 21 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2054, val=0.1798 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2047, val=0.1791 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2039, val=0.1784 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2031, val=0.1777 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2023, val=0.1770 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1977, val=0.1729 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1903, val=0.1661 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1832, val=0.1596 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1762, val=0.1534 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1695, val=0.1473 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1630, val=0.1415 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1567, val=0.1359 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1506, val=0.1306 (↓), lr=0.000001
   • Epoch  91/100: train=0.1448, val=0.1255, patience=1/15, lr=0.000001

============================================================
📊 Round 21 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1396, RMSE=0.3736, R²=-0.5847
   Val:   Loss=0.1211, RMSE=0.3480, R²=-0.5091
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.1388, RMSE: 0.3726, MAE: 0.3044, R²: -0.6785

📊 Round 21 Test Metrics:
   Loss: 0.1129, RMSE: 0.3359, MAE: 0.2781, R²: -0.3644

============================================================
🔄 Round 24 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1174, val=0.1111 (↓), lr=0.000001
   • Epoch   2/100: train=0.1170, val=0.1107, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1166, val=0.1104 (↓), lr=0.000001
   • Epoch   4/100: train=0.1162, val=0.1100, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1158, val=0.1097 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1136, val=0.1077 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1102, val=0.1046 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1070, val=0.1018 (↓), lr=0.000001
   • Epoch  41/100: train=0.1041, val=0.0993, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1014, val=0.0970 (↓), lr=0.000001
   • Epoch  61/100: train=0.0991, val=0.0950, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0970, val=0.0932, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0951, val=0.0917 (↓), lr=0.000001
   • Epoch  91/100: train=0.0935, val=0.0904, patience=2/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_14
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3035, R²=-0.0615
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0413
============================================================


============================================================
🔄 Round 27 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 27 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0117
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0033
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2489, R²: -0.0071

============================================================
🔄 Round 29 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 29 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0087
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0035
============================================================


============================================================
🔄 Round 30 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 30 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0063
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0029
============================================================


============================================================
🔄 Round 31 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 31 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=-0.0061
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0004
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: -0.0006

============================================================
🔄 Round 34 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 34 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0018
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0041
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: -0.0004

📊 Round 34 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: -0.0003

============================================================
🔄 Round 36 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 36 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0002
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0102
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0003

📊 Round 36 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0002

============================================================
🔄 Round 38 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 38 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0023
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0005
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0002

============================================================
🔄 Round 39 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 39 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0014
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0048
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0001

============================================================
🔄 Round 40 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 40 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0020
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0002
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0000

============================================================
🔄 Round 43 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 43 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0021
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0002
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 51 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 51 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0019
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0055
============================================================


============================================================
🔄 Round 53 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 53 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0011
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0131
============================================================


============================================================
🔄 Round 55 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 55 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0014
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0002
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 57 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 57 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0043
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0052
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 57 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 60 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 60 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0034
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0064
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 68 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 68 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0020
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0035
============================================================


============================================================
🔄 Round 69 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 69 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0002
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0070
============================================================


============================================================
🔄 Round 70 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 70 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0044
============================================================


============================================================
🔄 Round 71 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 71 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0028
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0178
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0005
============================================================


============================================================
🔄 Round 74 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 74 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0007
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0154
============================================================


============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0041
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0160
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 75 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 78 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 78 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0002
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0056
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 80 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 80 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0020
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0020
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 82 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 82 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0006
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0095
============================================================


============================================================
🔄 Round 84 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 84 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0032
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0071
============================================================


============================================================
🔄 Round 86 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 86 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0030
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0056
============================================================


============================================================
🔄 Round 89 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 89 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0141
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0017
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0125
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 90 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 90 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0017
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0014
============================================================


============================================================
🔄 Round 97 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 97 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0034
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0071
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 97 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0033
============================================================


============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0000
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0062
============================================================


============================================================
🔄 Round 108 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 108 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0014
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0001
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0009

📊 Round 108 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0009

============================================================
🔄 Round 110 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 110 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0003
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0068
============================================================


============================================================
🔄 Round 111 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 111 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0015
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0015
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0009

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 114 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 114 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0034
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0024
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0013
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0190
============================================================


============================================================
🔄 Round 117 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 117 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0035
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0031
============================================================


============================================================
🔄 Round 119 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 119 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0010
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0022
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 119 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 119 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 125 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 125 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0010
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0152
============================================================


============================================================
🔄 Round 126 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 126 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0013
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0002
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 128 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 128 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0951, RMSE=0.3085, R²=0.0006
============================================================


============================================================
🔄 Round 129 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 129 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0001
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0058
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0007

============================================================
🔄 Round 130 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 130 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0029
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0095
============================================================


============================================================
🔄 Round 131 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 131 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0042
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0015
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 133 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 133 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0000
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0089
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 137 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 137 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0000
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0123
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0007

============================================================
🔄 Round 141 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 141 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0012
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0015
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 142 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 142 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0021
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0017
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0007

============================================================
🔄 Round 152 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 152 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0011
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0009
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0006
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0191
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 158 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0004
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0024
============================================================


============================================================
🔄 Round 164 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 164 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0030
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0058
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 175 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 175 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0002
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0085
============================================================


============================================================
🔄 Round 176 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 176 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0024
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0093
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 176 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0041
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0085
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 183 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 183 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0001
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0047
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 185 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 185 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0010
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0001
============================================================


============================================================
🔄 Round 187 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 187 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0041
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0021
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 187 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 189 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 189 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0036
============================================================


============================================================
🔄 Round 190 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 190 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0043
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0149
============================================================


============================================================
🔄 Round 192 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 192 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0008
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0041
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 197 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 197 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0002
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0287
============================================================


============================================================
🔄 Round 199 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 199 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0014
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 199 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 203 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 203 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0014
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0022
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 203 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 207 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 207 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0021
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0044
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 207 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 207 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0028
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0075
============================================================


============================================================
🔄 Round 211 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 211 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0001
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0041
============================================================


============================================================
🔄 Round 212 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 212 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0001
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0049
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 214 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 214 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0010
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0012
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 216 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 216 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0013
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0021
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 216 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 218 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 218 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0005
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0078
============================================================


============================================================
🔄 Round 221 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 221 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0014
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0037
============================================================


============================================================
🔄 Round 223 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 223 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0029
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0171
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 225 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 225 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0003
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0034
============================================================


============================================================
🔄 Round 226 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 226 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0002
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0043
============================================================


============================================================
🔄 Round 227 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 227 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0031
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0048
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 229 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 229 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0006
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0055
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 229 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 229 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 233 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 233 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0005
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0051
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 233 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 236 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 236 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0013
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0082
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 238 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 238 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0009
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0342
============================================================


============================================================
🔄 Round 240 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 240 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0006
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0124
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 249 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 249 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0103
============================================================


============================================================
🔄 Round 250 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 250 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0037
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0115
============================================================


============================================================
🔄 Round 251 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 251 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0076
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 253 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 253 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0008
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0087
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 259 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 259 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0001
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0020
============================================================


============================================================
🔄 Round 260 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 260 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0018
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0324
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 261 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 261 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0009
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0029
============================================================


============================================================
🔄 Round 262 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 262 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0076
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 263 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 263 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0002
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0069
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 265 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 265 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0006
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0365
============================================================


============================================================
🔄 Round 266 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 266 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0036
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0109
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 267 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 267 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0311
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

📊 Round 267 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 271 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 271 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0014
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0043
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0008

============================================================
🔄 Round 276 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 276 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0068
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 277 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 277 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0031
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0235
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 280 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 280 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0030
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0040
============================================================


============================================================
🔄 Round 283 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 283 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0008
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0008
============================================================


============================================================
🔄 Round 284 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 284 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0000
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0109
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 285 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 285 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0014
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0006
============================================================


============================================================
🔄 Round 286 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 286 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0010
   Val:   Loss=0.0981, RMSE=0.3133, R²=-0.0059
============================================================


============================================================
🔄 Round 290 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 290 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0021
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0052
============================================================


============================================================
🔄 Round 294 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 294 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0040
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0210
============================================================


============================================================
🔄 Round 295 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 295 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0152
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

📊 Round 295 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 295 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 300 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 300 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0014
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0011
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 308 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 308 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0001
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0022
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 310 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 310 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0012
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0017
============================================================


============================================================
🔄 Round 311 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 311 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0013
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0063
============================================================


============================================================
🔄 Round 312 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 312 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0008
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0015
============================================================


============================================================
🔄 Round 313 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 313 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0007
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0048
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 313 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 316 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 316 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0005
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0052
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 316 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 319 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 319 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0004
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0073
============================================================


============================================================
🔄 Round 320 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 320 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0010
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0065
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 322 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 322 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0020
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0064
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 323 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 323 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0008
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0048
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 324 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 324 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0967, RMSE=0.3110, R²=0.0021
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 330 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 330 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0010
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0012
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 331 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 331 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0006
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0005
============================================================


============================================================
🔄 Round 332 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 332 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0009
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0072
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 336 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 336 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0006
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0051
============================================================


============================================================
🔄 Round 337 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 337 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0011
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0005
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 345 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 345 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0027
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0034
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 347 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 347 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0004
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0042
============================================================


============================================================
🔄 Round 348 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 348 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0008
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0189
============================================================


============================================================
🔄 Round 349 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 349 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0009
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0017
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 350 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 350 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0023
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0034
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 351 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 351 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0015
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0025
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 355 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 355 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0002
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0188
============================================================


============================================================
🔄 Round 357 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 357 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0015
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0030
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 358 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 358 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0031
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0035
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 359 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 359 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0006
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 362 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 362 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0000
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0012
============================================================


============================================================
🔄 Round 365 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 365 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0005
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0006
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 365 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 365 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 369 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 369 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0004
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0024
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 371 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 371 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0013
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0031
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 373 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 373 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0012
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0025
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

📊 Round 373 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0007

============================================================
🔄 Round 375 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 375 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0009
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0017
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 375 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 377 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 377 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0000
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0002
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 381 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 381 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0014
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0017
============================================================


============================================================
🔄 Round 382 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 382 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0001
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0122
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 382 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 386 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 386 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0021
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0077
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 386 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 389 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 389 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0005
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0028
============================================================


============================================================
🔄 Round 390 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 390 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0007
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0111
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 390 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 390 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 390 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 395 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 395 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0010
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 396 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 396 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0007
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0036
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 397 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 397 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0010
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0101
============================================================


============================================================
🔄 Round 400 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 400 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0012
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0007
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 403 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 403 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0018
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0076
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 404 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 404 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0002
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0009
============================================================


============================================================
🔄 Round 405 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 405 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0002
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0004
============================================================


============================================================
🔄 Round 406 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 406 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0014
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0054
============================================================


============================================================
🔄 Round 407 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 407 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0008
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0016
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 407 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 407 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 407 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 414 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 414 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0017
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0043
============================================================


============================================================
🔄 Round 415 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 415 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0086
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 417 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 417 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0008
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0011
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 422 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 422 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0054
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

📊 Round 422 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 427 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 427 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0006
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0022
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 428 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 428 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0003
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0016
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0006

============================================================
🔄 Round 429 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 429 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0004
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0042
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

📊 Round 429 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 432 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 432 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0013
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0037
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 436 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 436 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0007
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0023
============================================================


============================================================
🔄 Round 438 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 438 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0000
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0010
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 440 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 440 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0000
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0050
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 441 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 441 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0009
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0004
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0005

============================================================
🔄 Round 443 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 443 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0017
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 443 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 448 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 448 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0001
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0014
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 449 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 449 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0008
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0048
============================================================


============================================================
🔄 Round 450 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 450 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0011
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0028
============================================================


============================================================
🔄 Round 451 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 451 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0006
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0032
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 454 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 454 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0000
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0028
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 456 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 456 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0003
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0005
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 458 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 458 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0020
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0235
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 458 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 466 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 466 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0010
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0067
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 466 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 469 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 469 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0004
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0100
============================================================


============================================================
🔄 Round 470 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 470 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0013
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0066
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 472 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 472 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0009
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0049
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 472 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 472 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 478 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 478 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0000
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0003
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

============================================================
🔄 Round 480 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 480 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0004
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0002
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0005

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 495 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 495 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0018
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0090
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 496 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 496 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0002
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0009
============================================================


============================================================
🔄 Round 497 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 497 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0004
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 498 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 498 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0009
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0017
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 499 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 499 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0025
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0042
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 500 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 500 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0015
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0065
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 504 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 504 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0012
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0054
============================================================


============================================================
🔄 Round 506 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 506 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0004
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0037
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 508 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 508 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0008
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0026
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 511 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 511 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0002
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 513 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 513 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0026
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0039
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 516 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 516 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0000
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0131
============================================================


============================================================
🔄 Round 518 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 518 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0030
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0108
============================================================


============================================================
🔄 Round 519 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 519 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0019
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0072
============================================================


============================================================
🔄 Round 520 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 520 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0001
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0009
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 521 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 521 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0014
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0069
============================================================


============================================================
🔄 Round 524 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 524 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0001
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0015
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 524 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 526 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 526 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0007
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0014
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 527 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 527 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0002
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0066
============================================================


============================================================
🔄 Round 528 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 528 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0001
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0025
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 528 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 528 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 536 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 536 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0002
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0009
============================================================


============================================================
🔄 Round 538 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 538 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0005
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0101
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 540 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 540 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0010
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0022
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 544 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 544 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0117
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 544 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 544 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 544 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 549 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 549 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0429
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 550 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 550 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0008
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0095
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 550 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2485, R²: 0.0004

📊 Round 550 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 550 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 550 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 558 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 558 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0007
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0015
============================================================


============================================================
🔄 Round 560 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 560 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0014
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0041
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 564 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 564 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0004
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0088
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 565 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 565 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0234
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 565 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 568 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 568 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0007
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0150
============================================================


============================================================
🔄 Round 569 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 569 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0005
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0003
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

📊 Round 569 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 569 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 573 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 573 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0009
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0056
============================================================


============================================================
🔄 Round 575 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 575 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0001
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0038
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0004

============================================================
🔄 Round 576 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 576 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0001
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0107
============================================================


============================================================
🔄 Round 578 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 578 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0011
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0018
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 579 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 579 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0004
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 581 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 581 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0019
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0114
============================================================


============================================================
🔄 Round 586 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 586 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0003
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0016
============================================================


============================================================
🔄 Round 587 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 587 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0002
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0015
============================================================


============================================================
🔄 Round 590 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 590 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0001
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0019
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 590 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 590 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 599 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 599 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0008
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0045
============================================================


============================================================
🔄 Round 601 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 601 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0011
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0035
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 601 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 604 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 604 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0015
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0045
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 606 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 606 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0013
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0039
============================================================


============================================================
🔄 Round 608 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 608 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0004
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0000
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 610 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 610 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0012
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0018
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 611 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 611 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0017
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0116
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 614 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 614 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0004
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0008
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 616 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 616 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0004
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0040
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 616 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 618 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 618 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0013
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0020
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 623 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 623 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0019
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0043
============================================================


============================================================
🔄 Round 625 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 625 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0001
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0034
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 628 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 628 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0001
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0216
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 629 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 629 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0017
   Val:   Loss=0.0966, RMSE=0.3107, R²=-0.0036
============================================================


============================================================
🔄 Round 633 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 633 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0003
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0026
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 635 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 635 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0005
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0068
============================================================


============================================================
🔄 Round 636 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 636 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0022
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0060
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 636 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 645 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 645 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0009
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0053
============================================================


============================================================
🔄 Round 646 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 646 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0068
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 650 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 650 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0017
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0105
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 650 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 653 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 653 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=0.0004
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0028
============================================================


============================================================
🔄 Round 655 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 655 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0019
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0233
============================================================


============================================================
🔄 Round 656 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 656 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0007
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0153
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

📊 Round 656 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 658 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 658 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0972, RMSE=0.3117, R²=-0.0011
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 659 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 659 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0003
============================================================


============================================================
🔄 Round 661 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 661 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0004
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0019
============================================================


============================================================
🔄 Round 663 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 663 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0028
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0081
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 664 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 664 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0008
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0000
============================================================


============================================================
🔄 Round 665 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 665 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0022
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0094
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 666 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 666 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0006
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0032
============================================================


============================================================
🔄 Round 667 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 667 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0014
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0016
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 669 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 669 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0011
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0005
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 671 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 671 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0004
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0004
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 672 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 672 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0003
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0083
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0003

============================================================
🔄 Round 673 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 673 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0001
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0030
============================================================


============================================================
🔄 Round 675 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 675 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0004
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0037
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 676 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 676 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0010
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0050
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 676 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 676 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 681 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 681 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0015
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0095
============================================================


============================================================
🔄 Round 683 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 683 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0021
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0517
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 685 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 685 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0015
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0032
============================================================


============================================================
🔄 Round 687 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 687 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0008
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0001
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 688 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 688 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0011
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0028
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 690 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 690 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0004
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0014
============================================================


============================================================
🔄 Round 691 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 691 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0002
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0014
============================================================


============================================================
🔄 Round 692 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 692 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0017
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0043
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 693 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 693 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0014
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0016
============================================================


============================================================
🔄 Round 694 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 694 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0002
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0034
============================================================


============================================================
🔄 Round 695 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 695 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0015
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0181
============================================================


============================================================
🔄 Round 697 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 697 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0003
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0095
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 704 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 704 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0001
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0027
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 707 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 707 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0005
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0006
============================================================


============================================================
🔄 Round 708 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 708 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0040
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 712 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 712 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0019
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0106
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 713 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 713 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0003
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0032
============================================================


============================================================
🔄 Round 715 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 715 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0003
============================================================


============================================================
🔄 Round 717 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 717 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0012
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0032
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 717 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

============================================================
🔄 Round 727 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 727 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0021
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0150
============================================================


============================================================
🔄 Round 728 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 728 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0010
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0035
============================================================


============================================================
🔄 Round 729 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 729 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0017
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0170
============================================================


============================================================
🔄 Round 730 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 730 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0004
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0067
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0002

📊 Round 730 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 735 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 735 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0130
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 736 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 736 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0006
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0226
============================================================


============================================================
🔄 Round 737 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 737 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0011
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0118
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 739 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 739 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0019
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0048
============================================================


============================================================
🔄 Round 742 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 742 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0009
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0042
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 743 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 743 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0007
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0182
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 747 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 747 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0019
   Val:   Loss=0.0893, RMSE=0.2987, R²=-0.0314
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 748 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 748 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0006
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0040
============================================================


============================================================
🔄 Round 749 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 749 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0002
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0012
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 751 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 751 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0019
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0078
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 752 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 752 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0014
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0037
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

📊 Round 752 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 754 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 754 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0007
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0024
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 757 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 757 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0019
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0067
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

📊 Round 757 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

📊 Round 757 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 761 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 761 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0002
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0007
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 765 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 765 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0009
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0019
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 768 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 768 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0000
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0018
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 769 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 769 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0009
============================================================


============================================================
🔄 Round 770 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 770 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0006
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0022
============================================================


============================================================
🔄 Round 773 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 773 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0008
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0014
============================================================


============================================================
🔄 Round 774 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 774 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0003
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0175
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

📊 Round 774 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 778 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 778 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0002
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0033
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 783 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 783 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0000
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0036
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0001

============================================================
🔄 Round 784 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 784 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0010
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0004
============================================================


❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
