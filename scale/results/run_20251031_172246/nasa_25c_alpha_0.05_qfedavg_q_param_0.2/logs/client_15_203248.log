[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552aabe4-16b7-4c29-acc1-568003113839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce07545-e573-40ab-88e4-06e8cdf78a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9675748-2ceb-42a1-8351-f62ad1f36a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1e11c3-8db7-49e7-8370-fc51cf249ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3f902d-b1d2-400e-b871-f88163620d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0308ad6a-68f7-40a0-bd05-94ef858bc89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15b475f-b1f6-412e-b3f0-b4c7a24db5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f799466-4561-4320-82d9-a4540f1e4917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69052fe-e778-488c-ae1a-e10d0de4e8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fb3d81-a5be-48bd-9055-9547b5d28280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc2ef59-29ae-4634-b91f-761c69e36f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a77a95-668f-40ca-b291-ed30989e6b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ff9bad-affd-49ab-815f-2ef76fa085cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85ec088-35e6-4a9f-b57c-de9be9f2fdc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5473e3-dd3b-4602-ae9a-41a0322f497a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968f06b2-6935-4fd5-898f-8b3c5d6902c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cf9a15-6d3f-49c7-b19f-ab0f013e3db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1a8305-c866-484e-a7a5-9347dca0f08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10073e6e-8b9c-485b-a102-173a9b44dd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce2afbf-1659-433c-9899-c688f0465d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2236f295-3cca-432c-8c3d-fda0e57b099f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4cafe98-5842-411b-8602-6eccaba8adb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0e7493-7b15-474b-898e-3b5c6bc9c727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6ce4cb-84d2-4ca3-a17a-2f8030b60808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27565d8a-ca7d-4463-8cef-ffcffeade296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25bc1ab7-dd8c-4aeb-84eb-a87a8d468201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29f6cce-1068-4c6c-ba9d-276f0ed7ab7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad3dbde-8212-4c1d-bc86-8e8b1128ec4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84650ff5-8420-468b-a2e2-efc69a097df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc722baa-8aa9-4cfe-bad2-7771959863c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481e219d-ae93-4b71-adef-c1ef417730b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2417d9d-c0d6-4aa3-8687-d51516d12839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab0ecbb-7f3f-4849-a552-a29c66bb84ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b518d77-8b9c-4945-ae41-69c1c00d3db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86719580-e84d-4d0f-8e7e-40584b2b927e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0591f74d-f980-47b8-9161-eb01284244bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5131b3d2-dba4-4d97-98f6-8120be2b0852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a94c3b-db1e-4f97-b4fb-c25d8289bc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ffb095-c43c-4b63-85a7-c48771a4eaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ff82af-2563-46ad-9e27-e79416261cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13fb18ac-3b07-4d89-8933-78cdda076a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccd381e-bf6e-449e-b8de-3c35e5c24dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a55a6dfe-b9cc-4756-bb06-d57d620e27ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9399652a-48b7-4195-882f-683cb43d6209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba6055a-a543-4f14-b6f5-f04555ab70b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c179bc-4963-4521-b7fb-993ed67483c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31170313-b24b-4088-97ca-511a339364fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713a51db-2fd8-4436-bf50-8b942eacfee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bdf31c1-2435-40f6-bdbb-1ebbd4e0338a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3a4c64-4057-476b-bab1-b0352529f820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f6d34c-9d6b-4ec3-9bc7-fb931fe74633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2dfaf35-2e3a-48dc-9123-9036117b9b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7400e115-9f2d-4951-97b7-7f9259c8e262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb07a386-03cc-4f6f-81e6-09fdd6f5c864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e9b281-3ae5-455e-9206-03010fdf7b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da11db49-1224-4e00-b17f-e3f2604741e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49daeba-67f2-4b68-a110-777b55c3a1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad99c2c-90c1-454d-88bd-d1e0cadc6461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe60e52-e7b6-4010-8afc-1b93fe7804e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3ff223-b678-4178-a609-cf9be1dd2c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec7303a-3d32-4124-a845-3a440c6b4b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc7c7a72-f156-457c-8297-6d0e8238b116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3234935a-d8ed-4215-b931-8d4f8eb10cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58a02a2-d959-4004-8f4c-1d100276eb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f460f9a0-f2a4-4532-a444-0c4208bf9bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 930c81ae-78ce-45b1-8aa8-ca9a33b6ab35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e640426-848a-4a1f-8922-08e895bbd94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa89e985-6b00-4456-a298-1b39caaee6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8cf9fa-7243-474b-8bed-235c05226c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76b4f4a-4965-480f-be97-771d2e0d1657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ac1d56-9f43-496f-a5af-31e18aeee334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d16dc3d-0704-4c4f-92fb-4fbc0ffee328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c341285e-0be7-48dd-a30e-b99d50078c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb34f00c-88c0-425a-aa55-57a55180a028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454019f4-423e-4332-8e05-1e264131d3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c277ca-1035-44d9-ae33-01d07abdb37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2329804a-5499-4903-854a-096c2be5cd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52b136b-fb63-47a6-99f2-e59bdfadc2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885cfce1-823c-4594-a526-08a3cb2b919b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b69aba-e9db-415c-8595-cd6a434cf465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6d6b3b-199f-4021-ad26-a40b67a2b3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ba931a-f160-4814-85ed-f81b6c40ab79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bebcc329-5d07-4bab-99f9-9bf8dd705710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9259207-b4fd-42d2-ae88-81a66858c331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7335dda-3521-4bdb-8e39-19e4924cad59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bddbfcbf-3378-449a-b58c-ce7e614933ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe7cdf2-1cf0-4634-99dd-5043dfaefa28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9d1ec7-1e9d-4a36-85c8-ab853e02cfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0febde5f-3bd9-4460-affc-11219c39bf33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409adb0d-f785-4e01-b168-ee7c7b70852d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 679c9059-c645-47f5-915b-ead84c5648c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc963629-082a-41cc-915e-6502c3a6436d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc1cc97-c6c4-4286-b731-b5cf80dab6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c671bcb2-b973-4104-84b5-ef27c780c4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f42e563-d0a8-476f-887c-0422e23be55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bd03bc-0aca-4986-8775-372b2ef26873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b78b37-e51a-4852-9062-2ebf659127fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce4fc7f-abf1-439c-98c1-b4ff2e27b2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7974206-d9cd-4bcb-b96b-8c9bc42b2f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8062c0-0149-4cb8-bb28-fd9cc374be31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa39c27c-39bb-4ed3-9a39-8ca6ad300d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf3cbe1-c818-4a1f-b8b8-1f097c584af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf764197-586c-4e1b-892e-b0544cc805b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919ad380-77fb-4202-92d8-eef46ce02845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e1910d-dc89-436e-b737-08f0f5118485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8eb6bb4-05ce-432c-881f-c70867d893d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d898ff4-2d93-4211-8b13-bc06fe6fb701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9867cc4f-b4f7-4008-a8eb-3a890d45ffc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bae5165-df49-4d2d-ae7f-3d9739f56991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d475d760-116e-4793-a859-87b78fc5d4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba734657-07dc-4d73-80b1-21415bdf4419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d23c1c6-7fa3-4952-acd3-c6c0bc93d949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2aa0994-4122-420d-b571-e80c9fda73b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50925fad-b701-4b58-abbf-b395053fccc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2448ad1-d3c6-4bfd-9895-94886c844f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9e8dd1-0227-4a08-b1be-062f978e2ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df499911-3cc0-4624-bb07-7e6c28ce5664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f6174e-2667-4654-9d93-cb387395c855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c62941c-8bf6-4115-a3d9-746080c30272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24353d80-568c-4d6a-b066-c686b9b222d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 100aa675-de39-44cc-8593-a06436180711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13359021-e6ac-4c70-bc67-ee6d59bea505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b358f7d-c42a-4aed-9d9e-473361bbdfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c345b9-528d-498a-be2d-7decb1699fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a831211-0eca-4c9d-a6a7-7f18b60552a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6598e5b-1de7-424f-a373-d20a8432c929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfcaa2df-52bd-49fd-b204-b921b14c6279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf8c7f9-c010-41d4-93ef-5ccb63ed06ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c0b205-ec7b-46fd-a9c1-09d523bd8462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11fc6f40-8d0b-41d1-b801-3c0694206439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb3a7917-0abc-4260-ab10-36afa4235262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95061067-e58c-432d-871b-fff1be828527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536f36d2-f695-4c2e-8163-9f4c991eb5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85638922-548b-4d76-a269-2b6126b39ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5bedacd-6242-46bc-980e-5a9725fea2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bf9f89-77dd-4e6f-aafe-7fcc9a17743a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5175dc99-9839-4f01-98fd-4374ef5bb9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be4ce854-b8f7-4e2e-88c0-34a250741361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc72f1df-8508-4b66-92e7-1d8c445e7998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64812e45-d2b9-4576-9dc4-dd7d2c49bfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79056f87-25e1-420d-8709-81422c44f356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc43c317-b5f9-47cd-8439-7100998da876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56523c4-8f66-4d35-9043-811569856905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38eedd71-1993-40c1-a5a5-843f1eeefe5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aef42ee-944e-42c5-b44d-2e5cd9ab9f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53792d60-efa5-47c4-acfe-657fd368fa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cfa1c8f-b90e-4e74-97cf-672492cbd1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a47663a-b4c8-4dcf-b13c-45b9f00a8644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9eb7e8-20d7-4d37-abd8-dd0aa61f79d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e89b2a-1b15-488f-93af-40c9074e29ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac020775-2772-4fdd-84f1-57ee9849ba5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834683a4-313f-4701-94ec-8d9fd7b30ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d6a215-57c8-4efc-a48a-5f0d1b85f758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a0cd87-2b97-474c-a670-49c7fba191d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49503cc7-d78b-4023-8375-1396e85b75fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3520bfa-c7c5-46c4-8517-4db574a07de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3b7638-529f-4dad-8183-e41459ac10c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238f8a71-e7bc-4d50-8e5e-5cfdac8af963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 015b14c5-7ee3-4980-92ea-4d6c721a8bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2961b75-6a86-4421-9701-5a00dacab949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29a40d7-0824-4b08-ab15-4b0f6aefe025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0019be75-f6f6-4b17-ac73-4b70ca5c4647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e06e33d4-2422-4d83-82e0-fb9c8814a452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f24d743-f76c-476b-96c5-b8101d5f835f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9069dda8-44b2-4a24-ae40-08a85648fd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713ccb35-8c65-4ec9-bf43-b91406389170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c99bab-fdc7-4566-aa10-3eb5cc6af3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d2725a-34a6-4c96-9606-2cef4d52298c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2821e322-9f41-4841-a515-e25cac94850a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c0df6b-6b7a-4252-a203-12f31cd27406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13ad0c7-e9c5-4a32-b41f-b1f012176ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 207b7970-3d19-4b73-90cf-d07e6d96b9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a966d968-840f-4ba4-bfad-712d2e70c827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0748000e-bba0-40a6-a2db-410be8e83e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d89aab-8ebc-452d-b0d7-f470442286e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b2e9a6-ec11-441a-9a5a-bd238975c3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce2ec38-9317-4203-92ee-c62be7bf9f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2f7070-0f51-4371-a31b-61c84007c88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045a93c3-2873-41fb-a1d6-9e8c102f7ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9125f67c-ff24-48d0-a4ea-75e43bc6dca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca715ee-0079-41ac-99e3-deb0b9999b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da7aecb-5fcc-41cb-a8b8-321503821b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e3e364-7747-4cf2-9a67-500b55cde571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2e4991-4037-4b69-9e36-2257560e114c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c39383b-701b-4dd6-88c9-468d61eb0692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c73149-e6b5-4c50-98cc-46b1c247d4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05acb220-177e-4afa-a170-23666a433a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6762ae64-0b9f-4619-8f9c-2976c07a372d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 019a28dc-84bd-4077-b26e-cef4e5b34b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041b74a8-22b0-43b4-9676-0b1440e5cb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6e1ad5-af14-457c-bf15-96cec5f7fe23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5f39c9-72b8-45a9-a7ba-ab1ca44d91e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414f08e1-0b75-4ad8-9acb-eea3642288a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32cd8982-2413-4a4c-9e29-4d6a36e9dff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86a446e-413f-4320-83bb-a01091a7a25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1c86c1-d2a2-41af-bc60-d925640f365e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d5cd48-4d1c-4f90-bf54-786ede52f5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141e6aaa-57c2-4672-aa46-52837dc9ed68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5bdcd1-5ddc-46fe-830a-a9da3d92d07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0724e83b-d0d5-4375-9a6c-443263fcc4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cdf884f-a6e9-464f-9d76-dea7988df9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f08b107-c926-4b9c-bfa6-01ff4ee6af6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abd4e18-98e8-4a9f-8ec8-9762dbff5884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b1e037-634e-46de-9e38-9fb54fa2bb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c5b1d9d-5ccf-4117-bb10-6acb5ce884f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97b54fe-b11c-46ec-8873-70848ceb6598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf9c63b-2f23-4efc-91f5-6e6e5f2cafd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ca80a7-4422-4c10-a847-11eeb487a1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010c2f4f-3f64-4473-9a39-664c9e39edcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36052ac8-71f4-4b99-aca6-cf4597ff8e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f418e8-bab4-4d6e-a18d-75f073f640dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3d011d-b4a1-409d-b723-d4794debca42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbdf8817-7d16-4ec0-b21d-b4a45d538152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 513d3e44-d43b-44b2-a1a6-813e3f4a4179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec1dd66-d7bb-41f7-bb43-68cffb7cc7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13338ce5-6571-4666-b612-1f882c7a4330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136e8dba-951c-4997-ad3a-ede230b6e40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74bd849a-077e-457c-961f-f2acc6b05ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1d571f-1d4d-46c8-8b18-9c00e2e0e7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edae74e0-8aa2-47bc-beb6-252a0e04e2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9772753e-6fd7-48f9-92fa-c4ac8f279547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3580ad25-7c75-44b5-9470-4253d1770783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d835e469-27b0-49ca-b1f5-360d49b48f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99343b97-3523-4140-8833-84a52dfb801a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfed2793-26d4-43ff-96e7-6038cd084c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae073c3d-c4c7-4237-99b7-134a3d7b1084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28894769-54c4-4c90-995f-5147183795e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176233f7-970a-4aa3-b807-8d8b26f739aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2fad07b-f195-4f9f-b104-fb4c98127148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25eaca75-0ee4-40c2-8e1b-9a0aa1920500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd93bb7c-0053-44b8-bd38-a3484f2da883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fdbba6b-7af4-40fe-b7c4-a4b02d426b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc729ac-204a-440f-a90b-92c618351097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841c28de-9d7e-4cd1-b22a-1b483ee6124e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d950426-c4b1-42c0-bec7-05f95d6e5ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d20bd91-74b4-451b-8acb-7b799423bbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9255fe68-e447-4524-a12e-d1ae9ea38eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3f3645-4439-4b9c-9692-d4ee132ae518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a04176ac-7d9e-4925-b8c1-f7f5a0be9f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092b7d18-bd04-4363-9296-c8c716cb8af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea0f2723-f561-4058-a146-53c7f23b1d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd83700-f631-40d1-a695-8cf4da6c4094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d5dd68-e8ef-4581-8e8d-4b8fe2d116f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e031fa19-045e-4d24-b865-19097b50bafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb1d867-23e3-45a8-a643-8d562c571e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7dec74-4b68-457f-9de3-1e8698d6e8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79902bc-6550-4ed0-991a-0e6728be3c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a77f9a-48ba-45d5-87e3-a6f456c247f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0dfc676-7268-414f-b6f5-0750f12e8526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3b779b-fe42-411e-b8a5-ed0933905cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a8cf0c-b725-45b8-ba08-36777e26febf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4a0bed-2630-4773-a8e1-73b63e5a6c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d048de32-ab70-483e-a00e-606469a11d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9520fa6c-81d6-49fb-b9d4-e34613ba42f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11866be-c502-461a-81dd-4840de58a985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b456d93f-0081-4697-a25e-a72d42e00b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a2bc7e-3c81-493e-9cff-ce6f4a9ff38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345ad0f4-7515-4743-9d07-896e2606b3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17dda556-f6df-417b-8610-21f593939dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67ab1e2-f50d-4733-8439-ed0508b0eab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f521c7-b7f3-43a7-b64d-547dd1a31a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f684d0-2006-4bad-b373-8b12c67cd52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f201f8-0e9b-4a6e-870f-030a4be5b4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc73e42f-bbdd-4f72-8c3c-3fb4f4245561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d778b8b7-5cef-484f-b878-5b34e9d551cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c9be14c-0cca-4884-ac8c-6e4338be1020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a2f6f5-78de-4462-a81e-bc05ff5823f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c65011-76ff-4af5-ba37-a5e010a7b03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 463d5b47-8c67-42bc-991b-1cf700d20785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fcb21d7-c198-4223-afb9-f0eeff6f982c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792ea985-ec49-4c30-92e5-8e5586fd28b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c4929d-7e70-42eb-8e08-68fdc54c5410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cebdbf5-ba02-48ce-9def-4fc1b90dbe07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7379ed8-fabd-44a5-abf9-f73b0ae296fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4e7b23-9dfa-477c-97e2-42283c7ec5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa4d868-feb0-47a9-ace8-9eaf2390f802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07d9b00-b419-4d80-aefd-4b0c608eb344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5328aeb6-5dc2-4abd-b420-f4b6c8ac6425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab93fe5e-fc5a-4ded-b4eb-77473efcb507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51429083-1743-4ad7-b725-4e518b66b12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78c1a5e2-8ed6-419c-ac89-4cdfd86f0660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cd3d53-e2ea-490f-acb6-0e9592e174b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d074d3e-505f-498b-925e-a85a37349d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8401dc1d-0ebf-47d6-b5a9-3aad2cf8eb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6704618-00ef-401a-bdce-648fc65be354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab6f870-1dd5-4556-924d-9b667854f01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7643a7-5e90-4fc5-8933-464f9bc6c5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af3faa0a-4903-4d98-bcc3-9101cf4b310e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d7df7b-0f4e-4b90-98b7-95effc31a695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8f0c58-a4fa-46ad-84c2-cd8c246bd1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c550df-b8cf-4210-97c7-1b61d7caa2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f2d220-e9b6-4e56-a64a-f99e9aa06f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabe0bb7-4b86-4ff9-9e22-b402850b11c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e25b46-cb83-44f6-ba7a-66849d2fe097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95631180-6f2c-411d-a1bb-dad9e99332cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b7f8fe-d00a-4f82-b626-0eac084e39f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cfd57b-1f5c-47a9-a25c-1ef22f428b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae52c1f-c97b-4c44-97a2-dfb5e0e21b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b688474-e74c-4055-896e-ccc24a292b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d642ff-8436-4735-8feb-b0b55a005dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afd642a-dcbd-48f1-ae34-a43cbcf203d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774391fe-c5de-4503-bfa6-371e88e84e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76f3b77-ed30-48c4-9b7e-f74d4fb4b3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9370ba7-37a0-4538-8e11-46b4537ad6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960e865d-3869-4ecf-83b0-24cd091ae357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30bcf8fc-bddf-4f36-b38b-9a0b65ce99ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7afb36a-786d-4dbb-93ae-98886a27c9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b647b31b-f289-4941-ba83-88c59886c66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d92b1c-9cfb-40ba-9954-64928e7ebf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8656e04-7553-4121-93d2-8442ece410e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14e7f42-6bf3-40bc-8350-ea09407a4b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01b205d-3c4d-40fe-bcbc-0f23993217ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650ee67e-47d5-49d9-a70c-d6aeca92c6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223adb03-58c5-40d3-bcc8-961e53c5854d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5263875a-a2e2-44ac-8e88-5a36ecc1acb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be48feb9-0f3d-4371-b62a-e6cc8ba6f042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899b7213-33f4-4aed-935c-5d16353cc54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0e81f1-301f-485d-b6ad-3ea3b996fc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b98ef70-d2e0-4e1c-b43e-9d5c3ce1b48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce44c71-1c49-44e2-9e6f-72a6fb00ab78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661b2794-8f47-4228-9784-d6d27fa4d3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2732f509-c1c4-480c-a4a7-e28eb4eeae52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e554850f-68f8-45bc-8310-1438d8235ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa8b8ff-f764-4134-a70f-e9fce9ba1d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3f68084-638b-4ea0-b340-7708249e8ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d0f59f-7416-4b6a-982a-70e6b3ec98d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa6d832b-3cbe-4d2e-994c-879b5402ebdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a658882-29db-472b-bbb7-c0e4aa8d91cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f48a9d-2d2f-49f3-afa4-add0a9e3c822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fbfc65-44c8-4022-b54e-89805ba7163a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5fe36a1-f88a-486f-b37e-a3ba245bfae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b324005e-a89e-48cd-8497-625fe44b66ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2eba8d9-9f5e-489d-bdb8-eaf6b97f514a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77cd8375-6436-4a26-a3f6-254e87a38f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e202b05-75df-4f4a-aa42-76d0225792e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3398b2-9464-4fa4-a4a3-50084d095d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd45cc0f-3397-4e31-a3c8-df2d57871ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a27fe93-e9e7-4d5f-bf27-8b5c32f008c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d4145c-1508-4ce5-8ef7-029bb183d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63e38d5-1b7d-4927-adec-e397dfc2b29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e54ae31-f5c2-4ac5-8b71-15e7173a3379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d819555-f33d-40a0-9cc6-ab91f551fe25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc0fb0a-1126-430d-adfa-2059618d37f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f04095-39e3-43a3-8550-963fdea78ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ff70dd-bb2d-4634-9a93-58d2f2916e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8b6693-a8c8-4583-9ea7-01e5bd92f271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0d3640-bfa4-4f3c-8b3a-5fec4bb70e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3feef112-43be-466d-a150-bcaf2a938ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb908373-a589-4854-88e3-fd9a44aa3c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14ec551-a742-41b5-adcc-61a1ef83eb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404c758f-78f5-4424-938e-50999813b65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2b40f9-df05-4d2e-86e1-b641e2c5c64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e437ecc-c5fd-4233-94a7-806043365bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a85488-9b99-4e71-b33c-e7b77dbc2f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828b7986-55c6-4120-a131-92ab29618be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ffb2aa-5b81-4be0-b753-80ed52152c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761c0319-9b26-42f0-acd6-cadf0c14e309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7850956-3d3b-4039-a52b-729599100e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28374e55-822c-4154-909b-4318042b2adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b1c442-f67e-4aac-9a4f-77ecee8b02b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab519709-c377-48d8-bfc1-6ddd6f6d98b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45fed88-a820-4ce2-a99d-8f3cdff18769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d570077-4ba4-4b20-bbf5-883ae37bc5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b65c43e-3c95-4016-82e1-071468a6b055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fddb1e72-4969-480e-9047-95a53de40fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2534c58-1058-4435-a54b-9255ed7388fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a69fc74-9bd4-4eec-a7eb-f7028d716714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1823fa04-95e4-4951-9c3d-cb47371263ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a9db4a-56af-4912-b957-933790cf324f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94aa8de8-1c2c-4a73-83b9-ed94ea74a35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fa34e5-e151-4181-92ae-6f3d00bb7f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6805e8d-ac19-4512-b78b-d086569b48da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bba72e9-1f00-449c-8fcf-11daedd3e8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fef4384-405a-4585-9a67-698423805cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6365efc7-9c65-4cd7-beb8-4a6dc6c5f470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412c29b8-551c-4069-b53d-618b3b20c2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49143a8d-8e55-4a86-8fee-e69248eeeb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6dae9a-1e3e-4441-89be-25e7b50bd761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 706fb143-1638-4fb8-8da1-f5c64946a359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df97d95-b67e-4858-a952-3e4aa839b1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c239567b-1341-4a42-8dcd-c36eb6d06d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2915a07f-2bcc-47d3-9fe2-175cff1a9e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd957a8-daa8-4dfb-9ab2-098100d3ab2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15b8cbc-4b1d-4ac1-964a-1f9c2f7aa73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac379a5-0326-40a9-b46a-15f05a198445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2f98d2-0061-443e-81a4-69c195186bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2921f682-f231-4e37-9f94-61353776bdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa24f667-2893-4402-861a-248c239fe697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bc604e-130f-4f4c-94e6-8a285914e722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c834a792-bec5-4ce3-ab1e-8e0475303494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2907be66-a58e-467a-abaf-2430340add3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b320e9-7af1-4f99-b29c-fed2705a9f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7021896-9da8-4488-90d4-44fc6d87e4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfc8ffd-3f10-4c09-b41f-20f4236a8873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f16e559-7ed7-497e-b999-969e10b10481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a41cf2-56a4-49ed-8f95-2ea7e926ce05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb96b985-5c01-4eeb-b5fe-4ed50c5bbe6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6f05fb-a7b6-4f77-be0e-7527931360f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9ff2a6-41e3-4672-892f-a3ce2526979e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24d26e31-321b-4106-bea4-832c06aec1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c54e0a-f788-429a-b4a9-cc13d68b5759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6698c4e-380c-403f-9b87-b349e4d1ddea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efaaa75e-7025-4fdc-8f76-02b11ca8e9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f408ac-3d13-424a-91fc-d6abb38d0061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d63cfa6-0b77-4672-8ef6-91684840cffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0448a671-f4f3-4505-ae75-36f5e2befe70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9a3b3d-4d67-4fa2-bb76-d345664519a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66dbe463-bb00-4a7c-b2c8-a72047a0cbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9e88fc-1fc4-40f0-ac74-a20d2e0ff986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab1b68c-8457-44b5-a54b-714eb70d9f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf652f7-c07f-4565-8b14-979d427cc013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c1c277-9ee5-4e0e-8021-85dfcbc9e276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07324c84-2591-4e14-82ad-126e10ca781e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4cbc7b-6e0e-4646-b0a4-5a069a72e0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01a4a64-a80f-43c8-b422-5eb82841d442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae02711-d397-488f-96fc-d44b8397af15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccee025-11ec-49cf-a71d-ce07f026f6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fbaa2e-eeb9-4a36-bd8e-b171d84ee7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c9dd39-c5c0-45a4-84e6-2bbe1896ea81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b66111-f153-46a2-8bf3-0e8960e0ec0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efce7748-677c-484c-bcad-b9fe27bdbb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754c7fbc-3833-49ce-af67-c20c4d2d07dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4e4386-9d6a-4dc6-b968-1787cffb887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c463dae-46c1-4c9e-ba46-3849b5eb92f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e681d0de-a063-409f-be40-25b0c4ee68b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f38584-0223-43b9-940e-3c3c53dd4a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e87454-33a5-4e95-8511-e4cb0e8cb241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b509d71-158d-42cd-8698-89115d97b471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a73a7b-8eb1-4372-a55d-59da71e672ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23bb3f4-6470-4bc7-b3fc-16fd34401e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8401543-794c-45df-baf1-8cbba79abdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09cb17b0-1304-475b-84bf-c8667c92bec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c62801-e5dc-4f72-bf6a-366399d6960c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317fe5d1-c5b3-417c-b05e-1346facb2c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c633e25-dedf-45a5-b691-5486ec349496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b854b4c-b2f1-4ddc-9d57-6be1dea31fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83da65e-b7bc-4251-acf0-28cd72d8b842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdce2de-7708-40b1-ae36-ff3ba2543036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491d1838-411f-4097-9cd0-0e0e2b86a40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c510143-7aad-4177-9a32-508200508e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a40a398-9d36-4227-8f26-adcace4367a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22eecbf6-b91e-4d8b-bbc2-35d14c44cb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b539f47b-3f2c-4fe8-bf9c-d2d4a8e92bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ef87d9d-64cc-4d7c-89ae-940275ae18c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb87914a-7500-4556-82e2-7d13f3b9b444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ca188d-01c2-4abb-b434-167432fb3b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51cb75ab-e489-4859-a68a-81d027676796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2988dc-0cda-4fa1-8e24-a879e50ce6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f47f156-cd1f-49a9-896c-e584504a4ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395133ed-c9dd-4a3c-a9d8-1504c9da59cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29db1840-40d0-43a6-8e77-38f1197f136e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc72718-f7fe-4a00-b5d8-ce1e9c54ea64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c6d5cc-0201-4c7e-af0b-9267e02b0e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba3fd27-b1b4-4751-ae0e-8f90ccce82b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b927377c-c878-46a0-8542-63c0832a99d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ae748b-1dae-469e-b882-12554d917243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de65659f-6dad-4126-a9bb-ed8ec50927db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc86492-bb90-401f-9f6d-8f9ede4f82d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6b680b-067b-4fa2-b6cb-61d69c8d51f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbeb402-adf6-4ed5-9c73-3de5e28d0614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9244968-d413-4908-a17c-ec83c1d960fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb84a8d-d75d-4df1-a4bc-b2ac9e88d485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a96df2-c632-4c7e-8173-ec49680dbfad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a038c80a-222b-4f11-b73a-76b666926ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f82082a-789f-48e7-9a89-0f8bdd2dda16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2541d566-9e9e-4066-9df2-f074ac57fb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbede6e1-b3c7-43cd-b179-886c99016e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833735cd-474f-427a-b93f-adf4014285a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eaaae7c-c903-4307-9404-a2d24ef869c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b310ff23-5300-47ea-a77c-764d6e552367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12223ba-c233-49fb-9620-b1c8eee641d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f70c53b-34d0-4c33-a765-222198c5d8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a00efd-bb51-434c-9f23-514bee3fed88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a587a053-fea9-4063-8001-46de5b93189b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6d44b4-f16a-422d-ab8d-51488167fad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f368fd99-077f-4b7a-aa83-fea1b27a218a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc58de0d-a974-41c6-891d-dff1d58e33b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b54153-1c0b-44dc-a260-63e3005f30e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e406c906-b600-4334-9dca-2b7baff84551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c520cfee-a352-4e05-b7fe-24a1e3cce7fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d03742-fcf5-4009-8136-48de830c5058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5d6348-c776-4838-a695-9d4ec9416146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a527ecf-bc65-47e5-9088-2e8eaa9f6b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc3c5ce-61b8-4f33-ae1b-2d22227f3105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba0971c-2bca-4f9a-b4e2-367743de317c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f321bc3b-b311-4989-b957-8d50587587d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f25c4a7-497e-4f6d-9ca9-cdf6c9dd8c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ed1429-895c-4fc2-b602-a2c59bf07ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72625573-6ebe-42ce-b821-a7758b82085c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a84147cc-6808-4a5b-9876-d2c78c8a4a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7469083b-2fb9-409a-b65d-76f1068a1f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21bc28d9-7f8d-4c11-8e3b-bca3d8bc9695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13dede7e-557c-4dd9-956c-c7c2b11d1161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b831e800-5291-4ab9-9b8f-48d64fb44ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff61a57-e400-4dd3-a02e-783f4a1712e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2728d04d-1697-40e4-8826-cd03afd9c1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f62ef0-c6a4-43c6-8150-8a77aed80ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e41fae-523c-48a8-964a-bc94c4d14827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6186ebe-509e-473d-b40e-770a2de9d500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd92cdf-2102-46df-a8ba-493d4f8e17c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d85ea8-50f2-4a49-a0d3-d125b75e0cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7952280-edf0-4876-8a2e-b895e8f41152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25cae95-08a2-44f1-80b9-f732e3515c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c18d602-ecda-4c77-8d5f-a8f05484c773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d3f3c8-8f57-4a21-b36a-ff0a45082d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89555033-044e-4c3c-b2b1-7665dc91e7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77118b25-73b6-4117-9bf5-19c1737b7dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61df17ee-5ce4-4b9a-be45-223eb9d19bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb0a82c-9eb2-4350-90e1-59e8c9163146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95ef392-8f3f-4079-9ab0-d348e210864b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1108e908-500c-478f-83e4-d5c5e3299ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b55b764-0f50-4fd8-8cd8-d30125d15926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f4450c-2d2a-464d-b89e-fef17b05dddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d79592-77b3-4e36-88aa-62f3dd4af5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9c12d8-b908-4e92-877d-0ebf87504ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab272c9-f0b1-49f4-8a2e-89d1272af6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f29780f-1f4a-419b-9e47-f00d7aba6aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e53ed93-ce46-42f3-920b-05815d34764b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e21b16-92cc-4326-84f3-280bc269572a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c34aef-145b-44e3-a423-955bdeb64d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a03ad90-093c-4e87-95f7-e1779def4f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001c10e2-4566-4fbf-bac9-d1d60a9d2b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b225caf-1e59-44ca-8415-d4699f338dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497246dd-78b2-40a7-886d-5b9e486a01f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a23ac48-285b-4ce0-b3c1-bef2e6f5dbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b525ce28-e8f1-4315-a794-17e14046d318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd3c0bd-34b3-4270-a8c8-2e50508c60f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67d12df-afd5-489f-a1e0-2baad687fd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afbc4fc9-e3a9-4934-b2b9-e6d6332fc8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b3ceca-c826-4023-b973-51b1e8aac689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8214aac9-7da7-46a8-b79c-64c2eb4822ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1966df6a-5a64-4cc8-af4a-7d14115751ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e808e4a5-1b60-4efc-964d-7134f3cba832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82432b96-a4d0-4186-961f-defb4c5b6c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7f823f-c373-4278-bd63-6dd2d10f52cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2063d4cd-410b-4df6-84bf-e604f524b75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b703f31-9a95-44ea-8cc7-5d609a92cf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821bbe73-62ee-491e-aee7-78b636a92fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0143c4-3828-439e-ab73-62b59ad4d6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33bf7509-f6f6-4e33-afe0-b8b4d3ae2634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e63c3d1e-96a9-405a-a885-564bbccfe744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3704d9dd-05a5-4128-a043-a11bada01463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02adb8b1-ec9a-4569-b74a-4c6e13d97259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f35566-8586-4a8b-ac90-c02ca2f6f406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b36968-b617-47ad-bb0c-bebf03827e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a0fa0d-4ecc-490d-a9f2-6c53f8171d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ff8ef5-8ee2-4ca2-ba70-e9f66aefb04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd32758a-875a-493b-a457-109e6206779b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514d4b2d-8f99-47b2-8a24-c0ae34c263b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc2250a-132a-4ce4-b9fe-cc170d55dfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04d6262-0510-4bff-87a2-2f12309cb8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 385cc0d1-ce0b-428c-8c24-10935d315edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4cadf51-102e-4a5a-b259-5333e3785bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42f7362-6150-493e-9b5a-aa31730483e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae0e6b4-483d-41c5-b930-1dc5fab5b1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b98b531-ea49-4cfb-ae1c-38e1512c1c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871baa50-4ac8-4723-8558-c75852dbe65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0d2732-eb00-4e30-a7c3-5059e993f26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88d5fe1-af05-4ff7-a787-e48214caa7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a43a28-8d78-48e1-bfbd-3dcfb61227da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d88ff0-ae52-4c02-8115-01a6458749c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ecfaea6-f95e-46b5-bfab-55a9620e604c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ecb294-ee32-4f37-86dc-81c444713255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484101de-deb5-4151-939c-d3cd383eb4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cd7250b-60ed-4d95-9605-4b790645008f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10af8f1-d07d-47f3-9dc5-a3b5554571d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca8c8791-e996-4752-a2ed-9a65c2fd0349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b864923c-0505-4130-a73e-d1a5ffc1e980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083b9273-0f96-46f0-a042-bac08cdb5930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a44405-5dcb-49c0-b1fd-3a698492a605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7eed09-336c-4a47-ae76-19ea4df0b864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ae5bb5-eafa-4bab-a737-c5b566fb9f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8147b7ad-4718-4dd3-9cc9-508c3dda8fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d941fc-1fba-4d39-96e5-012c24155ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12c7a79-203c-484f-92b3-5c235643a0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d483f75c-b4a9-41c3-bd52-b3102b3c1fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0cef443-39f2-4095-9e9e-049a98c21ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2269b095-ef0e-4962-9379-6cc3577b4c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dda4362-1344-4309-bde0-4b32968a3bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae4badce-ff29-4a1b-bc85-81a2f5758d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1a5500-8182-4f4f-88ba-1da5ca879bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3109cc06-ee88-47da-a084-463ab51c3731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4b2250-9158-468c-b15f-4c6237f51121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2ba6fa-bf79-463e-b920-8955aaebb8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1728cd4-8310-42c6-8b9a-b0e0bd8f73ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06127ab3-586d-4ffb-b764-b7fea869d2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0244d42c-38b6-4ade-bd15-38145011f86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9496e1c-78c5-4aae-b840-9c47be74c27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5660fa-5772-473e-9806-3d6a271b58bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4fc33f-e9db-4a57-bb78-31672472b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77787e7-f9d1-446f-93cc-f65a29a2427b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a3e207-c4c2-4ef6-9d0a-ce9a2d1a78f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c669574e-444d-4aaa-8f10-110a460c543b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588a28d2-fb87-471e-aacd-2d894ecbbdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e3ea5e-791c-4d45-b97d-eb780beb06b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7daf9a6d-886b-4e72-aa8e-48a5fcc94fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a754f7-40c0-44db-86a0-00e57f7fd4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480b39f5-dad1-4bff-aeb5-e9b03be5c7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc901a61-99f2-4aa1-8189-6b2050f32c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9411a83a-1c0c-42a7-8d8e-ffa0304001e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc23e29-52f8-4e42-9ca5-efbcf526e47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310f14e3-5af3-4f97-94ae-330d4c1370b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7c6baa-d03e-4670-867e-a3fe4edc764c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b94da8-e9b8-497f-a1bd-5fb5475f3c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e217fe9-84d7-48b0-a111-51202c54053b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51e1dc6-c119-46af-b2c3-cffac0f10be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f17cbc1-dd21-4f1f-9ae0-81f7dcd8ff06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212005bf-e55c-440c-b18e-5ae53bfdce39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e0fb87-6cd7-4702-a43b-955c2ce985f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d21a34-7f42-42c2-bc41-e3cb2a10d492
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(4476, 24), y=(4476,)
   Test:  X=(1120, 24), y=(1120,)

⚠️  Limiting training data: 4476 → 800 samples
⚠️  Limiting test data: 1120 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3792, val=0.1714 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1003, val=0.0830 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0853, val=0.0778 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0855, val=0.0773 (↓), lr=0.001000
   • Epoch   5/100: train=0.0849, val=0.0773, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0838, val=0.0786, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 1 Summary - Client client_15
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0050
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0201
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.5061, RMSE: 0.7114, MAE: 0.6505, R²: -5.0985

============================================================
🔄 Round 4 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4586, val=0.4257 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3493, val=0.3043 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1981, val=0.0971 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0899, val=0.0744 (↓), lr=0.000250
   • Epoch   5/100: train=0.0869, val=0.0761, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0854, val=0.0747, patience=7/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 4 Summary - Client client_15
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0355
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0130
============================================================


============================================================
🔄 Round 7 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.4663, val=0.4577 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4117, val=0.4228 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3799, val=0.3905 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3492, val=0.3573 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3149, val=0.3174 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0883, val=0.0875 (↓), lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0839, val=0.0820, patience=5/15, lr=0.000016
   📉 Epoch 25: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0838, val=0.0818, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 7 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0025
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0150
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4768, RMSE: 0.6905, MAE: 0.6275, R²: -4.7455

📊 Round 7 Test Metrics:
   Loss: 0.4682, RMSE: 0.6843, MAE: 0.6206, R²: -4.6416

📊 Round 7 Test Metrics:
   Loss: 0.4593, RMSE: 0.6777, MAE: 0.6135, R²: -4.5346

============================================================
🔄 Round 10 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4843, val=0.4350 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   ✓ Epoch   2/100: train=0.4777, val=0.4285 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.4726, val=0.4255 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.4696, val=0.4228 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.4668, val=0.4203 (↓), lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.4535, val=0.4085 (↓), lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.4451, val=0.4009, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4408, val=0.3968, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4368, val=0.3930, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4329, val=0.3893, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4291, val=0.3858, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4253, val=0.3822, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4216, val=0.3787, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4179, val=0.3752, patience=1/15, lr=0.000001

============================================================
📊 Round 10 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.4145, RMSE=0.6438, R²=-3.9533
   Val:   Loss=0.3721, RMSE=0.6100, R²=-3.5155
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4487, RMSE: 0.6698, MAE: 0.6047, R²: -4.4060

============================================================
🔄 Round 12 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4543, val=0.4729 (↓), lr=0.000001
   • Epoch   2/100: train=0.4538, val=0.4724, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4534, val=0.4719 (↓), lr=0.000001
   • Epoch   4/100: train=0.4529, val=0.4715, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4525, val=0.4710 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4499, val=0.4684 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4459, val=0.4644 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4421, val=0.4605 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4383, val=0.4566 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4345, val=0.4528 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4308, val=0.4490 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4270, val=0.4451 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4231, val=0.4412 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4193, val=0.4373 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4148, RMSE=0.6440, R²=-4.0078
   Val:   Loss=0.4337, RMSE=0.6586, R²=-3.9956
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4211, RMSE: 0.6489, MAE: 0.5815, R²: -4.0740

📊 Round 12 Test Metrics:
   Loss: 0.4046, RMSE: 0.6361, MAE: 0.5672, R²: -3.8753

============================================================
🔄 Round 14 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4179, val=0.4337 (↓), lr=0.000001
   • Epoch   2/100: train=0.4175, val=0.4333, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4171, val=0.4328 (↓), lr=0.000001
   • Epoch   4/100: train=0.4167, val=0.4324, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4162, val=0.4320 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4137, val=0.4293 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4094, val=0.4250 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4051, val=0.4206 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4007, val=0.4161 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3963, val=0.4116 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3919, val=0.4071 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3874, val=0.4025 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3829, val=0.3979 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3783, val=0.3932 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3743, RMSE=0.6118, R²=-3.4579
   Val:   Loss=0.3890, RMSE=0.6237, R²=-3.7309
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3772, RMSE: 0.6142, MAE: 0.5425, R²: -3.5450

============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4018, val=0.3565 (↓), lr=0.000001
   • Epoch   2/100: train=0.4014, val=0.3561, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4010, val=0.3557 (↓), lr=0.000001
   • Epoch   4/100: train=0.4005, val=0.3553, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4001, val=0.3548 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3975, val=0.3524 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3931, val=0.3482 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3887, val=0.3440 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3843, val=0.3398 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3798, val=0.3355 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3752, val=0.3312 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3706, val=0.3268 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3659, val=0.3223 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3611, val=0.3178 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3571, RMSE=0.5976, R²=-3.1424
   Val:   Loss=0.3137, RMSE=0.5601, R²=-3.3169
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3512, RMSE: 0.5926, MAE: 0.5180, R²: -3.2315

📊 Round 15 Test Metrics:
   Loss: 0.3026, RMSE: 0.5501, MAE: 0.4696, R²: -2.6466

📊 Round 15 Test Metrics:
   Loss: 0.2399, RMSE: 0.4898, MAE: 0.4066, R²: -1.8909

📊 Round 15 Test Metrics:
   Loss: 0.1437, RMSE: 0.3791, MAE: 0.3116, R²: -0.7320

📊 Round 15 Test Metrics:
   Loss: 0.1167, RMSE: 0.3416, MAE: 0.2841, R²: -0.4058

📊 Round 15 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2629, R²: -0.1539

📊 Round 15 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2503, R²: -0.0142

📊 Round 15 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2499, R²: -0.0099

📊 Round 15 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2495, R²: -0.0065

📊 Round 15 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2492, R²: -0.0034

============================================================
🔄 Round 30 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0815, val=0.0977, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0812, val=0.0975, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 30 Summary - Client client_15
   Epochs: 33/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0123
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0163
============================================================


============================================================
🔄 Round 31 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0864, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0846, val=0.0862, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 31 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0163
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0123
============================================================


============================================================
🔄 Round 33 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 33 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0254
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0070
============================================================


============================================================
🔄 Round 34 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 34 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0240
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0162
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2487, R²: 0.0012

============================================================
🔄 Round 35 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 35 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0172
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0366
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2487, R²: 0.0014

============================================================
🔄 Round 40 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 40 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0222
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0193
============================================================


============================================================
🔄 Round 42 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 42 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0265
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0067
============================================================


============================================================
🔄 Round 43 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0882, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0878, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0835, val=0.0875, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 43 Summary - Client client_15
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0056
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0287
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0252
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0059
============================================================


============================================================
🔄 Round 48 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 48 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0213
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0083
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 49 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0965, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0818, val=0.0962 (↓), lr=0.000001
   • Epoch  21/100: train=0.0815, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 49 Summary - Client client_15
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0090
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0213
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

============================================================
🔄 Round 50 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 50 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0187
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0066
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0041

📊 Round 50 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2484, R²: 0.0044

📊 Round 50 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2484, R²: 0.0044

📊 Round 50 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2484, R²: 0.0045

============================================================
🔄 Round 54 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 54 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0218
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0028
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 56 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 56 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0194
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0002
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 57 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0873, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0842, val=0.0870 (↓), lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0866, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0839, val=0.0863, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 57 Summary - Client client_15
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0040
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0279
============================================================


============================================================
🔄 Round 59 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0814, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch  21/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0852, val=0.0805, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0851, val=0.0803, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 59 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0066
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0272
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

============================================================
🔄 Round 60 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 60 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0170
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0010
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

============================================================
🔄 Round 62 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 62 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0130
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0075
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

============================================================
🔄 Round 64 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0853, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0846, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0840, val=0.0843, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0839, val=0.0841, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 64 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0018
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0356
============================================================


============================================================
🔄 Round 65 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 65 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0169
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0132
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

============================================================
🔄 Round 68 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 68 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0172
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0037
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

============================================================
🔄 Round 70 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 70 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0129
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0173
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

============================================================
🔄 Round 72 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 72 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0118
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0085
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0060

============================================================
🔄 Round 76 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 76 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0094
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0177
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

============================================================
🔄 Round 80 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 80 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0160
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0098
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0058

============================================================
🔄 Round 85 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0852, val=0.0804, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 85 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0046
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0206
============================================================


============================================================
🔄 Round 86 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 86 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0092
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0172
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2482, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0055

============================================================
🔄 Round 93 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 93 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0080
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0263
============================================================


============================================================
🔄 Round 97 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 97 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0115
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0102
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

📊 Round 97 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

============================================================
🔄 Round 103 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 103 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0170
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0008
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

============================================================
🔄 Round 107 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0989, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0809, val=0.0987, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 107 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0069
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.0115
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0051

📊 Round 107 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 110 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 110 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0147
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0082
============================================================


============================================================
🔄 Round 111 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0838, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 111 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0051
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0191
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 115 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 115 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0137
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0021
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 117 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0877, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0832, val=0.0874, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 117 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0042
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0283
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0056

============================================================
🔄 Round 120 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0829, val=0.0893, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 120 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0058
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0257
============================================================


============================================================
🔄 Round 121 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0885, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0832, val=0.0882 (↓), lr=0.000001
   • Epoch  21/100: train=0.0831, val=0.0878, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0876, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 121 Summary - Client client_15
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0047
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0336
============================================================


============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0113
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0092
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0056

============================================================
🔄 Round 124 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 124 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0100
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0221
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0056

📊 Round 124 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0056

============================================================
🔄 Round 126 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0765, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0860, val=0.0762, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0859, val=0.0761, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 126 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0042
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0133
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0058

📊 Round 126 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2482, R²: 0.0058

============================================================
🔄 Round 128 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0822, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 128 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0068
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0051
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

============================================================
🔄 Round 130 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0856, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0839, val=0.0853, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0838, val=0.0852, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 130 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0040
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0266
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0059

📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0057

============================================================
🔄 Round 138 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0856, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0839, val=0.0854, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 138 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0063
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0121
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2482, R²: 0.0058

============================================================
🔄 Round 140 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 140 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0122
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0060
============================================================


============================================================
🔄 Round 141 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 141 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0102
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0067
============================================================


============================================================
🔄 Round 144 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0874, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0831, val=0.0872, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0870, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 144 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0026
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0229
============================================================


============================================================
🔄 Round 145 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 145 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0077
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0169
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2482, R²: 0.0058

============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0113
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0093
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0058

============================================================
🔄 Round 151 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 151 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0114
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0026
============================================================


============================================================
🔄 Round 155 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0855, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 155 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0022
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0274
============================================================


============================================================
🔄 Round 157 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 157 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0138
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0115
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0055

============================================================
🔄 Round 158 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 158 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0123
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0011
============================================================


============================================================
🔄 Round 159 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 159 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0081
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0224
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0053

📊 Round 159 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

📊 Round 159 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0796, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0849, val=0.0793, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0056
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0105
============================================================


============================================================
🔄 Round 167 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 167 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0145
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0024
============================================================


============================================================
🔄 Round 168 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0848, val=0.0810, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0847, val=0.0809, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 168 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0034
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0214
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 169 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0840, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0842, val=0.0837, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 169 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0054
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0139
============================================================


============================================================
🔄 Round 170 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 170 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0098
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0060
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0055

============================================================
🔄 Round 171 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 171 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0061
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0229
============================================================


============================================================
🔄 Round 172 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 172 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0139
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0137
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 173 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 173 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0118
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0199
============================================================


============================================================
🔄 Round 174 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 174 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0111
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0049
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 177 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 177 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0131
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0110
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0053

============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0172
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0027
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 179 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 179 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0067
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0204
============================================================


============================================================
🔄 Round 180 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 180 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0171
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0048
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0053

============================================================
🔄 Round 181 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0914, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0823, val=0.0912, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0822, val=0.0910, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 181 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0030
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0170
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

============================================================
🔄 Round 183 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 183 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0095
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0097
============================================================


============================================================
🔄 Round 186 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0846, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0838, val=0.0844, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 186 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0032
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0200
============================================================


============================================================
🔄 Round 188 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 188 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0105
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0052
============================================================


============================================================
🔄 Round 189 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0847, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0842, val=0.0844, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 189 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0256
============================================================


============================================================
🔄 Round 190 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 190 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0085
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0107
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2483, R²: 0.0054

📊 Round 190 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0053

============================================================
🔄 Round 198 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 198 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0040
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0295
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 199 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 199 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0111
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0048
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0053

📊 Round 199 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 204 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 204 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0087
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0123
============================================================


============================================================
🔄 Round 206 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0847, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 206 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0027
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0199
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 219 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 219 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0126
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0039
============================================================


============================================================
🔄 Round 220 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 220 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0141
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0040
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

📊 Round 220 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

============================================================
🔄 Round 224 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0869, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0866, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 224 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0057
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0092
============================================================


============================================================
🔄 Round 225 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 225 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0157
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0013
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

============================================================
🔄 Round 228 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 228 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0124
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0002
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 230 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0931, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0816, val=0.0927, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 230 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0055
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0239
============================================================


============================================================
🔄 Round 231 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0928, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0820, val=0.0925, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 231 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0015
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0448
============================================================


============================================================
🔄 Round 234 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 234 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0120
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0008
============================================================


============================================================
🔄 Round 235 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0785, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0852, val=0.0782, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 235 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0037
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0406
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 236 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 236 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0083
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0112
============================================================


============================================================
🔄 Round 237 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 237 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0086
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0100
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 238 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0851, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0848, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 238 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0013
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0306
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 240 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 240 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0094
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0061
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0051

📊 Round 240 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 244 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 244 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0051
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0224
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 245 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0920, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0917, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 245 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0010
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0328
============================================================


============================================================
🔄 Round 247 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 247 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0126
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0110
============================================================


============================================================
🔄 Round 248 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 248 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0146
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0003
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

📊 Round 248 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

============================================================
🔄 Round 253 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 253 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0147
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0027
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

============================================================
🔄 Round 255 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 255 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0098
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0112
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

📊 Round 255 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

📊 Round 255 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 259 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 259 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0094
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0098
============================================================


============================================================
🔄 Round 260 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0876, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 260 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0018
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0327
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 263 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0846, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 263 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0028
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0495
============================================================


============================================================
🔄 Round 267 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0851, val=0.0794, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 267 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0003
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0469
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

============================================================
🔄 Round 270 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 270 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0129
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0049
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

============================================================
🔄 Round 271 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 271 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0094
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0090
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

📊 Round 271 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 279 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0921, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0828, val=0.0919 (↓), lr=0.000001
   • Epoch  21/100: train=0.0827, val=0.0915, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0826, val=0.0912, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0826, val=0.0910, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 279 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0001
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0408
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

📊 Round 279 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

📊 Round 279 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 284 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0816, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0843, val=0.0813, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 284 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0003
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0335
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 286 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 286 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0084
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0082
============================================================


============================================================
🔄 Round 287 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 287 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0114
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0102
============================================================


============================================================
🔄 Round 288 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0831, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0828, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 288 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0043
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0095
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0050

============================================================
🔄 Round 291 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0842, val=0.0840, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 291 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0166
============================================================


============================================================
🔄 Round 292 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 292 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0091
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0040
============================================================


============================================================
🔄 Round 293 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0866, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0863, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 293 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0043
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0267
============================================================


============================================================
🔄 Round 294 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0905, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0902, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 294 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0007
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0532
============================================================


============================================================
🔄 Round 295 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 295 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0144
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0035
============================================================


============================================================
🔄 Round 296 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 296 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0059
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0099
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0052

============================================================
🔄 Round 297 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 297 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0054
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0139
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0051

============================================================
🔄 Round 301 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 301 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0079
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0083
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 304 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 304 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0092
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0041
============================================================


============================================================
🔄 Round 306 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 306 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0071
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0121
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

📊 Round 306 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 309 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 309 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0071
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0121
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 310 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 310 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0147
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0050
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 311 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 311 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0103
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0002
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

📊 Round 311 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0047

============================================================
🔄 Round 313 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 313 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0103
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0020
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

============================================================
🔄 Round 316 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 316 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0102
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0027
============================================================


============================================================
🔄 Round 317 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 317 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0080
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0074
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

📊 Round 317 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

============================================================
🔄 Round 319 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 319 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0038
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0255
============================================================


============================================================
🔄 Round 320 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0738, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0868, val=0.0735, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 320 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0008
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0964
============================================================


============================================================
🔄 Round 321 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 321 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0130
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0062
============================================================


============================================================
🔄 Round 324 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 324 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0115
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0057
============================================================


============================================================
🔄 Round 325 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 325 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0101
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0082
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0045

============================================================
🔄 Round 326 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0843, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0840, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 326 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0025
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0150
============================================================


============================================================
🔄 Round 327 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0864, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0831, val=0.0861, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0860, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 327 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0205
============================================================


============================================================
🔄 Round 328 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 328 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0096
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0016
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0048

============================================================
🔄 Round 330 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 330 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0040
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0228
============================================================


============================================================
🔄 Round 332 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 332 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0049
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0172
============================================================


============================================================
🔄 Round 334 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0843, val=0.0831, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0843, val=0.0829, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 334 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0022
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0466
============================================================


============================================================
🔄 Round 335 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0755, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0862, val=0.0752, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 335 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0028
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0126
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0049

============================================================
🔄 Round 345 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0902, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0824, val=0.0899, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 345 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0006
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0248
============================================================


============================================================
🔄 Round 347 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0925, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0818, val=0.0922, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 347 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0053
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0096
============================================================


============================================================
🔄 Round 349 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 349 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0064
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0141
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

============================================================
🔄 Round 352 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 352 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0113
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0056
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

============================================================
🔄 Round 354 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 354 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0045
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0186
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

📊 Round 354 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

📊 Round 354 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0046

============================================================
🔄 Round 357 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0925, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0922, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 357 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0007
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0317
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0045

============================================================
🔄 Round 358 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 358 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0138
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0099
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2483, R²: 0.0045

============================================================
🔄 Round 361 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 361 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0120
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0019
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 366 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 366 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0135
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0010
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

============================================================
🔄 Round 370 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 370 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0090
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0073
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 374 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 374 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0096
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0076
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 374 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 379 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 379 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0124
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0026
============================================================


============================================================
🔄 Round 381 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 381 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0113
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0016
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 383 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 383 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0084
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0107
============================================================


============================================================
🔄 Round 384 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 384 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0090
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0081
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0037

📊 Round 384 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 388 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0824, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0848, val=0.0820 (↓), lr=0.000001
   • Epoch  21/100: train=0.0847, val=0.0817, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0846, val=0.0814, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 388 Summary - Client client_15
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0018
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0220
============================================================


============================================================
🔄 Round 389 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0870, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 389 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0217
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

📊 Round 389 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 393 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0857, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 393 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0011
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0269
============================================================


============================================================
🔄 Round 394 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 394 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0104
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0039
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 396 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0844, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0839, val=0.0841, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 396 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0049
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0054
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 398 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 398 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0085
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0099
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

📊 Round 398 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

📊 Round 398 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 402 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0837, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 402 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0042
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0157
============================================================


============================================================
🔄 Round 405 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0977, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0806, val=0.0974, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 405 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0054
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0088
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0041

📊 Round 405 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0041

============================================================
🔄 Round 410 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 410 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0083
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0046
============================================================


============================================================
🔄 Round 411 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 411 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0101
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0044
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0041

📊 Round 411 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0041

============================================================
🔄 Round 419 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 419 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0087
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0068
============================================================


============================================================
🔄 Round 420 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 420 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0080
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0089
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 425 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 425 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0075
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0122
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 429 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 429 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0092
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0044
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

============================================================
🔄 Round 433 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0841, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0838, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 433 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0298
============================================================


============================================================
🔄 Round 434 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 434 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0141
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0102
============================================================


============================================================
🔄 Round 435 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 435 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0103
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0031
============================================================


============================================================
🔄 Round 436 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 436 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0081
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0080
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

📊 Round 436 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

📊 Round 436 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

📊 Round 436 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

📊 Round 436 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 444 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 444 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0056
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0162
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 446 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 446 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0072
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0138
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 450 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 450 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0089
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0069
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 453 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 453 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0054
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0226
============================================================


============================================================
🔄 Round 454 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 454 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0113
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0059
============================================================


============================================================
🔄 Round 457 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 457 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0107
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0002
============================================================


============================================================
🔄 Round 459 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 459 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0119
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0016
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 460 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 460 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0095
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0081
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 462 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0835, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0843, val=0.0833, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0842, val=0.0831, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 462 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0093
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 465 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 465 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0082
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0066
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 467 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0829, val=0.0879, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 467 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0026
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0237
============================================================


============================================================
🔄 Round 468 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 468 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0081
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0052
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 472 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 472 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0100
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0009
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 475 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 475 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0044
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0241
============================================================


============================================================
🔄 Round 476 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 476 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0105
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0007
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 476 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 476 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 480 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0827, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0824, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 480 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0036
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0099
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

📊 Round 480 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 484 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 484 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0088
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0054
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 486 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 486 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0132
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0012
============================================================


============================================================
🔄 Round 488 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 488 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0102
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0018
============================================================


============================================================
🔄 Round 490 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 490 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0084
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0041
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 494 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 494 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0090
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0087
============================================================


============================================================
🔄 Round 495 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 495 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0096
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0004
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 495 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 498 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 498 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0056
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0156
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 501 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 501 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0096
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0008
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 506 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 506 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0094
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0012
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 507 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 507 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0054
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0161
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 509 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 509 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0067
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0116
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 510 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0856, val=0.0765, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 510 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0000
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0725
============================================================


============================================================
🔄 Round 514 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 514 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0088
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0015
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 517 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 517 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0041
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0193
============================================================


============================================================
🔄 Round 519 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 519 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0089
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0001
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 522 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 522 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0108
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0003
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0039

============================================================
🔄 Round 525 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0870, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0867, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0834, val=0.0865, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 525 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0003
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0259
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

============================================================
🔄 Round 529 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 529 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0053
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0135
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0040

📊 Round 529 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 532 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 532 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0117
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0069
============================================================


============================================================
🔄 Round 533 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 533 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0136
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0000
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 533 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 533 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 533 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 538 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0830, val=0.0881, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 538 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0034
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0102
============================================================


============================================================
🔄 Round 539 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 539 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0101
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0001
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

============================================================
🔄 Round 540 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0848, val=0.0798, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 540 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0021
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0233
============================================================


============================================================
🔄 Round 542 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 542 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0036
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0212
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

📊 Round 542 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 542 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 547 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0898, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0826, val=0.0895, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 547 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0049
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0043
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 547 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 549 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 549 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0170
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0086
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0036

📊 Round 549 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 549 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0035

============================================================
🔄 Round 553 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0887, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0824, val=0.0884, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0823, val=0.0883, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 553 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0014
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0115
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 553 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 557 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 557 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0075
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0050
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 560 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 560 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0085
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0040
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 560 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 562 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0929, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0816, val=0.0926, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 562 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0027
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0205
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 562 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 566 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 566 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0075
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0065
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 567 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 567 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0098
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0020
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 567 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 570 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 570 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0072
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0076
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 570 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0036

📊 Round 570 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0036

============================================================
🔄 Round 577 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0953, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0813, val=0.0951 (↓), lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0947, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0811, val=0.0944, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0811, val=0.0942, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 577 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0009
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0428
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 578 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 578 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0089
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0030
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 579 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 579 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0094
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0026
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 579 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 579 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 579 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 583 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0915, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0912, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 583 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0018
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0185
============================================================


============================================================
🔄 Round 585 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 585 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0070
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0048
============================================================


============================================================
🔄 Round 587 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 587 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0083
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0017
============================================================


============================================================
🔄 Round 588 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 588 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0104
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0029
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 588 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 592 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 592 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0068
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0048
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

📊 Round 592 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 595 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 595 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0103
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0022
============================================================


============================================================
🔄 Round 596 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 596 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0088
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0100
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0037

============================================================
🔄 Round 597 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 597 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0098
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0015
============================================================


============================================================
🔄 Round 598 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 598 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0113
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0101
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: 0.0038

============================================================
🔄 Round 599 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 599 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0056
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0091
============================================================


============================================================
🔄 Round 600 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 600 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0054
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0119
============================================================


============================================================
🔄 Round 605 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 605 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0064
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0082
============================================================


============================================================
🔄 Round 607 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 607 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0048
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0138
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0036

============================================================
🔄 Round 609 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 609 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0078
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0019
============================================================


============================================================
🔄 Round 610 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 610 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0068
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0067
============================================================


============================================================
🔄 Round 611 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 611 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0054
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0125
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 611 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 613 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 613 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0049
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0163
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 615 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 615 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0053
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0173
============================================================


============================================================
🔄 Round 616 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0830, val=0.0875, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 616 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0034
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0039
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 616 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 619 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0802, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0849, val=0.0799, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 619 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0005
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0241
============================================================


============================================================
🔄 Round 620 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 620 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0162
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0035
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

============================================================
🔄 Round 622 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 622 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0091
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0035
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 622 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 622 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 627 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0821, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0845, val=0.0819, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0844, val=0.0817, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 627 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0018
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0087
============================================================


============================================================
🔄 Round 630 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0845, val=0.0821, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0845, val=0.0819, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 630 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0010
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0952
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 630 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 630 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 635 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 635 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0063
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0086
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 638 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0770, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0856, val=0.0767, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 638 Summary - Client client_15
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0023
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0228
============================================================


============================================================
🔄 Round 639 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 639 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0048
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0143
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0035

📊 Round 639 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 647 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 647 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0154
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0061
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 647 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 647 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 652 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0840, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0839, val=0.0839, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 652 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0021
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0041
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0036

============================================================
🔄 Round 654 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 654 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0073
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0012
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

============================================================
🔄 Round 658 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 658 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0046
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0135
============================================================


============================================================
🔄 Round 659 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 659 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0069
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0056
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 659 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 662 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 662 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0091
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0015
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 664 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 664 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0072
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0061
============================================================


============================================================
🔄 Round 667 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0821, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 667 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0013
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0219
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 669 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 669 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0088
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0048
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0032

📊 Round 669 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 673 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0846, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 673 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0156
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 676 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0833, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 676 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0012
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0178
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0034

📊 Round 676 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 678 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 678 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0061
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0089
============================================================


============================================================
🔄 Round 680 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 680 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0091
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0032
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 682 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 682 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0072
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0028
============================================================


============================================================
🔄 Round 683 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 683 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0063
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0074
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0033

============================================================
🔄 Round 689 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0839, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0840, val=0.0836, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 689 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0101
============================================================


============================================================
🔄 Round 692 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 692 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0040
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0201
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 695 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 695 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0063
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0075
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 697 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 697 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0108
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0025
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0030

📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 697 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 704 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 704 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0064
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0100
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 704 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 704 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 704 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 711 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0879, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 711 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0001
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0223
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

📊 Round 711 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 716 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 716 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0062
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0123
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

📊 Round 716 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 718 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0839, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0836, val=0.0838, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 718 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0046
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 720 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 720 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0043
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0187
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

📊 Round 720 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 723 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 723 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0065
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0092
============================================================


============================================================
🔄 Round 724 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 724 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0111
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0051
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

📊 Round 724 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

📊 Round 724 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 724 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 724 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 729 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 729 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0045
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0165
============================================================


============================================================
🔄 Round 730 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 730 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0100
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0023
============================================================


============================================================
🔄 Round 731 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0843, val=0.0818, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 731 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0020
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0079
============================================================


============================================================
🔄 Round 732 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 732 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0053
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0132
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0032

============================================================
🔄 Round 733 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0845, val=0.0826, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0844, val=0.0824, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 733 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0014
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0596
============================================================


============================================================
🔄 Round 734 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 734 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0071
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0024
============================================================


============================================================
🔄 Round 735 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 735 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0066
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0034
============================================================


============================================================
🔄 Round 738 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 738 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0083
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0020
============================================================


============================================================
🔄 Round 739 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0835, val=0.0866 (↓), lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0834, val=0.0859, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0834, val=0.0857, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 739 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0001
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0396
============================================================


============================================================
🔄 Round 741 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 741 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0064
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0063
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

📊 Round 741 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

============================================================
🔄 Round 746 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0925, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0922, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 746 Summary - Client client_15
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0031
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0164
============================================================


============================================================
🔄 Round 747 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 747 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0060
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0047
============================================================


============================================================
🔄 Round 748 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0816, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0813, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0843, val=0.0812, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 748 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0015
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0162
============================================================


============================================================
🔄 Round 750 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 750 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0041
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0171
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0031

📊 Round 750 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

📊 Round 750 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 755 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 755 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0067
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0062
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

📊 Round 755 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

📊 Round 755 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0026

============================================================
🔄 Round 759 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 759 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0068
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0076
============================================================


============================================================
🔄 Round 760 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 760 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0100
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0006
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0024

📊 Round 760 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 763 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 763 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0093
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0024
============================================================


============================================================
🔄 Round 764 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 764 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0089
   Val:   Loss=0.0876, RMSE=0.2961, R²=-0.0066
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0025

📊 Round 764 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0025

============================================================
🔄 Round 769 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 769 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0153
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0016
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0024

============================================================
🔄 Round 770 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0859, val=0.0773 (↓), lr=0.000001
   • Epoch  21/100: train=0.0858, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0858, val=0.0766, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 770 Summary - Client client_15
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0006
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0455
============================================================


============================================================
🔄 Round 773 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0982, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0805, val=0.0979 (↓), lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 773 Summary - Client client_15
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0023
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.0195
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

📊 Round 773 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 776 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 776 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0060
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0079
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0028

============================================================
🔄 Round 778 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0846, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 778 Summary - Client client_15
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0022
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0155
============================================================


============================================================
🔄 Round 779 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 779 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0044
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0132
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

📊 Round 779 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2485, R²: 0.0030

============================================================
🔄 Round 783 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 783 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0113
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0051
============================================================


============================================================
🔄 Round 784 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0887, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0826, val=0.0885, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0825, val=0.0883, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 784 Summary - Client client_15
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0034
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0004
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: 0.0029

============================================================
🔄 Round 785 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0861, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0834, val=0.0858, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 785 Summary - Client client_15
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0124
============================================================


❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
