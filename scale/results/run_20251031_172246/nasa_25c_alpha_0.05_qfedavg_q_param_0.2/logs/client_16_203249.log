[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9818194a-4f35-4f7a-8a05-9e9f66ef28c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfd20bf-e79b-43b4-8037-6441df44a5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f549bf-c333-4275-bcda-ede1084e8efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f7e881-7a84-4f20-8d3a-8580db7dcd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 291e597e-d6e6-4cf8-88a7-15931b1e2b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41893c7d-f0e6-4856-84ee-7cae7557caeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd65148c-07a5-4907-8a85-2cfec916d135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b6dff9-bc5f-4c0f-b910-c977e7264c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70398458-e515-45ca-b656-321a6990a687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9460bb70-bef9-480b-aad6-f80accfed3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6faabd67-9bd2-4adc-a2d9-d7d74ca6aa0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc2ae8d-60d6-4282-aff9-d8bcf0b8beed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecf2206-41ec-4b03-8e9e-b6ba90d23191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2db9a0-5b35-4a0d-af1e-e40d7b274a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8d0d08-b2eb-44d5-a8d9-fe56505f0518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa31fe7d-a15e-4963-b6c4-08d8df8846ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae410fa5-f6aa-40fd-a068-382b2064cd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2266c240-2a95-414e-89e9-5ad18d9d415b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2b2d83-ac9f-4884-b52a-798fcd48ad62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228e7dac-5770-49fc-8757-0c6b9ffe7d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8258e06-669c-4a44-9364-c848a2ed3f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28098d7-44da-41cf-8e78-66f7b4f2f488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1508af-6202-4431-9da0-822407ac683a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2e8a9c-3898-4f49-a99f-0edc1f629288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9762196-11d7-4c80-908d-cef678d5c1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c896ca-5617-4b95-9f85-7480f130d0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3730545-4162-47dd-9b33-c136f67e075e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0ac083-9c36-44e0-8fb2-874fbd8ffd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3afbb0-72aa-46ed-a2c3-1637a6d2cff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366b305e-31b8-4715-93be-0656556d3be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a05261da-935e-4413-be3c-89100683bd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805e2f6f-6cc3-47f2-9e52-378a4927786b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c085e371-f623-4fad-9cfa-4a70d3978833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b682b4-ead3-4149-94a1-e8b84fd26745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b9d1a1-a167-48ff-b594-6a776cc9ac2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ec4beb-98ca-4ff6-9b5b-6d84b1858afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ebf8f7e-efb8-46c2-9cf1-edb8d9bdd8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7860d33-3488-44ff-9991-5ebd237457d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d50b950-8e92-4c49-a228-f31a116fec2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abb1393-4eb5-40b0-a91d-89cb844ac9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4be91e-88c6-457d-8883-93929cd3b6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3b3d67-8721-4e2b-897f-8cec5873b752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3013d58c-f64c-4063-8496-54fa99ec404c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2aa576-ee25-48e2-814b-8a141d07a3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99afc979-bc7a-4372-bfb3-0bc476fa1676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0742e871-d866-4ea8-939b-c418fe23193f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88da80d1-252d-4442-b9a9-6bd2cef9961d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08a367d-12eb-41a9-9776-42fea0565517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5363a704-11dc-4f1f-9f19-e6d47c13ba29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d1a40b-c106-4e9c-b99e-0c2979bfde5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b02d0ad-37c5-48f3-981a-052e379b5161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b84fb4-fcf2-4e22-ac8e-320423279d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4b25b3-6f75-40c4-97c3-04a3e4282a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e438c1d1-6fd3-4aff-909e-0e8f60bc8942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1761cde-f24d-4526-88f8-7d1a715b3c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb791da-40c9-43ec-94c6-ecd6c1e53b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca8638e-b7fd-4aba-ae14-7eca8a398406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067c0b3a-cde5-4664-837a-2f1e823c0b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53116be-b5e8-4c95-b4ca-c629a8dc0d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18dc7bcb-260d-458f-994e-3ff4cc84ce7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c6b668-d9ef-45f0-b72d-329064c97947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b457ca-05a8-4f54-ad12-19375e54c93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739792bd-b460-4c58-a2af-b2fdcca7218d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f60c235-a5e1-4c95-a759-1f37e1803c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd04c921-bcd3-485f-a0f3-1f865e9af9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffdbfafd-666a-40b7-81f8-1ced21e71fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cea365-c352-4837-8284-6b9a2c8cba1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65201845-5093-4040-8a66-fe8f28902328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b894977-88b8-41ed-b058-64fab74811a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af679279-ffb6-44be-a878-c5018b602889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a67a46f-f8c3-41dc-9211-81eb472ac494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba522da8-2250-4f43-9c96-afb1cdd561f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef70429c-34d7-4714-aefd-eaaa664e42b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f055f8e1-cb1a-4b58-8c97-bacf8b93cd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b542b1bb-a527-412d-80d4-4f38776ce39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cf1572-e0f8-41d0-9af6-cdf4b0ac0a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fceb44-feee-455b-a21d-8e46b9a5d40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64def206-79ae-489f-b4fd-196cef0653c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829b4c93-ecb1-4e07-9209-0453fe48c2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37cb117a-e728-4262-8178-426a28740fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840d2fb2-7f63-4882-b71d-a70f3f90126c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4139be83-f81c-490b-9730-19dc90a5e1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94ab861-7462-4d79-8b47-9b756cc80819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cee332a-37c0-4170-b893-98485afee66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48043888-7fa8-4e97-9743-215764ff0e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f6a390-7d13-4e50-8427-16c513541c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216202a3-c293-4ae5-ad1e-6f1dcf51bd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a9d79c-22a0-4c0f-be13-891385a852eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba0f9ff-c29f-410b-ae83-6e40cb001b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2f7a5b-9ac2-46bd-abc8-fa3512a62970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d91329d-a9b9-45ab-8b0b-69cca0d21ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52a9076-7a80-4d22-8ac1-6618caff33b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23a7f2f4-30c7-4152-a327-e08c85f939b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8123a514-23c3-4b8b-9816-50789b3a9879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc53cf3c-41ed-4912-b401-5d120d0bd06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fd4482-ddd4-4f28-990b-b79e0d38a569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf78f40-970f-4164-80d7-a9195eeb125c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba94743-aee1-4830-b6cf-fe4d629134e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005b642d-d36a-4bcd-97bf-eea3c40e8c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85db321-e3a5-4003-a08b-d70188fb3aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0e01f3-ad0a-477a-8a3d-6dd4c2140e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0a25e1-2811-4528-8806-698ca66f733f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b41196f-7313-4ece-90f1-f78a3385b1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe5479a-685c-4112-af51-73766edaeeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b92b455-4fa4-443c-ac73-689e2b286de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdc7d75-33a2-4ab2-a3f6-b7283044d842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd02bec-9a74-4eb7-8330-eae60aa9937f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3ae4d2-7093-4255-a5d3-ba29a68f784b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac2280c-a0b7-4eff-a09e-4b3ca2fbe34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b5f86e-5f0e-4012-b592-016dde827071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e590a6-00df-43fe-862a-411fbd651317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f257f797-a446-4c02-8a83-7e22c08a342d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088fcdec-a0b3-41f4-b40f-070d562ff06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 134a357a-b1d0-4525-a033-e364983f7826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d19699-3efe-43b9-ad5a-ff6809df6e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0193292c-f7dc-45a1-89b7-c51e2383f265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852160c2-4e10-417f-a1e4-e6d1fa26747c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1615b32-2981-45d2-960c-f14c1589ca90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f80da3-4e07-489f-af3e-bf4f1151b56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a094834d-d4c9-48e6-8030-652641334e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3b1274-0d44-497a-9f58-ac92890570c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ee0b24-0415-401e-a516-8ca4a8b02e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8094dfb3-e837-4ca3-bba1-72e2349875f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0e065c3-e76a-4a6f-bcd1-7b009be0e1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151475a5-308b-47b5-a204-a34e7f5a97b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b476698c-86c3-4fa2-a867-f4c13c93ee45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751f5fae-b97d-4f4f-9ab1-530fb925a6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1904e8-8503-45fd-aa97-3cdcaca2c6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d68eb7-63d4-48e6-976f-3773b79f08f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50a5823-37c2-4be4-83b6-d66440453905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcbdedf-7b71-4273-bc60-2066385a5102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 526358b3-a47f-497a-b3e2-2ed67da12e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6a9816-af14-4f59-b24e-c761bcc2cfa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1d5dba-1d24-4240-8686-bee88991d2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6960ae3-a786-42e4-902b-bba3fc6d2ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f6692c-3e16-45af-9a26-2cee2c53bb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f74a085-d000-4e16-9291-d397368b3e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6ed05e-2fef-4471-abbd-6784f12c957c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909fdbe2-4acd-4e14-ae83-27a3f50faf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052ad7f8-17e8-4a0c-81a4-81e3daaf2031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dd3974-edff-49c4-b64d-603305c40299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9524bb6f-3245-47dc-97ee-40174583021a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a0cc02-ccaf-4bda-8e69-77317e37f72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506403f9-386e-4f0c-b47c-8e721fedcf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab7d418b-884c-4715-83c2-ac56c44213dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d49b5dcf-7f9a-4aab-8fd7-477bdf6f9ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a50a708-1e3e-47b9-81bb-bf9ec162361f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1800860d-2da3-49be-929f-5f11255452e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f8417f-662b-43fe-93bb-569711c28623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b9f00b-7827-47c0-9d66-af4fcd9d47c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec85495e-9815-41cb-b0ac-61008d67e07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3cf2578-30c5-4136-911d-5b12dcd77563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb028a6-4fdd-4cf0-ab14-403eb4bffecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efcf24f5-b088-42c4-8088-e74782137678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf93c42-87d8-4cc8-ba6c-7c5a596f4fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d56e2c3-b9d1-45e4-91fa-731d7bdf3b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0ce319-da06-4cec-9beb-b5f07bf357d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcd7f219-dbc9-483c-b56d-b1536c87cfed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330608f8-a53a-4480-92b5-f895be5a2fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bed458-f63e-4714-ba97-799462634ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb399c9-6fab-4ceb-9aee-819e51d4e28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc39125-52df-4cd9-9f26-0e5322fa8769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ec5138-ea2d-4507-9e64-ff3fd943f6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af25587-38ca-4eda-809b-8e55b6203106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168db188-935e-4098-9787-fc760b40afc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc19f252-b917-4d29-9363-aa4281fd7c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2c45bd-88f4-49c0-b566-e28872d83e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89eff57b-fc34-40e8-be5a-139194fe3d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1879c4e0-fc17-4ea8-84a2-824c63dc789c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99d4d17-82aa-47a5-af3f-9e6574d1a18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce32b954-5b5a-4eb6-9c3f-4069a9bcba6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525a4d3b-4a62-4240-ba62-f24c6620bbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d82373-a3d0-4e22-a49e-efb5aa9f1a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8787a68e-c48d-412d-b1bd-27265f2950f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330b8b20-02b7-4660-a43e-dbe6074f91a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02015f15-be80-4fd2-b9e1-bede697003f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed81f6ac-1264-471d-98c7-5974aa2fc73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7cb5680-da6a-4938-b410-f970b78b6da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4e9571-d02e-4b7c-a3ac-a12f4da5f108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6138ef-6eb1-47d9-bfcf-e7b1a086484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f70ae294-18cc-4669-905c-ea922d13bd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b336971-33d6-49f8-accb-19e332b43473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fedd1b-ad5c-405f-8b82-7dfc1e25e411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f16393-f177-4d2e-b43b-ffda98a3df69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4167be9-e3b5-43d8-a6c0-2637d3f9c000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb894a7-a282-4756-ad96-0f1a5ce77e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc668d56-a377-4186-825c-de2ea2ab3292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628da4a9-63bc-4767-b28a-c40845102cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0092972a-6d27-4fc9-9917-51bbe57bc2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360fe707-8864-4eab-9e85-2119939e081e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2c004d-c05f-476c-b9dc-7f6e603f0cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd8e8f8-838f-4abc-b461-5865e7f546b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7354a1a9-a529-4872-9d1d-4d93382b4883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8361b23-a2d0-48ac-aee3-5d76f9ed5b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5662698c-a93c-446c-be20-cb434c321b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17588fbd-bd8a-4bd8-babd-75b1eba3cf03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2bc855-2e06-4502-8c29-4f8bd278b828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6cf53d-a711-4666-9783-a1604ee13db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07010a52-1c26-4f54-b400-7ef9928cf45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5443714b-836d-4158-9da2-fab0f9ad9352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97559cf5-fa53-492e-b277-f81e0a2e23a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d0f164-a74d-4b94-bb5d-84b5ac2a2cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8badbcf-0c27-4f52-bac7-7f212cb5c800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453f4410-4ccd-4e57-baf7-d2ef375e184b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b4bd8f-8f1d-417b-a4e3-f7e6938f1758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde86ff7-a81d-48a2-a9f0-605f547d5c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2147a9d-ee36-47ea-ada1-ca3435366c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1d4a43-1705-4268-aad8-4cee94948330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef013d3-2c7c-4947-8ec6-b4a8fd1d25c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15310aa5-a9e2-437c-ab24-c6143a088efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6eda7a7-c5d1-4f89-9ec8-320c24435e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5978bba-80c0-45c5-8b6f-fcc6adafba41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813fc98c-516f-4f19-9e9d-1b668317d640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d34008-0cbd-43d1-8a58-82277e4b0a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e19876-5f53-4489-975f-ff271cceb60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c668ca6-2904-4f16-bf97-32b29cb1787c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31952a2-9601-4d8d-a2d0-9b2874921872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78cff13-06ec-4000-b405-850dcadba465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cf5c3d-fd54-497d-a0fd-dfc0c969b753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91c1d38-b86d-4269-9215-45ba18e5e1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3902117-03f7-4292-bee5-ec00cad6b0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f5d971e-0a49-4415-964f-5499635f6c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99c613f-522c-482b-bcf4-a621efb37ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d788c6ca-5f4e-43d6-b729-f9e6b7a8e15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41930b7-bc3d-45c3-9447-46a901d392a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17876b13-038e-4fe2-9b72-52d601645f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6c66d7-e0e3-4cc7-8c97-76702e8a23d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03266ba3-fd78-40bb-aaea-a701918aba79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b748aa-3677-467e-a6de-c58ccb608cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ff984e-ae22-4553-af4a-4a9e931f3735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34efb922-5890-45e4-a207-d78efccf72fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc2f9a6-b430-46a8-963c-da5ed7d75013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb7a8a8-51de-482c-acfb-c795ebcf9bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d66d6d-820b-4d24-b2bc-04db308a3cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6892e1-1336-4e8b-bf34-5d8d3c25bb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c96ee4f-4f63-4892-8254-0351a0f65d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff0c6c0-1817-4fd5-a96d-cc44e5acb4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3935632b-4518-4180-888f-027416b2be7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8264889-660d-46c5-9163-180a41e13271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message addc47d4-3301-4ae3-b5fe-7c21dfcb6acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a94f8e-f07d-4775-b29e-9999bb68e725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dedf9fb-ddbd-43f4-8ab6-455d5270bdc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8d441a-c74b-4085-a351-fecff52ae81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290834f2-b7ea-4932-bcc2-40f2df925cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f98a182f-6bde-476d-8ece-2774f916a39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5823709d-0193-4339-9983-6d6384b4a889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3ddc9d-354c-4283-95f8-d7de35bbbf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ff76d0-79e1-4d47-9499-1af04d516264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc74d255-92c7-47cb-afe6-a1d7e2c10edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad91b090-a4e2-434c-9e79-dc5de6124a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6372c4d7-a68d-4427-9664-46d7c5727dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a01ca60-0f0f-4bf6-b3a9-04cf1fd93a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c91b16-81ff-40a2-91be-f0c01b2ed25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9040c200-388a-4e67-83fc-b6bc163fc811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb9f18be-e974-4e36-a513-5d80cc2499f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e71975-8185-4839-9d71-b7892743f4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d875583d-e802-4fb5-b023-3556bc74de98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e95d8e7-2c35-4d27-8a06-4524834d1d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05843751-8726-4457-933d-29220fbf7bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a961001a-6b65-4798-8440-5362b29ecae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b46a6c-8929-4e4c-ab56-860865020bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28724ca0-b196-4996-b3bc-b480f12114d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc91cd0-b6b7-4cf8-bcbd-51aa4ca370ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2fb5e3-81c8-4d7e-b701-4ded26baa81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac5a107-f653-49de-a351-ad02f83658aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6570a3e4-81bc-4e2e-b3e7-6e3cb8eec246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0affe8e1-a5ec-4779-a15b-415df71acad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d54cf45-7567-4e34-a58b-87b2663e197f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36122c6-9b10-41d5-a0a9-7127f39bdac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc59bf1-ca66-4d71-b86b-eb088b86571e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507ed2e5-a47e-4f88-ab28-03cf8edf6aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b15da7-2607-4096-ac1b-f7b83c8b984a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4905df79-fe31-48b8-8216-de22a5cbfddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980b85dd-995e-4187-bc9d-972b07f5157d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249870a9-794e-47f6-b9fc-06cb7f78aa7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837661e6-c950-4af4-89d1-2705c9e343e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d9bcd7-9494-4c2e-9e04-2736cd502403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9c7489-90c5-428d-80c8-b553c0bcbad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0687d34c-8dc0-4ff4-aa95-b7419f424983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61db4130-14f7-40dc-9e11-51d385ce6a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b194f204-c034-4ff8-8f8e-0610f4386888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6640e8-651f-4f9b-9f59-04c4d87ca741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75515bcd-a817-4a8a-afb0-0b16bb88bc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c0f611-6adf-48fd-ac9c-b39efb0e5fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb38f067-5749-4b6c-8090-c3644172f436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e14edf-3e61-4ccd-b6a0-d8cb3ef9f620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339249b1-0dfd-40a5-800b-77e488f0bef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d8572f-94ab-42a1-b1b1-701c2d4f8a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7849242-759b-445b-b0b2-5208020fcbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e92dd9-4a0b-408b-82f6-e030cef1ffd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cb5414-3b74-474f-af0a-cac2d8607ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0a2423-b8a5-4fde-b1de-0ff88e718626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc74816-5f5c-4f6b-88eb-377e1fc256dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a42593-725e-4b0b-b568-75b45778c1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6f4ed6-89e3-4fdf-9daa-72f41c3a0501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef51eff0-b559-488c-ae8a-8c9268eefce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f1ee91-86bd-499b-8999-6dde6b612b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c39517-cb16-4714-84c9-061fe57b4920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644a2940-4955-4220-8055-0345cb369c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4e96ab-fd28-4f67-be43-15bb9f7e9677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92a17e4-84cc-4a7b-9234-c5999b601cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170528a6-f1b1-4238-89d1-062d069cd66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319c1ec3-2577-463c-8df5-375b314b8cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951ac3cb-0bb5-45bf-ada1-f13ba7d7e9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330a08d2-44d9-4f5a-94e6-6d7f2187ca83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fe0204-cade-443e-ad22-efb75da8d797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608081ed-0237-4667-b9c0-6fefd4ca7ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0bbbcc-4906-4e4e-b767-15488d443b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2294a62e-3613-4c1d-9394-8af8147f2a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f535ee9-494e-4087-a9a2-ae523228b546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff51abdd-b78e-4f2a-bbb4-2a4a670c71cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31372035-9c0a-4f7c-93ed-206327cc0665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7afa351f-9f15-4573-ad29-0d004b20adad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4d43884-2cbf-4e0c-9f0e-6e01b108b73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f36db22-9f54-46c1-a3ec-0fc20db13f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8325897-5aa6-4374-a651-e1851a737fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3d5d0d-0019-401e-a9c8-ea329e781f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b0817a-65f4-4fb2-ad96-3f265ee21b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d87e9092-71f1-4c80-93e8-d04206ba1a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c8eadf-bbc9-46c9-83d9-692637948047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac55dd9-7f17-48e2-99dc-6f92d9a0e2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d754e95b-2088-4c39-98c8-c9c1b32eacc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663cf22e-33e4-4d53-aee1-2d71e29da1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77c8d14-e1e2-4eb9-b49f-06d2676b7cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdab0cd8-12e2-4c8b-9cb6-fd099307cece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10a7b72-5622-4f86-9d02-8a383f5bd6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc4c482-50b9-4e95-9b7c-ddddf27db4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f391ed0-0a22-4dfd-826d-7527b11bb2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51311f52-9be9-4e5c-8fd1-abacde203f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e7ab07-9531-4d6e-8e8c-8d6d1a79c2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6cb9947-5085-43dd-a688-c21410368a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6bd0ff5-eed3-43fe-900e-06cb503d7a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d73fd27-2e17-4173-8652-7ae5524095d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50b231c-55b0-4dac-bb16-98499f9e50b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcc8cb7-b032-44c1-bdca-93a3378fdcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79eebc6-e347-4ea2-9332-884dbddeb1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74cdf470-71b1-44bf-9201-a745d0a36990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4cb01dc-1990-4d8b-b17d-a6d26796bbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f339919-3ee0-40c9-93c4-649be67d991f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message febff768-fe4d-4d32-9bae-db900a150a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa93cf5-6f22-4e3c-94d0-2fd13373deaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0570a75-1b39-4da8-9b55-b4f737dde3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f90a03-62d1-483b-8629-c09131c514f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fb8dd2-ddb1-4898-931f-0484836e9971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5bbab2-2cfd-4f95-bab6-d2074902fa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9437468e-0580-42d1-88d1-56bf821a4027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ebdd44-cd19-4d20-af33-a2a54cdd263c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9816e0f3-b3f5-4324-bc29-7da9ab413963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0f89f4b-abbf-4fb8-a786-afd22b7968c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfedfc5c-74e1-4442-a734-6793e8259a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1290d540-5545-45c4-b03f-4e3b91a5c4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4d6b6e-9872-403b-9923-5323c12fa3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b1da848-6c53-418f-9955-6db687250f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af3eac45-9b8f-4014-aad5-4048e2c4d1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b29133e-ce0b-455b-8f4d-07a34d79b80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ca8141-1a75-4be6-9eef-8d51c31496ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da9fd96-1e02-4825-bf32-b90f9c4cb5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac42781-9613-4962-89e4-b71f86a7f18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09380384-680f-451f-b0fd-62ec211f917a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a076db7d-1e50-493b-9696-28676eaccc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ab1475-a2f7-40db-8757-ef830359d585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c09ef90-add9-4e9b-be33-49ab5ac96fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2afba6-afa4-49bb-be1a-5368dd73b079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e341e8a-58bd-4de2-bc8f-2fb479708d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b64d75-e5eb-4254-a55e-6faf7ef51e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a63f4d1-22ad-436b-b82d-bda7cdb32e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941a604e-8efd-4cf1-8e9b-358b09c05ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f110aa7-3b54-4cd7-b522-acaf5dff2aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b893ec-708b-4263-bfd4-6c5f1b6cf286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77c5c23-00dd-4472-93ad-dbcfec9c3335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efa0d3c-812a-40dc-817c-9aa55e84a452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a1669f-a300-4e63-8c7d-06c1fdfc35da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d3353a-fd49-48bb-9db4-46d39fd7147c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f42aa9-bb00-43ee-8a92-845190974b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7300149e-93f6-4992-a9a5-69ada4b68693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89dcba18-b0f4-4889-b7f0-d8ec50e5a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37981ab7-4255-4eab-b44e-660b33232729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6962aa-d405-4754-970c-76305aa19907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396794e1-e6ef-4c81-b584-38b7c089ed4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d737dd5e-6bd9-4e47-8f4a-e8a06c141f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689e13eb-d92c-4e5c-a219-f32900bf8ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e1c8f1-0bfd-4c1c-9760-fbdcd45a1d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34ccea5-2760-44dc-a50d-621f9d480d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 747138da-3268-4938-a0e9-201ebe58dd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee53938-05dd-4668-a9f8-94a2c84a9dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feaba75a-e2f5-4b66-9364-16c14f97d070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ecdb2c0-89dd-4fd4-a946-f5c912cee029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d98c46-9b3c-47c5-bc4d-884edecb74ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf4ea4a-4ee0-43af-b0cf-a00cda12dd07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd3796f-feef-4ba4-9367-395a6e13ba25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e111db-1114-41e8-87be-09f896786fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09913394-e758-46a1-b7d9-6d0c2276842b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae731b0c-2d5d-49eb-842a-576063433349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34629534-615f-4a34-9140-f1d379fb9bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7744970-3b4b-493d-97a1-e3a622c52987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b329088-ba2a-4765-b258-6cf9a72ffad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa41ca9-0608-4ffd-bc16-f45eda49153c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401e98d0-4b0c-4b02-addb-901e9c5be345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396e1a5e-59f5-4a0a-84bc-b872736081a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea37cffa-7acb-4589-b6ff-e1518c2542d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0181037-a33d-4756-83e7-1980b6f41636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8696004e-04a3-402d-97d6-6a18f33e2dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd644df-9e25-4364-bddd-8bf82d3857b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c6a6f6-1025-4adb-b7d3-f4ec71f27429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4f6a00-63ff-4120-b703-06a251ddf362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507e6395-bd38-4dc3-9fdb-6ffdcc823eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06fa296d-5ced-43b0-9716-b0bf7df2466b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9690f5c-3755-423a-bd6a-25cce837cd35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6948e1c7-591d-4ca6-b87f-ba33e15fae92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7994bcb0-a83c-4038-9079-f93a90548a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230ae7e2-107c-447d-a1f0-bac46a5e8c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04172d33-ced7-4aef-8261-98a58cf2d064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feec3558-06a0-4300-8469-55ce655d3755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16c23b3-59be-4191-a1a2-0bba357700a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd76228a-dc38-420b-b82e-04341e1e12d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a94becb-64c7-4beb-bf90-0ac76295c858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d939a6d-edde-4efb-9acf-1fc64f43943e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72dd9bb6-feab-4db4-a6db-28fb7d9cfc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 566f0c9e-5503-4785-b14d-c4dce3289dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287bdcad-20d5-4fce-89b0-c90e7ec0b0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913ad0d2-6827-4b28-9984-cbcdaa5597a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d9e5f5-eacd-4d77-86ca-6bd1b2f48d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de4727e-f6a9-4f3d-a8fe-f472ed282aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1b7314-bfb4-4d0a-b94d-f74a5fd6c005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37df8164-c73f-4747-a006-7ddfa19c328f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a287c315-c657-42be-8894-fd1530309da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a06c0e-cf0f-4212-9e91-4f59f3f19675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966606f6-8845-4bd4-ace9-dbbc129ee48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d629cc5a-3944-4093-b113-6a32a3daea63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1176b35d-7162-459e-8e62-c48de3a0fa4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72df0b4-dc91-44e3-8844-6f7d571edffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716c09b8-13e9-42a1-94c7-09ab3bc5de78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ff6493-41ff-4fc0-8354-e56118bba786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 516f4870-cdcf-48f5-a928-aba6a8996ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8d66a4-77dd-436e-99a6-3dec012ffafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0eb7cf-3129-49ed-851c-577330dbc03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d38acbbc-aedd-46ec-9cad-04af944196b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be35edbb-4f8c-439c-9408-b58591fdfb45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a0ddf9-df76-4c83-b53d-c32fdd258410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d2befd-73bb-4b15-b795-e647419b70fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ad87d2-b021-4c98-a4f4-e5076cc5d7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f164210-67d9-485c-b97f-fcb369bf5f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4179444-bb7d-42ad-93ef-324830a54153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3cec612-c075-44b3-9b9e-25894d2e5c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a816df-f6dc-464b-9c4b-f1d060b2e8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1351389-f2bd-432d-b1bc-3ee066ba0d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 804878e7-2e40-4528-ba1f-c1d80640848f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f621a29-4f30-4534-b1a3-ed683a43263c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba86cfb-661b-40ed-a179-d7e4d7a35744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b72e3e0-1f2f-4a7b-882d-9a10ac3a51fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed748b31-8393-4b5b-aaee-683caa363312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2377e0c0-e564-40cf-90b4-23b481037a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a1c8c7-22fb-466e-aa0a-a29a4bfd8191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e24079c-b296-462b-b8a7-af97291113f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0a0454-aa39-4f5f-b590-348473a96a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f377c1-b58c-413b-9b62-36da37859ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1d1590-dc87-4fe3-9c43-fcf6afd7bf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f735721-3cb5-4208-a7be-11a912b2c131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207657cf-082a-46dd-ba45-a7658d396f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cafa66b-ca14-4d24-98d9-558bd9ea58b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d322bb1-05bb-4489-bd33-0e0044ba8bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872ca858-df32-4d5e-9991-6db23cf3d8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252e7b5b-fd61-48e7-bc9e-5d7c9057a2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce58c7d-e068-440d-bfb5-d34459afa883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7209ae5-f8c7-401a-8561-86bf267b8a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea77cb6-048c-4204-ac51-a605848fdb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5cf50e-93d5-4bca-87fa-3bbb624bc6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46809d8a-6440-4e4a-b03d-992dfe6b4223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b1bfd4-f4a2-4e8c-b07c-6425e5002a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f9ed10-9120-4ceb-9669-da2046fcbebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcb1ca3-f114-42f7-bb70-2cbec509643c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad39cfb-cce4-4df8-838d-6880b048044a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd9aa61-9da8-415e-bbd0-8256bef16534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a42814-24b5-461d-a011-b65c95239d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942b9fd4-13ca-4d56-a50a-f5c2eb199bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd87b85a-500d-4254-a19f-6f2f33d2f701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31fec34b-b8d4-4ae3-9108-fbb567b336cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fcdf705-b4ee-403b-a905-dc58835e6c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db67f92-d8d8-4578-97f1-109a43d69fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f434ebec-1ac9-4656-9a48-161efa4a368f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1bb57fa-03df-49c0-b25a-0f476db9ddc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2824a9-09f2-470c-96a3-797c2864e834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafd383b-b8f2-42f6-84b6-b6c2b2cc727b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed5e16d-9f8d-4f3f-8d20-a9d256dcf1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d624a1-8dc9-4acf-8408-e876bb4c65b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d20d89b6-ffdd-47d8-add7-f95c1323b8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f350d81-3fc8-4474-acce-8956f6b4b3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d19a56a-f678-41c6-9783-0643c29face1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ea6c82-b92d-480f-b951-641fa6f491e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb7b47b-9576-4e3b-b13a-6b2869557fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e86ee70-eba7-4fa6-ae16-5b27e5bf640f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7846f45-3313-4af0-8648-b0f6ecc6fbd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30379225-660a-4d5b-91e3-2c7c1d02f146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b9534b-6dcf-4b8d-9c68-b6dba9b4d129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86013380-9a2d-414b-9988-fcb75f58774f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a8dab6-c584-429e-a7bd-39597cb3131a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0225b229-b7a0-4268-a5f4-45e35957d566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69256ebb-567c-4b8e-9bba-b4802a2956e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd4e9a2-c80a-41eb-bdec-df214af9ad3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1dfb01a-e49c-4016-934c-473639714805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf493bb1-15f0-4454-8714-bef8c21b361f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e83707-48f5-4575-a814-197b15fe5a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad3009d-1592-4bda-9125-15b823dc9ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a3d236-96d4-4a44-bc55-363cf81fe83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd93010-9481-4dcf-8a41-b96ee0c6199f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ce478b-ff80-452f-99c1-128ee22eb2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022dc9b2-e258-4491-9767-3895c7656676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1be1f93-4e06-436f-9578-c18e1b890141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a220f9-a6da-4c57-ab90-1f7b11b5034e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb47e2e-0c1e-4f8e-bdd0-5cc1c44a7e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f250b96c-c914-4f5c-9ff5-f37c094c9d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2dfbd82-b400-4078-a34e-db45d50af952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9d8385-200f-4a7b-88cb-f174bc8c5e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d821fb0-8383-494d-a1c0-46475510c1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96bf5a27-cd16-441d-8b10-8d4c75c1ad4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d39aa2b-9c92-4906-9e3b-76a46060d2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ea304f-5d47-43bc-9eba-23373fddc9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56864874-7ebc-4dce-9ac5-13ecb711e6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a8bcdf-fd8f-458e-9626-7f3f1bca0411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad7264d-3dd7-436f-90da-8bcd4db9308a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbbfa88-ea89-45f1-a495-e3c7418d2a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4922efe-2d50-411d-8257-297a6da87713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d550e0bf-a653-4e81-88d6-ffea8ad88c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ced797-fe6d-450f-beba-0501b79d658d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ea2144-baa8-4ed4-b6c7-5ba99c68de77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36931b4-5e03-4496-a385-521bcc033678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b8428a-3617-4d3f-be30-5ebf87b02784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2f8209-2d0f-4567-a2ba-e6500c2257d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ce9f92-c751-45d4-84b4-48510eb4a987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd88082-ba77-43aa-960f-3c086c5fa609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68e912d-9d07-423e-8a42-2d2763b34ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27235413-b5f7-4a27-84a2-1dfd4e67e4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9713dcbb-099f-4874-ae8c-b783e9cf3642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7009cde-3f17-46cf-abbb-6140e8cfee81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a260d6-a5d3-4d54-9feb-e181200a2964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f75264-4629-42bd-94dd-3824cd34a2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b122f0e5-4d47-41bb-bb8d-1f809551776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8357d5-dc8d-457a-8476-aca4321ac1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a48c710-5bc5-45d9-8300-9ae6ce09fc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6055590-5a8e-4009-84ce-3fb63195ed27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401d65ad-76c1-458a-b6af-aa02aa6fe1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28a7489c-09b8-4bdd-b62a-4e77356c0f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4374877-22ec-4b0d-a07f-263f77de8cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f61ffb-0adf-41bd-bcbd-caa25e08136a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1e3081-51e2-4b34-986b-38c1de900cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59448c32-006d-4afd-9e8c-222fabd45213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d2571d-f330-4ae4-a7e3-bfbf3c0880b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7187592d-e890-4a21-9abb-6fbbb475dc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ce7226-fa75-4215-8cfb-0255fbd6a740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7975b41-6289-45a6-890e-400c1f770bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af38386-a8f4-400c-b42d-5db3c344aad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e107e622-e0e9-4516-8676-56764502361a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6180ce-09ca-41d6-a823-e2bc7c8bc141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e285a150-a480-4f1d-b6de-950890c93259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9073e49d-3628-4644-9934-d302ef02b342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa823cf-e81b-42f2-a4dd-29a756aec5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626adaa5-f5bd-445b-89d6-2378a4a91242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 668c6607-0940-4640-b6b5-aca77574aaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc763c3c-2a8a-4610-aba1-e53d8a1a20fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beaa18af-b62f-47da-a80f-7484fa61f14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82fa6b1d-dd51-409b-8f98-7a50102db919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af20fbb-3ba8-4ddf-9fa2-c153951e69b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda770eb-f477-49fd-a2e8-5486a38d0958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aacaee3d-6f8f-49fe-ac4e-8cd546a49d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ddaf971-bf40-493c-b888-6052135323bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db8ef09-7748-4acf-92e1-b2b9f55dd6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c263d9-4ff0-45b2-bd70-b83205bedb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95979801-e7f4-4400-83a4-127af69d8ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8021c12b-c345-426e-93fe-d58ebe83d14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579e8789-3b9a-4946-9d42-d25d979fae4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476d0fa9-6561-444b-84e2-d1f8ac746872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71b79a66-36da-49dc-82e7-c89fe7ee7b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5825cc4a-2289-4354-8e0e-916906a7946c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c320e6-d397-4edd-b9d5-09480af57dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69ac7b9-3261-48bf-a130-30200e24456d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5635f5a0-3762-4ed0-aabf-96b7b24e3b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9989b554-f2c7-49cc-b150-4744cf10417f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a8c781-9119-41fb-bd72-e1bc9c4608fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68fd1c5-ef0e-4e06-a6bc-f96dd81da228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e4d989-2221-4d19-9ddc-c629836c7115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ef0000-6b4e-469c-923f-7561561847ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8baa4fd6-0a60-473b-afad-e76d3189031e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a101fa-7464-451a-9874-ff7377e00cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46c75ed-660e-4289-8bed-a69a14d3997c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2470984-e2d1-4ac6-bc78-3418a4d22493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3263311d-4363-4986-9821-3f23c0d7f7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299c88ca-9aaa-446c-b143-fca12c64aff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9eb1ab-12b4-4b99-98c4-52ef498df0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698024fa-962f-4045-b22b-1e191999903f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1e1bb8-7d6c-402b-b432-468e3d98ec00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976ae0c3-d1b3-4970-b839-c19fe03b6ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54b44e9-5e30-41fd-818c-31301adc6045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a2adbe-5936-4310-826a-4e607f575e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31c3853-2946-433e-ae37-f20efb742bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed58ed0-97be-4968-8cdd-ef143293935d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a9d9d9-6cc1-4986-b1e2-eac4d19d565c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2b8936-c47a-48a7-9188-893efeb83595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c27f0c3-e5be-435f-98d3-49d9bb4328c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be205427-c682-4740-8548-23b252b4eed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ade99de-d3be-4358-9f52-69eeabbaa59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00b0b0a-97e8-4902-a54b-1a1bbe8c8741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b64016-5a7f-4302-9c8b-b073b7132d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166dd6f9-264f-4734-aee9-59bb66b60c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18185ae-7d19-495e-8c41-aabc123ad2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d930da9b-99d7-4a20-8e19-fcee5fb57b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d08eb4f-1305-4852-bd7f-a1981f4e3c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb6cb23-17e8-48f2-a064-ae31775b33ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262966a7-07d6-42bf-8f79-71513374069c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5925cb-bf09-4791-9ad5-3bf8c543c1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe0fc2d-e145-4724-9c1d-a9adefbae563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa60a82-ee86-4d38-beb8-9805e3ace6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4acc15b-73a3-48e2-978f-0fd53b6ecf1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 702d68b9-ac84-4e32-a589-9f8cd5815435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616c78d5-c474-455c-9aab-c3ed7424ecee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00328eb-5f70-4968-915f-11edaab5c06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d805fcd4-91a8-4d70-80b4-4e58c66cbcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac1a9838-65ed-4c6d-8d1d-35f4c773b454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e9e32b-9f83-4b3e-b800-1042d7d2d5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d1e2f1-0311-416b-9be4-dc6084cd6930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d98bb93-1412-45ef-96df-3f80c12213d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c957ecfd-6d33-4449-b33f-b4e6dccf93c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02016d63-a2e8-4475-b1d6-3214536bf6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b784d7e2-3680-46e1-bb46-b7097dae8cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734fa288-a22b-4543-9f1d-bb9e12cc5387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cdce18-45a4-408c-9a78-ea993dbcf0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5023658d-4a19-4dee-a178-7e5c24775a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410e3138-a436-4d8d-85ca-d53c7499d600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a39245-b49e-41c7-af11-66b3e62f608e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0784cc00-db10-4589-a5e5-e89b8fd11232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2317f436-27e7-473a-85f4-bdf9388651e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1583d4a-93a6-4edc-b57d-52eb8b3623b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931fb29b-d389-4586-899d-b528dc4a6d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85fde1b3-ee8a-43f5-ba1c-90e3edb74f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e20c01-32ce-4404-b068-6bb662463ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9734b24-ef50-4864-90d1-15cf3752f4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003ef018-8dce-412b-ab6f-9d3234f7d360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90a1e4d-e72b-4f19-9500-3bab9504b965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6796fd-ee0f-412a-a02f-de459fdc2161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd921fe6-2c5d-4ca7-9d79-fd46ecb2fe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488a0f62-510c-42fd-9e5e-8aad10fb1d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0833eb-e66b-4a09-bbe0-3e32a388a7a0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(3836, 24), y=(3836,)
   Test:  X=(959, 24), y=(959,)

⚠️  Limiting training data: 3836 → 800 samples
⚠️  Limiting test data: 959 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3873, val=0.1795 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1013, val=0.0854 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0813, val=0.0824 (↓), lr=0.001000
   • Epoch   4/100: train=0.0788, val=0.0824, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0788, val=0.0820, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0784, val=0.0820, patience=8/15, lr=0.001000
   • Epoch  21/100: train=0.0769, val=0.0809, patience=2/15, lr=0.001000
   • Epoch  31/100: train=0.0738, val=0.0807, patience=4/15, lr=0.001000
   📉 Epoch 34: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0701, val=0.0836, patience=14/15, lr=0.000500
   📉 Epoch 42: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 1 Summary - Client client_16
   Epochs: 42/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0605
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0158
============================================================


============================================================
🔄 Round 3 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4639, val=0.3959 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3318, val=0.2508 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1579, val=0.0781 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0837, val=0.0756 (↓), lr=0.000250
   • Epoch   5/100: train=0.0805, val=0.0760, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0803, val=0.0755, patience=7/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 3 Summary - Client client_16
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0029
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0018
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.5000, RMSE: 0.7071, MAE: 0.6494, R²: -5.4005

============================================================
🔄 Round 4 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4934, val=0.4213 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.4160, val=0.3568 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.3493, val=0.2865 (↓), lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   ✓ Epoch   4/100: train=0.2612, val=0.1842 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1721, val=0.1294 (↓), lr=0.000063
   • Epoch  11/100: train=0.0792, val=0.0790, patience=3/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0792, val=0.0791, patience=13/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 4 Summary - Client client_16
   Epochs: 23/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0017
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0010
============================================================


============================================================
🔄 Round 5 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.5090, val=0.5361 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.4955, val=0.5219 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.4830, val=0.5099 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.4724, val=0.4996 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   ✓ Epoch   5/100: train=0.4631, val=0.4904 (↓), lr=0.000008
   ✓ Epoch  11/100: train=0.4383, val=0.4671 (↓), lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004
   📉 Epoch 21: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.4187, val=0.4476 (↓), lr=0.000002
   📉 Epoch 29: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.4118, val=0.4409 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4085, val=0.4373 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4052, val=0.4339 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4020, val=0.4306 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3989, val=0.4273 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3958, val=0.4240 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3927, val=0.4207 (↓), lr=0.000001

============================================================
📊 Round 5 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.3888, RMSE=0.6235, R²=-3.7765
   Val:   Loss=0.4177, RMSE=0.6463, R²=-4.9106
============================================================


============================================================
🔄 Round 6 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.5144, val=0.4994 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.5137, val=0.4987 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.5131, val=0.4981 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.5125, val=0.4975 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.5119, val=0.4970 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.5089, val=0.4940 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.5046, val=0.4898 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.5008, val=0.4861 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4973, val=0.4827 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4939, val=0.4793 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4906, val=0.4761 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4874, val=0.4730 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4842, val=0.4699 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4811, val=0.4668 (↓), lr=0.000001

============================================================
📊 Round 6 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4787, RMSE=0.6919, R²=-5.0324
   Val:   Loss=0.4640, RMSE=0.6812, R²=-4.8274
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.4833, RMSE: 0.6952, MAE: 0.6364, R²: -5.1875

============================================================
🔄 Round 8 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4938, val=0.5207 (↓), lr=0.000001
   • Epoch   2/100: train=0.4934, val=0.5203, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4930, val=0.5198 (↓), lr=0.000001
   • Epoch   4/100: train=0.4927, val=0.5194, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4923, val=0.5190 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4900, val=0.5166 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4862, val=0.5128 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4826, val=0.5090 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4791, val=0.5054 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4755, val=0.5017 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4720, val=0.4981 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4685, val=0.4945 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4650, val=0.4909 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4615, val=0.4873 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4580, RMSE=0.6768, R²=-4.7829
   Val:   Loss=0.4841, RMSE=0.6957, R²=-5.0456
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4681, RMSE: 0.6842, MAE: 0.6244, R²: -4.9925

📊 Round 8 Test Metrics:
   Loss: 0.4591, RMSE: 0.6776, MAE: 0.6171, R²: -4.8772

============================================================
🔄 Round 10 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4766, val=0.4976 (↓), lr=0.000001
   • Epoch   2/100: train=0.4762, val=0.4972, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4758, val=0.4968 (↓), lr=0.000001
   • Epoch   4/100: train=0.4754, val=0.4964, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4750, val=0.4960 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4727, val=0.4936 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4688, val=0.4896 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4651, val=0.4858 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4613, val=0.4819 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4575, val=0.4781 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4538, val=0.4742 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4499, val=0.4702 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4460, val=0.4662 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4421, val=0.4622 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4384, RMSE=0.6621, R²=-4.5389
   Val:   Loss=0.4586, RMSE=0.6772, R²=-4.7050
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4394, RMSE: 0.6629, MAE: 0.6010, R²: -4.6253

📊 Round 10 Test Metrics:
   Loss: 0.4201, RMSE: 0.6481, MAE: 0.5847, R²: -4.3778

============================================================
🔄 Round 13 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4393, val=0.4459 (↓), lr=0.000001
   • Epoch   2/100: train=0.4388, val=0.4455, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4384, val=0.4450 (↓), lr=0.000001
   • Epoch   4/100: train=0.4380, val=0.4446, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4375, val=0.4442 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4349, val=0.4415 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4306, val=0.4372 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4263, val=0.4328 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4220, val=0.4284 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4176, val=0.4239 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4132, val=0.4195 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4087, val=0.4150 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4043, val=0.4104 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3997, val=0.4058 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3960, RMSE=0.6293, R²=-3.9131
   Val:   Loss=0.4016, RMSE=0.6337, R²=-4.3745
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.4031, RMSE: 0.6349, MAE: 0.5700, R²: -4.1602

============================================================
🔄 Round 14 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4150, val=0.4573 (↓), lr=0.000001
   • Epoch   2/100: train=0.4146, val=0.4569, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4142, val=0.4564 (↓), lr=0.000001
   • Epoch   4/100: train=0.4138, val=0.4560, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4134, val=0.4556 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4110, val=0.4531 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4069, val=0.4488 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4028, val=0.4445 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3986, val=0.4401 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3944, val=0.4356 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3901, val=0.4310 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3857, val=0.4264 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3812, val=0.4217 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3767, val=0.4170 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3727, RMSE=0.6105, R²=-3.8147
   Val:   Loss=0.4126, RMSE=0.6424, R²=-3.7454
============================================================


============================================================
🔄 Round 16 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3618, val=0.3925 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3613, val=0.3920 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3608, val=0.3914 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3603, val=0.3909 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3598, val=0.3904 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3568, val=0.3872 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3517, val=0.3819 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3466, val=0.3766 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3415, val=0.3712 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3363, val=0.3659 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3311, val=0.3604 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3259, val=0.3549 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3206, val=0.3493 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3151, val=0.3437 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3092, RMSE=0.5561, R²=-2.9651
   Val:   Loss=0.3385, RMSE=0.5818, R²=-2.9904
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.3192, RMSE: 0.5650, MAE: 0.4910, R²: -3.0863

============================================================
🔄 Round 17 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3366, val=0.3369 (↓), lr=0.000001
   • Epoch   2/100: train=0.3361, val=0.3364, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3356, val=0.3359 (↓), lr=0.000001
   • Epoch   4/100: train=0.3352, val=0.3354, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3347, val=0.3349 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3317, val=0.3319 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3266, val=0.3269 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3215, val=0.3218 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3163, val=0.3166 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3109, val=0.3112 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3053, val=0.3057 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2996, val=0.3000 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2937, val=0.2941 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2876, val=0.2881 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2826, RMSE=0.5316, R²=-2.5648
   Val:   Loss=0.2825, RMSE=0.5315, R²=-2.5279
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.2988, RMSE: 0.5466, MAE: 0.4703, R²: -2.8244

============================================================
🔄 Round 21 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2045, val=0.2403 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2036, val=0.2393 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2027, val=0.2383 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2018, val=0.2373 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2009, val=0.2363 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1957, val=0.2305 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1874, val=0.2213 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1795, val=0.2124 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1719, val=0.2038 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1646, val=0.1955 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1575, val=0.1874 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1507, val=0.1796 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1442, val=0.1720 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1380, val=0.1648 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1325, RMSE=0.3640, R²=-0.6918
   Val:   Loss=0.1585, RMSE=0.3981, R²=-0.9168
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.1681, RMSE: 0.4100, MAE: 0.3348, R²: -1.1519

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1782, val=0.1903 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1775, val=0.1895 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1767, val=0.1888 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1760, val=0.1880 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1753, val=0.1873 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1710, val=0.1828 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1640, val=0.1756 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1573, val=0.1686 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1508, val=0.1618 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1445, val=0.1553 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1385, val=0.1490 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1328, val=0.1430 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1273, val=0.1373 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1221, val=0.1319 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1173, RMSE=0.3425, R²=-0.5009
   Val:   Loss=0.1273, RMSE=0.3567, R²=-0.5054
============================================================


============================================================
🔄 Round 24 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1190, val=0.1177 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1185, val=0.1172 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1180, val=0.1167 (↓), lr=0.000001
   • Epoch   4/100: train=0.1176, val=0.1162, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1171, val=0.1157 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1144, val=0.1129 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1101, val=0.1084 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1061, val=0.1042 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1025, val=0.1004 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0992, val=0.0970 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0963, val=0.0938 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0936, val=0.0910 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0913, val=0.0886 (↓), lr=0.000001
   • Epoch  91/100: train=0.0893, val=0.0864, patience=1/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_16
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0919
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.1035
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2405, R²: -0.0269

============================================================
🔄 Round 26 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0816, val=0.0832, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0807, val=0.0819, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0803, val=0.0814, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0801, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0799, val=0.0807, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 26 Summary - Client client_16
   Epochs: 72/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0107
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0182
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2399, R²: -0.0178

============================================================
🔄 Round 27 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0794, val=0.0826 (↓), lr=0.000001
   • Epoch  51/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 27 Summary - Client client_16
   Epochs: 56/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0070
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0161
============================================================


============================================================
🔄 Round 28 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0811, val=0.0774, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 28 Summary - Client client_16
   Epochs: 25/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0222
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0163
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2394, R²: -0.0111

============================================================
🔄 Round 29 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0854, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0788, val=0.0851, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 29 Summary - Client client_16
   Epochs: 33/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0131
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0081
============================================================


============================================================
🔄 Round 30 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0848, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0790, val=0.0846, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 30 Summary - Client client_16
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0124
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0146
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2391, R²: -0.0058

============================================================
🔄 Round 32 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0887, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0780, val=0.0882, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0779, val=0.0879, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 32 Summary - Client client_16
   Epochs: 34/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0072
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0131
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2391, R²: -0.0050

============================================================
🔄 Round 34 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 34 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0253
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0119
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2391, R²: -0.0049

============================================================
🔄 Round 40 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 40 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0118
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0220
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2391, R²: -0.0043

📊 Round 40 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2391, R²: -0.0042

============================================================
🔄 Round 42 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 42 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0100
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0250
============================================================


============================================================
🔄 Round 44 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0786, val=0.0846, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 44 Summary - Client client_16
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0057
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0144
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2390, R²: -0.0033

============================================================
🔄 Round 45 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 45 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0138
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0094
============================================================


============================================================
🔄 Round 47 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 47 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0205
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0014
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2390, R²: -0.0032

📊 Round 47 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2390, R²: -0.0029

============================================================
🔄 Round 50 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 50 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0063
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0241
============================================================


============================================================
🔄 Round 51 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0872, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0782, val=0.0869 (↓), lr=0.000001
   • Epoch  21/100: train=0.0781, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 51 Summary - Client client_16
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0030
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0340
============================================================


============================================================
🔄 Round 52 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 52 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0100
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0073
============================================================


============================================================
🔄 Round 53 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 53 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0093
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0110
============================================================


============================================================
🔄 Round 54 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0801, val=0.0784, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 54 Summary - Client client_16
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0214
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0024

============================================================
🔄 Round 56 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 56 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0083
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0090
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0024

============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0134
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0019
============================================================


============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0104
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0039
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0017

📊 Round 60 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0018

📊 Round 60 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0017

============================================================
🔄 Round 71 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 71 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0062
   Val:   Loss=0.0679, RMSE=0.2606, R²=-0.0055
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0017

============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0076
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0095
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0018

============================================================
🔄 Round 79 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 79 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0065
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0064
============================================================


============================================================
🔄 Round 80 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 80 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0049
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0418
============================================================


============================================================
🔄 Round 81 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 81 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0096
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0026
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0018

📊 Round 81 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0017

============================================================
🔄 Round 87 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 87 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0079
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0020
============================================================


============================================================
🔄 Round 88 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 88 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0036
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0297
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2391, R²: -0.0017

📊 Round 88 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0018

============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0827, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0824, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0022
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0279
============================================================


============================================================
🔄 Round 91 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 91 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0126
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0004
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0017

📊 Round 91 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0017

📊 Round 91 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0017

📊 Round 91 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0017

============================================================
🔄 Round 96 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 96 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0045
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0247
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0017

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0018

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2390, R²: -0.0018

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0019

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0019

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0020

📊 Round 96 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0020

============================================================
🔄 Round 105 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 105 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0084
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0068
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0021

📊 Round 105 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0019

📊 Round 105 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2390, R²: -0.0019

============================================================
🔄 Round 111 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 111 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0040
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0244
============================================================


============================================================
🔄 Round 114 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 114 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0079
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0021
============================================================


============================================================
🔄 Round 117 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 117 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0107
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0083
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0016

============================================================
🔄 Round 118 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 118 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0082
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0000
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0016

============================================================
🔄 Round 119 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 119 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=-0.0043
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0133
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0016

📊 Round 119 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0015

============================================================
🔄 Round 124 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 124 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0072
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0022
============================================================


============================================================
🔄 Round 125 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 125 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0080
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0032
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0015

📊 Round 125 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0015

============================================================
🔄 Round 127 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 127 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0039
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0118
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0015

============================================================
🔄 Round 130 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 130 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0021
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0546
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 138 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 138 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0110
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0002
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 138 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0013

============================================================
🔄 Round 145 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 145 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0044
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0100
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0013

📊 Round 145 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0014

📊 Round 145 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2391, R²: -0.0014

============================================================
🔄 Round 149 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 149 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0061
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0017
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 150 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 150 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0049
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0084
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 150 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 153 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 153 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0049
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0106
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 153 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 153 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 158 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 158 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0053
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0100
============================================================


============================================================
🔄 Round 161 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0816, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0813, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0791, val=0.0812, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 161 Summary - Client client_16
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0039
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0108
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 162 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0851, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0785, val=0.0848, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 162 Summary - Client client_16
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0010
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0328
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

📊 Round 162 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0015

📊 Round 162 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0015

📊 Round 162 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 169 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 169 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0022
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0236
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 169 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 172 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 172 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0101
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0054
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 172 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 175 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 175 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0099
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0003
============================================================


============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0089
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0028
============================================================


============================================================
🔄 Round 177 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 177 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0074
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0030
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 182 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 182 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0026
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0275
============================================================


============================================================
🔄 Round 184 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 184 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0072
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0024
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 184 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 188 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 188 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0030
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0310
============================================================


============================================================
🔄 Round 191 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 191 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0037
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0116
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 193 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 193 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0069
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0003
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 194 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 194 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0069
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0003
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 195 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 195 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0040
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0104
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 197 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 197 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0105
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0026
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 199 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 199 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0040
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0115
============================================================


============================================================
🔄 Round 200 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 200 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0102
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0071
============================================================


============================================================
🔄 Round 201 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 201 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0026
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0247
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0091
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0025
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 203 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 206 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 206 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0591
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 207 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 207 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0082
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0040
============================================================


============================================================
🔄 Round 209 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 209 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0019
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0205
============================================================


============================================================
🔄 Round 210 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 210 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0048
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0113
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 211 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 211 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0133
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0281
============================================================


============================================================
🔄 Round 212 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 212 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0027
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0211
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 212 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 215 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0787, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0784, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0799, val=0.0782, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 215 Summary - Client client_16
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0305
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 216 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 216 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0085
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0016
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 216 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 223 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 223 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0058
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0090
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0014

============================================================
🔄 Round 224 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 224 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0090
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0012
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

📊 Round 224 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0013

============================================================
🔄 Round 229 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 229 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0066
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0096
============================================================


============================================================
🔄 Round 230 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 230 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0090
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0036
============================================================


============================================================
🔄 Round 232 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 232 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0125
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0100
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 234 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 234 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0047
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0124
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 238 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 238 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0075
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0013
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 239 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 239 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0060
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0010
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 243 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 243 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0058
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0039
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 244 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 244 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0058
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0039
============================================================


============================================================
🔄 Round 247 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 247 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0096
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0143
============================================================


============================================================
🔄 Round 249 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 249 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0079
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0048
============================================================


============================================================
🔄 Round 250 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 250 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0061
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0055
============================================================


============================================================
🔄 Round 252 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 252 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0048
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0093
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 254 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 254 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0037
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0235
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 255 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 255 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0085
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0063
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

📊 Round 255 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 258 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 258 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0052
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0135
============================================================


============================================================
🔄 Round 261 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 261 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0147
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0003
============================================================


============================================================
🔄 Round 262 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 262 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0027
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0478
============================================================


============================================================
🔄 Round 263 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 263 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0023
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0324
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 264 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 264 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0059
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0048
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

📊 Round 264 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 266 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 266 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0003
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0722
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 267 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 267 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0048
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0107
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0011

📊 Round 267 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0011

============================================================
🔄 Round 274 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 274 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0044
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0132
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 275 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 275 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0052
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0109
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2390, R²: -0.0012

============================================================
🔄 Round 278 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 278 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0109
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0102
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

============================================================
🔄 Round 280 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 280 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0042
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0127
============================================================


============================================================
🔄 Round 281 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 281 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0054
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0054
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

============================================================
🔄 Round 282 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 282 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0007
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0260
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

============================================================
🔄 Round 284 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 284 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0087
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0006
============================================================


============================================================
🔄 Round 285 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 285 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0042
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0328
============================================================


============================================================
🔄 Round 287 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 287 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0048
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0079
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

📊 Round 287 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

📊 Round 287 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

============================================================
🔄 Round 291 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 291 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0077
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0027
============================================================


============================================================
🔄 Round 292 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 292 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0037
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0090
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

📊 Round 292 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 294 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 294 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0025
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0204
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 295 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 295 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0023
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0185
============================================================


============================================================
🔄 Round 296 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 296 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0039
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0060
============================================================


============================================================
🔄 Round 297 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 297 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0040
   Val:   Loss=0.0681, RMSE=0.2609, R²=-0.0083
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 298 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 298 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0027
   Val:   Loss=0.0693, RMSE=0.2632, R²=-0.0226
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

📊 Round 298 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 300 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 300 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0035
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0114
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 302 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 302 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0042
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0177
============================================================


============================================================
🔄 Round 303 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 303 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0004
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0713
============================================================


============================================================
🔄 Round 304 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 304 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0080
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0028
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

📊 Round 304 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 309 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 309 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0001
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0383
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0010

============================================================
🔄 Round 310 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 310 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0209
============================================================


============================================================
🔄 Round 312 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 312 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0019
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0228
============================================================


============================================================
🔄 Round 314 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 314 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0042
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0106
============================================================


============================================================
🔄 Round 315 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 315 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0050
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0068
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 317 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 317 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0003
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0415
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 319 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 319 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0085
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0073
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 320 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 320 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0018
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0294
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 321 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 321 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0022
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0375
============================================================


============================================================
🔄 Round 322 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 322 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0054
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0072
============================================================


============================================================
🔄 Round 323 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 323 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0041
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0172
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 325 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 325 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0041
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0115
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

============================================================
🔄 Round 331 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 331 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0075
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0022
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0009

📊 Round 331 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 331 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 336 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 336 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0088
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0077
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 337 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 337 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0049
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0042
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 342 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 342 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0024
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0222
============================================================


============================================================
🔄 Round 343 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 343 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0110
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0021
============================================================


============================================================
🔄 Round 344 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 344 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0109
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0019
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 344 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 346 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 346 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0077
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0018
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 346 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 350 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 350 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0087
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0015
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 350 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 352 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 352 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0055
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0038
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 354 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 354 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0056
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0053
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 356 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 356 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0071
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0039
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 356 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 358 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 358 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0041
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0102
============================================================


============================================================
🔄 Round 360 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 360 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0091
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0055
============================================================


============================================================
🔄 Round 362 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 362 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0040
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0127
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 363 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 363 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0033
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0196
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 363 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 363 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0011

============================================================
🔄 Round 366 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 366 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0060
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0080
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 367 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 367 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0073
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0022
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 370 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 370 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0075
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0023
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0011

============================================================
🔄 Round 373 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 373 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0053
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0187
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0012

📊 Round 373 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0012

============================================================
🔄 Round 379 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 379 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0126
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0040
============================================================


============================================================
🔄 Round 380 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0844, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0788, val=0.0841, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 380 Summary - Client client_16
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0022
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0297
============================================================


============================================================
🔄 Round 381 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 381 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0073
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0028
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0011

============================================================
🔄 Round 383 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 383 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0042
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0252
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0012

============================================================
🔄 Round 385 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 385 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0033
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0272
============================================================


============================================================
🔄 Round 386 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 386 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0104
   Val:   Loss=0.0735, RMSE=0.2710, R²=-0.0002
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0011

📊 Round 386 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0013

============================================================
🔄 Round 392 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 392 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0110
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0058
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2389, R²: -0.0011

============================================================
🔄 Round 393 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0603 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0602, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0602, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0602, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0602, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0601, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0603)

============================================================
📊 Round 393 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0084
   Val:   Loss=0.0603, RMSE=0.2455, R²=0.0008
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 393 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 396 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 396 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0063
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0100
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 396 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 396 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 400 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 400 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0048
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0123
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 402 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 402 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0141
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0054
============================================================


============================================================
🔄 Round 404 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 404 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0024
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0317
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 407 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 407 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0076
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0023
============================================================


============================================================
🔄 Round 408 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 408 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0085
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0033
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 409 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 409 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0102
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0090
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 410 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 410 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0080
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0022
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 410 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 413 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 413 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0111
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0103
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 414 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 414 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0056
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0067
============================================================


============================================================
🔄 Round 415 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 415 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0082
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0021
============================================================


============================================================
🔄 Round 416 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 416 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0072
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0005
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 417 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 417 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0092
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0057
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 419 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 419 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0042
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0196
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 420 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 420 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0081
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0007
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 425 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 425 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0076
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0020
============================================================


============================================================
🔄 Round 426 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 426 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0050
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0110
============================================================


============================================================
🔄 Round 428 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 428 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0067
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0042
============================================================


============================================================
🔄 Round 429 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 429 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0037
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0176
============================================================


============================================================
🔄 Round 431 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 431 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0489
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 431 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 438 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 438 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0106
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0028
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 439 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 439 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0029
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0338
============================================================


============================================================
🔄 Round 443 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 443 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0072
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0024
============================================================


============================================================
🔄 Round 444 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 444 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0069
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0023
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 444 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 444 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 448 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 448 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0074
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0035
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 448 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 448 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 448 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 457 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 457 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0035
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0193
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 460 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 460 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0078
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0025
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 462 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 462 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0051
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0093
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 463 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 463 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0040
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0137
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 464 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 464 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0073
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0038
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 464 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 464 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 471 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 471 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0070
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0015
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 471 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 471 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 476 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 476 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0035
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0201
============================================================


============================================================
🔄 Round 478 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 478 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0079
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0005
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 478 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 480 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 480 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0067
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0045
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 480 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 483 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 483 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0053
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0081
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 484 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 484 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0188
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 484 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 486 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 486 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0105
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0044
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 489 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 489 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0041
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0159
============================================================


============================================================
🔄 Round 491 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 491 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0065
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0032
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 492 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 492 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0039
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0150
============================================================


============================================================
🔄 Round 496 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 496 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0045
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0127
============================================================


============================================================
🔄 Round 497 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 497 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0041
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0194
============================================================


============================================================
🔄 Round 498 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 498 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0098
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0031
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 498 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 501 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 501 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0062
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0049
============================================================


============================================================
🔄 Round 502 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 502 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0006
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0618
============================================================


============================================================
🔄 Round 505 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 505 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0048
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0124
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 505 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 505 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 505 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 505 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 511 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 511 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0083
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0021
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 513 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 513 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0103
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0029
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 513 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 520 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 520 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0027
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0199
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 520 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 528 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 528 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0026
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0204
============================================================


============================================================
🔄 Round 529 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 529 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0041
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0106
============================================================


============================================================
🔄 Round 530 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 530 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0063
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0046
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

📊 Round 530 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 533 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 533 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0032
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0193
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 534 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 534 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=-0.0031
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0180
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

📊 Round 534 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 536 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 536 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0064
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0064
============================================================


============================================================
🔄 Round 537 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 537 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0059
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0094
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 538 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0796, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0798, val=0.0793, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0798, val=0.0791, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 538 Summary - Client client_16
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0026
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0387
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0008

============================================================
🔄 Round 543 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 543 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0039
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0162
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 545 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 545 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0069
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0019
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 545 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 550 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 550 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0038
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0275
============================================================


============================================================
🔄 Round 551 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 551 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0117
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0109
============================================================


============================================================
🔄 Round 552 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 552 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0043
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0126
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 557 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 557 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0057
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0059
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 562 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 562 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0047
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0108
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 562 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 562 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 565 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 565 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0033
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0215
============================================================


============================================================
🔄 Round 568 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0777, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0802, val=0.0776, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 568 Summary - Client client_16
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0011
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0266
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 568 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 571 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 571 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0061
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0055
============================================================


============================================================
🔄 Round 572 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 572 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0070
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0013
============================================================


============================================================
🔄 Round 573 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 573 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0034
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0154
============================================================


============================================================
🔄 Round 575 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 575 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0045
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0126
============================================================


============================================================
🔄 Round 577 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 577 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0013
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0362
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 577 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 582 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 582 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0078
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0012
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 582 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

============================================================
🔄 Round 589 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 589 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0068
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0000
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

📊 Round 589 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

📊 Round 589 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

============================================================
🔄 Round 593 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 593 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0034
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0187
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

============================================================
🔄 Round 594 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 594 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0064
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0005
============================================================


============================================================
🔄 Round 595 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 595 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0059
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0027
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

============================================================
🔄 Round 597 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 597 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0030
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0231
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

============================================================
🔄 Round 598 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 598 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0072
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0029
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0006

📊 Round 598 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 602 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 602 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0045
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0105
============================================================


============================================================
🔄 Round 603 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 603 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0056
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0059
============================================================


============================================================
🔄 Round 604 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 604 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0057
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0051
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 605 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 605 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0067
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0026
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 606 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 606 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0037
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0299
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0007

📊 Round 606 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 606 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 612 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 612 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0068
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0016
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 614 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 614 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0038
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0156
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 620 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 620 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0036
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0133
============================================================


============================================================
🔄 Round 621 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 621 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0048
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0092
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 621 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 627 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 627 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0060
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0077
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 628 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 628 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0063
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0041
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 633 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 633 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0070
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0055
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 634 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 634 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0074
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0023
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 636 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 636 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0057
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0065
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 636 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 639 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 639 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0053
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0093
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 640 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 640 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0076
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0008
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 641 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 641 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0082
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0062
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 641 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 643 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 643 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0060
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0048
============================================================


============================================================
🔄 Round 645 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 645 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0075
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0014
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 646 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 646 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0052
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0075
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 646 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 652 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 652 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0045
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0199
============================================================


============================================================
🔄 Round 653 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 653 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0028
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0201
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0006

============================================================
🔄 Round 655 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 655 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0050
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0066
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 655 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 655 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 655 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 665 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 665 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0070
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0037
============================================================


============================================================
🔄 Round 668 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 668 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0040
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0164
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 669 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 669 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0079
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0002
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 671 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 671 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0084
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0031
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 671 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 676 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 676 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0072
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0006
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 679 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 679 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0051
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0143
============================================================


============================================================
🔄 Round 680 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 680 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0036
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0153
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 681 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 681 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0081
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0031
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 683 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 683 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0052
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0070
============================================================


============================================================
🔄 Round 684 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 684 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0111
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0035
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 686 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 686 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0024
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0242
============================================================


============================================================
🔄 Round 687 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 687 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0097
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0036
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 690 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 690 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0082
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0041
============================================================


============================================================
🔄 Round 691 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 691 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0033
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0176
============================================================


============================================================
🔄 Round 693 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 693 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0055
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0070
============================================================


============================================================
🔄 Round 694 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 694 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0060
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0049
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 696 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 696 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0051
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0159
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 696 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 706 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 706 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0110
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0060
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 707 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 707 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0033
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0284
============================================================


============================================================
🔄 Round 708 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 708 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0053
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0101
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 709 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 709 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0089
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0010

============================================================
🔄 Round 712 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 712 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0048
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0196
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

============================================================
🔄 Round 713 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 713 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0088
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0036
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 713 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 713 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 721 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 721 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0109
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0000
============================================================


============================================================
🔄 Round 724 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 724 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0053
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0097
============================================================


============================================================
🔄 Round 727 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 727 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0075
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0016
============================================================


============================================================
🔄 Round 728 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 728 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0065
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0047
============================================================


============================================================
🔄 Round 732 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 732 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0083
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0000
============================================================


============================================================
🔄 Round 733 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 733 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0054
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0068
============================================================


============================================================
🔄 Round 734 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 734 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0066
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0028
============================================================


============================================================
🔄 Round 735 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 735 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0043
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0131
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0006

📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0008

📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 735 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 744 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 744 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0050
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0152
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 745 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 745 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0109
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0058
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0006

============================================================
🔄 Round 748 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 748 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0037
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0126
============================================================


============================================================
🔄 Round 749 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 749 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0048
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0061
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2390, R²: -0.0006

============================================================
🔄 Round 753 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 753 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0073
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0001
============================================================


============================================================
🔄 Round 755 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 755 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0108
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0004
============================================================


============================================================
🔄 Round 756 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 756 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0046
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0147
============================================================


============================================================
🔄 Round 757 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 757 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0166
============================================================


============================================================
🔄 Round 761 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 761 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0113
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0025
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 761 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 764 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 764 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0057
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0135
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

📊 Round 764 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0009

============================================================
🔄 Round 768 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 768 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0053
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0143
============================================================


============================================================
🔄 Round 770 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 770 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0050
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0159
============================================================


============================================================
🔄 Round 771 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 771 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0035
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0208
============================================================


============================================================
🔄 Round 772 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 772 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0103
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0003
============================================================


============================================================
🔄 Round 773 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 773 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0000
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0661
============================================================


============================================================
🔄 Round 775 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 775 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0065
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0047
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

📊 Round 775 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 777 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 777 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0062
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0051
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0007

============================================================
🔄 Round 780 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 780 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0075
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0016
============================================================


============================================================
🔄 Round 781 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 781 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0044
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0141
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2389, R²: -0.0006

============================================================
🔄 Round 782 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 782 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0088
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0009
============================================================


❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
