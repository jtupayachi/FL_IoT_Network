[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e62b20b-beb8-4650-8e00-d535eef6411f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23624ba9-a284-453a-8268-4e6729b022ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0009f4-7a4d-4ee0-8e87-9742e1fb61d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e88e5d-67ff-422e-b8f3-a811c94cbd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6d40d1-bdae-42fb-9935-5a2501a90e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea3ab14f-23c1-4887-a9da-04abef1e792d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d259fa0-2c23-43db-b12b-e0a7dc9fb441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16566fb5-d6ad-4ee6-b289-db2297c490e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c591a51-2663-47e7-ad9f-8efbf3368a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffd5415-32b5-4cad-aa1a-a8e8b24f2d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861c7f5c-ba0d-4d9a-b8fc-a90482122ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc926bc-1830-4d1a-9148-e0e56a1bd435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84128efe-40e4-487d-bfe1-44cc00f52fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2a8ea1-4419-41a1-a3c0-efc93bed2811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a008b97b-abcc-4f5b-9cfa-0977fefa157a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d2def0-33ef-4f5f-b572-238affa2c39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8954a406-4c93-4767-8735-4898509d5e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a43c8b-59e8-42c4-a6f6-6ac0d6c231fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa60723-0d50-4b87-8715-81d544a50e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e636bb88-315e-464b-9e92-b7e28cc784fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2908efa9-664d-4c53-be8d-6b9bde060b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83077162-6294-45f9-9ac7-f490d82bd4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44ae71b-8a03-41b0-b6eb-60e0f56e597c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c60595-caf2-4aa5-9c68-1eb58afa4c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9b7525-74d4-4ec5-8688-fcfa88efc034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04359a79-73d6-4b34-9a30-4579a69b9fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163b4a5f-9488-45f2-b964-d39444b09f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b036a5e1-628c-43e7-b808-ece9863fc8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c641209-30fc-478d-b5bf-4c5128319fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0908f3d0-8794-4454-ac56-e2b95ae5f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64799e67-972e-42b7-a1af-fadf6a6971e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e8a4aa-50bb-4829-af52-d0d4232ea27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59776ba3-8790-4377-9cf9-d2e8bcc0488f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09afcace-6168-4906-93e5-362d7220fe54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55ed3ca-87ea-4c17-a197-d044f5114fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e9e4de-7419-4bbd-a096-5c7ea9c2d21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6195b3b9-f92a-4770-9a09-88013abe87aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf6cb91-d1aa-4dde-a594-95d4b56be196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18180d7-b168-4dd3-b904-8df5fbdb2f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc15014-2785-470b-ab30-36eaf66c3768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5e9423-36c3-4057-80b0-509dd7c9aac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d258b87d-d38e-46ad-ac37-4c79a82f89f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9996a2bf-4336-4fe4-bf4e-07f57fe5039e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf92ee5-5789-4e9d-bd94-ee51554c79b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ecff9f-60f0-45ff-9ecc-ce440589fd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c34267-421a-4156-ad3f-5f83ba7c2351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0d1ae0-b342-442a-a8f0-f3b7e6fad334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f646b62-e23a-4406-8659-037fc944fa50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717a09e7-3644-40ee-855f-6c1b93b8ccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5af400b-4539-4cd1-bdaa-7d89b2d21e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 428b7bb5-ebf1-4ebd-800c-e7e964a16a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8860c593-8ac7-4891-a825-9a57483229d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd30b34-ccf1-4c51-8177-b6db7ded2eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ad54d0-25d5-4233-832e-de60728f6c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9a50d8-3bd5-4343-8d96-66911ebd34e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a22f156-eff0-44ef-80ff-165581793d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff0c18e4-300f-456c-ae70-44bb59ad7737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05cd5c53-553e-409e-bd9d-07020eb87225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd78e81-2f92-487e-ad3a-89069d3e51e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2df65b-5943-4787-be75-7e05a49b5b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f164220b-5754-4dad-a155-790ee37cf1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1dfc1e-1750-4fad-9d86-d42aa253c923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b227c1db-1c6e-4718-9e39-8a613ab4a7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b6773de-5056-4854-b0f1-3729979d831d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce7cab1-669e-4610-8ef5-177575263362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7344445e-209e-4f25-b731-eea693c62ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ed6013-fb8f-4c53-9a66-fb590730b3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f5a19b-8410-4875-b35d-4d406fe1502d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789626a1-dbc8-4f7e-9482-9eae2c03336f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4ce8e9-a538-4db1-8828-d41f5f57efad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb4ce6b-df00-4b48-91b7-74ba2daad5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95985043-c64a-4a47-94c7-1b933e00c59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c55fe1-e149-46fe-bce4-bdd105595a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2604507-6c7d-45c9-b7ef-a6b4e6c4faf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bbdf931-e7d0-4c40-bd77-d7783c85540f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e648cc5b-764a-4a83-9c7d-963d5a965be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 956571fe-5169-4c27-b30b-99e2749200e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dae2653-c975-449a-8bf4-6c2926594ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd935e3-48a4-4bb9-ab11-a6bf64560d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482be0e8-272b-4ffe-b1f7-80b3a7944a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22b2be7-ba3c-4791-a896-be3fd0dfe786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366d91be-8fb4-4025-af3c-33c4ea3513df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee43c1b-7d1f-489e-b7ab-9d149eb38e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790166d6-8fb0-463a-a745-e1f6df387611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e361dd-8b78-4985-b3c4-c7c13a706479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86dfc773-05dc-4465-84e5-b6d58c810e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffeaae1-a905-487d-ab4b-7b822ee996cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e464f2a-d388-4999-8282-7cdf1acef9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02deea9b-f44d-49de-82b5-9a3fc007c97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1906c299-ff0a-4131-b987-a2c7177c461f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b22a56d-1fce-4d7c-a850-8672b434b723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe696e2-1e92-4504-a641-ce7ce6197b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77dba2a-c480-4523-a42b-b5a2aeacaf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d66860-5bd0-4160-a205-81d525827847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9fb5967-1a51-462f-be5a-d2f34232ce03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d19c61-8892-4912-b2cc-32f84f33af76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a424ae-8162-47c1-b4a1-9300cfa741a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc43712c-689a-4d24-9c0b-f61023a4afaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10d1613-08d9-46cd-b43c-2e3d61e7314e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e2f27f-e30e-4c3e-9eda-382166df829b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c60206-7a73-428a-8465-b782a1fcf052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f16efca-7ae7-4f4d-a09f-36d541ac4753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cc1598-b10f-4991-acf5-bf3f40f71b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4bcca9-4ab6-48f5-8ca6-33430aee89e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6423c160-1d65-48d8-b0a5-f0e15a51c5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95efdd8-c3b8-4ece-9b65-b46266624778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a712ed5-6611-4173-8c77-8217876ed2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a490386-1031-495e-9af3-003594eba7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9550c74c-42d3-4da0-9b40-19787b862aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8599cd-b059-4c43-b874-8158664850bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f944b002-d8bf-4da4-a21c-0dd753071c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38195bc8-0d5e-4a6f-83b8-80822bea96ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c036a40-5bd2-4879-99a5-cd771da1e300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e26c3eb-8cee-45a3-a6be-351cdf530a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cc6ec9a-7ab7-48c3-8756-2f620fd53258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f672f70-64c3-4a51-91f3-6c4c7b2da6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d75ce3-7f60-483f-9e14-5e316bbd8e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a809b2-4090-443e-9ad5-edeff180bfaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a2b6f4-4a92-4091-b34c-c35488eda228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5643120-2b28-4936-a869-0d92bf5d0bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fb8603-8fb8-4eca-97b5-244f4bfa0ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f567cd04-3bf1-4fe7-9149-100f63867c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ebbb9e-a4ab-44fa-85b3-0863ddcafad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a490d50a-c039-4335-ab28-dedbea2d384a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e3e541-5a34-4764-a7d4-e9fa9d4b8f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1d1809-1ff4-4b82-bb49-17ce7918d338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98fac1cc-4bc4-4225-8621-87384ffb6121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149d7ad5-48e4-4b34-a6f6-fa6783a81c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d944d84-755d-4a3e-97f3-79851604c6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39468fef-9ffd-4e40-8648-1b13af5feb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc96d8c6-6d2e-4e90-be69-576f15f2f76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc9a22b-672c-41c6-b1cf-f7fb324def0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89088cf5-ef8a-4c6e-ac47-38adde4e394c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc4ecb7f-0b5e-4534-8625-adb5fe432dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b23203-8f29-49cf-9af9-ad8464f43ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8f5ea8-fd52-47c5-878e-fa576f624cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4d944f-9bc9-4a01-8d0f-c973b757ac77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4725c6ae-9797-4e45-8929-555a2cba5f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee27631-c355-409b-9668-4194bef988b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8ab53f-d881-440e-beb2-415618e8dce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690fb38e-04fe-4db3-b667-b6ebfc81a70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3276063-66f3-4cfa-9f91-e823c80143d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62df079c-5b39-4775-80ac-5fe2625c72e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78d5b29b-4dea-4d51-af83-6bed5c6bbf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ffc955-d6aa-4d65-9f2b-3e5127b3f9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6e736e-6a6e-4488-9b1c-479d3e4b5972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d753d403-28f6-4038-9989-362288a5210d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35145e3-f5cf-46c7-9a55-6d699eb9ec63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93471c8d-bf19-413e-b6a8-0f7545c1d3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ede03cd-d472-4080-a951-811476e208c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ea4ad6-cae3-4478-a807-a25b7d41644a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8c759c-9555-4b78-ad68-5a4753bdd58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d765fbb6-6f31-4332-a4d9-3e8defcd608f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b55a8e8c-6911-47dd-bd97-c46d23bf50d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1106508-b9ec-4dcc-9354-e862194e71e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d864f037-07e6-4801-8c6b-711c64ea6032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6faf0e90-52d2-4a90-b8bf-455c9f28d72e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e6066c-e00b-478c-a58a-74571e6447c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecf668f-17e3-4f22-9e9b-77449041000c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c00f06-a6df-4b05-952b-e0407e6e078e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82f4a81-7322-495d-a1e0-4e5aa3f14a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1127e65e-3341-4213-925a-484fb98a374d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60d09ea-70a8-461d-80e5-b523c6bb90a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee4de2f-4c77-4271-bd08-4a91e9c2c9b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5ed1e2-cf18-4f3d-bfe7-60d62e651810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2133f1c4-b603-4755-86a4-fddefd554e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e6e24e-276b-4d49-9de0-a01d35fbacf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe08ea1-d8ff-414c-9dd2-a9d5d1e5e5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08bc7377-d759-4047-94eb-e973e02c7e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5d5700-0e6c-4bac-952b-80dd171d4e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee64d09-fc9d-43ee-86ea-4daf1ac182a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d09408-5aea-4bc6-8b30-8849c6dc16be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e3c571-9f13-4dfc-a0b4-959ae5f31bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcca29a-d49d-40b8-8b62-6b0ffa12ccb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae413540-8d5e-4e6b-a962-0c1e104ca39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777b75ec-b219-48c5-b866-a87a4b87cc0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275c0e5d-09a3-41ae-89b9-0bcf18b52b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac32ae87-da22-452c-88dc-582a2587ccde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd30041-57c1-4c8f-9204-1b209a4e4f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33f2d643-75d5-41cb-b755-e43d75cf5c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eea98ff-99e3-4d1a-ad62-01a9a6424190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240fc9ac-67f9-4879-8be5-32b3acbb8006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80529bb4-efba-497a-9cf9-d3cb4afc72ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c437a7b-beaf-4253-99df-c15f9f00731b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62717a3a-0a64-470c-96b9-239e6befcdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48cc8add-6fb5-48ae-b312-35055f41b4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e1a536-f79f-44d6-96b7-c98389487b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f655af-c668-4467-8984-9644bc517b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d022c37a-833f-4a7c-b067-12c5d9c95652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0764f17f-f615-4420-aeba-8ad4e528b1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f993173-ae02-482d-be53-eec1e29d9e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1450d33b-62ba-4e28-9071-a02b09736021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090a105c-c735-408c-92a2-59a9b8a9ec8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7f615a-2dad-4d81-a5e9-56b1a8f6419b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f22893-9b16-4692-8ba4-888e4a8e9eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af3c459d-8467-42a4-a2b4-d49286cc6863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab65ebf2-79f3-49e6-95fb-f68812a0d04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a30f2f2-e8e2-4a49-b9a8-5b7f9cbaf23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec57fcf7-40f2-45e4-bd8b-06b6648c2eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06fde6a7-67b9-41fb-a3ec-0bce454d6a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b2b850-f512-4ef9-8a77-d714f4da8253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09bedb5d-e197-45c8-8b0b-2711204b7caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b6c246-6df6-4704-a0b9-cc7f0fefa1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 342c3765-e5ad-432a-b033-a9264b200c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c376a896-5cb3-4ec7-b134-c70940a9f213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f73bd3d6-7eb4-4d82-a510-03cfd12a8a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b205d4bd-669e-4ad4-b678-388447eeadc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ce37db-c009-4921-bdbf-44aa69a6f826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1623076-6672-4fe5-8e41-2e4463749023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644721af-f2fa-4bf0-84b6-88499f33e5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208f4981-9a93-4a89-b1f2-96a52b10f666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5ab172-d2fa-4c32-a39d-c688b8b2c9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5dfb12-2c8a-4acf-9e5f-d54ff1530bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a54f92cb-da34-4b04-b393-51f3df350936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fd2080-106a-411d-ab2c-67653a2d113d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53d7f29-93b2-4cd4-a91e-eaba158ee0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0963982-20e0-429e-b84b-818dfce1c945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051b3724-a28c-49e4-a0bf-4e5d9630fe4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b252e7-5f87-4892-a04e-0ebd0b09c61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf967f3-1b38-408e-89c9-15d111388420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01254c83-bf31-4198-8df1-7f52d1c7b202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44c3a7e-e7fc-400a-83ab-46a8ed0d02c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ffc6a03-0ba7-4829-8067-a5b23975766d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2cacb6-aa0f-405c-94ed-9da3778dbfe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9101a180-d100-4576-85e6-95190183af25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6b411c-15ff-4ebc-a028-12d64df31ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ac17e5-05f1-420d-90a2-b51de6eb5f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc9860f-c300-4619-a2d9-1f68d7298d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a923f40b-1648-4d52-a090-8cf2d0c47d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08013b3-a4ef-40a1-b77f-ca238a17337c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1083df05-28bb-4506-98ec-8ddcab8ef334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49eda65-9a12-4b5c-b4a4-05e34906502d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ed194f-e146-486c-b1a1-192b94b36331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b17269-d84b-4000-8df0-e5559fcf79a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958123d1-75ba-452f-9f86-44d7548d8df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749cb6f4-6cc2-49eb-986d-9edee98d712a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4502b81d-604e-4d15-96f2-3d9f5b14cd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c615d4b6-e2d6-4c0c-9348-10c51d64418b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe6f309-fcc4-4ba3-a458-aa0e801e7509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ddefdf0-e5a9-45bc-9c49-fd0747f4a2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8ef7c0-f8c5-4a28-9d91-e98b7a79676f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16621a71-34d8-48c5-b132-26ba575ebedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cc1b27-0734-41ff-a160-b331701df5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a5613b-54b3-44f8-984b-9839eddd5d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45026e1d-188c-43d9-bca6-0daaebd9650f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1244ea24-5eeb-4991-91f5-783dd304e75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c75d93b-cf20-4df7-9cb1-ac4aa140e792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3a1704-02e8-4fed-834d-3f6b24eecf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb51147-435c-4b1d-add5-19a3b522f78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4d7c28-b1c6-4be6-acae-cba9f6d07e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 671cfabe-b48f-44a5-8dce-84f604937d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6080551-0dc1-4366-bd26-cc4110a5d2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8186f531-6041-4561-88e0-07b2c9bea9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed09a771-e5b1-4794-9a9a-9fbab807f53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6040a6-b1d9-42a7-9fb6-d8d0d0766469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ff907f-9992-450d-a0d0-c77da2a9518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfce539-ee54-432f-92e3-1aab22bc3627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21f4ca9b-1ddd-4cdd-9a6e-aa8248658fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7be31a5-30ad-4fc2-950f-12afe618748f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea856516-d258-43b3-8ec2-e6473743a2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b20fab-808d-4dd6-a6b7-d0902dc63d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d2ffa8d-1994-41bc-ad1a-8923c249388c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac348437-8379-4b82-badc-c48dbacc5681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d681aa43-34fa-4d37-b4b8-7fdbf78d0bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b43b1e-6f23-43d0-8bf5-09e2589feea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53350e48-3525-4af1-ae6d-6258576b45df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0968633-f858-4cbc-931b-6b28c6da72a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e6f6e3e-6049-4707-885d-9b6da8d0c658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec0345f-aefb-43d0-9a13-8a212ac26f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53688961-e4e0-42d9-88ae-a1ead9120ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2412038-da4b-49c3-8ffb-789d6d76cac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d042f9f0-b025-477b-81a0-f7707f4b9b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dff2634-e9cc-4145-b274-d1c19b51d6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171872dc-dff1-4447-934f-6df951cea696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff97e122-6a22-4a0f-a602-e74e86f97d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98454655-0cc4-4d99-b9ad-3e0fff3dc348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17797a75-4c35-427a-9bf7-194d030af5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd241f3-6fe1-4aa0-be47-22fb129b3821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d519f50-fa4e-40a3-bd31-debfb1b8c04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ef9c67-cd22-46b6-befd-518d8cc566bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da85e31-24db-4693-ab63-38a807935fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629f31e8-e708-4670-bf0a-f23c94eeed98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376c9096-21dd-4e9e-b075-a8e3051a9eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff807b67-e330-4e59-a466-46b8dec26138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6cdb82b-5ef9-44cf-848f-6bd451cd2334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06cf98a3-daab-4e0b-916f-6a7449df1678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447c0d07-fb6c-4e4a-9e90-7274af79e842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd97393-9008-4e08-8a91-a0c2caa64eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9350e445-a1e6-4f6d-8baa-b35df09285a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ae566f-7106-4e42-b9a1-dbe173bd9f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6949bb3f-bb34-41ac-b98c-a396f56b76b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fb8974-2e90-48f7-a00b-d60913f62a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9d6bb2f-db46-47ca-918c-05ea9ef119fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535b63ec-1475-47a8-942c-75131504ca69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0fcae3-4643-48a5-9790-e4bf237fa966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06191fd-93f9-44bf-8908-cb354134a701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b4f72a-f82d-461f-9b5a-c4191f3a5439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b79cac1-5399-47b3-9aed-2acbdfc4c599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2e7c7a-7d26-40ad-a32a-7c7dc375f158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb6b3c1-5a55-4a3e-b9cd-f94733bb1567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfeac224-7485-43ff-8041-6edb0f9e21f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edee5913-ba50-48e8-928d-cfd9f87e3e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d973ca-1bdd-4b51-a0a5-af33461d9efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9378e214-299a-4e7c-a9e6-1a02d08053b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf5c7fa-3a5c-4234-b68c-55b08f44404e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a2504d-eaaf-436a-a99a-591872204275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c28ca2-1cee-4437-8cf1-c3de7da0b634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4603d5-9a94-4c33-852e-63859914cc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7871c0-5a91-469f-8eaa-a9ce6e843d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b87612-2ef1-456f-8d32-9472f0022fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbf97a90-3394-4dc1-9c3e-7ad30776e79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d1b7ae-e41b-4be9-9a7d-d73dff015510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e13a81-b0a8-4072-bd98-0db129f6e549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcbe63d-78a3-4bd5-9a71-c7d6a5e722d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ad612b-0a39-4af3-9e2d-6fde5c3b38e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f331824b-635d-43e3-8284-a08aad60cc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff8ca5a-2b4b-4009-b4ba-2f4ee194b873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14246ac9-d6f0-480d-99e9-ee6092cc3888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4af71a-7c2e-416c-8835-d2ee2e51c20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d1df4c-a038-47c8-97a8-9bc81f86d30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34b95824-da0e-465d-b0a1-92a88eb35967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724ed61c-29d4-4389-95e0-89cb2f0e7505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04bb1ade-0d04-4a8d-bb12-9c36cbf7685d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd207e3-18cc-4548-8531-9428a5e8a056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831d18cb-bffe-43a5-8dbe-b38d7a530c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50956689-8df3-47bf-8fca-5e0901a178f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78babbe-cbc7-445c-9151-4690e63a7311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b3aaac-dbe1-4bed-85f9-81965201e9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af245f5-dd9b-4495-8c4f-a46d2a65d0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6219eb0-f955-4172-b272-b5748b14a4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d90ac3e-301f-4236-8df2-bfe7348109ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3be770-7c0c-472c-99ab-3f078264bd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db3c389-8a4f-4300-a2c4-c2b926961925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c44b51b-94f6-4815-8fa3-91397df30e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309d0b00-f992-40e1-860a-4fb76a14b25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa4fddf-a435-4129-9deb-9572e8ec2d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af565475-6cb2-4859-a31e-0630aec86f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb5c874-a5ae-41fa-a4f0-18424cb5dc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fde6605-378e-40ed-bd78-fa9af8583c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf4030e-41c6-4438-b61d-f128e5d8e892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35d7910-9fd2-48e6-9815-0ff13cbb0562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e68aca-96f6-4977-86b9-a8c2f94aac2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3962d20d-53e7-4b75-b383-a244ba767897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed30b8e-3e81-4165-9db2-73d54a51f588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4188bfd1-25a5-44da-85ff-8491a34c6a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee57cea5-19e1-4a7b-b68b-88ff342bdaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f35b30-b89a-4b25-9c97-4d495bc4e28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e9d6bd-dca7-4ff0-aaa0-bcdd759f2210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d480447-4955-4bff-b59b-2f949fd2005c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628130fc-e29e-46e4-a4e4-70d89eb569ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35bc15ae-48dd-4740-baa3-66216e437cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c66e3d-5eec-4049-8228-4da2e2c8c117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b42deb9-3bec-4330-8e0e-c23742513720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4bf1e6-1e83-4f1e-91e7-6b932d2f120d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b045efee-3556-4f3a-86f9-accf7c146dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6faab9c5-b029-420b-96dd-dc90bdf2d987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582085e5-a374-453d-a817-c6b3c4c089b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389e9b89-2ebb-4a5c-8f3c-2a6fdcec4654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588dcede-fc93-4db0-bd89-2efdb97f2bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb88c1f-b29c-44cc-9c61-ce80147980d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128366af-787d-45c4-a4c9-09879fd174ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748d7651-6250-4ec6-81ba-9b8d7fe3071b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35ce5ea-bd87-4e99-af97-90ef081e3026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a34fc6-e7af-4817-88e4-5d6fb150bcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3066a14b-6a3b-4ed3-8560-cf84d08b3569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069a3f21-4c99-4923-9912-4f240369b3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1923ca0d-38d0-4693-824b-94189e2ac53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad7d13b-d264-4b31-b781-caef5615716e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0262c3ba-42df-4aed-bfcc-09a5f054ab7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e1dcd4-c3ba-4313-90bf-c84250a67364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00bd7b5-b269-4499-a6e0-ecdd0b428faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7347c5-ae76-4b19-b5eb-68c8e7cbce74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef77e7e-e84d-455f-bfbb-1b395d97b49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79354b9d-f7d2-4398-8d2b-aa6a8d48512c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edfe0573-c5eb-4dda-af29-c9e6ed5625f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2c38e2-1516-4675-8b4e-f2e56598870f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a3ac18-6395-493d-ab22-8094b4d89ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e84b36-ccd6-4be3-a38d-330768931c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d29f1f-5d20-4b9c-b8d3-8afde39eb1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8082562-f4cf-4935-a65d-3484d8f91cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da3a0d2e-25e7-4129-849a-342c41e9f342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122f1491-757b-425d-b58a-7566256e1777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e76e146-0663-43b4-a215-cc5fbd4cd167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c344d0-7ee4-4435-a1cd-53efc63d03df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8942628f-b2b3-47ed-82e8-331dc06e18bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8de9854-6940-4502-969b-6641214abe57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a23d1f3-5a82-4340-9b7a-63b80458f588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed7f180-3f3b-4e21-a4c2-637c4d063e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1715808b-0cff-4b1d-841b-f9c93b820511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca04c77-d41f-4995-b445-e4000a55d82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a6e1f5-3933-42f7-981b-bb2e012c9766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb5379f-0a98-4099-80c8-bda1695ea4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5509f6-2dd1-4ab6-bf30-3f3ceb0b10c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2ddd6e-9cb2-4570-8175-931e4b095b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9ea3bf-b1ce-4a0d-bf8c-0c161b02af36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793dc554-cc50-4bf5-941a-cfebe4f626d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aad7218-6650-4c61-9fc5-ab494ad7ec8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb40072-2a57-4e12-89ac-3451637d0501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20e4f8f-4a17-434f-b4a0-3c8bf3763d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 416643e5-7098-4878-a5b8-8c51b6d38f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b711ae8b-87f4-4178-b404-6b7b0103a6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff1b73c5-88cf-4462-9436-ae3f2d560ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3320570-c888-4c88-bf03-e3b90e430327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd151f72-fcfa-448e-8741-b88e0b075e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ea29a1-f250-4f6b-a9e7-fadfc229d90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a415d8-e922-45d4-a1c2-15e9c2a68dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ffe5ee0-1eb0-4289-9529-3b3a73928773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb6f6af-f0c5-4020-b271-0fe31c583991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0b706b-1935-4958-b460-34d1026a547b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a6302c-e2c0-49d6-b913-2f15d382937a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876c27b7-36fd-4c5b-a530-9676a637a473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e04bc3-5ba8-45b7-82ee-2c142a5989d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c904452e-82ee-422d-8f80-a32da0158a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdff2075-1ee1-4c2f-9c77-b35346e79b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c79bfb3-2697-414c-8029-a0c430038d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d4204c-bdfe-4f4e-8adc-8b5f18def6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32200268-6f8b-4213-9e9f-820d687fc1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1e0189-9ff5-4e93-b67d-591c1f9bf5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b27ce6f-2a12-45a1-9db4-0090d586f3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a8db67-48f1-46d2-9f29-aed9b0f6007c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a070b995-86a1-46aa-ae90-491487be5f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e61b91-7a22-4696-9225-ff6083328171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903b54c7-27ed-488c-8e5d-d470febf13ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c80adb7-db85-4f51-acbe-6355c3c6ec17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bfacdf9-9889-4708-9ae9-ed0ebcc6321d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57483743-45e8-402e-b08a-822e79bc293b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7eea3c-b265-4b62-b916-a8388f59f246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1906cbdc-9067-43fd-a486-18d894e41e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf9860b-1d94-43fa-b924-b1791748cf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c6fc40-be2a-47fb-a952-3c880c400811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6473dfd4-5fc9-4fc5-8741-19bf913d2a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255e6491-4250-451d-82c4-c3280451a1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c77e465-885a-40d1-8f31-0fd6b6432b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85673eab-1aeb-458f-83d8-877d91516aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2642a974-9e3c-4c76-88e1-417472bafdcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25e9e85-0499-4f45-8364-798f2dd6b1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08f8876-80f4-4008-acdd-b5765d11362d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f5f1e8-d38f-4456-89c2-602d9d2b9da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5c768e-6caa-4fbe-9c9b-7b1cfa993711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29029ecc-b683-48fc-b428-62cf0d85f7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9305d7ce-87d4-49ac-847c-e7536a9caa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9c39e8-836d-49d1-9e1d-4e9997915b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a934a90a-a995-4ddf-973f-9bcea5db4fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d24deb-bfd1-4e65-bc2f-9433e7a17c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35501f9-4b63-4ae9-afbe-8c6d18e61ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5307e956-7ecb-43a8-8eeb-4340b664da18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb68cc7-1202-475e-a458-3b650fc1cc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acb2ce3-e7c2-4fde-b2dc-e0a9025f9a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868344c0-c51f-45d5-8d34-422182f0b0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf54b8e0-a94c-4164-8507-c999dc9dc527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573631b4-5f06-4b85-b97d-0436634132f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41faa83f-6824-4530-af1f-be7bb671fd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c868474-b51f-44ce-b77b-28d2f81c0a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d14cd5f-80ff-464f-a274-a6a9f45a48ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2ec03f-fd3e-48e1-a73d-04fe6cfcc0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03892205-e0a3-4fb9-947d-5482f4ec1479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b42f93-46c7-4c2c-a4d2-1cbfcf705d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1277dbad-daac-4ed9-b63d-99f9f8c2488d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c605cc2e-cdc2-4acd-b2c5-d542f9eb37f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb392093-84d0-419a-871a-1787b946db76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0160c3-6826-4426-ba78-3025f4706ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898c7081-a970-41e0-8203-ebab2dc21baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78709d9-4b91-4b55-ad2d-d4f5585bdbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 966e0d18-6b97-474f-9008-dc83c81f7329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea5a659-3539-48de-8f88-4c8d74b0096a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912d42e1-5b4b-4ee0-b95d-a6f075c69d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343158d2-bcc4-436f-b7cd-7f74f47a57e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ffc0e15-745c-4bc2-b29f-2a1297520d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f5c9dc9-bef7-4093-bc71-6c780d18f291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25894200-811a-4072-a59a-4a4983889c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3651319-a119-4ce2-9e77-bb4df22e6df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5c0568-3e51-45c7-8b7b-85b92794dc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15840bdd-49d7-4609-96c0-2161eb9e0279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e807ade-de92-4f66-a25d-65f71037706a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5432f58-aea6-42dd-954b-502feb889998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e11ab3-6e93-420b-92e0-8880ceb1e250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c6843b-4e8b-4a81-94aa-1c9fbe46dfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26907938-5d60-48dd-b53f-18a30ea446d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1ceffa-34fa-47b4-8023-68058cbe8e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d168344d-3b78-4c0f-aab3-eaace0bed6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1db1145-676f-484b-8ba5-43f57dddd056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b100979c-2339-4442-b3b3-46c245cde605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a85e94-61e1-48da-9d16-a851f0638048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d3a930-6260-4887-ac68-7f2d2946963f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac9bbfd-56e1-41a6-925e-9eaecd4c1b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0c2e1e-2094-4089-be61-b2c6566e6289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd4e0018-7c19-44a7-ba41-c85470001894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77510217-f85d-4512-b3a7-bc97b0931bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76580da6-45eb-4b37-a5f2-71f7a0047f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b8218f-74cd-4b02-ba7a-f1fd201bff2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5fd12c-d790-436d-8153-f947afc0fdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7470056-f233-494e-9065-934522655211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658b53b6-12d6-43b0-9532-a1f01255b71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb9c584a-9bf5-47be-8f03-d70b4ebfd430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59035b1e-d47d-4776-bf96-1fde97e5d1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0295e8d8-217b-44fb-9685-8ac127d9ad20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0296abbd-8e34-4496-8443-592ce50fedad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190865ec-1ee1-4b14-9477-842c1ee96a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c588dc12-33db-4453-94de-b0ef0cd4f15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858b80fb-694b-432a-ae8b-caa0369aab97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a332db2-1dcf-4f3c-8ffa-d114f2e97ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d36469-b01b-4da3-ad47-7ac79e8a7f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c6ebc7-eb9c-4b99-b82c-f15d546fa9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c496a773-2053-4581-9691-3fc4ffe882b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963052ee-3e14-46fa-b3bd-8302d1d09c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a51a04-b31b-44e3-8914-405c6763e151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52443857-1db7-455d-abec-9b76c4a4e2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007d4a7d-fb34-4078-9628-560444c06e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d0afbe-7fd3-4d21-a095-f859827dee88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a74895-9a9b-4bd5-8f4d-49cdc03ca0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44b01ba-2564-47c4-9b48-4243df666d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc00f7bd-3281-4fa4-a307-e24dc199a468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9334bf-1184-442c-b3d4-437d8be24b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf1a8db-d9b4-4bc1-8725-0e2e5ea8436a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93eca972-3312-4bb9-bde4-96e730587227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c789a57-bbaf-4135-98f9-cef3b5c7347d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2385c76-2e0f-4ff4-a86e-4db573ceee1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad974cd-c758-45e3-b6aa-e0a7d76ee116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825d01d7-67a5-444f-876b-9862514196b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431054ef-0fcb-4ea8-b7c6-3c852b07ae6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744186a0-e5d0-4e4a-ba38-d972290fc284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675f9be8-2edb-4798-997b-b047db579891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599c30dd-92c5-4db2-8e4d-a2ffd1e82a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4552351b-ed2b-4f82-bc33-96a627767e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34743e5-aa58-4b1e-a736-a8c841b24c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfec2f26-fb4e-4587-8ad8-580042e25b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d1ec55-b549-4c78-8804-45ae9c42b3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcaf360-68c5-4d26-9676-ddb40fc79712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40d5427-5e9f-4b19-a897-b5be74d166d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea01e372-73c1-44d0-9709-2f6f8fabf48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0da8ce5-0ee1-462f-9a23-d561d6829b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93b8873-bc4c-4fcf-86d0-721392e94063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688ab409-f1c2-4837-9898-8387c8ccbd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862890f7-ab31-4561-9c76-3facfec4b156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e298869a-c15c-4bf2-aa29-a28f0d13605b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef917c09-1001-4147-948b-9c521c3c1022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c50e972-cc80-42c5-8949-0abc25970de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a2a119-d624-49bf-9d8a-b894a296a0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafdd809-160f-402d-9300-eedf8d1844ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d957b31f-f0f5-43aa-84d1-21d7fa874ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f39360a3-72ca-4022-aff4-02705ce36646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad5add62-7ab0-422c-9052-018f05d5abb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f6bdc3-d4fa-4d6e-bfe8-f57def024e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b8f7036-3464-4eaf-bc7c-2edcc68ab553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95332f18-58ea-4dc4-b3f0-0ad97a4f9bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202293a1-198d-4d74-9ce4-e3e0cde1fa8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0f5a78-79a2-4cdf-ab14-ae556f8d7018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd29f37-8216-4cb5-b24c-76f4cb7957c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e63d97-541c-402b-9d08-450c2d956d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebeb1eb-1fb2-4545-ab20-270007625ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb22dbe-f6a1-4854-92d4-cff64ffe3c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9cbf2a2-17e7-444e-82ab-574579395e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb713110-9bbd-4a8a-a42f-51fee4eb252b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db0064b4-bd1f-4402-8bc6-fef6398da793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcce650-bb5b-4fb6-a3b9-824551940452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5694a672-cf06-4b8c-a2c8-25c9a82dbab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0072569d-8eb6-4360-a7bc-eb49fdfd2b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaafcaa4-a2eb-4c8d-9d46-2811114fee3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c223aa36-a236-4b01-affd-b6a45fb06291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97096cfd-a805-44f0-bc46-49c7db398fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cab112-c4a2-4bea-9335-719f310f28fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a928bca8-4912-45a2-ae58-5d2da0edfcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690bf0c3-8883-405a-a04e-c71d8ad4310a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e134a73-038c-49e4-a994-b7c4208204e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588e0216-9fef-4ac8-a461-f30874223494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5dca27-112c-4dd7-875d-699e54e5b622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b699e22-35ac-4db0-8381-26bc0425efa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c582dc-1d40-4b15-9e4f-1becc2fa7977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37af6b49-c3e4-4efd-a74f-d408a3b984fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d20955-3e2d-4b99-8f1f-c372ca80a15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb13fdd-354e-446f-92e5-2d91fe6f7438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760909fe-7f61-4c25-968c-2ed4450c09bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9268e9c1-e84c-4222-a6c4-4836e550da9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb13bad7-31bb-4e8f-928b-3909c444ef6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c896bbeb-61ed-4dfd-aecc-84a70154f5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e7e7b5-3eff-4584-ac53-8bc57b1f6f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00aca0c-1041-4b30-80d6-59713011c15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b71e86-1d1d-4c16-92c5-d77efc4fa908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22e3042-cf1e-4e43-b3cd-2b3c55bcdce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd81f43c-2f5d-42ff-80e1-29308cb2bc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3d0c9cd-dea4-433e-be23-d4280140ca14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e46568-bfb6-44e0-9f5f-63932c249559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23d28ac-bc9b-45bf-adf7-1fdb0ad27760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3c0d88-38bb-424c-b05d-3d6302b144d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff092a4-10a0-476f-8dd4-9146e2825d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74097187-1365-4f0a-960b-a154145d903d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f7bf88-21d7-47ba-a5d2-1214106c2ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b17c7230-53da-4ab7-94a7-d772e626b067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecc077b-646c-4c0b-8ed1-1be960b3a81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f84635-00f6-4678-82f8-ce7a65954072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e27ceb3-1104-43aa-b3d1-9d7e6012e1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea27445-2599-4192-adbc-d7457424865d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8719c9a-7223-4826-83de-54b840e957e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d0d429-e458-4164-8555-bb14870658cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de81cd0-8a44-4f15-a985-ea2db97c4d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b47111-06d5-48ee-a1cf-7c8f9227353f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca39d922-eba6-4f26-8f27-f770a03abef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0c03b6-ad6e-4947-8349-b4594fed33ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cad9abec-92ab-4b07-a2f4-4cc29e767695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78088ae5-8536-4836-9093-91da38bd4b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e019702-edc1-4f18-b26a-b62c5c40124d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27dddfd-5281-4da2-b8c4-ddee8aee4ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827c1bf9-4db7-41b2-9ebe-0ce6640d1d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11f5a77-2818-4de0-bf3d-113ecc66a168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f982da74-e71f-4d49-8a32-7907de971860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e0b5561-f6c1-4048-b390-8d9af627ff84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe92158f-511e-4eb0-8a2b-49fe70a7f121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8dfc33d-a701-491b-b08b-7fe4fc5529c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36f7d62-388b-4606-a02d-8c6612c21bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45227c72-a5a1-435c-8b13-064a80cccfe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1916aa0-1c47-4540-b2b0-3867c6823cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c46099d-adac-4b7c-9fd4-72877194e42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03949c04-2b3f-41c1-9c74-c27e60e82239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ae08ed-0c39-41ee-8fc4-7d8d8f0b183f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c825ae66-d8a2-4649-8385-69bf5c98cb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a264c26-72c5-44ea-a1ef-714acd5a7e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65def338-1221-4768-a403-522ef02c9c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e8c797-708d-4e27-af34-c47bc5c905e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba5a6be-5b22-4e2b-8119-995a56ba74ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acedda0-6bca-42e7-881e-6256032a36ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da618fc5-6fa8-458e-ac6e-64128457dac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e110ce-6a51-4925-86f0-19c6d3d717b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7634e122-5d71-47d5-ad42-dc58b4360258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6604b90b-bba3-45ab-8557-1215b04311ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bffdfde-ee9a-48d5-8beb-2050c8703839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63aee0a4-5d2d-4a71-94f3-51e7060bf103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15bf4d53-734b-4d01-b1ed-d15b24dd0a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e5a5ef-d92c-4554-b675-927e1e0c3d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa3bdf6-4557-4fc8-b345-cf2342232b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8062340-e008-431b-b83a-6595a0fb0f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b2c66c-576a-456d-a693-4e563fbf216f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9c0afa-77da-45fb-bc66-6154c3efa363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd31c9d1-3cb1-49e3-b645-3f1218ee4f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 481e57c2-136e-4e82-9497-698dfc1270bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035d86b2-9278-40ae-8d1f-f0ffd94e057a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b90bce6-7889-4372-8d50-e0cf9417fb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165b7daf-0a7c-4c40-8e2f-81f84308374b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0954a465-05e0-45b3-8d1a-832c356fa2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ade6ba-3753-4af4-b9cc-a80ef3d5a777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e349e5-fa1b-45b6-a75d-bd0cc19070d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5014a0fe-a1a5-4c6e-8daa-4e65aa9390b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fc283e-459f-4530-a86a-fd845f6066d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016a48d4-d786-49c8-a22d-9263ceeef020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d75f7b7-0e4e-4c23-8b14-dc40949540fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ddc9bb-bc24-4dde-a2da-6451d9ab4168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce7abb6-f4ad-471c-8c0d-3d6509e282a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08ca743c-d8f4-4e5f-b88c-23db78f67f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d69c29-0ddf-4ce7-a6db-74fbeecdebb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37326400-613d-4464-b264-cb4fc361cd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440f91a7-bd98-42c3-baf0-8ec858d09c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c69d64-db50-4dba-86cf-48296d2be86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77dd085d-b27e-4073-890e-eaf15a1aaadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8af07b9-1c21-474a-91ce-5edd0341a5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12823801-1f70-4824-a948-3b6226308dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e9937b-d2be-416f-9063-4427eecd4207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0aef8d-1103-49e9-8b7d-ed71fac13e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430bca00-4553-4d9a-8c96-5682a2d6c321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7d3ff5-ea81-4570-aac3-36c933971796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8ef2c2-b47f-4bc3-9261-53c88545be19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42dfaf24-cbf4-4628-8c5b-704cb59c3a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72c291d-93f5-490d-835e-77f589914e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068f3279-a45b-47bb-9515-10064113a3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142d6369-c849-4bf7-b4a3-644208e1c6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee2bdbc-2ffa-4e1c-b59c-71ae6ed375e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74aa671-bb97-4d2a-9cf5-fc358255e085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff60914c-e422-4b0a-92bd-05f4ddc2a5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ae310d-59e9-4555-b758-352780bb5ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f61cb16-10c1-4d70-bef9-726b239f6e8b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(4164, 24), y=(4164,)
   Test:  X=(1042, 24), y=(1042,)

⚠️  Limiting training data: 4164 → 800 samples
⚠️  Limiting test data: 1042 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5108, RMSE: 0.7147, MAE: 0.6555, R²: -5.3078

📊 Round 0 Test Metrics:
   Loss: 0.5091, RMSE: 0.7135, MAE: 0.6542, R²: -5.2866

============================================================
🔄 Round 4 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3564, val=0.1244 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1034, val=0.0849 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0869, val=0.0820 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0851, val=0.0812 (↓), lr=0.001000
   • Epoch   5/100: train=0.0850, val=0.0810, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0835, val=0.0798, patience=1/15, lr=0.001000
   ✓ Epoch  21/100: train=0.0753, val=0.0734 (↓), lr=0.001000
   • Epoch  31/100: train=0.0676, val=0.0711, patience=6/15, lr=0.001000
   📉 Epoch 37: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 4 Summary - Client client_17
   Epochs: 40/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0687, RMSE=0.2622, R²=0.1919
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.1240
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.4857, RMSE: 0.6969, MAE: 0.6361, R²: -4.9985

============================================================
🔄 Round 7 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3933, val=0.2266 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.1310, val=0.1122 (↓), lr=0.000500
   ✓ Epoch   3/100: train=0.0894, val=0.0869 (↓), lr=0.000500
   • Epoch   4/100: train=0.0836, val=0.0903, patience=1/15, lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0840, val=0.0889, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0834, val=0.0887, patience=8/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 7 Summary - Client client_17
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0075
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0034
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4707, RMSE: 0.6861, MAE: 0.6242, R²: -4.8128

============================================================
🔄 Round 9 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4394, val=0.3835 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.3540, val=0.3008 (↓), lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   ✓ Epoch   3/100: train=0.2637, val=0.1958 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1816, val=0.1423 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1358, val=0.1041 (↓), lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0874, val=0.0717, patience=1/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0873, val=0.0717, patience=11/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 9 Summary - Client client_17
   Epochs: 25/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0028
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0027
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.4509, RMSE: 0.6715, MAE: 0.6081, R²: -4.5684

📊 Round 9 Test Metrics:
   Loss: 0.4421, RMSE: 0.6649, MAE: 0.6008, R²: -4.4591

============================================================
🔄 Round 12 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4385, val=0.4367 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.4241, val=0.4219 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4133, val=0.4153 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4070, val=0.4091 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4011, val=0.4034 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.3723, val=0.3764 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.3540, val=0.3586 (↓), lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.3466, val=0.3514, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.3421, val=0.3469, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.3378, val=0.3425, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.3336, val=0.3382, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.3294, val=0.3340, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.3252, val=0.3298, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.3210, val=0.3256, patience=1/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.3173, RMSE=0.5633, R²=-2.7650
   Val:   Loss=0.3217, RMSE=0.5672, R²=-2.7878
============================================================


============================================================
🔄 Round 14 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4043, val=0.4275 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4038, val=0.4269 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4033, val=0.4263 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4027, val=0.4258 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4022, val=0.4253 (↓), lr=0.000001
   • Epoch  11/100: train=0.3994, val=0.4224, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.3951, val=0.4180, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.3910, val=0.4137, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.3869, val=0.4096, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.3830, val=0.4055, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.3790, val=0.4014, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.3750, val=0.3973, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.3711, val=0.3932, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.3671, val=0.3891, patience=1/15, lr=0.000001

============================================================
📊 Round 14 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3631, RMSE=0.6026, R²=-3.3146
   Val:   Loss=0.3853, RMSE=0.6208, R²=-3.5303
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3784, RMSE: 0.6151, MAE: 0.5454, R²: -3.6729

📊 Round 14 Test Metrics:
   Loss: 0.3520, RMSE: 0.5933, MAE: 0.5206, R²: -3.3470

============================================================
🔄 Round 16 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3518, val=0.3618 (↓), lr=0.000001
   • Epoch   2/100: train=0.3514, val=0.3613, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3509, val=0.3608 (↓), lr=0.000001
   • Epoch   4/100: train=0.3504, val=0.3603, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3499, val=0.3598 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3471, val=0.3569 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3423, val=0.3519 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3375, val=0.3470 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3326, val=0.3420 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3278, val=0.3369 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3228, val=0.3319 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3178, val=0.3267 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3128, val=0.3215 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3076, val=0.3162 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3039, RMSE=0.5513, R²=-2.5638
   Val:   Loss=0.3113, RMSE=0.5580, R²=-2.8544
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.2753, RMSE: 0.5247, MAE: 0.4438, R²: -2.4001

============================================================
🔄 Round 20 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2367, val=0.2695 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2359, val=0.2686 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2350, val=0.2676 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2342, val=0.2666 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2333, val=0.2657 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2284, val=0.2601 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2205, val=0.2513 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2129, val=0.2427 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2054, val=0.2343 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1981, val=0.2260 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1910, val=0.2179 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1839, val=0.2098 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1771, val=0.2019 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1703, val=0.1942 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1637, RMSE=0.4046, R²=-0.9332
   Val:   Loss=0.1873, RMSE=0.4328, R²=-1.2938
============================================================


============================================================
🔄 Round 22 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1737, val=0.1891 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1730, val=0.1884 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1724, val=0.1877 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1717, val=0.1869 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1710, val=0.1862 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1671, val=0.1820 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1608, val=0.1750 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1546, val=0.1682 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1486, val=0.1615 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1428, val=0.1551 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1373, val=0.1489 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1320, val=0.1430 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1270, val=0.1373 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1223, val=0.1319 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1181, RMSE=0.3437, R²=-0.3940
   Val:   Loss=0.1273, RMSE=0.3568, R²=-0.5448
============================================================


============================================================
🔄 Round 25 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0990, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0988, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0986, val=0.0922, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0984, val=0.0920 (↓), lr=0.000001
   • Epoch   5/100: train=0.0982, val=0.0918, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0971, val=0.0904, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0953, val=0.0884, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0937, val=0.0865 (↓), lr=0.000001
   • Epoch  41/100: train=0.0924, val=0.0849, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0912, val=0.0834, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0902, val=0.0822, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0893, val=0.0811, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0886, val=0.0802, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0880, val=0.0794, patience=5/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_17
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0113
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0350
============================================================


============================================================
🔄 Round 28 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 28 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0197
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0028
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0106

============================================================
🔄 Round 29 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0910, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0836, val=0.0907 (↓), lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0903, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0833, val=0.0899, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 29 Summary - Client client_17
   Epochs: 38/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0012
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0427
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2466, R²: -0.0075

============================================================
🔄 Round 32 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 32 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0046
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0065
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2462, R²: -0.0032

============================================================
🔄 Round 33 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 33 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0152
============================================================


============================================================
🔄 Round 35 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 35 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0016
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0102
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2461, R²: -0.0022

============================================================
🔄 Round 41 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 41 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0218
============================================================


============================================================
🔄 Round 42 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 42 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0028
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0017
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2461, R²: -0.0017

📊 Round 42 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2460, R²: -0.0011

============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0030
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0348
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2460, R²: -0.0007

📊 Round 44 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2460, R²: -0.0005

============================================================
🔄 Round 47 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 47 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0037
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0095
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2460, R²: -0.0004

============================================================
🔄 Round 48 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 48 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0004
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0152
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2460, R²: -0.0004

============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0041
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2459, R²: 0.0001

============================================================
🔄 Round 52 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 52 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0032
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0211
============================================================


============================================================
🔄 Round 53 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 53 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0042
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0183
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0005

📊 Round 53 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2459, R²: 0.0008

📊 Round 53 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2459, R²: 0.0008

============================================================
🔄 Round 57 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 57 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0025
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0197
============================================================


============================================================
🔄 Round 58 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 58 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0001
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0037
============================================================


============================================================
🔄 Round 59 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 59 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0043
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0153
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

📊 Round 59 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

📊 Round 59 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 63 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 63 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0017
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0117
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 64 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 64 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0024
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0044
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 64 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0029
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0048
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 75 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 75 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0027
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0155
============================================================


============================================================
🔄 Round 77 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 77 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0151
============================================================


============================================================
🔄 Round 79 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 79 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0005
============================================================


============================================================
🔄 Round 80 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 80 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0027
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0063
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 82 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 82 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0007
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0081
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 84 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 84 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0017
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0082
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

============================================================
🔄 Round 86 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 86 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0025
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0027
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 86 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

📊 Round 86 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 92 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 92 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0022
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0039
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 93 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 93 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0079
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 94 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 94 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0005
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0057
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 95 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 95 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0041
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0116
============================================================


============================================================
🔄 Round 96 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 96 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0004
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0078
============================================================


============================================================
🔄 Round 97 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 97 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0021
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0029
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 100 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 100 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0019
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0321
============================================================


============================================================
🔄 Round 102 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 102 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0002
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0047
============================================================


============================================================
🔄 Round 103 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 103 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0028
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0070
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2459, R²: 0.0009

📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2459, R²: 0.0010

============================================================
🔄 Round 108 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 108 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0012
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0081
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 109 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 109 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0006
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0020
============================================================


============================================================
🔄 Round 110 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 110 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0036
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0014
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 113 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 113 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0056
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0043
============================================================


============================================================
🔄 Round 114 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 114 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0015
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0004
============================================================


============================================================
🔄 Round 115 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 115 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0009
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0087
============================================================


============================================================
🔄 Round 116 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 116 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0004
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0131
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 117 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 117 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0024
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0105
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

📊 Round 117 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 122 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 122 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0004
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0055
============================================================


============================================================
🔄 Round 123 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 123 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0029
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0052
============================================================


============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0024
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0066
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 126 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 126 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0010
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0070
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

📊 Round 126 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0022

============================================================
🔄 Round 129 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 129 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0008
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0038
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2458, R²: 0.0022

📊 Round 129 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0023

============================================================
🔄 Round 131 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 131 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0038
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0139
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0022

============================================================
🔄 Round 133 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 133 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0037
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0054
============================================================


============================================================
🔄 Round 137 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 137 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0002
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

📊 Round 137 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0022

============================================================
🔄 Round 140 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 140 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0005
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0054
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0022

📊 Round 140 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0022

============================================================
🔄 Round 142 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 142 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0047
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0123
============================================================


============================================================
🔄 Round 143 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 143 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0052
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0131
============================================================


============================================================
🔄 Round 144 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 144 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0024
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0459
============================================================


============================================================
🔄 Round 148 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 148 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0007
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0082
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0022

============================================================
🔄 Round 149 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 149 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0024
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0051
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 152 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 152 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0054
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 153 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 153 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0023
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0019
============================================================


============================================================
🔄 Round 156 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 156 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0018
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0012
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 157 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 157 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0082
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 157 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 161 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 161 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0003
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0010
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 162 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 162 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0024
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0085
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 163 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 163 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0029
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0121
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 164 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 164 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0013
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0078
============================================================


============================================================
🔄 Round 165 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 165 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0003
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0020
============================================================


============================================================
🔄 Round 166 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 166 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0017
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0016
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0014
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0039
============================================================


============================================================
🔄 Round 170 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 170 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0011
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0000
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 173 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 173 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0020
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0039
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 177 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 177 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0013
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0007
============================================================


============================================================
🔄 Round 178 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 178 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0016
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0078
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 180 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 180 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0045
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0243
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

============================================================
🔄 Round 183 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 183 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0053
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 186 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 186 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0031
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0198
============================================================


============================================================
🔄 Round 189 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 189 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0026
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0083
============================================================


============================================================
🔄 Round 190 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 190 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0031
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0190
============================================================


============================================================
🔄 Round 191 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 191 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0067
============================================================


============================================================
🔄 Round 192 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 192 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0035
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0070
============================================================


============================================================
🔄 Round 193 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 193 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0011
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0014
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

============================================================
🔄 Round 194 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 194 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0096
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

============================================================
🔄 Round 195 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 195 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0041
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

📊 Round 195 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 200 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 200 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0032
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0071
============================================================


============================================================
🔄 Round 201 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 201 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0036
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0122
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 207 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 207 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0018
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0064
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 208 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 208 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0004
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0006
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 209 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 209 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0007
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0033
============================================================


============================================================
🔄 Round 213 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 213 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0025
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0050
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 215 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 215 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0129
============================================================


============================================================
🔄 Round 216 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 216 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0004
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0034
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 220 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 220 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0019
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0037
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 221 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 221 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0032
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0139
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 225 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 225 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0042
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0046
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 229 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 229 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0008
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0128
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

📊 Round 229 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 232 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 232 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0011
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0111
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 234 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 234 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0048
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0125
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

============================================================
🔄 Round 236 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 236 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0049
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0124
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 236 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 236 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 242 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 242 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0013
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0052
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 244 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 244 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0003
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0053
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0020

📊 Round 244 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0021

============================================================
🔄 Round 247 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 247 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0000
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0071
============================================================


============================================================
🔄 Round 248 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 248 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0012
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0105
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 248 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 251 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 251 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0006
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0054
============================================================


============================================================
🔄 Round 252 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 252 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0039
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 254 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 254 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0107
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 255 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 255 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0027
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0078
============================================================


============================================================
🔄 Round 256 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 256 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0030
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0081
============================================================


============================================================
🔄 Round 257 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 257 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0018
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0009
============================================================


============================================================
🔄 Round 258 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 258 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0003
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0059
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 260 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 260 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0037
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0080
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 261 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 261 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0003
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0031
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 262 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 262 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0006
   Val:   Loss=0.0988, RMSE=0.3144, R²=0.0065
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 262 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 266 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 266 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0022
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0074
============================================================


============================================================
🔄 Round 268 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 268 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0029
============================================================


============================================================
🔄 Round 270 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 270 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0098
============================================================


============================================================
🔄 Round 271 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 271 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0017
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0088
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

📊 Round 271 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 275 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 275 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0021
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0042
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 276 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 276 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0013
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0241
============================================================


============================================================
🔄 Round 278 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 278 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0018
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0049
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 279 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 279 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0013
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0062
============================================================


============================================================
🔄 Round 280 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 280 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0003
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0022
============================================================


============================================================
🔄 Round 281 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 281 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0004
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0058
============================================================


============================================================
🔄 Round 282 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 282 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0018
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0136
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 284 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 284 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0005
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0060
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0021

============================================================
🔄 Round 285 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 285 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0004
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0062
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

📊 Round 285 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 287 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 287 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0031
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 288 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 288 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0010
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0022
============================================================


============================================================
🔄 Round 289 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 289 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0010
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0128
============================================================


============================================================
🔄 Round 290 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 290 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0000
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0053
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0020

============================================================
🔄 Round 291 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 291 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0005
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0002
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0022

📊 Round 291 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0023

📊 Round 291 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0023

📊 Round 291 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2457, R²: 0.0023

============================================================
🔄 Round 296 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 296 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0014
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0003
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0021

📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 302 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 302 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0017
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0183
============================================================


============================================================
🔄 Round 303 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 303 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0048
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0189
============================================================


============================================================
🔄 Round 304 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 304 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0001
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0007
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 306 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 306 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0002
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0028
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 307 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 307 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0014
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0144
============================================================


============================================================
🔄 Round 309 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 309 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0066
============================================================


============================================================
🔄 Round 310 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 310 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0031
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0068
============================================================


============================================================
🔄 Round 313 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 313 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0018
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0005
============================================================


============================================================
🔄 Round 315 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 315 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0022
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0208
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 317 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 317 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0004
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0051
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 318 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 318 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0033
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0067
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 318 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 321 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 321 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0022
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0044
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

📊 Round 321 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 325 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 325 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0029
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0159
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 328 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 328 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0098
============================================================


============================================================
🔄 Round 332 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 332 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0016
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0011
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0020

============================================================
🔄 Round 335 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 335 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0003
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0054
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0022

============================================================
🔄 Round 338 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 338 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0033
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0059
============================================================


============================================================
🔄 Round 339 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 339 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0022
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0011
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0022

📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0021

============================================================
🔄 Round 342 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 342 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0033
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0150
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 342 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 346 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 346 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0034
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0122
============================================================


============================================================
🔄 Round 347 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 347 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0013
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0043
============================================================


============================================================
🔄 Round 348 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 348 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0023
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0043
============================================================


============================================================
🔄 Round 349 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 349 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0028
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0256
============================================================


============================================================
🔄 Round 350 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 350 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0001
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0026
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0019

📊 Round 350 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 350 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0019

📊 Round 350 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0019

📊 Round 350 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0019

============================================================
🔄 Round 357 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 357 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0031
============================================================


============================================================
🔄 Round 360 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 360 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0000
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0044
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2458, R²: 0.0017

📊 Round 360 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 363 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 363 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0007
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0021
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 366 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 366 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0015
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0029
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 367 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 367 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0001
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0039
============================================================


============================================================
🔄 Round 368 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 368 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0026
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0038
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 369 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 369 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0018
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0006
============================================================


============================================================
🔄 Round 372 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 372 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0075
============================================================


============================================================
🔄 Round 373 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 373 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0043
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0046
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

============================================================
🔄 Round 376 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 376 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0077
============================================================


============================================================
🔄 Round 378 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 378 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0004
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 378 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 384 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 384 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0000
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0044
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

============================================================
🔄 Round 389 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 389 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0011
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0009
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 389 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 392 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 392 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0015
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0025
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 395 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 395 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0026
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0087
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 395 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 398 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 398 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0006
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0060
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 398 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 401 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 401 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0006
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0067
============================================================


============================================================
🔄 Round 405 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 405 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0007
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0004
============================================================


============================================================
🔄 Round 407 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 407 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0011
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0013
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 410 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 410 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0005
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 411 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 411 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0020
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0094
============================================================


============================================================
🔄 Round 412 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 412 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0026
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0127
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 413 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 413 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0063
============================================================


============================================================
🔄 Round 414 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 414 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0002
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0031
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

📊 Round 414 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 418 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 418 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0035
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 421 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 421 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0010
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0003
============================================================


============================================================
🔄 Round 422 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 422 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0001
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0015
============================================================


============================================================
🔄 Round 423 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 423 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0001
   Val:   Loss=0.0995, RMSE=0.3154, R²=0.0038
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 424 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 424 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0016
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0028
============================================================


============================================================
🔄 Round 425 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 425 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0025
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0058
============================================================


============================================================
🔄 Round 426 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 426 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0005
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0052
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 426 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 431 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 431 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0034
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0125
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 434 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 434 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0017
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0003
============================================================


============================================================
🔄 Round 435 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 435 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0027
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0058
============================================================


============================================================
🔄 Round 436 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 436 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0009
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 439 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 439 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0006
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0032
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 441 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 441 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0001
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0070
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 443 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 443 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0004
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0013
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 443 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 443 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 448 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 448 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0013
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0010
============================================================


============================================================
🔄 Round 449 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 449 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0008
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0069
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 450 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 450 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0029
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0081
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 450 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 453 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 453 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0028
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0131
============================================================


============================================================
🔄 Round 454 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 454 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0014
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0027
============================================================


============================================================
🔄 Round 455 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 455 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0049
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0596
============================================================


============================================================
🔄 Round 456 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 456 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0025
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 456 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 458 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 458 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0036
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0128
============================================================


============================================================
🔄 Round 459 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 459 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0018
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0111
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 459 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 463 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 463 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0026
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 463 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 468 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 468 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0037
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0288
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

📊 Round 468 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 472 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 472 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0041
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0179
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 478 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 478 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0000
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0013
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

📊 Round 478 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 478 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 483 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 483 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0013
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0068
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 483 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 483 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 486 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 486 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0116
============================================================


============================================================
🔄 Round 488 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 488 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0023
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0018
============================================================


============================================================
🔄 Round 489 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 489 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0021
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0046
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 489 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 495 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 495 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0001
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0028
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 495 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 502 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 502 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0013
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0000
============================================================


============================================================
🔄 Round 503 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 503 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0003
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 506 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 506 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0004
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0066
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 506 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 510 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 510 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0001
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0031
============================================================


============================================================
🔄 Round 511 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 511 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0011
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0011
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 514 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 514 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0035
============================================================


============================================================
🔄 Round 515 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 515 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0011
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0010
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 515 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 515 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 518 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 518 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0002
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0033
============================================================


============================================================
🔄 Round 519 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 519 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0021
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0038
============================================================


============================================================
🔄 Round 520 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 520 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0016
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0102
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 522 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 522 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0015
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0030
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 523 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 523 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0011
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0009
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 524 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 524 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0008
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0075
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 526 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 526 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0036
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0125
============================================================


============================================================
🔄 Round 527 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 527 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0018
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0065
============================================================


============================================================
🔄 Round 528 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 528 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0000
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0040
============================================================


============================================================
🔄 Round 529 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 529 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0023
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0027
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

📊 Round 529 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 532 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 532 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0016
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0037
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 533 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 533 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0003
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0040
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 533 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 533 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 533 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 541 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 541 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0021
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0039
============================================================


============================================================
🔄 Round 543 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 543 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0011
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0014
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 543 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 545 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 545 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0016
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.0040
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 545 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 545 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 552 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 552 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0006
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0023
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 552 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 554 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 554 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0014
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0025
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 556 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 556 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0007
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0026
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 556 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 556 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 559 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 559 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0075
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 560 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 560 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0000
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0027
============================================================


============================================================
🔄 Round 561 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 561 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0026
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0132
============================================================


============================================================
🔄 Round 562 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 562 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0001
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0045
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 564 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 564 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0055
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 569 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 569 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0003
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0065
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 570 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 570 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0023
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0068
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 570 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 570 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 574 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 574 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0015
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0005
============================================================


============================================================
🔄 Round 575 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 575 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0025
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0050
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

============================================================
🔄 Round 578 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 578 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0023
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 578 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 578 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 578 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 583 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 583 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0003
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0002
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 583 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 583 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 588 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 588 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0023
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0200
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 588 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 590 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 590 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0014
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0069
============================================================


============================================================
🔄 Round 592 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 592 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0014
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0299
============================================================


============================================================
🔄 Round 593 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 593 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0031
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0149
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

📊 Round 593 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 596 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 596 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0001
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0071
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0014

============================================================
🔄 Round 597 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 597 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0019
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0012
============================================================


============================================================
🔄 Round 598 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 598 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0001
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0062
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0015

📊 Round 598 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 600 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 600 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0050
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 601 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 601 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0028
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0495
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 601 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 601 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 606 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 606 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0008
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0008
============================================================


============================================================
🔄 Round 608 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 608 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0013
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

============================================================
🔄 Round 609 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 609 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0015
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0082
============================================================


============================================================
🔄 Round 611 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 611 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0016
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0010
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 612 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 612 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0019
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0036
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 618 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 618 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0030
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0193
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 620 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 620 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0023
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0051
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 620 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 623 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 623 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0005
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0024
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 625 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 625 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0000
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0058
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 626 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 626 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0011
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0004
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 628 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 628 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0011
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0028
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 629 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 629 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0140
============================================================


============================================================
🔄 Round 632 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 632 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0014
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0038
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 635 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 635 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0004
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0055
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 635 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 638 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 638 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0009
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0021
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 639 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 639 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0018
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0019
============================================================


============================================================
🔄 Round 640 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 640 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0015
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0003
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 642 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 642 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0019
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0033
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 642 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 644 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 644 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0003
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0039
============================================================


============================================================
🔄 Round 645 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 645 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0014
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0171
============================================================


============================================================
🔄 Round 646 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 646 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0011
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0035
============================================================


============================================================
🔄 Round 648 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 648 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0045
============================================================


============================================================
🔄 Round 649 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 649 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0010
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0046
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 654 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 654 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0014
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0003
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 656 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 656 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0034
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0088
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 663 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 663 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0022
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0060
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0007

📊 Round 663 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 663 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 663 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

============================================================
🔄 Round 674 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 674 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0003
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0007
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 677 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 677 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0036
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0161
============================================================


============================================================
🔄 Round 678 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 678 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0012
============================================================


============================================================
🔄 Round 681 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 681 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0060
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 682 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 682 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0004
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0002
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 687 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 687 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0007
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0416
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

============================================================
🔄 Round 689 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 689 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0025
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0056
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 690 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 690 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0018
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0030
============================================================


============================================================
🔄 Round 691 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 691 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0021
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0062
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

📊 Round 691 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 691 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0008

📊 Round 691 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0008

📊 Round 691 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 700 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 700 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0007
   Val:   Loss=0.0952, RMSE=0.3085, R²=0.0014
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 701 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 701 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0030
   Val:   Loss=0.0984, RMSE=0.3137, R²=0.0043
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 702 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 702 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0161
============================================================


============================================================
🔄 Round 703 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 703 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0006
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0006
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 705 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 705 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0017
   Val:   Loss=0.0689, RMSE=0.2626, R²=-0.0035
============================================================


============================================================
🔄 Round 709 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 709 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0004
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 712 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 712 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0002
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0034
============================================================


============================================================
🔄 Round 713 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 713 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0015
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0023
============================================================


============================================================
🔄 Round 716 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 716 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0028
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0126
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0006

📊 Round 716 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0004

📊 Round 716 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0006

============================================================
🔄 Round 720 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 720 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0011
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0011
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0007

============================================================
🔄 Round 722 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 722 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0017
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0112
============================================================


============================================================
🔄 Round 723 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 723 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0003
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0001
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 723 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 726 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 726 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0014
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0012
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 726 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 728 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 728 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0032
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0121
============================================================


============================================================
🔄 Round 730 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 730 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0000
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0012
============================================================


============================================================
🔄 Round 731 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 731 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0030
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0183
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 731 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 731 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

📊 Round 731 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0011

📊 Round 731 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

============================================================
🔄 Round 738 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 738 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0011
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0005
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0007

📊 Round 738 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

============================================================
🔄 Round 741 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 741 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0030
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0237
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

============================================================
🔄 Round 742 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 742 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0032
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0366
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

============================================================
🔄 Round 744 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 744 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0017
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0049
============================================================


============================================================
🔄 Round 745 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 745 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0006
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0025
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

📊 Round 745 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0013

📊 Round 745 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 750 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 750 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0013
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0055
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0012

============================================================
🔄 Round 751 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 751 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0149
============================================================


============================================================
🔄 Round 752 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 752 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0020
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0074
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0010

============================================================
🔄 Round 754 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 754 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0017
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0055
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 754 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 754 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

============================================================
🔄 Round 758 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 758 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0002
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0028
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0005

📊 Round 758 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0003

============================================================
🔄 Round 761 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 761 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0007
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0015
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0003

📊 Round 761 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0003

============================================================
🔄 Round 764 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 764 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0151
============================================================


============================================================
🔄 Round 765 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 765 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0004
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0001
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0004

============================================================
🔄 Round 766 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 766 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0032
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0006
============================================================


============================================================
🔄 Round 767 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 767 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0016
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0038
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2459, R²: 0.0005

============================================================
🔄 Round 768 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 768 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0002
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0007
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0006

============================================================
🔄 Round 772 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 772 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0009
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0002
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0006

============================================================
🔄 Round 774 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 774 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0018
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0022
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0008

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

📊 Round 774 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2458, R²: 0.0007

============================================================
🔄 Round 784 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 784 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0127
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2458, R²: 0.0009

❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
