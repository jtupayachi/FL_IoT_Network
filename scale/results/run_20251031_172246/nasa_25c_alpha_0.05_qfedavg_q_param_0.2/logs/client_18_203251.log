[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e20ee9-aa4b-44c6-ab58-647cdcb739d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135db9f9-040b-49cb-988d-1e900dc8eef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39509130-82a9-40cc-998c-6be4eb3afcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd3a9d3-3c15-4372-bfef-1de88ccf9220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa5dfeb-4ee2-4799-87d9-4b4ed50f7c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9a9a66-efd5-40c8-87ff-7526dd9be725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e130c3f8-1f50-427c-972f-61b3fec487cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec26ffa7-9bd4-4c35-a34a-4a79f77faaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8823539a-5cf9-43db-b15a-faa5a85b9328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25b8790-e8b2-4308-8d97-e0161c34e501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd64c9b-c2d3-4807-941a-c94b37ce0919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c6c19e-aa83-4c4a-ad3f-0bb98134ab65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef882d3f-992c-4ee9-ad89-57b5127eed00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa2b775-fb37-46d4-9e78-29e4f00fb52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9b5b66-8108-4d20-800b-9fc32707f8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23298ca6-d11a-4a19-a2f9-cf57335200b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f29d49-c826-4207-b0b0-85da88c91eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10304b28-1db8-421a-a1c7-31477ba6e391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c384db80-085e-4988-a891-2c5aed0263fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2345ef-a4d6-48a8-81a7-f172560823f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c186d0-00a0-4cf7-a06d-238bb2cf7882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147ac4b3-de89-441b-9960-bfa44523886f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe3e490-996b-41d4-b699-90d6463d4ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b609fd5-49fe-4cb0-bdd3-fe097b0ce018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e882ee30-330d-42d8-875d-bd7783377bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2386a80-c9c2-41ac-ab71-1524173fd117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98720496-1d0b-4154-9c6d-1daa3ab14b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd56a235-db1c-4096-ac67-15a0ff3a463f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ae2103-4630-4a92-8657-1b35b7dd5b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e57b800-9315-48d4-a592-17853a47be35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3aba51f-ebda-480e-9c15-20e99d6f8c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0ee6c3-d96c-4880-80c6-efe854b2d79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b006a2-e09f-4265-9021-57b73d3cf994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06296b3-71ed-49eb-aa53-56f865f06b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc100b3-dc05-49da-961f-7f83e28018de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85fc344e-40f0-49c1-813b-90583d48317b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a0fbbd-cbec-45e6-9bb9-2ec942e22868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6394b41-3ddf-4496-b142-2e7eedad6aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa1fd56-fde0-47ad-89f4-c71cee4bb9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e834342-75a1-44c2-ab92-1e4117a76ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7da5453-0d9e-4d73-a3c1-fc4ffc2e8c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41255929-68c6-43ab-9395-e3e7c2ea67e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8f9c92-92b0-4bed-b281-7c9fdcb2a89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5fc546f-e80c-4467-bafa-625a03b84b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd03b42-3b35-4267-9fcd-85ed416d6e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 517153d9-cd5f-4000-9320-7744268404b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5527106a-a2ac-450a-a9bf-19a55f83d829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba3cde8-4ee8-415d-9ac6-00739a8a8099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89606ed6-067a-4aef-a2b2-da8e4a8474dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb61ddd1-4444-4dc3-b7db-16aeedcbf4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b1bcb1-49b9-4136-a872-a5c4927b8071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a2d8d6-72ca-438a-9cac-ca978102f232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6455204-53cb-4ce5-8b20-23e361e40803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0918df41-fcef-4fcc-9ae7-20072e0da77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95da5b3c-ae44-473c-8a05-d6d995aba808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2cbc6bf-cfbc-480b-bfcf-994dc3f303cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90c4c8e-adac-4830-bc63-f0ce7138c4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c9b6fb-e9f4-40e1-b90a-d43102e63083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ba62c4-d056-4cb3-99f9-a5278eaeca8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05f7bdc-8759-4d5b-ae50-5f78a612c176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4b6e83-d0eb-4057-844a-09aee74a5427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe9cfae-9b5c-46b9-bc6f-1bdb0a586919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f90b4d8-d227-4e35-9bf3-09602bea0c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b012a64-2a9d-44d7-87a9-b6e55d242999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbffe1d-6360-42cb-9e10-c7d2d08407d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad07dc0-2c04-4e2b-a8f7-ada68deaa21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70043fda-987c-428b-b709-af2c43652158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1d0562-76f0-4756-92af-7ac73447fb54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c476e730-45f9-436f-90d2-fa757d73e3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f4d930-395f-437b-b454-74ab155231a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bb2769-a162-4766-854c-0cd03c96129a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6d0cf8-2feb-4743-9c7b-effee1835e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af43252-889f-44d3-89da-15d827363c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd68a0f-3d82-498d-9ce2-37e0f6fed31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20656028-c8b7-41ca-b093-cf87387c0800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d64a6b0-1f84-488e-b657-a131ac2f3381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145d1772-5f6d-4d70-8216-2be8d41a9fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3cc464-62e7-4dfd-a5fe-53dc792f661f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ce89d9-1f71-4bd3-ad1d-2d887dda98ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb7c155-e3c6-46d7-93f4-df292df95b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c328836-dab3-4ceb-b55a-b083cd0c4b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a03e69-ef36-4463-bf02-678bef5ecb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fceb24f0-cdd9-4799-86d5-9b7603250842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d126057-49ec-48e1-b4cd-b9f92c051405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639f768b-e77e-4519-8649-5937b14783c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6efb7cd4-959b-4b8e-b0d9-ef42596447f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 162c8e56-26b9-423e-b6ca-d9cb8e06d3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e53f960-9459-4a8d-a9c2-219b38fa7639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0b126f-1d4f-48ae-9809-d0392326a834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1111fada-f7aa-470e-8c08-844928eebb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c32b1e-66e2-457c-88a2-acd776bd63dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f463ebcf-0045-4789-8ba9-b726b538f8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b006fb93-9c26-4f2a-99a5-1a07b81e0294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e67bbc-8f97-486a-89e5-03294596f5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed141949-1efb-4e6d-803c-fea6c8db3a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c53fe3-a9a3-4422-9c63-25039741e7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51d1d96-7a87-4138-892f-354f6ff4fb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35aa0a11-4810-4eea-a659-15699ae5f00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a940d9f-f9d6-48c9-9b4c-bfff7836fa08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82ba4ba-3e65-4773-b924-d677565b8ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41b9f4d-eec5-4e68-8996-e97ccd760387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7586445f-e97d-4069-9277-509be8d905b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962eda8f-9019-41fd-a0c7-a9c9240f17cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9f1f15-e13b-462c-8b1f-f6a6123afdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c403039-7ba3-4a9b-b87b-c8bf79891587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82920202-3dd2-495f-a64d-9a152f1d25fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57fde188-f26d-4716-9762-b0fe5c5a90a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f749e874-4383-4d8f-85f3-ff18ecaad9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf438642-f946-4e98-9a68-5fe518dff631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5e33c9-760c-4d1b-b4ec-c54e7a416f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a953f3-962f-44a4-a3e0-0b1d5c20f3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf5cb48-2c70-420e-b251-ed1abe11b0ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3bb7830-88ee-4f3b-a83f-6f27342c2ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fbc8dd0-7d6f-45aa-b0e5-66aed68e66af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75006eaa-823e-4528-ab82-a99eb094919d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c2e93b-3da1-4183-966f-e5dea8dd47a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326c5bd5-030c-48ff-9c88-fa5cc9edb56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33fc2d68-0f4b-4903-ac4b-6c233bed1484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a507e78-bfa9-4726-a7ff-7ebd9077dc01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4b16fa-e1de-4a43-814b-34ff4448fb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7761e67d-d0f9-4306-922d-39ca925e284d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bfaf67-9827-49f1-882b-d31008dea74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa8b877-9a64-4c65-a36c-8820b0783e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7def2b9-297a-4e3f-ae8a-f1153b779240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c3adfd0-a520-4b64-9714-3a3414594353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25529554-1460-4fde-af1e-5986b9fde294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a90d41-35de-4416-a9f2-809467b16712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf96673-9405-4652-8bc1-9da2a43fdf94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2df6950-c2fb-4e69-8b83-af4d88efc3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f81d041c-d926-406b-8e73-baab4549fd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe2f15e7-4001-4ac8-b456-036cda6efa8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819926ce-3155-4c25-8625-f012ea2bc0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc2e586-86bb-403f-a3d6-338e9e6b4db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2d2ec9-6e17-43f3-a131-ae0a62f84153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a8c50f-7fd2-428d-9828-d7cfc917769d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113d4e39-48e7-40a1-a4be-96530d8f4420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8135fd2f-6b6c-414c-8697-f0120f1c0bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb665f0b-16fc-4ba8-a36e-28b7821d3026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006c7acc-38dc-482a-b4d7-be0bd329db6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79340ee-ca58-4734-84dd-d9cc976a0909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a574ec1-a83c-455f-956b-6827037a5916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f9e2f2-c99a-4218-a162-f00889cab5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6ceed7-637a-4cb3-a334-77449b17a0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1938a2-bbfd-4bfd-a396-7d4b552100d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf4242a-4252-4da2-8a7c-6ef2e3221475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f05eea6-cbb7-4295-b0e4-9e70f61c9408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651dc010-20e8-4d54-81df-bc7057e63707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07c74cf-b619-4343-9df5-0f7e6773e3a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea370ab-7bb9-46f4-8b69-d734379ced5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ccac7a-224b-4ac0-8b5d-f37182f73dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25194f8c-510d-499e-87fd-fa0fbde3d0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ce1382-a88c-413f-8e6e-6c5ced15dc90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9316c57-39da-40ee-b253-99ca4af8e05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b86ddfd-d089-43bb-8a68-0b008bd4c922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc2104f-ba96-4a9f-926f-9f201f8c6722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4354b6b5-b59f-497d-b2fc-4bcf77a70b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66bea8c9-760b-4165-8faa-6befa151329d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ceefde-5f4c-41d5-aed2-831bc7bcc084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffdae418-1cf1-412e-a386-0c0c22796990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39e61019-a59b-4840-98a5-1e84f8787922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b47817-8ad6-44ce-b14a-a94965b230e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14c6f00-4c03-45e8-9445-cda15a155108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba7f188-a37d-4c63-b496-93c94d0126c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb2aa1a-0b82-415b-bc52-8c8d11c121f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d732425e-f0bb-43ee-8670-03977324893a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23fb1a7-88d1-4887-baa2-f873da736313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db1046ea-e805-4a41-9ff5-23be07879161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea8b8ed-b30e-4d18-a8ef-1b7b2c43ad94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e99eee52-23c8-4b0d-9190-abde051494b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcc74fc-9dcc-4097-b8bb-c6b5d80a2a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b8d09d-f5e0-4ade-a0b7-bd9218d66f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d126e70-8433-4ca7-a664-c8a80b384550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297cb256-a3f1-4ddc-84ce-c79184be7f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a864cc37-c9b3-4ec2-82ea-688b09d798a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d210d1-6e07-4ed9-bd51-9907e53568f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba398d13-bb0b-465d-94c4-f4c2777b3004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410b4256-13fe-49b8-b49f-a0d6d9c08576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33320e5-1a07-44b9-8ba3-582bd26370cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 434eccd2-1255-46e0-b2d9-951ebd8db4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c6366e-7ecc-422a-ac3c-a036ee1071b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f25b03-fbbe-46d9-9479-c0ed37373aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd782e75-b2af-4b54-8032-6d4de175c459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ceeba84-4139-4e5f-8c7b-7eb0111c28c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0c5785-96c5-48ac-83be-35299ff944f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2860fe6c-1e79-4220-b9f9-977d2b3b7c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0c4858-bd20-40a7-a41d-f74ae537d2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e192e21-9ab7-404d-a4e9-b72853408ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56abede-3179-49a7-a567-c56bb539ec28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cae4459-5654-482b-b49c-db97d5ccb11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96095df-d54a-4076-bd9e-b01db8216d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b373b4d5-9912-49c4-9381-a30bfa54fc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0b2336-b6cf-4eb6-aff9-804ec6418bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f960e7-efec-4502-a568-f1f444fa94eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd787ed-cfb1-4d02-8cdc-772beac2e369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217c4160-b0d4-493d-b29f-ac355273e7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e3ce73-7003-4557-801c-d896a6e47bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c270ea8-9d75-4483-a9e6-6b99730913ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c868552b-e48a-4a54-9881-8a89b9ed45c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a601a7bf-6aba-4b9f-bb79-c5c52dd21faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3482575-27a5-476a-a39c-58f8fdfd00ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11d359e-0fc8-4625-b6bf-c6502b08f4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39967c4f-4c03-48ce-9ad8-9d431e3d75e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73cd22d-53ec-4d4e-bcba-78fed9501c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493110e3-380f-4233-8d09-7c8245b72d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1cb61e2-e3f9-4c01-8ddd-568d4d0fd8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63bbdf36-83e8-4286-9623-2bf539d7233f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a414d67f-8487-4ee0-a56d-24de0126aa94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c6bfa5-5dab-4aa9-8c0b-d1d07277f694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc03859-5c17-4b83-8518-5479a16c1069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b82c5f5-d725-4c4e-866b-6e2663bd1e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203c10a8-ad1c-41bc-8422-b09fba8a75a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab180c5e-5ed3-4a38-b38d-058ab8fdc579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b3a082-f610-411c-b459-b4ea5be3a9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd4dd2c-bd49-4d82-91ca-5d654262ecee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d7ee4db-eee8-4545-ae2e-5f113e28f873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea55225-e5c3-4952-b8f7-b65bb2c28e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d9d346-4a93-451b-a133-d54329c8eb77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 572c7a59-f902-4eb3-991a-fd25ca9c9e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4c3309-a5a3-4c57-ac34-0300364686bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65778a21-a504-42bd-a9d8-f8629a76ce21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d64915-a957-4f0d-ad5c-7998c0da8f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad5a2c76-c8c4-46c3-b70b-a05ae12a1af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71016cb-a457-447c-beaa-7c197efb37c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d69e66a6-7291-41f6-89d0-23709ed115db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95785464-6b6c-4b7d-81d3-a70e49ec2b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5f5a8c-0dd8-4eea-9560-1fda4603d659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcb34c2-6b45-42e7-ac16-85d200167660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9580d61-17a7-40b5-96de-27227cd76a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73570687-f95f-4605-85f1-1c48b37fabad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba8bd01-7c23-42a9-99e2-cd6477dae99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f938259-48cd-4c40-8246-e25073bdfeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be586680-6695-4cfa-a9a1-d390dd5f7e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f2d386-e9ce-456e-8a7a-975707c89a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6699cc7a-55d2-4c8c-a336-399bd314fba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98422dc3-a402-4716-8fdc-441b97cf1b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d9e4b7-a23a-42cc-b024-65424216e80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95653771-1832-4477-8390-7e11d69bdf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9cf331-3a59-4dc7-8a50-f9e68bb95d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6334f1c-2b88-4f1b-8f65-1237cfb58bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b785370-106f-4a19-9a30-f676acc83ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a20215f-0e37-4d5f-836a-8a2dcbbab1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc00364a-4e5a-469f-ab40-cb86078a3c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c4ef4a-ea2e-4f30-834e-3d70ddaa3085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57f39bf-4a40-4e2e-839b-1f0b722663f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adda930f-c842-4cda-a0b5-00401470e50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831cfa31-c3b4-4428-96a5-27fe2a1e7800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3820715d-b82d-45b9-914a-1faec0401a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf491edc-0393-4d6f-8b5d-0f160b034ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388d5b5c-43f8-4245-bffd-ba6ef1fbe5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a19e3b-6677-4818-935f-65cf02a43419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a829b2c7-4b4f-4a67-b715-063231b0166b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1842f3e-2ba0-452c-8767-e59e70b9f291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a5c3e5-f503-4d1c-b189-555b5427cd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05e1fac-447f-41d2-a0c7-ad106143885a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 799c62b6-16a4-40a1-9a4f-767e543c3e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8827a816-f041-4fea-8e7c-00538fde11f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e624c0-6bf9-4841-82fb-9954816760e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47e9032b-f521-4b62-a261-255da44c641c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141f7db7-2d87-4e3a-8f38-652d09a9176a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170c8cc1-0210-42eb-8ab8-1f76f07ec140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0790d0a0-dbf0-4191-a5a4-213a1e6c99de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e795210e-c857-41ab-b74c-b5790494389b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdc4b63-9208-4ad9-a21d-5814d2558dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b219dac-130b-4113-9cca-4bca0e1ee863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8daf85f7-6255-4328-b967-3dea1a3d9efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f84567d-c25e-4cea-ac46-5f09a34e12c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f098be8-84a7-478a-b65d-d08ba1b4fad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d08d8e-4586-44db-aced-ebd559c091ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7230e036-0056-43d5-853f-f906c8d26251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ff9be5-e1fa-4812-9e7a-3818a6ac7076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9d3317-3323-4a76-9df6-d420c485ea39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f46274-5727-4ff6-acb3-bb4a7f0d452c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4944ba8-00d7-4123-9d2e-e2b5caa34f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76ddae5-98eb-4a8a-ab7f-ca3ece6fa938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47915582-7f6c-4e59-8b77-bb58a03da079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa61a71-a8b9-47c7-a789-5928b3517a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae9ad7a-2c4c-465a-93ad-485e842994f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0851d0a-49d4-438a-ad56-c169bfe520ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ebfb8be-d36a-4269-8500-57ac2e1f4e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97ea379-62d8-4a54-a666-4c72a012d9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6fcbe3-8e1b-4df4-81d4-bde9a399c0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29e08c5-14ec-424d-8e9c-c0995954630a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 189e0af8-ae63-462c-9978-b9957d43de68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460c9e95-9a8d-4f5e-a8f7-9de6f86b305d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4ecc62-b37a-4e35-af02-f0aa24dff17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64fc080-d989-4748-a191-f5d39de6553c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f14304-6cf5-4d10-8cac-2534003dcc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc176582-91e6-46de-a009-a65f046b6dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d3459e-da19-472d-90f0-175b5c32b9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3361c232-c7a7-49c2-872e-b2ecd289566f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d88741-98d2-43c8-864a-3084b77bb696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833eb609-ecf9-4485-9946-1ddb3cc731d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472b3859-14fe-46ea-891b-06fe8b346bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954e50f5-4536-4ec3-abe4-afce199ba1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6db81ed8-7fb8-41d8-90c9-8e282e574e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e98b5e-d3aa-4245-aaee-5cf1bb9b46ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607f34b8-55cd-4f07-9fc3-e50d816257ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9318fc-7ccc-4dde-86f4-2ca889d10747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7f8e71-25ee-47ed-b87e-76e0882a0c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f1060c-cd03-4a78-a75a-da6a98ef2dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7c2189-f823-444e-95a4-eb1a84c3ce32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42eb762-e770-44f4-8d6d-ba2fb4adb8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f639f96-f411-4aa5-b8b6-3777ed38e041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290588d7-e6e8-425f-ab4f-c97044aed9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e9ab4d-a5e6-45ed-82e2-0539f6c2b33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056e9c57-94ad-489c-80f8-804df8230f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456f942c-8282-4cd0-939c-a013845ffe29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e250c05-f4f9-47de-b447-b6553fe4bb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e173cdb-2e92-4e9a-9227-2187c3156699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6c4cb6-9d5a-4c1a-809d-d1eb4017dab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586cc95f-d0e4-4c3f-b837-2693f7e1dd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2de1a7-8b80-483c-b653-1b12df4f01c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d71d97-59ad-4b81-9c7d-9ecddd496c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ac0999-609c-436f-a001-3f646840325e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c95dda-c2ee-491e-a62c-a2d67f29e90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb677fdb-7520-47b4-8808-a7b411396b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c96576-3ceb-44c0-a878-6de942cd4b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af1d3520-087f-4ed5-bdaf-c349de4d1310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24740ae3-e894-432d-999c-7d4c80bd306e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b71002c-0a2d-46f8-8963-29570cad6e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c816d39-a8f2-4734-a5a1-05082d9ebe4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e223769a-f242-40d7-8212-2cb952e3519c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793b536b-8146-4a77-869e-150ff9e90b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b8b6c7-15bf-4adc-a09a-bc9c12c5738a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37eb2487-1fd8-4ea6-a766-a7e430c4dda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6e1993-e5cd-4c13-8992-3299333265c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77085143-734a-419c-9463-c0d127db4608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601f88fc-3ea1-4412-bbb3-e9e8bf5756b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b7c14d2-7640-4cf5-a201-921a7bed3bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f504cae-79ba-42ce-8e56-0262cb60a390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3c7529-0851-4e1d-9c29-24854352e3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f475c86d-22f8-4e16-87f8-097e97f11e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5532ed9c-f632-4fb5-a731-bfe9ca6db942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0ba81a-6c83-4de9-854d-44c791bea24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257dc9b7-5d94-4c0f-bedd-090c16408fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e38d7db-33c5-4bd2-bb1b-a3e55abf78cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d15ada-571a-4834-8a12-d708c958356c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7aa329a-0e03-4379-af04-bb37ca7689b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f21dde-295c-4f63-8c57-55191a77f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390177e3-c78b-42d6-9e37-6b75c30dbe09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a1d445-3967-4d97-bbbf-6cbdfa22a22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6aac87d-d585-4657-a5b4-467e0a6bf2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752184dd-94e7-4b57-aeb8-9c1ce8aae754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ada5aa-fe98-48a4-8030-6e797f7d9320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc931f15-5090-4422-84b2-37bb8b1240d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9e6d45-fa8e-4c77-988c-6905246fc9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a66b1fc-3fd9-4805-a9b0-e39a29155b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9533b600-dcd3-4162-b078-7006d77544ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a03af99-2e66-4119-9409-b0e684dd842a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0d131d-925c-4eb2-afa7-e65b209c2c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7b54d5-97a1-4a12-a76b-2bae24c1b99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23aeec57-b83d-4dbd-ac04-0b80afa617fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acaa67ed-4888-448f-aab4-0a816f32b80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf62c35-083a-484d-8415-cebd9ad43eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd86781-5f10-4993-b473-4406d1dafca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181c25ab-9960-4846-a1cb-be70f5e596ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0256481f-2a05-481d-8833-171c557bb035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2569ee19-ca62-4630-ae8c-a2add4df11ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28dfbba3-724f-43f7-8bd6-a3a3689c7216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8424e5ec-ce35-4ff0-88b7-00edbbeeb9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bb02d00-48ea-47a2-92b2-03bd8230e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8be0a0b-c721-4ec4-93ae-74831cbde0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faba32d9-4eba-40a6-9a68-94a0d4032ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd82bb85-bf77-4a6c-b124-e6566332168b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 332d8276-a640-4bea-8a80-94f63ce441a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c74a0ad9-6b0c-4397-aff1-7e825cdc280b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35f15c3-4912-4c85-8dca-48f9931480b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a963c1c2-1c4d-4faf-9211-237928c3d8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f57557-8f55-4e51-b285-741f2d1c4065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10a62fc-efb0-492b-8c75-7bf6674a9739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7f75ff-e9f8-4697-bb23-72db950c9caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccdf7826-1d68-4390-8cc5-a7690a14c36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e984920b-bdce-41c5-b29c-b3983eef55cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77cfebb3-c5a0-49e6-b987-ce57de6d0cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418a8c48-20b3-4449-bad8-2ef8f30aa138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a551d9c7-0aab-4b89-b5c5-5abd24e37a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c67f63-69f3-4314-b36a-dcf316eb05a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a060ae-d002-4cbe-953c-3bf16a0b2e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca08ac8-801c-464e-a874-9fea622a2753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110a629c-91f5-422a-b8e6-8ff5a4d3da67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d1630f-d70a-4c49-acc9-98e877c725ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff0d2d88-f1a1-41d7-a65c-3e072906c233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a5b81b-3e96-4bb0-bc94-3e579ca7b896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c5464f-827f-4092-a0e5-7c75f8fcdea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58892b8c-767c-4235-b821-6433faf57efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c114ebbe-9996-49a4-9bd4-f72acb3742be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d96c11-4874-45d0-a628-0e419e324a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4beb4a42-394d-4a36-bb10-b3e96acbdc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a167e82-de46-498e-a4a6-fc99161cb85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359ca102-b766-470f-9db8-dbfdbb0a4d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3aea3c0-765a-436a-a58f-916d9921c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee0dd00-ba3b-4bbc-aa84-6212c6abec20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14143a07-55cf-4286-8346-ea9cac0db8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe1b216-981b-4389-8d10-f4e6f27c5183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a43df7-1305-4a48-973a-c28032dcf0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3666a913-3f4f-424d-8de4-a008fc4514bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e666b898-c8b1-4ee2-9953-5d057afaf714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e55369-d406-4ebc-8e44-3ff28d682e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3286c4-4ef7-4e84-95a8-e9f0699f8d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 475bf42d-1a95-4e7d-83b5-9470c91a910b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e300766d-d47e-4247-9f72-410d9c3f64c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e19bdda-85b8-443b-a938-e06f375c86bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70651229-b9fe-45c2-b6b7-275f620a8728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14033162-8f4b-4fe9-8dda-cbd1a59a23e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac91504b-94c9-4c46-b9b9-8c91fb12d2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ee6a1d-e07a-40ad-9c91-cba9281352fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155c6b67-3eb4-4ee9-809f-e95fe95f2e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9004675-5668-4395-8b22-556d3b3cc828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0adae5-1d6e-46d1-9318-379cc8aaa949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c6f556-62f4-483e-ae2b-a97f8c329c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc77a085-ec75-4989-be87-bb62bf0e5559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6657aff-297f-44c6-b6f6-658a112bfcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c5e4da-61ca-4901-84da-ff2652dbd777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6db4636-48d0-4433-88a5-eed8185d166d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac8830b-45ed-411e-84f4-7d42dbe44ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c28ff13-0793-4d73-914f-561bd529b0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30767ab7-1c22-4a07-a3fb-6807f975d455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180d33d0-b480-4bb0-bdae-8a424b9ec275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8980881-5e4e-43b3-ac3d-5d926e8761a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530490a9-6d62-467b-84f2-9bf1375f4328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ff6912-350c-4b53-8679-77c46d03c98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b8ddcc-4c8b-4fea-97c9-90570c6dbaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad7c743-9d2e-4b55-b907-ea3ed7b84168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c471a7ca-f690-4783-ade5-9b09085d075a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4549edb7-88cf-4bf1-aff3-8748b9db0de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397a7f7d-4baa-49c4-a50d-c9d24636d615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc332058-5f9b-4c51-b2eb-0a2d54f39b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92943f2c-bd2f-406a-90f5-3c7a34f858be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f42a23-d804-4413-969d-14bd38699087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3968535-fe42-45e9-8162-a4e9e485b8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b833150b-ecca-46e2-a48e-0ba0c7ba882f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fc0d86-1e76-47e3-90bf-0be6ccf1142e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d113d19-6465-428f-9d8a-17f5a0e9e744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc39381-d605-4433-96a9-fb430384a1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27cd4bfc-862a-42e9-8770-cb24d1085bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6a3b3b-edb4-42b5-a941-a273127f70c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe49484e-c82c-49fa-a54b-510ecc429204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ee277e-3490-48d6-80e8-6f73b2f5c521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e580cda1-3364-4d1f-b484-8678378a7fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c82ab5-a7ec-4ab1-82ce-a70d683c847e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b259fbfe-c17a-49aa-b3a0-b378cc2abdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30815dc8-6c9f-4537-be86-5f22653d3c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48650c68-6282-41ec-a7bd-686549382816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced7b1e9-d345-42e8-8d1b-9ce27ef1dfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da49c117-091c-4317-b580-d6ddf10e965f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918657c9-8105-44eb-af5a-077fc601ed8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2260b5-cae9-4973-ad2f-5f1c46c92016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc446a3-56ac-4179-a3c5-817073606616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e7388f-6352-49e0-9fcf-6fed94a154b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa435bf-992c-400a-89c6-227792d9495d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7d0753-6170-4979-93ba-9cc2616118d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab2192f-8cd7-4216-90ba-f03b3be3ed82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e89234e-4bf0-431e-839b-5a5d5bae6869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2829ae-c130-4f1e-a34a-0d5cab956be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af19c4c-865b-4882-8e24-644374993a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e167ea02-5d74-4059-9691-8f9deb669ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c935f4e2-a3c9-4486-a0c6-3c86b8be6767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4926c89d-2278-4a1a-b8c2-3cbf99854d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f27e68-5a00-4240-a6fd-9dbde0db9960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126b5c71-a48c-492c-9ccb-c4efb75e61cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3aebde-996b-45f3-9eed-80c17c493486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66dadbde-f130-485e-b0bd-b53c5faeca0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f2820c-ced5-4370-a27d-1e05074b92f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13ef8b4-9977-4038-ac7d-7b5066196ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341c430c-8b47-483f-9a31-9c91a26c7e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ba280c-bbb3-45cd-83cb-bd87db274ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77a4b74-62c0-4d63-9c4d-c9c8b8f36b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490061b9-a637-4f1a-b392-e2cf39b5bea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c932472-418b-4fc9-9071-aca6e42e5e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159031ef-0e54-4902-a603-a85881a28e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43536ec1-6223-487b-87c2-c8a415c19707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27721889-e19d-419b-bdfe-7641db96b076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f9737c-73b3-44f5-9a22-898566545d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515ab03f-7a9e-4cd2-8af6-8d25e4d8777d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74008965-c130-4257-a782-abdd6130c530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee0b7cf8-f39c-4770-961f-37427c2a4e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 803bcea8-29ce-4f52-aeaa-70a6cc6ddf8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88c54ee-337d-4dcf-953d-3accd75a9887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7f001c-6c71-441b-912e-012df6d0455d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bfe86a0-3e07-4f46-862c-60df8e56d26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b298f8-b708-4950-ac9c-b75333ecb13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2297dcd-fe0b-471b-b3c4-47550db45634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f7c538-a462-4bd8-a487-bb468594889e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df12cc5-4870-4dda-97a8-2b4832686e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c4d104-fd4b-418d-8137-c582a324e0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a576ced7-73d2-466b-888b-a1f197894b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca51bf9-4e46-40c8-b886-c8ab79a69e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0395d0-746b-419b-b391-83f1c532ec91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c96e8f-51e0-4f5b-9eaa-d57d21f67040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5155b0-00f1-44ac-9388-fd72944c0a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53db8652-d92e-4f6d-938b-44b2d4cd3557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17eb595e-dd21-4ad3-ae6d-c571c2a2efad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d0d219-b442-4058-b929-7ccc13929842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70309f87-8962-44c0-bcb6-d7951d6cd896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5550157d-d956-4e34-bda8-4f8f095fe7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8f0264-1800-4366-94dd-e75f61edc732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621812a8-f889-4722-8cca-b6f8fadf0d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9f793a-2e35-424f-b28d-4aa542212dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb5a039-4d0d-4224-b407-bd3a9ddac0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59ae115-cbe7-4d35-b59b-39514b66e2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ff658f-d85d-4c05-b348-65c4ec1dc868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fb9b6a-a0bc-4a97-81a7-c101da696d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3523efe1-67cf-4f2e-94b1-fc307a28142e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb871c8-1ebf-4d88-b4a7-98f8e39bdc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b2c634-1346-4652-94fa-8550e521141b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bfc92d2-c3e2-41bf-920a-3410b906e933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058cee08-6f39-4216-8124-0937756d3864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe567ad-a6fc-4313-8962-ef93667f7e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b487689-ebc7-41bb-9358-784112bb7715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d41aa6f-a21d-4449-9569-3bde5c7a14f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ff6ba4-784e-48f2-9e8b-3e1077024689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1274fead-b3c2-4575-856d-73a0e01610cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844adb55-4dbc-41f3-92cc-469f8d05da6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaec050c-0c52-46a7-bd99-7c9d3a815787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf9507a-6ae3-4b08-b910-e916541eb0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5860fc-904c-4a2e-bf0b-98edec18e2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b48ca5-2f32-4747-9260-e9360eca9b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e16b581-ee14-4801-81b5-f45ae7c3017b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b016f9f7-0768-4bf8-92a9-40c2983d971b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 256d9ecc-0e61-470b-8b5d-27725a5e41c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33d569a-da7d-43eb-8da2-f8095caabe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad90b623-39b0-4fd5-bb48-93c25dac55ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 965550f2-76ce-4b72-a525-ff9ec931eb37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb8bd08-f2b2-4658-a49f-c4f27214b279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9408566-1191-4951-82e8-d416017beccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f990f92e-035d-40c1-892b-6cc0ed336c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1043e84-6093-49cb-a9fd-f86acec06c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206e7357-4093-487b-b356-7e5db43fd0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61210a15-70d0-49c4-8f67-6354cfb06b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde2574e-3066-4a9f-a982-11a675db47a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b617f17-74fa-4e0e-b86e-f627b36d9d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87741c9-de2a-409e-a8d2-25ef449d37f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aca5888-1f7e-4f79-9a25-de57e8862d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513b8e73-f123-4f1f-9375-f0956d71b88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f47fe77-0dfa-4e1f-bfa1-152d88be6123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a2f88f-1534-4bec-a27c-fce399550736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4708f400-9844-4a13-af72-4ff18fa4f6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df410e0-a86b-4087-93b1-5bed432760db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9673cb0c-f324-4111-ab5a-6a7e71954e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381899c4-b42c-4270-acca-9672bd756972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683def3a-7cb4-455e-9301-59006c07abc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7bb63a-12fa-47c9-83e8-928b1b1a6747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1f835b-1182-417b-8327-d8129d4d9f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2109b699-c46d-465d-a492-67c5af47570d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d15a9d1-2840-4e26-afb2-bcd7dcc72b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bcf7734-87e8-47a2-88ae-a13aba7bf63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5757c357-0d98-4668-9fca-08ce0576b9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1027345-80a9-4117-b4c4-a870cedaacf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b2f9e2-4302-4112-8afe-ca289cc2a7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8807a564-e149-41ee-908e-fb9b2e627860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9e9146-8e83-4421-ac29-83490ad38c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffa039ba-e585-4e65-918c-dd96354d7b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c001740-622b-4d09-bc69-ad0727fce892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9641e66a-f69e-4199-811d-6107ae8ab11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8d6b4e-ce6b-4780-82af-8a8596d0c2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc2ab18-cf91-40b2-9d6c-eb5a6c8d6b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd0b5c4-78d8-44a5-8f24-18b7078fdae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da853e3d-734b-4c96-9f9b-a5ee60f67cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecef5b9a-3546-4e49-8cf0-a6f8d7e335fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0f6bf8-ad43-47df-9529-52985f843406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18abe779-b13e-4a8b-bbb4-94f4adb64ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b5e2a8-54d7-40d8-9f73-2ac01f50eebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e28eae7-fcdf-47d7-b6d8-2b026dcc6b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35268ff-1e09-44c0-af74-7538d9840c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca56420-fca7-4aae-bb55-74ba89acb85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00eda2e-def9-446a-b803-8c14afa5da24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd8648b-6100-4fae-834c-972c32d62097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2206e5f3-40e4-4ff1-a773-f524fd238cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03dba1fd-d2c2-414d-83e0-8d4608ad65b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9bed0d-a54b-419d-b9af-abca1982f3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7713b523-ecf2-4959-86db-b67b1e9775fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9d029c-1d6f-4672-ab91-7bbcca1ba630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ac08cd-c25c-41ec-a071-1e9b9650b921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99057099-1f32-4110-9025-5d8732a16e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6fd336-8663-4e82-b1e2-ece8c7f82c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca13b76b-7054-4543-a5cd-75a762e4be7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394635c8-1a25-4c75-bd5e-bbd1786bc6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cbafcfe-281d-47ee-a3a5-e5d2bc7c2be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057fdf07-b081-49a3-bb68-78e1b4e421c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478bb679-0aad-4f58-ae85-81aad9d404c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03649d23-53c1-4619-a03a-280b704e4a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e57b78e-c41c-4516-990d-20c0914178e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd00788-9d46-442c-a51c-5590a674ff11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb1ff4a-37ac-4249-8683-aca3392fc741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 154befdb-6362-456f-9d8b-92ba582dcc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b187657-7265-47ee-aa12-4885b5f891be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e4a09b-de35-4b2b-b20b-8afada0cff9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0936a2a2-6960-4d61-a439-10da0c6b615c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b769223a-a417-44aa-aac6-08527f03ff8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a880e72b-ad7d-4036-a9df-b6a77c3a1f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23494b5f-bd21-456f-9287-936928e85ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e122da-a752-4d1f-8c24-b752e60a1c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833431dc-1f9c-4fab-8439-51ba5b0e2833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbc3249-16e6-4e10-bce0-2ad375c64bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9eb359b-0252-4b22-b259-5c8b9e49d233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28979af8-acec-4e4f-af2c-fbdf88903d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28fceae1-b6aa-43b8-b47e-e6e6d018665e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e094adfd-647f-402a-b1a0-01ad7d02b1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ada2ee8-15b5-4f40-96d8-8e3c26b78dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2db366a-db84-4854-b73d-4f56579d8c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cfc3ec-4b47-4132-9a30-37e5ff27f8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502b83b9-3fa2-4683-a24c-e6b9dad4d638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdf8f59-f190-44f6-b29f-e3d24a20929e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d8ff094-a16c-4844-9a57-c35f30cdfa06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f161d95-0db9-4b7d-8d6a-5fb7ba82c8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10071efb-f4a0-4e45-9999-e00e15d4a730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349ea50f-f085-42b3-9b73-522f45c09383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618ff6e2-3174-4e5a-bd29-45bc5553ae17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9380b68-886c-4595-baaa-247d6ab00dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60dce9b-e2ae-45d9-a614-c18a6a0979f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b4dbb9-36f6-43e8-8c8d-c1ff93fb730d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52b7350-ee8c-4eb9-8d77-9a1df1fed0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65468697-80d0-4743-b30a-498f47aa5d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e370cc3-7ac9-41c7-a6aa-abdd115d28a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c373cad7-5ced-431d-ac53-63e9dbb29725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba10566-de74-4231-94d5-46b0a95f7eb9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(3505, 24), y=(3505,)
   Test:  X=(877, 24), y=(877,)

⚠️  Limiting training data: 3505 → 800 samples
⚠️  Limiting test data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.4708, RMSE: 0.6862, MAE: 0.6275, R²: -5.1048

📊 Round 0 Test Metrics:
   Loss: 0.4644, RMSE: 0.6814, MAE: 0.6223, R²: -5.0212

📊 Round 0 Test Metrics:
   Loss: 0.4610, RMSE: 0.6790, MAE: 0.6196, R²: -4.9782

============================================================
🔄 Round 6 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3075, val=0.0991 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0883, val=0.0872 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0803, val=0.0842 (↓), lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0841, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0803, val=0.0842, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0798, val=0.0846, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 6 Summary - Client client_18
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0038
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0087
============================================================


============================================================
🔄 Round 9 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3994, val=0.3265 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2626, val=0.1619 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1079, val=0.0850 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0820, val=0.0807 (↓), lr=0.000250
   • Epoch   5/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0812, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 9 Summary - Client client_18
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0036
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0046
============================================================


============================================================
🔄 Round 11 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4153, val=0.3989 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.3702, val=0.3545 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3293, val=0.3144 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.2887, val=0.2696 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2401, val=0.2144 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0834, val=0.0789 (↓), lr=0.000031
   • Epoch  21/100: train=0.0816, val=0.0772, patience=7/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 11 Summary - Client client_18
   Epochs: 29/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0021
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0085
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.3887, RMSE: 0.6235, MAE: 0.5582, R²: -4.0406

============================================================
🔄 Round 13 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3996, val=0.3775 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.3763, val=0.3540 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.3537, val=0.3330 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.3331, val=0.3133 (↓), lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   ✓ Epoch   5/100: train=0.3134, val=0.2939 (↓), lr=0.000016
   ✓ Epoch  11/100: train=0.2409, val=0.2262 (↓), lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008
   📉 Epoch 21: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.1597, val=0.1507 (↓), lr=0.000004
   📉 Epoch 29: LR reduced 0.000004 → 0.000002
   ✓ Epoch  31/100: train=0.1343, val=0.1286 (↓), lr=0.000002
   📉 Epoch 37: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.1258, val=0.1207 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1212, val=0.1163 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1170, val=0.1124 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1133, val=0.1088 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1098, val=0.1054 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1066, val=0.1024 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.1041, RMSE=0.3226, R²=-0.2796
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.2557
============================================================


============================================================
🔄 Round 15 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3729, val=0.3154 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3721, val=0.3147 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3714, val=0.3140 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3706, val=0.3134 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3699, val=0.3128 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3663, val=0.3095 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3612, val=0.3049 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3566, val=0.3007 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3522, val=0.2967 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3480, val=0.2929 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3438, val=0.2891 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3397, val=0.2853 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3356, val=0.2816 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3314, val=0.2778 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3279, RMSE=0.5726, R²=-2.9633
   Val:   Loss=0.2744, RMSE=0.5238, R²=-2.7925
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3210, RMSE: 0.5666, MAE: 0.4938, R²: -3.1627

============================================================
🔄 Round 17 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3072, val=0.3131 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3067, val=0.3126 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3062, val=0.3121 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3057, val=0.3116 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3052, val=0.3111 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3022, val=0.3080 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2972, val=0.3028 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2921, val=0.2976 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2870, val=0.2923 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2819, val=0.2869 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2766, val=0.2814 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2712, val=0.2759 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2657, val=0.2702 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2601, val=0.2643 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2544, RMSE=0.5044, R²=-2.0760
   Val:   Loss=0.2590, RMSE=0.5089, R²=-2.5021
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.2491, RMSE: 0.4991, MAE: 0.4178, R²: -2.2295

============================================================
🔄 Round 19 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2566, val=0.2828 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2560, val=0.2822 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2554, val=0.2816 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2548, val=0.2810 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2543, val=0.2804 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2508, val=0.2768 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2450, val=0.2707 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2390, val=0.2644 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2329, val=0.2581 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2267, val=0.2516 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2205, val=0.2451 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2141, val=0.2384 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2077, val=0.2318 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2013, val=0.2250 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1952, RMSE=0.4418, R²=-1.4967
   Val:   Loss=0.2190, RMSE=0.4679, R²=-1.3770
============================================================


============================================================
🔄 Round 20 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2318, val=0.2094 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2312, val=0.2088 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2306, val=0.2082 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2299, val=0.2077 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2293, val=0.2071 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2256, val=0.2037 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2192, val=0.1979 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2128, val=0.1921 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2063, val=0.1862 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1998, val=0.1803 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1933, val=0.1744 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1868, val=0.1686 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1803, val=0.1628 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1739, val=0.1570 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1677, RMSE=0.4095, R²=-1.0745
   Val:   Loss=0.1519, RMSE=0.3898, R²=-0.8770
============================================================


============================================================
🔄 Round 21 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1887, val=0.2060 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1881, val=0.2054 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1875, val=0.2048 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1869, val=0.2041 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1863, val=0.2035 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1827, val=0.1996 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1767, val=0.1932 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1708, val=0.1867 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1648, val=0.1803 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1590, val=0.1739 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1532, val=0.1675 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1475, val=0.1613 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1420, val=0.1552 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1366, val=0.1493 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1319, RMSE=0.3631, R²=-0.6264
   Val:   Loss=0.1441, RMSE=0.3796, R²=-0.7973
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2439, R²: -0.0971

============================================================
🔄 Round 25 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0946, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0944, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0942, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0940, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0939, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0744, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0913, val=0.0735, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0899, val=0.0728, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0886, val=0.0723, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0718, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0867, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0859, val=0.0714, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 25 Summary - Client client_18
   Epochs: 72/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0492
   Val:   Loss=0.0716, RMSE=0.2677, R²=-0.0082
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2378, R²: -0.0064

============================================================
🔄 Round 26 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0809, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0805, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 26 Summary - Client client_18
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0126
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0334
============================================================


============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0114
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0263
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2382, R²: -0.0008

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0125
   Val:   Loss=0.0776, RMSE=0.2787, R²=-0.0081
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2386, R²: -0.0011

📊 Round 29 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2388, R²: -0.0016

============================================================
🔄 Round 36 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 36 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0082
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0156
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2388, R²: -0.0017

📊 Round 36 Test Metrics:
   Loss: 0.0773, RMSE: 0.2779, MAE: 0.2388, R²: -0.0017

============================================================
🔄 Round 38 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 38 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0098
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0009
============================================================


============================================================
🔄 Round 40 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 40 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0075
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0048
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2389, R²: -0.0019

📊 Round 40 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2389, R²: -0.0020

============================================================
🔄 Round 43 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 43 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0081
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0090
============================================================


============================================================
🔄 Round 44 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 44 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0045
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0192
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2391, R²: -0.0027

============================================================
🔄 Round 46 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 46 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0075
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0049
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2391, R²: -0.0029

📊 Round 46 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2391, R²: -0.0029

📊 Round 46 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2392, R²: -0.0033

============================================================
🔄 Round 50 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 50 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0060
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0168
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2392, R²: -0.0033

============================================================
🔄 Round 52 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 52 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0081
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0018
============================================================


============================================================
🔄 Round 56 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 56 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0076
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0069
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2395, R²: -0.0050

📊 Round 56 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2396, R²: -0.0055

============================================================
🔄 Round 60 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 60 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0072
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0090
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2396, R²: -0.0056

============================================================
🔄 Round 61 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 61 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0094
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0005
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2396, R²: -0.0056

============================================================
🔄 Round 63 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 63 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0087
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0169
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2397, R²: -0.0062

============================================================
🔄 Round 65 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 65 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0100
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0003
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

============================================================
🔄 Round 66 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 66 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0085
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0174
============================================================


============================================================
🔄 Round 67 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 67 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0112
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0111
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2397, R²: -0.0061

📊 Round 67 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2397, R²: -0.0062

============================================================
🔄 Round 70 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 70 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0054
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0164
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

============================================================
🔄 Round 71 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 71 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0059
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0181
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

============================================================
🔄 Round 72 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 72 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0104
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0054
============================================================


============================================================
🔄 Round 73 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 73 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0092
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0086
============================================================


============================================================
🔄 Round 77 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 77 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0088
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0058
============================================================


============================================================
🔄 Round 78 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 78 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0084
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0354
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0058

📊 Round 78 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0057

📊 Round 78 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0058

============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0076
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0178
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0059

============================================================
🔄 Round 82 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 82 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0080
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0053
============================================================


============================================================
🔄 Round 83 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 83 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0098
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0005
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0063

============================================================
🔄 Round 90 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 90 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0066
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0102
============================================================


============================================================
🔄 Round 91 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 91 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0090
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0101
============================================================


============================================================
🔄 Round 92 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 92 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0094
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0067
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

📊 Round 92 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0057

📊 Round 92 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0057

============================================================
🔄 Round 98 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 98 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0076
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0067
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0053

============================================================
🔄 Round 99 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 99 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0064
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0109
============================================================


============================================================
🔄 Round 101 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 101 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0070
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0086
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2395, R²: -0.0049

============================================================
🔄 Round 102 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 102 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0061
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0149
============================================================


============================================================
🔄 Round 103 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 103 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0061
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0109
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2394, R²: -0.0042

============================================================
🔄 Round 105 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 105 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0057
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0118
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2395, R²: -0.0047

============================================================
🔄 Round 110 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 110 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0065
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0130
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0053

📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0053

📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0053

============================================================
🔄 Round 116 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 116 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0093
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0008
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0057

============================================================
🔄 Round 118 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 118 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0044
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0209
============================================================


============================================================
🔄 Round 121 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 121 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0070
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0110
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0058

============================================================
🔄 Round 126 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 126 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0064
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0134
============================================================


============================================================
🔄 Round 128 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 128 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0067
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0170
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0066

============================================================
🔄 Round 130 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 130 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0092
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0026
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2399, R²: -0.0069

📊 Round 130 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0063

============================================================
🔄 Round 135 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 135 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=-0.0073
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0082
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

📊 Round 135 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

============================================================
🔄 Round 138 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 138 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0106
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0275
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0065

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0076
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0162
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0064

📊 Round 139 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0064

📊 Round 139 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0064

============================================================
🔄 Round 143 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 143 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0096
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0000
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0067

============================================================
🔄 Round 145 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 145 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0073
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0087
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0067

============================================================
🔄 Round 146 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 146 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0074
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0086
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0067

============================================================
🔄 Round 147 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 147 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0075
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0146
============================================================


============================================================
🔄 Round 148 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 148 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0068
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0110
============================================================


============================================================
🔄 Round 149 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 149 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0096
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0158
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

============================================================
🔄 Round 150 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 150 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0081
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0043
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

============================================================
🔄 Round 152 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 152 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0076
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0094
============================================================


============================================================
🔄 Round 153 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 153 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0063
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0113
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

📊 Round 153 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

📊 Round 153 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0058

============================================================
🔄 Round 157 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 157 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0060
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0241
============================================================


============================================================
🔄 Round 160 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 160 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0071
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0079
============================================================


============================================================
🔄 Round 161 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 161 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0095
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0289
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0058

============================================================
🔄 Round 163 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 163 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0074
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0095
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0051

============================================================
🔄 Round 165 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 165 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0068
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0081
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0051

============================================================
🔄 Round 167 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 167 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0054
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0154
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0059

============================================================
🔄 Round 169 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 169 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0039
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0204
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

📊 Round 169 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

📊 Round 169 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

📊 Round 169 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

============================================================
🔄 Round 176 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 176 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0088
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0075
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

============================================================
🔄 Round 178 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 178 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0071
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0069
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

📊 Round 178 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

============================================================
🔄 Round 184 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 184 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0062
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0139
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

============================================================
🔄 Round 188 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 188 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0070
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0089
============================================================


============================================================
🔄 Round 189 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 189 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0095
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0021
============================================================


============================================================
🔄 Round 195 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 195 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0070
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0172
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0062

📊 Round 195 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

📊 Round 195 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0057

============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0072
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0072
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0049
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0172
============================================================


============================================================
🔄 Round 202 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 202 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0110
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0075
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

📊 Round 202 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0050

============================================================
🔄 Round 205 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 205 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0054
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0130
============================================================


============================================================
🔄 Round 208 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 208 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0075
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0212
============================================================


============================================================
🔄 Round 209 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 209 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0075
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0110
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

📊 Round 209 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

============================================================
🔄 Round 212 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 212 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0062
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0113
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0050

============================================================
🔄 Round 213 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 213 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0077
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0045
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0050

============================================================
🔄 Round 214 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 214 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0048
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0148
============================================================


============================================================
🔄 Round 217 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 217 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0096
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0173
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0052

📊 Round 217 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0048

📊 Round 217 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0048

============================================================
🔄 Round 223 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 223 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0063
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0084
============================================================


============================================================
🔄 Round 228 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 228 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0090
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0044
============================================================


============================================================
🔄 Round 229 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 229 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0064
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0083
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0051

============================================================
🔄 Round 230 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 230 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0066
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0073
============================================================


============================================================
🔄 Round 232 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 232 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0108
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0080
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0059

📊 Round 232 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0059

============================================================
🔄 Round 237 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 237 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0075
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0066
============================================================


============================================================
🔄 Round 238 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 238 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0056
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0136
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

============================================================
🔄 Round 240 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 240 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0077
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0100
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 243 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 243 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0088
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0008
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

📊 Round 243 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

📊 Round 243 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

📊 Round 243 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

============================================================
🔄 Round 249 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 249 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0045
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0220
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

📊 Round 249 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

============================================================
🔄 Round 251 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 251 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0056
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0128
============================================================


============================================================
🔄 Round 252 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 252 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0075
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0114
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

📊 Round 252 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

📊 Round 252 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2397, R²: -0.0056

📊 Round 252 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

============================================================
🔄 Round 257 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 257 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0080
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0070
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 257 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 260 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 260 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0053
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0252
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0054

📊 Round 260 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0055

============================================================
🔄 Round 264 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 264 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0094
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0041
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0052

============================================================
🔄 Round 266 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 266 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0062
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0089
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0052

📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0052

📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2396, R²: -0.0049

📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 266 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 273 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 273 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0092
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0056
============================================================


============================================================
🔄 Round 274 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 274 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0061
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0105
============================================================


============================================================
🔄 Round 275 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 275 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0049
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0151
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0051

============================================================
🔄 Round 276 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 276 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0064
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0104
============================================================


============================================================
🔄 Round 277 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 277 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0100
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0005
============================================================


============================================================
🔄 Round 278 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 278 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0061
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0158
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0052

📊 Round 278 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

============================================================
🔄 Round 280 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 280 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0061
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0098
============================================================


============================================================
🔄 Round 282 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 282 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0065
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0171
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0058

📊 Round 282 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 285 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 285 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0061
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0106
============================================================


============================================================
🔄 Round 286 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 286 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0084
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0211
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

📊 Round 286 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2398, R²: -0.0061

📊 Round 286 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0065

============================================================
🔄 Round 292 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 292 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0070
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0084
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0065

============================================================
🔄 Round 294 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 294 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0089
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0055
============================================================


============================================================
🔄 Round 296 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 296 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0071
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0168
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2400, R²: -0.0070

============================================================
🔄 Round 297 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 297 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0058
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0540
============================================================


============================================================
🔄 Round 298 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 298 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0084
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0049
============================================================


============================================================
🔄 Round 302 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 302 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0056
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0125
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

============================================================
🔄 Round 303 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 303 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0063
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0134
============================================================


============================================================
🔄 Round 307 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 307 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0087
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0000
============================================================


============================================================
🔄 Round 308 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 308 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0076
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0041
============================================================


============================================================
🔄 Round 310 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 310 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0081
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0018
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 313 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 313 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0066
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0163
============================================================


============================================================
🔄 Round 315 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 315 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0059
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0307
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 316 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 316 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0082
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0016
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

============================================================
🔄 Round 318 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 318 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0073
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0084
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 319 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 319 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0079
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0035
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

============================================================
🔄 Round 321 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 321 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0058
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0140
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0055

📊 Round 321 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0055

============================================================
🔄 Round 323 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 323 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0061
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0141
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2397, R²: -0.0054

📊 Round 323 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0051

============================================================
🔄 Round 326 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 326 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0050
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0133
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0059

📊 Round 326 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

============================================================
🔄 Round 329 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 329 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0069
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0080
============================================================


============================================================
🔄 Round 330 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 330 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0066
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0080
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0060

📊 Round 330 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0059

📊 Round 330 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0062

📊 Round 330 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0065

📊 Round 330 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2399, R²: -0.0063

============================================================
🔄 Round 343 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 343 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0101
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0118
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0055

============================================================
🔄 Round 346 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 346 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0064
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0106
============================================================


============================================================
🔄 Round 348 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 348 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0073
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0181
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

📊 Round 348 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 354 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 354 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0058
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0320
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0057

============================================================
🔄 Round 358 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 358 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0072
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0056
============================================================


============================================================
🔄 Round 360 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 360 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0053
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0142
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0053

============================================================
🔄 Round 361 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 361 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0071
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0064
============================================================


============================================================
🔄 Round 362 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 362 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0064
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0332
============================================================


============================================================
🔄 Round 363 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 363 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0093
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0040
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

📊 Round 363 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

============================================================
🔄 Round 365 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 365 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0052
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0124
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 366 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 366 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0060
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0080
============================================================


============================================================
🔄 Round 368 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 368 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0063
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0113
============================================================


============================================================
🔄 Round 370 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 370 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0082
   Val:   Loss=0.0668, RMSE=0.2584, R²=-0.0066
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 373 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 373 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0079
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0008
============================================================


============================================================
🔄 Round 374 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 374 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0061
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0060
============================================================


============================================================
🔄 Round 376 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 376 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0051
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0172
============================================================


============================================================
🔄 Round 378 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 378 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0063
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0048
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2395, R²: -0.0039

📊 Round 378 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2395, R²: -0.0040

============================================================
🔄 Round 380 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 380 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0067
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0063
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 381 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 381 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0061
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0080
============================================================


============================================================
🔄 Round 382 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 382 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0048
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0106
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 386 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 386 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0056
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0079
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0042

📊 Round 386 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

📊 Round 386 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2395, R²: -0.0039

📊 Round 386 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 395 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 395 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0044
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0139
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2395, R²: -0.0039

============================================================
🔄 Round 398 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 398 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0051
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0238
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

============================================================
🔄 Round 399 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 399 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0070
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0018
============================================================


============================================================
🔄 Round 400 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 400 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0076
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0082
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 401 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 401 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0050
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0145
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 402 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 402 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0053
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0109
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 405 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 405 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0071
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0073
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 409 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 409 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0068
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0102
============================================================


============================================================
🔄 Round 412 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 412 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0070
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0038
============================================================


============================================================
🔄 Round 413 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 413 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0060
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0097
============================================================


============================================================
🔄 Round 414 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 414 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0053
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0099
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 416 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 416 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0050
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0114
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

📊 Round 416 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

📊 Round 416 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

📊 Round 416 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0045

============================================================
🔄 Round 422 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 422 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0085
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0094
============================================================


============================================================
🔄 Round 423 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 423 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=-0.0071
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0034
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

📊 Round 423 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

============================================================
🔄 Round 426 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 426 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0077
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0036
============================================================


============================================================
🔄 Round 428 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 428 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0074
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0089
============================================================


============================================================
🔄 Round 429 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 429 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0069
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0103
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

📊 Round 429 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

📊 Round 429 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 432 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 432 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0074
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0359
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

📊 Round 432 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

📊 Round 432 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 435 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 435 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0042
   Val:   Loss=0.0673, RMSE=0.2594, R²=-0.0275
============================================================


============================================================
🔄 Round 438 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 438 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0047
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0120
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 438 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 438 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

📊 Round 438 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 443 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 443 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0059
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0068
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

📊 Round 443 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

============================================================
🔄 Round 445 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 445 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0047
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0198
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

📊 Round 445 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0045

📊 Round 445 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0045

============================================================
🔄 Round 452 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 452 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0062
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0047
============================================================


============================================================
🔄 Round 455 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 455 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0071
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0014
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

============================================================
🔄 Round 456 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 456 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0030
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0416
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 457 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 457 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0047
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0122
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0046

============================================================
🔄 Round 460 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 460 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0059
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0057
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 463 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 463 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0035
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0145
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 465 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 465 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0048
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0148
============================================================


============================================================
🔄 Round 466 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 466 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0126
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 469 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 469 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0072
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0101
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 471 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 471 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0104
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0208
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 473 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 473 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0053
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0083
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

📊 Round 473 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

============================================================
🔄 Round 477 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 477 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0054
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0067
============================================================


============================================================
🔄 Round 478 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 478 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0043
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0166
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0044

============================================================
🔄 Round 480 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 480 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0064
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0032
============================================================


============================================================
🔄 Round 481 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 481 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0062
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0051
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 482 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 482 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0048
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0109
============================================================


============================================================
🔄 Round 485 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 485 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0072
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0001
============================================================


============================================================
🔄 Round 486 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 486 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0048
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0126
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 491 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 491 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0043
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0177
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 493 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 493 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0047
   Val:   Loss=0.0681, RMSE=0.2609, R²=-0.0139
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 494 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 494 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0037
   Val:   Loss=0.0696, RMSE=0.2637, R²=-0.0229
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0046

📊 Round 494 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 497 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 497 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0039
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0170
============================================================


============================================================
🔄 Round 498 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 498 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0120
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0110
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 499 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 499 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0045
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0113
============================================================


============================================================
🔄 Round 502 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 502 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0088
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0174
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 504 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 504 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0054
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0075
============================================================


============================================================
🔄 Round 505 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 505 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0068
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0072
============================================================


============================================================
🔄 Round 506 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 506 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0075
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0110
============================================================


============================================================
🔄 Round 508 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 508 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0045
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0110
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 509 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 509 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0076
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0036
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 512 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 512 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0051
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0173
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

📊 Round 512 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 516 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 516 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0056
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0083
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 522 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 522 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0066
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0046
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0051

📊 Round 522 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0051

============================================================
🔄 Round 524 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 524 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0043
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0186
============================================================


============================================================
🔄 Round 525 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 525 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0040
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0157
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0055

📊 Round 525 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0054

============================================================
🔄 Round 528 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 528 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0048
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0201
============================================================


============================================================
🔄 Round 529 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 529 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0067
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0125
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 531 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 531 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0054
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0079
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0046

📊 Round 531 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

📊 Round 531 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0042

============================================================
🔄 Round 535 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 535 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0061
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0030
============================================================


============================================================
🔄 Round 538 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 538 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0064
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0149
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 539 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 539 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0069
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0009
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 539 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 539 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 545 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 545 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0081
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0129
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 546 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 546 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0057
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0051
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0042

============================================================
🔄 Round 548 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 548 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0107
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0296
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0046

📊 Round 548 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

📊 Round 548 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 555 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 555 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0069
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0121
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 556 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 556 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0049
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0083
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 557 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 557 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0055
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0077
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 557 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 562 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 562 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0053
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0111
============================================================


============================================================
🔄 Round 563 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 563 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0057
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0074
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 563 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 581 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 581 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0049
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0266
============================================================


============================================================
🔄 Round 582 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 582 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0048
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0110
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

============================================================
🔄 Round 587 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 587 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0052
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0081
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

============================================================
🔄 Round 588 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 588 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0037
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0250
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0053

📊 Round 588 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0053

📊 Round 588 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0054

============================================================
🔄 Round 593 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 593 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0067
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0013
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0053

============================================================
🔄 Round 594 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 594 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0060
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0611
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0054

📊 Round 594 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0054

📊 Round 594 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2398, R²: -0.0055

📊 Round 594 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2398, R²: -0.0056

📊 Round 594 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

📊 Round 594 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0051

============================================================
🔄 Round 606 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 606 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0070
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0102
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

============================================================
🔄 Round 607 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 607 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0049
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0324
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

============================================================
🔄 Round 612 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 612 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0080
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0003
============================================================


============================================================
🔄 Round 613 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 613 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0052
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0127
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 614 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 614 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0056
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0135
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

📊 Round 614 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

📊 Round 614 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0046

📊 Round 614 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 620 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 620 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0064
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0020
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

📊 Round 620 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0051

============================================================
🔄 Round 628 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 628 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0080
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0020
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 629 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 629 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0044
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0486
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0050

============================================================
🔄 Round 630 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 630 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0053
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0068
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 632 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 632 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0057
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0047
============================================================


============================================================
🔄 Round 633 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 633 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0063
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0132
============================================================


============================================================
🔄 Round 635 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 635 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0039
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0118
============================================================


============================================================
🔄 Round 637 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 637 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0088
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0002
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

============================================================
🔄 Round 639 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 639 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0032
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0492
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0051

============================================================
🔄 Round 642 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 642 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0047
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0111
============================================================


============================================================
🔄 Round 643 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 643 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0077
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0241
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

📊 Round 643 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0051

============================================================
🔄 Round 647 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 647 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0064
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0144
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

============================================================
🔄 Round 654 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 654 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0050
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0211
============================================================


============================================================
🔄 Round 656 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 656 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0050
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0082
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

📊 Round 656 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 658 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 658 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0066
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0066
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 659 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 659 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0061
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0063
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 660 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 660 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0041
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0261
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

📊 Round 660 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0041

📊 Round 660 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0042

📊 Round 660 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0041

============================================================
🔄 Round 668 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 668 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0044
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0082
============================================================


============================================================
🔄 Round 669 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 669 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0039
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0110
============================================================


============================================================
🔄 Round 670 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 670 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0120
============================================================


============================================================
🔄 Round 671 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 671 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0080
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0001
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

📊 Round 671 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0049

============================================================
🔄 Round 674 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 674 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0042
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0508
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0053

============================================================
🔄 Round 678 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 678 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0050
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0075
============================================================


============================================================
🔄 Round 679 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 679 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0037
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0136
============================================================


============================================================
🔄 Round 680 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 680 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0055
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0091
============================================================


============================================================
🔄 Round 681 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 681 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0057
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0048
============================================================


============================================================
🔄 Round 682 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 682 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0048
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0126
============================================================


============================================================
🔄 Round 684 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 684 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0048
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0074
============================================================


============================================================
🔄 Round 685 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 685 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0094
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0154
============================================================


============================================================
🔄 Round 687 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 687 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0036
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0122
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0049

============================================================
🔄 Round 689 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 689 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0080
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0032
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0053

============================================================
🔄 Round 691 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 691 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0071
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0009
============================================================


============================================================
🔄 Round 693 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 693 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0059
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0042
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

============================================================
🔄 Round 698 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 698 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0067
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0046
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0044

📊 Round 698 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0043

============================================================
🔄 Round 704 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 704 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0066
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0073
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0043

============================================================
🔄 Round 705 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 705 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0034
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0245
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0043

============================================================
🔄 Round 706 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 706 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0044
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0083
============================================================


============================================================
🔄 Round 707 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 707 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0045
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0077
============================================================


============================================================
🔄 Round 708 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 708 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0051
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0084
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2396, R²: -0.0043

============================================================
🔄 Round 710 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 710 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0045
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0172
============================================================


============================================================
🔄 Round 712 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 712 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0068
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0128
============================================================


============================================================
🔄 Round 714 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 714 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0040
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0248
============================================================


============================================================
🔄 Round 718 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 718 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0140
============================================================


============================================================
🔄 Round 719 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 719 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0051
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0050
============================================================


============================================================
🔄 Round 721 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 721 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0070
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0048
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0042

============================================================
🔄 Round 722 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 722 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0029
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0131
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0043

============================================================
🔄 Round 724 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 724 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0038
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0104
============================================================


============================================================
🔄 Round 726 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 726 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0058
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0022
============================================================


============================================================
🔄 Round 728 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 728 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0045
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0177
============================================================


============================================================
🔄 Round 729 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 729 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0084
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0122
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0044

📊 Round 729 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

📊 Round 729 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0049

============================================================
🔄 Round 734 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 734 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0051
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0070
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

============================================================
🔄 Round 736 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 736 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0055
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0066
============================================================


============================================================
🔄 Round 737 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 737 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0066
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0003
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0047

============================================================
🔄 Round 738 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 738 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0049
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0229
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0044

📊 Round 738 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

============================================================
🔄 Round 740 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 740 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0043
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0131
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2397, R²: -0.0048

📊 Round 740 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0050

============================================================
🔄 Round 747 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 747 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0057
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0041
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0052

📊 Round 747 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2399, R²: -0.0056

📊 Round 747 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2399, R²: -0.0055

============================================================
🔄 Round 750 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 750 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0065
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0019
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2399, R²: -0.0056

📊 Round 750 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0051

============================================================
🔄 Round 752 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 752 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0044
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0233
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0049

============================================================
🔄 Round 753 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 753 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0047
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0086
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0046

📊 Round 753 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

============================================================
🔄 Round 756 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 756 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0076
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0010
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

📊 Round 756 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2396, R²: -0.0040

============================================================
🔄 Round 760 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 760 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0064
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0100
============================================================


============================================================
🔄 Round 761 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 761 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0064
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0167
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0037

============================================================
🔄 Round 762 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 762 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0063
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0003
============================================================


============================================================
🔄 Round 763 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 763 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0047
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0168
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0038

============================================================
🔄 Round 768 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 768 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0038
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0175
============================================================


============================================================
🔄 Round 769 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 769 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0054
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0016
============================================================


============================================================
🔄 Round 771 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 771 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0045
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0064
============================================================


============================================================
🔄 Round 773 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 773 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0041
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0104
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0045

============================================================
🔄 Round 775 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 775 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0049
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0056
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2397, R²: -0.0046

============================================================
🔄 Round 777 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 777 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0038
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0141
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2398, R²: -0.0049

============================================================
🔄 Round 785 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 785 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0058
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0054
============================================================


❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
