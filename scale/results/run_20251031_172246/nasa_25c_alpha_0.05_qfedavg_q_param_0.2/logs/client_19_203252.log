[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45814300-4c82-4e63-a8be-779c7a581a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4244070-4f85-4458-a278-0a31a1c1a989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 226cb723-440a-4601-9ebd-d4b8ab22e268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1a5418-927c-42db-97f8-bfab75184a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60531dd9-ccc6-43f0-bc29-6c04058ecf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0a2627-1e4e-4b9e-9dee-d23b612181ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a06b9d2-be0e-47ce-9e56-1db69c6d15b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e9d9ff-671a-4c18-b30e-f51ee1592ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233864cc-6d47-4f70-8768-c0a9507e7e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d7b876-31b0-412d-8205-1f9504a9c77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130bd962-5f4e-4439-bd1f-b7cf3978bc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbe86aa-a781-4883-a31b-d4a828cd930b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8932632b-b057-4b3a-8551-1170656c7090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 994fb49b-5f44-4803-9d8e-27bde5f29ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ac01a2-8d3e-47b4-a826-d1b5f4beb3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7805096-e7f9-4962-bf68-c1c5d06844f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebedc371-3b19-4d7a-a551-ed3feefbe7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003771a0-6c5f-47cc-9eca-0628d1471920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40c41e25-9d49-47d8-b418-deafb18018a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac8dbbb-5f85-426c-9c05-f7ae174bc172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6261870c-ef0b-4587-ae7a-7f2d313d8db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85b683d-9ae6-4a6d-a79b-57f8d99cac3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046e30d9-e11d-415b-9a5c-c1223f6d59da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f50d55f7-f56d-479f-8b76-1bf57cb9bf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2d39a0-0498-451b-af50-7c2905b65696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b2888c-d623-481b-9a64-2cd6e4c4a11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c3ec7d-da31-4c7f-b204-627ab1b7f51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2eb08c7-af70-481a-ac12-85350e2b3220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf662b5-4d04-431a-9408-6794d9abd5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a991a2-107a-4882-9bca-388fdcf5cf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead3e285-8b28-4522-917c-200a8d1b8af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62041ecf-41b7-4774-b5ae-aea9b8f335fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b037433-e5cb-4be8-ace6-98388c3598a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674ca8d0-9c95-4121-9df1-b53533b7d75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf6ea069-216f-4b1c-94ec-f5b30b78d46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59005db3-b6da-4e66-ba17-2e848c2c2d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4857f13-83f4-40c8-b021-de8c8a7f55b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e86a5ef0-b784-4e36-88f1-44c3a98772f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83bcd447-2b37-4023-af8d-275637c09756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d4a802-befc-4215-b61d-a946a568fb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90d2158-8fe0-4ea2-9c16-d47a9855cdc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbf01dc-91b3-4304-88ec-aff238288f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff3efb7-ce23-4558-bedf-75d36aa88d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85354538-f5d2-4926-b126-94303728c741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fa1a6d-3d17-46ae-a5a9-2f8b91e2589d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd05341-1234-4c1c-a67f-6a8d7ac9f237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470de4e8-c9f3-45a5-a884-4b048ae12f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72741946-49da-490a-a2e0-1cf2389e887b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d169295d-925b-4666-9455-12c6cd9ffcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6480a8-1a42-4e49-bec3-4044afd9a88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3649729-8d5b-40d6-81f9-b434a9087ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc039aa-3ec9-4a4e-b4e6-6b9e51a2bd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66202ebe-55d4-42b1-9632-cbaaf7c6f2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d5a319-6307-4e1d-8ce9-b0da28da67b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0b473b-d5c6-4d8a-b447-a65c5851127b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da61c3a-fe5c-412d-9093-66c10e811e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485ab72e-9a51-46dd-b968-ae911e3fccda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916338ba-c3ad-4660-99a4-209590f83741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aabec27-fe45-4396-abaf-d76ef97af4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82d020a-a13c-4062-ab62-65df3315c41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa11f63-7585-409e-845a-5c7e4fd764c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90d4217-d066-477e-958d-18af31cedb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3135270-8c2e-4360-8eaf-3e78b0e502d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc6a769-aa78-415c-bc5a-a2b263fa92eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba601704-f919-4a12-ac29-6ed7bf069fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c4d8f8-6292-464e-82db-7c09754ee277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc9e9d3-4b95-46f4-8502-d6c867980e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c6ce04-d508-4412-8a55-fe004f920496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5039ac5-273a-4cee-93ed-f6b9cba3933b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d877f5d0-fe68-4ddc-b95f-46597b6da347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bd0afa-350b-4217-96fe-6cf25905595f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375110be-df6c-470e-825d-cc83999042c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905b2203-9fb8-4f85-9fc6-b2f9dd1bcb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7048ba02-2949-4d29-a6c3-a5ce3b8befde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eea689b-063f-4b44-88db-8978ed5ef224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90c600b-422e-4c5c-a8b3-47f48ab92a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb627b7a-0b0e-4a81-84f5-004cdabc76cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7986f5-ba85-4aa0-a6ba-a426b353a395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310a726d-d02a-4338-9733-a306554979ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1509b308-fbf1-4783-91c9-945d77f0ee3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d48d5be-40d6-4edf-b3f8-43541bd5480f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a97593-9df7-4071-b2d7-abc02f8f4a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e233fced-7606-420f-ac12-8a32e00c171e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ffe1c7-3583-4f40-a261-0719a564523a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3c656f-f133-40ef-8d7e-d5ca4d42782c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a441d645-23b0-42c0-b31f-480b54aa8f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb4fce1-cc31-45ed-a379-239cf7b71540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3423894-a3cf-41c2-a636-c23f856cc60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b9471a-1c69-4369-a3fe-9d7259b97e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813c3014-b7fb-48c9-8fa3-6ae525ea26f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 031f5ae3-cf63-46dc-ae1c-9a7cc32501bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c3d292-a891-45db-ad3c-b442f5950a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c236830a-9570-4129-b5e3-cefd99641f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb3b977-0343-48b3-8faf-17c10131d8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8eb9fda-2ee8-4fba-b04e-32d98fcd9d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f927bf-a07c-4e75-999b-f641e84caa2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f46890-2c0c-4dd7-84c7-945fe10584cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9eb74f-c90c-485e-afa2-2da6edfd01fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee3e7c6-1ea6-430b-9f1c-626381f5005c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e7a926-5b40-44cc-8b0f-72463584efd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9d1261-9f34-47e9-b1cf-d395ac53bbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5f28ff-3bc2-4c3a-9e19-9c70d99fc663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ab327a-ac45-48b1-a8fc-032676479419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ad9481-e72c-4095-9df9-f9b7c686bf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5cd2730-5731-40a8-9f36-860bb10d5cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2ff569-6cef-4f8a-92b7-5aa30146abd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58aa0df5-2a72-48ca-966b-79ce3fefd58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f9015d2-bbdd-4834-97f9-bf2809a80609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299d7034-034b-4ba0-ac46-ebe2fa563a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc0d5d3-adcb-4092-9bed-0ad9d1caff7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1c11bc-9be7-4386-9aa3-a654ac7fdba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a81409-2198-4726-820f-56de2efb9658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f42a07-0f82-4302-a5ba-22c7ad759b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5ba8f3-bc9b-40af-b808-11fb2f3786d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13db69c3-8390-484b-ad58-35b44215e792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9bef323-963c-4291-b946-9328bc89876d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7991a8fd-f334-402f-8feb-752bbe18ca26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e782a6f3-a99f-43bf-9272-534d0662429f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2d0811-11e3-4dd0-bb03-81966d8a1045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fbca159-7c27-4857-95cf-91ac6678045d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d940e1f-96bf-4b93-9517-5c5d6de4d317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c49d22-11d4-4ca9-8519-45272a089fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270493b1-3739-41a7-b287-1aa62885e5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c5a1a5-0cd7-4375-9325-b134ede6841c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e3069b-b500-4ac8-b189-961e19c0f0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be202ec3-39a2-4343-be21-1aae892d34e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630d9acf-97ed-41ee-80b5-58f750d0b4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04dd50d7-b6a5-48f1-80a8-155e8fc8aa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ce034f-9502-4504-b4bb-63bb17095079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b9ac7b3-7b17-4c6a-9545-d0bb2cc24954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a354efb-10c8-4117-8bbe-5f1a950283b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c014e31d-6fc2-47b5-9af3-7f2088504e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c2a748-8072-4324-8a1c-6811ab252ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64ab48a-b0e1-4965-9a5c-e5dd2649a91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05996d7c-64eb-4610-ac32-a6df09d35357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc89c257-7f8e-4e7b-b2d2-feb4eb6d88be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49775ae8-a7f2-4883-840f-14c6f0ca5049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2160a8-210b-4994-9a46-dbda45a78753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec00410-0780-4f2f-8ef1-56422fa54d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bd36eb-de1c-40a3-8dca-4ef5370e95f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba593f9-2eb7-4560-8e17-bd21465eee44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d66f25-6e9a-4f28-835e-92f7e96062a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fc91d5-acaa-465c-9458-81138992166d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f30abd1-222d-48e1-8b9b-2dec1225559f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245fa340-8ae5-41f1-a025-cbb70d2b4bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476183da-ad2e-4c89-965c-7d22116ea451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20d95df-34c0-4bfa-82c7-1e6d2f7c7781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ac3d14-91e0-48c0-8c33-9019764906d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c6c2f5-cbf6-4360-b7c8-bdc6bb910690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0bfb12-3686-478b-a08b-0cf80ee76756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92cc6bae-51ef-47f0-8b48-42dadcf8b687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1550070e-bd53-48ae-9eeb-2b3f9477567b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0209b309-ec0b-407e-a31e-fa47ff327e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd582d6b-81a2-4640-a76b-6aeaf5993462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1cc0e3-6f3e-4a0d-b63b-d9d850b8446d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab969a4-8596-4cac-82e9-d096dac491a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d3f823-5548-4f2a-9690-abd4dba05e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55b67c4c-7cee-4194-bfdb-572cdd66d63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac2eb50-88d4-4b6f-bc06-e261366e2503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24ded87-f99f-4a88-8595-840cd45d9100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e599f15-89ab-43ff-b331-b2e4ac8d3e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814d5eb5-a210-45fd-a0fd-73909b7d9559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce6e2f3-3ff3-4f44-9e25-55c7a2b0efcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f07564-cd3c-4cc0-a025-b895e35ed001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26205540-c171-441d-9e37-d357f926fef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4209c96-aac2-4e1c-9d35-7e54b6ac16c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b13334-1dfa-43cc-b0db-272e49e4109e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6336b4-4890-4ea6-affa-ca80a4e04f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68f66bb-c8b5-4c86-b3e6-2d57494740cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5ff9f5-f8fd-4856-bf86-639431aef274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1262b15d-327c-4f53-a70a-31f8d67695f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a979ed-fc3b-44fc-a265-05ccaaabe74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be282499-6539-43a1-89b7-c64baa1b9542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0beed6a3-f75f-42c1-96f9-4eaa41befca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e365a4-494a-4fd2-b289-161e11d5b57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f88f64-2f64-4284-92a1-e96a993de778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6270d15c-ea87-422c-9ebf-eb2f9c79ea26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d863402-e1cf-4a67-8741-bf2d6ca7d717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3209cd2d-b921-4bfc-b301-67a9f98d3a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60e18ca-dfbc-45a6-b022-cc7e4c5bd95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bfbc8d-e9b2-49db-9640-08abae7889cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9cec49-89c3-4f6f-afb2-91b0ac22d408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51811c8-488b-4ea5-936c-7cee24b698c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567536c0-b8cb-4e22-bb84-956f83557e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e23012-3816-4f6b-8d40-5aff508421c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b72028-48e1-4635-93d0-5954e39ce6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd11bb84-6244-49b4-a239-050111ee8a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb1bbc8-5e11-451d-97ba-8387140ea5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20881701-a02c-4376-9588-78d47779800a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7811fa34-edf9-4f2a-9540-86979b4ea84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0957e75c-ccdf-4e3d-98ea-5b57b843d889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e075b515-1f38-4265-96de-3e00a0d3d355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6e076b-63ea-4d16-aa2f-cded0ca5f2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da77e6e5-3cad-4bdb-b000-da316f1a4209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0df31d-ebf5-4cd9-ac87-8bdb3f8e6014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f7120f-efbc-44c6-b384-6f3d1ccf0ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8faee0-5da5-4efd-9326-0c4c278b335d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9391501-6807-4f24-aa25-453183f709f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4604b17-8a08-4504-889a-b92acde13a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9162b2b0-e6a8-48e0-aa06-091259fbf748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f486ab-6f3b-45bb-834f-85c213fa1d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddb9114-c0fe-43bc-81cb-1842686f6074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768cf441-83db-4b42-b305-8c3237e67922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9660a813-0e50-4b33-9df2-a4534a298913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46544e29-274f-46a6-8012-e510b2d8a8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2cbc413-8515-457a-9972-e5693d2e4bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e820b04b-1c28-495f-96ec-557ead1db3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7512869-63af-4df4-b691-1717c9b88082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2495383e-954e-4787-8362-dbb47b63183f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df499f8-4cfe-4dea-b7a5-948b8a01228b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae35d7f-ec85-492f-9b60-48e2910b46c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0968df24-60ea-4f52-878e-a92d0d4b6c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3955976-de6f-47a6-9b50-f123e9cb995a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662fa14f-d84c-45c1-b21f-419a672a041a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b50f7892-86c2-40c0-9396-caffae3cb9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc94b40b-70d7-4fda-b8a2-4cd674f5724b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b2821dc-3a20-4676-9e2e-30d6aaf9745c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188c8de7-f521-4c7c-b896-ac78af9b082e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7658b0a0-7d65-46c3-b4e7-c084805dd1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d7c641-9fd6-4e84-9e1a-97e993a74242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93686d6f-b97a-4299-b4a3-db67435092ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42cc154-4282-4844-a854-2e3ef0ecaf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e374b60-4b9b-4e82-a2aa-8890461dd48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5dbdfe-2910-4551-8e63-a6b8f012fdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73ae187-050c-432b-904a-8e944f1d4bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc97f17-06d5-4651-bdd7-ef63b4e204e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed58fe13-4fbe-4a1a-a1d5-a2819d5eb286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c0f7d2-a5ad-47da-8ff5-5131f70d6fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cb8814-4e61-4fcd-a29c-592c26d01f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5839c3-640b-4c74-89d3-8240e50a3abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31a12c5-d37a-402e-b966-f85e8094b10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761d6a10-c303-4666-9020-be6cfaf58781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171f8039-a805-4f82-b34f-fe296c441690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259fa940-4094-45a7-a793-e584fb517660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec31dda0-2d62-4afd-bdc4-4f743c108f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe23539-d493-4adc-bc08-871d05431101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e3cc66-8468-4835-9a06-11d3fe061bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93628129-ec3c-4f9a-a4fe-82cddbaddc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ce35b5-8d95-49cb-b1ff-63ad3031e606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4825742-6060-4341-8147-ad1c1631a1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c65203f-3d72-4790-bc33-f777b8643cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676a1d28-5180-489b-afa9-964ea9b746c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3bf729-8d6f-4ebd-bb2f-983dd774531d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1532bc8f-a027-47b5-bd13-1e041fe8b079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa2efd0-ea72-4f91-badc-227640ad8cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9296a20f-3100-4a87-af3f-e0bb376ae48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011fe4c4-4c27-4433-9b98-f90fdc7b01de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a206a3ec-f6cf-4e76-abc9-f9b53c049ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19fc691-1e69-4fd2-b17d-19082bef4dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f45aa6f1-8dd3-4c53-bc6e-b60e3877eda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8bd79e0-d6b9-436e-8aed-98e252ea1ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a02925-4efa-4945-9a6a-f8322a0c788d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e498909b-517b-4103-9ae4-b721fad47fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b252862-a53e-4e9a-ab37-145a0f820aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62331319-0f3b-4c05-9a90-3aa36e26dca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b98a0e-aba5-4ca7-b47a-2859b228200e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3235185-6b96-4cac-8cfb-4b8cc35073dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8067c6-acb1-4cd6-8c14-866e97b267ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5996de70-7937-45fa-8bd2-d31c6220dea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db944c6d-ae71-4353-ba98-b8c9608a08bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92374948-b31b-495c-8bf8-a1fad077573a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46fdf680-d21b-481b-8be4-505bb25029b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb46ab2-f527-4a7e-8d2a-157705754bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e39290a-a332-4b08-a5e4-3ae85084f421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631e32c7-3e93-473d-8ae9-6bb774d814ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f06f261-3590-42f4-9be0-6912852efa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dedf0805-7bc8-4768-9a4b-bc83273ae953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dfc20a-8a33-4bbd-be95-7fe4e2ffc52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2704ca9-830d-4737-8add-faa1d5dc13e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6bd11f9-4ff4-4f37-a835-714bc5392c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54046bd-0cbc-4acb-85ff-330d5d105692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f916bbe1-910f-40f7-b2bb-19e97af8e19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e58a2a-1846-4f3d-9af5-1ace85429bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcceedbb-606f-41ae-8edd-c20b6448cea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08de5195-e568-4500-8d54-c694e3965526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4110d3-1cda-47df-9adc-865d33abb342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a4477b-7269-435a-bf31-95acd5da9835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25dc5466-29e5-4835-9772-64227fb6be8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f24b9b-1c4e-4690-b5c1-0b322ac7f1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c177d5-24eb-4a42-b744-09e2ce574652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a19ccf5-02ed-41fc-8385-be68ed61ff38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb8bfee7-6009-40f6-bf9d-6b4117bd8c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e5bce89-392f-4c54-a242-dd6766a62fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27d6aef-e0d4-44d1-9e1b-c7706bf348f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e69e957b-b7b6-4fb8-b991-e890fc65cbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1923183b-69a5-4639-9095-d9eb14b2a8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8831aa67-1253-47a8-aa84-279976bf2402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0dfed2-8bf6-4664-85ef-8eaa797290b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170e33e9-3763-43b3-aa66-653c50ef41c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56b4490-6696-4881-bdc5-77e9ddf949c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4b35f7-a72f-4eb7-b642-69669dd511df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65cf712f-cde8-4977-ab48-1347a9615680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a49a97b-00f1-46c1-9c38-19d82997d37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d98c448-e137-4991-b2a6-3abe3fb41e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d1f15a-20d8-42b0-ba6e-008102a27b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a04bc15c-6973-4341-8d8e-e2655e4e03be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b0845f-f30a-4375-9068-d16ebd930e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0454057-ca77-4426-9e39-b08353eb4cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a663aa81-62f4-4c71-9b34-674f4d9ed5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2ee885-81ba-42b1-ac00-319f175e275f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a21ff54-6731-4895-9839-17daa4b7df72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c97321-361a-4d90-81de-d617176f08af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93069730-d57e-41b0-a2cd-d021a0577fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c70810-a96a-4ccd-9e41-ab63d58925ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6042f583-824c-4487-a698-3e505fb36273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4156871-5819-4281-a469-7cd5b7b954ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70806732-9727-4c67-bae4-88a2b1ce3b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24934088-dc30-4f92-8f30-08487874cb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2d1ea2-6de0-4c85-918f-3b594142324a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e513a7f-578d-4cd1-85b8-dbf64da994b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b6f10a-6fe0-4bda-9b94-68bd2aca2267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d9842f-6386-4a0c-816a-01d748c07970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98929cb7-bb5f-4cbf-8c8d-17eae7ceffbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b75efa2-5e16-4b50-927f-18d536196f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a255d7-d781-431c-82a3-0530f1fdd536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28a4fec-19da-44c4-a048-97d6ea4b1825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c661f3bb-3882-462a-8117-440f9730b26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf00d000-be78-42f5-bcba-00e3035e5f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af8ed92-fce7-4a28-a446-60630a8ee184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6627fa1f-6207-4d83-b070-413006e761ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9e5c4f-fe49-48fd-9866-85c5d77905bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef3af70-4f1f-4e65-8bc3-a8af74d99049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afad3f9a-d969-4533-b25e-986c83a87810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53ba239-fc3b-42ee-9497-6e751648292a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a270806-0550-494e-ad80-64c81a6e32c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90aaa82-1506-41f9-9c12-66f85d8db64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7968b509-ea5f-4856-abe2-d2fae84465a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f666c6-61e9-4056-a607-22d82a3ed393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d232dfdf-82a4-485d-ad70-1972d3395fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545e1afa-2964-4a8e-8c9c-1b6486266cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ce88e0-02e2-4d16-b6c5-951ee62aba1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bf3832-4209-47a5-a28b-b21bde117829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f8caa9-3616-4a2e-b374-05e8f18b94e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276f8602-0101-4b0b-982d-e7b624df10ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de19e16-01b4-45f1-b4b0-312edd654982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d0a583-e525-4f7a-87e3-22efe12f6547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c66043-86de-4cdb-8267-7bf6a4a9b078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688b6bd7-cd10-4205-ad4b-d34ecdb0d7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7654e530-d417-4976-b593-b44213176fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e2f12f-8dae-4814-8f4c-c487bbe8afe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58b9d8c-8ee2-45a8-88ba-028834488084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7cd2177-a81e-4f00-9502-326c88913bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e1d2da-a1fb-4f73-a358-ed5b0f254763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f91d42-eff7-4dee-afe6-930078465cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752be099-c87e-41dc-97df-62b86208ccf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7748799-6ff9-44e2-a7c1-8484eecbc129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59e068c-317c-4332-996f-9be98d957e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea989a7c-eba8-4c6a-9182-2e49d46d838f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a5d31d-a43e-4997-9c21-f704c6f0810a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e65c7ff-b2a7-4512-8d03-39f7b340a69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58492c83-104c-498c-b437-730d725db0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9958f7e-2532-41dc-9f04-d318afbae103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d71089b-e0ad-4604-a059-a5d7e5efb4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547b7578-8e2f-4ba3-adac-49c784c48e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7026f7c3-d07e-40d6-89a7-76b6eccf68ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd679282-1fbb-429e-97b7-04a55fd65eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80241bd-a9ac-47a9-822c-0032ffdcab82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6a89bb-46ef-4d0a-8796-d4d17749f9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d670720c-6b0e-408f-932f-afd954713458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591709d8-625a-4354-a44f-7d44954ee533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e0c0772-222c-48b7-bc64-823705f193b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5383071b-20a8-4ff6-8208-b7f4df212654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e725146-2c0d-49cd-b6ae-f5e8cf18d803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d547093c-5d1d-4a40-8016-e6c199ad270d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2fe04c-a685-4dd3-b5ea-88ce3385cff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39c5c67c-0971-4d8d-8b23-ae2c5a7cac01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6885d50a-23eb-495b-b80c-d50a0181be56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81fa8c01-c1b1-45d5-8e35-b846331695cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6f512b-4697-4598-8c6e-c54bb3bcc008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c77447-7677-4f69-9e1e-873c3e659ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06aa3c53-3101-4448-97c2-9d9ca6f2069a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570c9dcf-23ce-49f4-b730-cd0920b710ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f76843-6b64-4993-98bf-99804c7f1887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5583e285-e0b3-4048-b528-e6bf9d8540dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2b79e8-d3fd-4f5c-929e-e38e0650219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58a4ff9-3379-4058-815a-effe2898714c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab0d1df-2fc2-463a-879f-2c040f03739e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0874ebc0-6bb6-409e-b6bd-862b946c2173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193fd243-7a47-4891-994e-4f32e0be9f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f94add-538c-4aa4-9d5a-3f6a75076ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42a1b4e-40aa-4f0e-b86b-973d11664b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0dd212-8b7a-4ffb-94ac-481c10d7bb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1836ac85-c12c-4dfd-9a6a-9d5cacc9d338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b85108-c7b1-4e5a-bd8f-97ec53ae9c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e516b9-7b2a-4b7f-972d-26163e3824d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9658b0-1cd7-4066-ae5a-b415b18b275e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abafdeb7-83f8-4a9e-b490-fa8cfdf976df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bdfcfd9-1e02-4110-a384-693aec4e50ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df0e41b-5b4e-4756-a4a7-1c1a65ee217d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e507c5b-9ed2-4992-8252-3daa5327692f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9836ee89-27f9-4292-ba0a-d897a85b5e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f016e2-9e10-4867-a4b1-07745bec66c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b8a819-5e73-4087-b6dc-a71bf9f96101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016ac75d-e769-4382-beea-34d8f207437d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87253a7c-930a-4ad6-87cc-f51c0bb1f4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a46bd8bd-38a2-4a19-953b-50e8945bc2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b46ead-ba28-4d0e-8190-d914e32663f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deeb1aa3-9bdc-4531-800f-ec8340f6026a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 099d036b-c50b-4e97-b562-a1c60e92778a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b982fb5a-521b-4dbc-ac18-97182d8f0e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62b9ef1-69e5-4e49-b52f-e23f13445d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c76c1c3-c103-4e17-9099-cdb005577bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73390b3-7803-47b7-a0f8-c188d955ea15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e82b501d-4516-43c0-85dd-0e546de97367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72b4faf-ab5c-41fb-a0e2-435572b7f025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae4fbaab-e43a-4224-9a2e-138626991bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b8e0aeb-59ef-4f19-9cda-db68bd5332c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a935be5-e2e4-4c45-82ec-c1e3f02c7b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59e0350-11bf-47e2-b471-dc872cf30a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92190895-4046-4eda-8317-911811577916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84636273-37ca-40ed-96c4-9fdf4dcd47ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e9dfa1-dbf4-4657-9bc0-9f724f62d89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18c8a354-bc00-4f53-a419-8edad101aa12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886bef41-6827-4a2a-b46d-1fff2808c037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f16f75a-3470-453e-97d4-8db60ca91afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45562f7c-acc1-4579-b04b-2b5e65857a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63a78ac-cc1d-447f-8e7e-240a328ae323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ff1248-fb68-4dc7-b037-d26be207ca37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d6c5bf-5992-4583-8709-8834a519074a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77d882a-1940-481e-9721-602c90ece1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62c2cc5-c6d8-4544-8e6a-e5013e600e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9422129-51cc-4b14-9f05-3e052db07546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe5bf34-d1f8-452c-93fe-20cb6dc495a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bce5140-037f-44cc-904b-51c8c59aa9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4010f359-0360-4296-9a1e-ac7d2e043904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01d5631-2158-45df-8b34-30da3e0f5558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee11e35d-d0e9-4850-9225-cba441e3a080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bcc07d-1ffd-4edf-bc06-463409932419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5a59d5-3e59-4145-be32-dc873b8874e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cd39b3-3e8c-4565-bac5-e0bb4ceffcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bcd5c0e-218a-4dbb-83ce-ff327523064c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f77fc79-1fdf-422d-bee0-98700ffc6ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b112ea8-b68b-4ff9-b694-b485bef38c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b4e4a8-a26f-4bcc-8779-45211b7976eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f044352-55a7-4a53-9399-918708fab309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 392e0b6f-8192-4f63-acc9-c578bb67d0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74b8d1e-9d74-46aa-97aa-16c3fd339ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1497b97-38f2-49ea-88b2-ef6a10e50e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f1fd00-3ab1-4d8f-82ff-ac8acd51d9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbc1961-dec7-4421-aff4-9070378e0805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8183f102-ab17-4095-9bc4-8614a830e912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12dd5310-7c0f-4bc5-acf3-f10087ae13b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288ce053-e98b-4abb-ab0e-73eefa17102c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a40698d-3f8b-4d4a-b238-17e9c2a249d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe3c9a9-4d13-4cca-a82c-9c3ca41c6271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15b7662-eeae-4ab8-933e-d22b45717307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30035733-16cd-45df-a8bc-a789e8628bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced3e5fc-1198-4d2f-a73f-6fdb5c7390bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a855f64-3600-4748-a14a-b3d0575d39a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2f6f94-5bc5-406e-aec6-a984075ec8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca37d0f9-8a2d-40e1-8b21-5ae33a994011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3335acf2-875f-4318-8511-b8f4cb0617ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 351d5f07-9ec6-4f09-b4d1-80a566a6db63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06393d8e-ac3a-4ca7-901e-d5c7dbb8ba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e432d87a-b156-44fa-a730-1934a5d6d977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5666c28-03b6-4845-a7ad-6b7fbb13f72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d800916-c9b0-4c67-95e8-4aa682ee35ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4740f1-71f1-41eb-8769-0adde24710d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be821005-e6f4-485b-8e5c-6d74c5eb0a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04016a71-dc1d-4474-9e0d-7bc1eeb0c7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fefd96-60b5-4d9a-a16c-65a3e5e51bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816f3cc5-8898-4112-8cb2-40bfb298980f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c02f44-99ee-4a59-a84f-53057db10362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6bd9675-4d7e-453a-b128-0739bdfb3d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4f4b20-5d92-42ef-8534-f41e571b4b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99789b9c-fe31-42de-9288-4dd01df6bd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d98d83-564e-4131-9b01-edcbce4b5669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2f3d5f-8454-474e-8312-b041420b4c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dfbe60-9877-4faf-a0ec-cda83db3e04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29db6b61-6ada-4bcc-ae22-a2b98c4f96db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cf4dbb-39d3-4406-b50c-c401c8c86ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a1cc81-beb8-43f7-9b61-58141c0bd773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f490efe6-16b4-485d-9d50-8534504ead03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536659aa-12c7-4caf-a9ab-6a4a2a22914b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda5c824-0f93-4354-a397-4f476b015b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ef7f83-1d60-48bc-8cff-a5c81879728b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32d1ee5-0a56-487b-b015-c5aa611ea1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f922f4ca-43d7-4ff5-b0cc-50daefab6d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f79f0a5-18c0-49f0-8da0-f441cad34973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c67558-78ae-4ce6-b149-f513a21d2388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5618476b-8358-48e9-98af-f988968be748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2aea3ed-5f4f-4c2f-8210-32d8b4b1f669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de7deaf-b870-446f-9ff7-70b45422765d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011c0a6e-b730-4762-9456-ad877daa3dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4f6f82-b710-4dda-9b62-f829cf270e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95100fc-8316-43f3-b63c-67b60525a185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f6e641-7705-40d6-97f3-b52ff17b4358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08aa2c7e-7c6e-4abb-b1c7-dddaa264b2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdfd56df-953f-45c2-977d-411db056733b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f72b7b-226c-4479-bb10-d63ecd820083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6685801-1403-41d4-9755-7eeb584528fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad64306b-5e6e-49c1-97fd-9810f20bc308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485408d8-034c-48fb-8a6b-16fe3df0a726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90d7783-5f9e-46e8-8875-25b07bbb3bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a5cbd8-fc13-4303-97c8-d820d8633555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64ff782-0c8d-4319-8b51-7fa9ee543ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27a3109-91aa-4945-b23d-aedd5c87ca0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe71395-4bc5-42a4-9341-2f3e50a92c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b942cae-1e3c-490a-a8bd-c1f0e7582b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25eade4c-e4cf-4211-a50a-0939fd86df58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7239d9a8-07a3-476f-9020-2850c7500e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0885953e-3c48-4fce-a33f-ce907496be21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5dcb423-d494-497e-a334-bf7ece5117ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd806cc-7257-489e-b462-6a5fb8c7ea5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7064d50-faa9-48c4-b9a9-6ff85b8c11de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8f3e62-d5d2-4b22-b92c-d0f8abb2ad38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464775cd-c823-4e74-a8a1-d7ea61809226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2c347d-a9a8-4a21-a2a5-62960580253d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 829581d8-699f-4320-920b-745ce115d62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fab5d42-9b64-4ab1-860c-30eeb3a3c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af528425-f205-46e3-8fc9-a8f5895fa9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2d164d-22b4-4d06-a769-2e6fe40ccd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8c8033-30a6-4d79-a5df-bde23d7f9413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f435aa-05f4-426b-98e8-9d87fdf969c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4191781-efd9-4db7-8217-84a1cc469d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f85103a-e3fe-431a-ad9e-5be125bf8bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc49690-67d2-4019-b885-08224c6d6131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b964fa-f4f1-491d-a867-358b9f0a871a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e41012c-37bc-4a49-bd8d-b8bb7fed1fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263c8fdb-585f-4bfb-b433-becff5b9234c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df653fbe-27ee-4d6d-8a15-dc7ade47a949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e9c9ad-156b-4131-ba3e-ddbe2415ea6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6062245c-dbd7-4d6e-acff-2da62acee30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ef852b-5c5c-44d5-ac68-8819775b269a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed65904d-28b8-4c62-910f-e785fff4270d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d4a9ef-1962-4af5-ab8b-d953ebb1b2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9eee77-ebde-4271-aa08-4e486f222434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab29fd21-6e6e-47ab-bb1d-abdd6642abc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a21eaa0-87ea-4ab0-9153-dcad5e42bf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e860c50-b8af-47b4-a0d1-4899822160b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c15c7a21-e314-4dee-9cf9-f7337702a928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbd1122-7d20-4ac8-ae46-23c16c5aa841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce70f4c-e302-4b0e-b43f-a876b473128f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fce77a-b5d8-431b-bfd7-780f7c25f202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495a93e0-b4e7-4901-9d73-d0a8e843b51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35bf1911-527d-4d13-8eb7-9da0b4ec59ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f96e77b-9e08-4ee1-96d0-f43e7314c8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc83a62b-aa3d-4e33-9367-d22f735d5d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7541f31-ccae-439a-b7d0-001e9dac5ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4a33fd-de85-44ff-b550-7f6874705d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05071cd5-6269-4b90-9d63-92f4c80cde46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94663a2-27eb-4881-825c-77bdf3da442f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54326de2-04d6-4ba1-971e-d206a20f2c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aeb6c82-eff1-426d-b0e1-0692007f391d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d20bd509-c8a0-4559-b13f-6d5fa781bef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbff83d-1541-4cf6-a932-4f678685d0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8ff4ae-bd90-4757-adcf-e6cbba700397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9267a819-38fc-42a0-8333-3e94c86c2ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d59c2b6-cde6-4d82-946b-b7687000e01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4144741f-8c31-45d0-a4cd-1c84eee7ff5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233a613b-b0f7-4ed4-999e-ddfffba34bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ff355a-9e89-4dc2-bfa0-e8bfcf14391b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535b480a-dcfe-4ed0-a776-9da903b3f850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acd3d35-fd44-40d3-90ea-a81ea7e87657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca29a58-7b0c-4076-987e-8006d8be4b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae91560-c42e-4070-9033-af447f5f97d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520978d8-fe9e-4e07-a792-714391e306a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48a6a9d-5157-4265-a80c-553e186c5d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb293610-be9d-4aef-95ba-6af07ad72efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657d01f8-a225-45bc-8989-0c77034b9c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c4ca79-c7b8-4481-b309-c1cbf158b183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b617aa9f-a832-4294-927f-ed5fb58d83db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae4c1cf-ca08-4e62-b791-25049f65e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75f8679d-dc27-49aa-ae89-ddee1b8b6202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdc3b52-c3c6-477a-9442-a4942e0a592f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269b3488-4fd9-4278-8551-440979db0963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39080222-d9b2-442d-8c62-1a0a406a083a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd44e40-0b63-4d9d-b22f-7d5995b8aa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec1dd0f-cc2d-42e7-b275-14527d354223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ccbb4db-d602-4bcf-af91-0d0f5618ba01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06afd1dc-f711-44c3-a98c-a71a13f1cda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53da639-ccd1-4c4c-8476-bb00eabbe78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65ad948-f3f7-49f0-956d-e34b318cb50f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c072f75-dcf1-40a4-a9a5-282550b9b75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9885b9a0-3d36-4108-8d54-03a532d2ed16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77eaa9db-1feb-4771-b2ef-abe64466c7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3acb1cba-8f5c-4a35-9034-a154c0cbf664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe6f862-0193-438a-9856-50f17d14ce72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f02684b-c8be-4360-ad4d-d3eae48f5504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4bcde38-dabb-4398-9019-7703a4148bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca202574-5d05-4076-b752-21967022a624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bdf05d-6e44-477e-ab2e-23ce515e6c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27083228-c2c9-4a5f-a86e-525e0b37836d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49178c2c-90d7-4cf7-8566-a2e4c2f92fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81b8e9c-8ff6-478b-8a31-c879a45149b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aebbf74-1e8c-480b-970e-4d7a4107cbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a982122-b672-4d0f-8295-abd63b32cf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba63256-2381-45d6-8627-27a0db78d788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633c7918-b8f8-4f1d-b675-42b0198c5736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f0c9ad-356a-4808-84d4-3be644e5e583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cca16ae-e891-4a75-90bc-2298c5a8ec61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212e543f-fc1c-4b4d-852f-1c0e22fbd5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec5937c-8b5c-4124-9f24-b795cf27e427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05245992-13e3-40cc-8057-4e166c901a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b5eed7a-7478-472b-b28e-61d405a36dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b234f24f-a46f-443a-be78-e17003606c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bf98c5-0021-421e-815e-f929a5d32e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb291344-d89b-4b25-8f10-fbd75bc7a24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b3e8ec-7748-44aa-b863-9841f84f19d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b48476-db31-49b8-b4dc-d10ae3aa847a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b47b1b-2ed5-466e-a94f-da295b0ff292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7934b5cf-c792-4a33-bd88-0b1cdabfc63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367a5b96-2d51-40ae-b311-8b5a69ba7bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28201236-c054-4527-b3e6-14c24d72dc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12077670-975e-4b57-a409-1f1b502938b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f619401e-ec83-474e-82b9-55aca59b522f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0cf35cb-fc45-427f-8c1a-cb2ebda4f3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1603522-c533-45f0-8886-d6cb295928d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db0439f-9f57-4d5c-a69a-fb30058614a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc1adc7-df17-44e0-8055-9f7f1fc804cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b488706-67ca-4985-9853-07b7434f16c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f039a0a8-2905-4f39-96e2-8ab4faf81689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d89e2e-7c03-45cf-8c4f-91bca41fde27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e31f6ac5-fe44-4e18-bf17-330888db6f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b96d5e-ad03-4d21-821d-b1243c6b1310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9d69c4-6af0-4296-b930-202d5fdc7170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b57382-56c5-4af4-8ffa-4474ea632094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff8d0a93-57a2-4741-934c-1b764fdd4834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5dac6c5-5215-4374-8c73-86c381f08327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140e9d7c-345d-4bb4-a913-9e61b0cac265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcde5a3f-0ee1-420f-990b-caee418cf279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44df1dff-dd83-4716-a7b0-a82decece365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc445e7d-b6cc-4886-9179-71b1cf91d41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a791ba1-9525-45e6-8c0f-d598a1d2a45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b71db6-9bde-4aed-9390-b3e2b77c8a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9bef1d-3fd1-49ab-b26b-bb66e43bbefd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bba036-5835-415a-92af-daa20a091f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f211fd34-59c4-4f9e-a46a-8d8aaac1ad37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e045df3a-486c-4dcb-a8b8-065893ade714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4688b3c7-433b-44a8-b32d-1c9f2a16e169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4b6872-504c-482d-aa75-5a83b28dfd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9583d3-5420-4d6d-9c20-fcbdc32ce323
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_19
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_19
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_19/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_19/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_19/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_19/test_labels.txt

📊 Raw data loaded:
   Train: X=(3776, 24), y=(3776,)
   Test:  X=(944, 24), y=(944,)

⚠️  Limiting training data: 3776 → 800 samples
⚠️  Limiting test data: 944 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_19 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3886, val=0.1517 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1031, val=0.0817 (↓), lr=0.001000
   • Epoch   3/100: train=0.0854, val=0.0867, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0822, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0832, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0832, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 1 Summary - Client client_19
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0443
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0015
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.5095, RMSE: 0.7138, MAE: 0.6537, R²: -5.2046

📊 Round 1 Test Metrics:
   Loss: 0.5011, RMSE: 0.7079, MAE: 0.6472, R²: -5.1017

============================================================
🔄 Round 4 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4668, val=0.3936 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3622, val=0.2922 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2284, val=0.1235 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0939, val=0.0880 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0848, val=0.0813 (↓), lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0829, val=0.0823, patience=6/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 4 Summary - Client client_19
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0049
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0054
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.4907, RMSE: 0.7005, MAE: 0.6391, R²: -4.9753

📊 Round 4 Test Metrics:
   Loss: 0.4845, RMSE: 0.6961, MAE: 0.6343, R²: -4.9002

============================================================
🔄 Round 10 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4453, val=0.4783 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4019, val=0.4333 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3627, val=0.3938 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3263, val=0.3534 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2855, val=0.3043 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0930, val=0.1076 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   ✓ Epoch  21/100: train=0.0806, val=0.0925 (↓), lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0806, val=0.0923, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 10 Summary - Client client_19
   Epochs: 36/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0134
============================================================


============================================================
🔄 Round 11 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4615, val=0.4531 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.4582, val=0.4497 (↓), lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   ✓ Epoch   3/100: train=0.4548, val=0.4464 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.4524, val=0.4450 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.4509, val=0.4436 (↓), lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   ✓ Epoch  11/100: train=0.4436, val=0.4365 (↓), lr=0.000001
   • Epoch  21/100: train=0.4382, val=0.4315, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4336, val=0.4271, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4294, val=0.4229, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4253, val=0.4189, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4214, val=0.4150, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4175, val=0.4112, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4136, val=0.4074, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4098, val=0.4036, patience=1/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.4067, RMSE=0.6378, R²=-3.9494
   Val:   Loss=0.4001, RMSE=0.6326, R²=-3.6367
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.4414, RMSE: 0.6643, MAE: 0.5993, R²: -4.3744

============================================================
🔄 Round 15 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3796, val=0.4229 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3791, val=0.4223 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3786, val=0.4218 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3781, val=0.4213 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3777, val=0.4207 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3747, val=0.4176 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3698, val=0.4124 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3650, val=0.4072 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3602, val=0.4021 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3554, val=0.3969 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3506, val=0.3918 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3457, val=0.3866 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3409, val=0.3814 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3360, val=0.3762 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3312, RMSE=0.5755, R²=-2.9928
   Val:   Loss=0.3714, RMSE=0.6094, R²=-3.5263
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3027, RMSE: 0.5502, MAE: 0.4702, R²: -2.6860

============================================================
🔄 Round 18 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3156, val=0.2954 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3150, val=0.2948 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3144, val=0.2942 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3137, val=0.2936 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3131, val=0.2930 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3092, val=0.2893 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3028, val=0.2832 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2964, val=0.2771 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2900, val=0.2710 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2835, val=0.2648 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2769, val=0.2585 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2702, val=0.2521 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2634, val=0.2456 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2565, val=0.2391 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2497, RMSE=0.4997, R²=-2.0046
   Val:   Loss=0.2331, RMSE=0.4828, R²=-1.8333
============================================================


============================================================
🔄 Round 19 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2762, val=0.3166 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2756, val=0.3160 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2751, val=0.3154 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2746, val=0.3149 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2740, val=0.3143 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2708, val=0.3107 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2653, val=0.3047 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2596, val=0.2984 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2537, val=0.2919 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2476, val=0.2852 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2414, val=0.2784 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2350, val=0.2713 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2285, val=0.2642 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2220, val=0.2569 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2150, RMSE=0.4637, R²=-1.6216
   Val:   Loss=0.2503, RMSE=0.5003, R²=-1.9202
============================================================


============================================================
🔄 Round 20 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2480, val=0.2396 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2474, val=0.2390 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2467, val=0.2384 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2461, val=0.2377 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2454, val=0.2371 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2414, val=0.2334 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2348, val=0.2271 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2280, val=0.2207 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2211, val=0.2143 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2142, val=0.2078 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2073, val=0.2013 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2004, val=0.1948 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1934, val=0.1883 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1865, val=0.1819 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1805, RMSE=0.4249, R²=-1.2336
   Val:   Loss=0.1762, RMSE=0.4197, R²=-0.9301
============================================================


============================================================
🔄 Round 21 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2044, val=0.2318 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2038, val=0.2311 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2032, val=0.2304 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2025, val=0.2297 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2019, val=0.2290 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1981, val=0.2247 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1917, val=0.2175 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1853, val=0.2103 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1789, val=0.2031 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1726, val=0.1959 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1664, val=0.1887 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1602, val=0.1817 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1542, val=0.1747 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1483, val=0.1679 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1429, RMSE=0.3780, R²=-0.7164
   Val:   Loss=0.1619, RMSE=0.4024, R²=-1.0023
============================================================


============================================================
🔄 Round 22 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1822, val=0.1664 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1816, val=0.1657 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1809, val=0.1651 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1802, val=0.1644 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1795, val=0.1638 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1753, val=0.1598 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1686, val=0.1534 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1620, val=0.1472 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1557, val=0.1412 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1495, val=0.1354 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1436, val=0.1299 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1380, val=0.1246 (↓), lr=0.000001
   • Epoch  81/100: train=0.1326, val=0.1196, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1275, val=0.1149, patience=1/15, lr=0.000001

============================================================
📊 Round 22 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1229, RMSE=0.3506, R²=-0.4610
   Val:   Loss=0.1109, RMSE=0.3330, R²=-0.4144
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.1428, RMSE: 0.3779, MAE: 0.3111, R²: -0.7393

============================================================
🔄 Round 23 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1453, val=0.1566 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1447, val=0.1559 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1441, val=0.1552 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1435, val=0.1546 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1429, val=0.1539 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1393, val=0.1501 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1336, val=0.1440 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1282, val=0.1382 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1232, val=0.1327 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1185, val=0.1276 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1141, val=0.1228 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1100, val=0.1183 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1063, val=0.1142 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1029, val=0.1104 (↓), lr=0.000001

============================================================
📊 Round 23 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0999, RMSE=0.3160, R²=-0.2082
   Val:   Loss=0.1073, RMSE=0.3276, R²=-0.2752
============================================================


============================================================
🔄 Round 24 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1182, val=0.1226 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1178, val=0.1220 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1173, val=0.1214 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1168, val=0.1208 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1163, val=0.1203 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1136, val=0.1170 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1093, val=0.1119 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1056, val=0.1073 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1023, val=0.1032 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0993, val=0.0995 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0968, val=0.0962 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0945, val=0.0933 (↓), lr=0.000001
   • Epoch  81/100: train=0.0926, val=0.0907, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0909, val=0.0884 (↓), lr=0.000001

============================================================
📊 Round 24 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0619
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.1446
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0951, RMSE: 0.3083, MAE: 0.2623, R²: -0.1577

============================================================
🔄 Round 25 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1001, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0998, val=0.0868, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.0995, val=0.0865 (↓), lr=0.000001
   • Epoch   4/100: train=0.0991, val=0.0862, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0988, val=0.0859 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.0970, val=0.0842 (↓), lr=0.000001
   • Epoch  21/100: train=0.0944, val=0.0819, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0924, val=0.0801 (↓), lr=0.000001
   • Epoch  41/100: train=0.0907, val=0.0786, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0893, val=0.0774, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0882, val=0.0766, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0874, val=0.0759, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0867, val=0.0754, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.0862, val=0.0750, patience=4/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_19
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0078
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0061
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2480, R²: -0.0059

============================================================
🔄 Round 33 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 33 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0152
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0095
============================================================


============================================================
🔄 Round 34 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 34 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0104
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0013
============================================================


============================================================
🔄 Round 36 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 36 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0094
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0025
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: -0.0044

📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: -0.0042

============================================================
🔄 Round 39 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 39 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0123
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0026
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2478, R²: -0.0040

============================================================
🔄 Round 41 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 41 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0073
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0084
============================================================


============================================================
🔄 Round 42 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 42 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0057
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0136
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: -0.0037

📊 Round 42 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2476, R²: -0.0027

============================================================
🔄 Round 45 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 45 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0065
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0021
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2476, R²: -0.0027

📊 Round 45 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2476, R²: -0.0025

============================================================
🔄 Round 48 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 48 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0106
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0019
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2476, R²: -0.0025

📊 Round 48 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2475, R²: -0.0021

📊 Round 48 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2475, R²: -0.0018

============================================================
🔄 Round 52 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 52 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0061
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0009
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2475, R²: -0.0017

============================================================
🔄 Round 55 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 55 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0046
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0018
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2474, R²: -0.0013

============================================================
🔄 Round 57 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 57 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0130
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0089
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0009

============================================================
🔄 Round 58 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 58 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0032
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0657
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0009

============================================================
🔄 Round 59 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 59 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0054
============================================================


============================================================
🔄 Round 60 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 60 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0036
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0027
============================================================


============================================================
🔄 Round 62 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 62 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0008
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0188
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 64 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 64 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0003
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 65 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 65 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0031
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0044
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 65 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 67 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 67 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0017
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0230
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 67 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 69 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 69 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0043
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0020
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 69 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 74 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 74 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0002
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0263
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 76 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 76 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0069
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 77 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 77 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0015
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0072
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 78 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 78 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0038
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0068
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 80 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 80 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0016
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0050
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 80 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 83 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 83 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0069
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0126
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 86 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 86 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0009
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0054
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 88 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 88 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0031
============================================================


============================================================
🔄 Round 89 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 89 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0024
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0102
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 92 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 92 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0017
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0015
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 100 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 100 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0083
============================================================


============================================================
🔄 Round 101 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 101 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0134
============================================================


============================================================
🔄 Round 104 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 104 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0029
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0038
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0011

============================================================
🔄 Round 106 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 106 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0085
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0048
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0011

============================================================
🔄 Round 108 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 108 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0004
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0202
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0008

============================================================
🔄 Round 112 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 112 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0004
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0141
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

📊 Round 112 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 112 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 117 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 117 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0038
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0007
============================================================


============================================================
🔄 Round 118 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 118 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0050
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0042
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 120 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 120 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0081
============================================================


============================================================
🔄 Round 121 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 121 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0008
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0071
============================================================


============================================================
🔄 Round 122 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 122 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0035
============================================================


============================================================
🔄 Round 125 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 125 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0008
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0158
============================================================


============================================================
🔄 Round 127 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 127 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0010
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 127 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0000

============================================================
🔄 Round 129 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 129 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0025
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0238
============================================================


============================================================
🔄 Round 130 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 130 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0007
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0153
============================================================


============================================================
🔄 Round 132 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 132 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0007
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0209
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 132 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 134 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 134 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0032
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0009
============================================================


============================================================
🔄 Round 137 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 137 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0018
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0122
============================================================


============================================================
🔄 Round 139 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 139 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0028
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0057
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 139 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 143 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 143 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0032
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0035
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 146 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 146 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0024
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0045
============================================================


============================================================
🔄 Round 153 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 153 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0000
============================================================


============================================================
🔄 Round 155 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 155 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0020
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0020
============================================================


============================================================
🔄 Round 157 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 157 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0044
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0105
============================================================


============================================================
🔄 Round 158 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 158 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0021
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0028
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 158 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

📊 Round 158 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 164 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 164 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0064
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0094
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 165 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 165 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0007
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0159
============================================================


============================================================
🔄 Round 166 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 166 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0163
============================================================


============================================================
🔄 Round 169 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 169 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0005
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0282
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0000

============================================================
🔄 Round 171 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 171 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0029
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 171 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 174 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 174 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0006
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0084
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 176 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 176 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0009
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0160
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 179 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 179 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0227
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 180 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 180 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0029
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0004
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

📊 Round 180 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 180 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 183 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 183 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0008
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0081
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 185 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 185 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0002
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0092
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 186 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 186 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0039
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0005
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 186 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 186 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 190 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 190 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0015
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0017
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 190 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 194 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 194 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0019
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0250
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0000

============================================================
🔄 Round 196 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 196 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0023
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0515
============================================================


============================================================
🔄 Round 197 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 197 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0049
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0130
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 198 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 198 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0007
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0027
============================================================


============================================================
🔄 Round 201 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 201 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0006
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0087
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 201 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 203 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 203 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0298
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 204 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 204 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0006
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0060
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 207 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 207 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0027
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0050
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 208 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 208 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0007
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0084
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

📊 Round 208 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

📊 Round 208 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 208 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 208 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 216 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 216 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0019
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0029
============================================================


============================================================
🔄 Round 217 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 217 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0063
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 217 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 217 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 217 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 222 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 222 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0059
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0137
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 222 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 224 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 224 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0012
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0033
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 226 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 226 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0014
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0001
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 228 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 228 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0023
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0026
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 228 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 232 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 232 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0011
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0011
============================================================


============================================================
🔄 Round 233 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 233 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0016
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0341
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 236 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 236 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0018
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0241
============================================================


============================================================
🔄 Round 238 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 238 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0049
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 242 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 242 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0047
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0067
============================================================


============================================================
🔄 Round 243 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 243 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0029
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 243 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 245 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 245 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0016
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0022
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0000

============================================================
🔄 Round 250 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 250 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0065
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 252 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 252 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0002
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0052
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 252 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 252 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 268 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 268 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0007
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0034
============================================================


============================================================
🔄 Round 270 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 270 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0021
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0298
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 271 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 271 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0001
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0081
============================================================


============================================================
🔄 Round 272 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 272 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0074
============================================================


============================================================
🔄 Round 273 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 273 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0024
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0020
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 274 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 274 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0040
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0061
============================================================


============================================================
🔄 Round 275 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 275 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0086
============================================================


============================================================
🔄 Round 276 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 276 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0008
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0087
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 276 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 278 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 278 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0005
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0102
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 280 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 280 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0014
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0005
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 282 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 282 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0002
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0048
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 283 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 283 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0023
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0152
============================================================


============================================================
🔄 Round 286 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 286 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0001
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0093
============================================================


============================================================
🔄 Round 287 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 287 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0023
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0011
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 288 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 288 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0029
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 289 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 289 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0016
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0019
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 291 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 291 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0017
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0020
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2472, R²: 0.0001

============================================================
🔄 Round 293 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 293 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0032
============================================================


============================================================
🔄 Round 295 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 295 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0005
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0002
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2471, R²: 0.0002

============================================================
🔄 Round 296 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 296 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0015
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0054
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2471, R²: 0.0002

============================================================
🔄 Round 297 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 297 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0039
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0081
============================================================


============================================================
🔄 Round 298 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 298 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0012
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0159
============================================================


============================================================
🔄 Round 299 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 299 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0096
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0001

============================================================
🔄 Round 301 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 301 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0005
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0076
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 301 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 303 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 303 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0013
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0004
============================================================


============================================================
🔄 Round 305 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 305 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0160
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 305 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 310 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 310 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0004
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0018
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 311 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 311 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0015
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0007
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 318 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 318 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0001
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0029
============================================================


============================================================
🔄 Round 319 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 319 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0004
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 322 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 322 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0023
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0127
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 322 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 322 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 322 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 322 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 329 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 329 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0032
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0282
============================================================


============================================================
🔄 Round 330 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 330 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0021
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0060
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

📊 Round 330 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 333 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 333 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0018
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0110
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0000

============================================================
🔄 Round 334 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 334 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0022
============================================================


============================================================
🔄 Round 339 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 339 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0012
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0218
============================================================


============================================================
🔄 Round 340 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 340 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0004
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0315
============================================================


============================================================
🔄 Round 341 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 341 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0006
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: 0.0001

============================================================
🔄 Round 343 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 343 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0011
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0122
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 344 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 344 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0031
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0012
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 349 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 349 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0016
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0049
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 350 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 350 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0029
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0565
============================================================


============================================================
🔄 Round 351 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 351 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0053
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 352 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 352 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0030
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0044
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 353 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 353 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0022
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0002
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 353 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 353 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 359 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 359 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0025
============================================================


============================================================
🔄 Round 360 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 360 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0025
============================================================


============================================================
🔄 Round 361 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 361 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0040
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0001
============================================================


============================================================
🔄 Round 362 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 362 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0016
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0022
============================================================


============================================================
🔄 Round 363 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 363 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0069
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0008
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 364 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 364 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0010
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0022
============================================================


============================================================
🔄 Round 366 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 366 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0018
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0203
============================================================


============================================================
🔄 Round 367 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 367 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0010
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0158
============================================================


============================================================
🔄 Round 369 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 369 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0001
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 370 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 370 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0022
============================================================


============================================================
🔄 Round 371 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 371 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0070
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0006
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

📊 Round 371 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0008

📊 Round 371 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2474, R²: -0.0008

============================================================
🔄 Round 378 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 378 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0013
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0201
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 381 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 381 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0029
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0034
============================================================


============================================================
🔄 Round 384 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 384 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0023
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0007

============================================================
🔄 Round 385 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 385 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0019
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0019
============================================================


============================================================
🔄 Round 387 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 387 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0018
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0026
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 387 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 392 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 392 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0010
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0182
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 397 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 397 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0031
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0004
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 397 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 403 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 403 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0013
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0007
============================================================


============================================================
🔄 Round 404 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 404 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0005
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0063
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 404 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 404 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 407 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 407 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0003
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0076
============================================================


============================================================
🔄 Round 408 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 408 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0007
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0271
============================================================


============================================================
🔄 Round 409 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 409 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0032
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0055
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 409 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 417 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 417 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0166
============================================================


============================================================
🔄 Round 418 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 418 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0041
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0043
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 420 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 420 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0013
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0037
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 421 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 421 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0084
============================================================


============================================================
🔄 Round 422 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 422 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0043
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 422 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 422 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 422 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 428 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 428 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0011
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 429 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 429 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0004
============================================================


============================================================
🔄 Round 430 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 430 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0040
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0147
============================================================


============================================================
🔄 Round 431 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 431 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0260
============================================================


============================================================
🔄 Round 433 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 433 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0035
============================================================


============================================================
🔄 Round 435 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 435 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0035
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0306
============================================================


============================================================
🔄 Round 437 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 437 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0029
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0055
============================================================


============================================================
🔄 Round 439 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 439 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0018
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0019
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 440 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 440 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0020
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0033
============================================================


============================================================
🔄 Round 441 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 441 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0046
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0040
============================================================


============================================================
🔄 Round 447 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 447 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0030
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0032
============================================================


============================================================
🔄 Round 448 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 448 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0037
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0036
============================================================


============================================================
🔄 Round 449 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 449 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0036
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0027
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 449 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 454 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 454 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0016
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0011
============================================================


============================================================
🔄 Round 455 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 455 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0043
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0396
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 456 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 456 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0022
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0218
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 456 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 456 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 460 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 460 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0003
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0066
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 460 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 460 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 460 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 469 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 469 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0019
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0037
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 469 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 476 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 476 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0030
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0023
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 476 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 479 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 479 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0005
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0076
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 482 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 482 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0006
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0299
============================================================


============================================================
🔄 Round 483 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 483 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0013
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0010
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 483 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 483 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 483 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 489 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 489 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0009
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0093
============================================================


============================================================
🔄 Round 492 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 492 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0006
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0085
============================================================


============================================================
🔄 Round 494 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 494 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0034
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0039
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 497 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 497 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0038
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0038
============================================================


============================================================
🔄 Round 498 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 498 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0016
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0008
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 500 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 500 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0000
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0097
============================================================


============================================================
🔄 Round 501 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 501 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0010
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0073
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 502 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 502 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0019
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0028
============================================================


============================================================
🔄 Round 505 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 505 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0032
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0043
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 505 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 505 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 514 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 514 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0023
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0301
============================================================


============================================================
🔄 Round 515 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 515 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0022
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0036
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0002

============================================================
🔄 Round 517 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 517 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0004
============================================================


============================================================
🔄 Round 520 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 520 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0050
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0046
============================================================


============================================================
🔄 Round 521 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 521 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0012
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0001
============================================================


============================================================
🔄 Round 522 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 522 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0028
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 522 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 522 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 522 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 522 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 530 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 530 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0044
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 531 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 531 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0006
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0054
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 534 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 534 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0026
============================================================


============================================================
🔄 Round 535 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 535 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0010
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0037
============================================================


============================================================
🔄 Round 537 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 537 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0026
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0012
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 539 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 539 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0010
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0008
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 540 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 540 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0035
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0028
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 542 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 542 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0015
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0026
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 546 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 546 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0077
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0078
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 548 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 548 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0149
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 555 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 555 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0008
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0010
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 555 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 555 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 555 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 562 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 562 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0007
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0091
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 565 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 565 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0010
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0180
============================================================


============================================================
🔄 Round 566 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 566 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0124
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 566 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 571 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 571 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0009
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0034
============================================================


============================================================
🔄 Round 572 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 572 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0003
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0047
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 572 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 576 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 576 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0216
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 576 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 576 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 581 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 581 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0014
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0164
============================================================


============================================================
🔄 Round 582 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 582 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0031
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0029
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 582 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 584 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 584 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0017
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0046
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 584 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 584 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 590 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 590 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0015
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0011
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 591 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 591 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0013
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0158
============================================================


============================================================
🔄 Round 592 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 592 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0006
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0064
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 594 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 594 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0019
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0056
============================================================


============================================================
🔄 Round 596 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 596 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0013
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0029
============================================================


============================================================
🔄 Round 597 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 597 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0011
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0086
============================================================


============================================================
🔄 Round 598 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 598 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0008
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0104
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 600 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 600 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0012
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0127
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 602 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 602 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0032
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0028
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 604 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 604 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0194
============================================================


============================================================
🔄 Round 606 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 606 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0018
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0130
============================================================


============================================================
🔄 Round 608 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 608 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0010
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0098
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 610 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 610 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0109
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 612 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 612 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0052
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0024
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

📊 Round 612 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 612 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 612 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

📊 Round 612 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 618 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 618 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0025
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0017
============================================================


============================================================
🔄 Round 622 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 622 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0043
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0031
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 624 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 624 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0025
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0455
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 624 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 628 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 628 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0016
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0200
============================================================


============================================================
🔄 Round 629 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 629 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0017
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0026
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 631 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 631 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0012
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0020
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 634 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 634 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0007
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0072
============================================================


============================================================
🔄 Round 636 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 636 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0046
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0058
============================================================


============================================================
🔄 Round 637 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 637 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0010
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 637 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 643 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 643 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0012
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0316
============================================================


============================================================
🔄 Round 644 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 644 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0014
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0011
============================================================


============================================================
🔄 Round 645 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 645 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0023
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0195
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 647 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 647 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0023
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0041
============================================================


============================================================
🔄 Round 648 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 648 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0015
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0234
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 650 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 650 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0014
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0096
============================================================


============================================================
🔄 Round 652 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 652 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0043
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0047
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 653 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 653 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0007
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0013
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 654 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 654 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0017
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0010
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 654 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 660 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 660 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0048
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 660 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 665 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 665 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0126
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 665 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 667 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 667 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0008
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0153
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 667 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 670 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 670 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0085
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 672 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 672 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0026
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0026
============================================================


============================================================
🔄 Round 674 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 674 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0003
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0071
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 675 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 675 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0017
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0016
============================================================


============================================================
🔄 Round 677 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 677 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0029
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0038
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 681 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 681 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0031
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 684 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 684 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0016
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0035
============================================================


============================================================
🔄 Round 685 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 685 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0007
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0021
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

📊 Round 685 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

📊 Round 685 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 688 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 688 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0008
============================================================


============================================================
🔄 Round 689 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 689 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0004
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0016
============================================================


============================================================
🔄 Round 690 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 690 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0015
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0082
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 694 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 694 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0000
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0073
============================================================


============================================================
🔄 Round 695 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 695 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0044
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 697 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 697 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0082
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0055
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 697 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 697 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 697 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 709 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 709 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0012
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0009
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0007

📊 Round 709 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 713 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 713 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0009
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0024
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 714 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 714 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0011
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0202
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 715 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 715 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0002
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0111
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0006

============================================================
🔄 Round 720 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 720 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0024
============================================================


============================================================
🔄 Round 721 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 721 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0020
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0486
============================================================


============================================================
🔄 Round 722 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 722 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0046
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0013
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 723 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 723 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0004
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0039
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 723 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 726 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 726 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0015
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0528
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 727 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 727 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0034
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 727 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 727 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 731 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 731 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0031
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0035
============================================================


============================================================
🔄 Round 732 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 732 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0103
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 734 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 734 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0052
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0075
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 735 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 735 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0029
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0039
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 736 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 736 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0006
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0009
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

============================================================
🔄 Round 738 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 738 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0032
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0055
============================================================


============================================================
🔄 Round 739 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 739 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0059
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0002
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2473, R²: -0.0003

============================================================
🔄 Round 741 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 741 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0084
============================================================


============================================================
🔄 Round 742 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 742 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0017
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0194
============================================================


============================================================
🔄 Round 745 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 745 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0004
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0088
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 745 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0002

📊 Round 745 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

============================================================
🔄 Round 750 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 750 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0032
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0624
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0001

📊 Round 750 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 754 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 754 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0013
============================================================


============================================================
🔄 Round 755 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 755 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0156
============================================================


============================================================
🔄 Round 756 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 756 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0013
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0005
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 757 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 757 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0015
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0041
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0006

📊 Round 757 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0008

============================================================
🔄 Round 761 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 761 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0009
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0124
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0008

📊 Round 761 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0007

============================================================
🔄 Round 765 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 765 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0099
============================================================


============================================================
🔄 Round 767 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 767 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0004
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0082
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0008

============================================================
🔄 Round 772 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 772 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0060
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0032
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2473, R²: -0.0006

📊 Round 772 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 772 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 775 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 775 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0058
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0055
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

📊 Round 775 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0004

============================================================
🔄 Round 778 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 778 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0005
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0613
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 779 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 779 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0002
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0046
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 781 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 781 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0017
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0027
============================================================


============================================================
🔄 Round 782 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 782 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0002
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0023
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

📊 Round 782 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2473, R²: -0.0005

📊 Round 782 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2472, R²: -0.0003

============================================================
🔄 Round 785 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 785 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0039
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0007
============================================================


❌ Client client_19 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
