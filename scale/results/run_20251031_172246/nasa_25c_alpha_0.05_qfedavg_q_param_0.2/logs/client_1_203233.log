[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc4700f-4bbc-488b-971d-91d0aa84216e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a9b682-8d40-4f1b-9976-2d91adeb36f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccedd459-c251-4edb-baa6-02d68478ad2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5e3cc0-30a0-4f6c-98fd-d4125e8f5171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0c6e68-b654-4519-a86e-19e4a5d04336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7483a0d5-b3ad-4b3f-a41f-ddaede8f131e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880e57c8-d33c-4969-92cd-0f7c60728413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da761b2-bc9c-4499-88ca-e9642be92955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aed70fa-20f3-4907-a00d-8635e7d825af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69bc4a9-ae3e-4757-bd5f-27f6f50e6072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11120b4-dd65-4b82-88bf-3a7c80a27a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7374eba-47c9-4c79-ac55-ca76b49fa26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1c6e01-ff86-4b46-9c30-251c8aab1236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51db134-0034-4490-9403-813625e8728e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86000215-139d-4ef9-b29e-a0beec2ab0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f181f6e-b801-42ee-be0e-5a82ca8412e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433feb7d-d547-4bfe-8c70-4dd3c6a6e770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d134d253-4b95-4c7c-974d-afe8518e63f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14804bfc-e750-4c4b-92b4-766e0b7e66ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f635a4b-fe8d-4f1a-aebc-76418007fb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be31cb81-2acc-40e2-8962-93f8a4825180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34ca4e4-a7c2-4b72-b256-6d57fc5a1cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789075b0-35b2-4596-8d84-81345917b8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2207f6-2376-4030-bef3-eaacb73b4743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806e3955-257f-4e8f-b4bb-e9d4879b50eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151a7a6b-39e2-4878-a9ee-e7c4bdfeff9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff19752-72b9-414f-b6af-15cb469c8994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eac6dcb-0c86-412e-a05a-7b018ca45359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33567c6-f40e-4b8f-a156-2938e2743a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2daf8070-81e2-4b27-a53f-72c7759f03ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852eeabb-2784-4fff-bef1-4af890d818c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbce7609-5a35-4d35-a8e1-3e52f0f4523d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604e6cdd-a588-4b74-af87-52f4dcd7f5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e93719-9e59-4615-9382-cee89b70d070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 778a7f1d-1056-4bff-823d-a3085fe57672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb3da2e-240b-4b3c-af39-dc3aa5b2f945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 375909cb-3415-4b4b-8575-25d8fcbd83d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f300a91-d08e-4ab0-a49b-1b76cb3afb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf12f912-c03e-4ac3-a8be-91eaf654e085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba9a033-f66a-418f-a84f-f3073add9f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b632220-e17d-41a1-8aab-18e7d6f18a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e823a15a-39ed-49da-879f-026c8dca14ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8e5a7e-8b15-4237-8d05-0a904e7381a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456bc7be-b6cc-414f-aa95-e6c5d7b047f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3e1e06-ba2e-47f0-a354-ff5a4fcfc59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cd28011-6269-4d09-aa02-baa56167b418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e65216-a79f-4d46-b1c9-aec83d7786c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b1e7f0-2056-43e7-9527-80dd90e23399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba6ac44-9a4e-4c68-be2d-ceb891c1f381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa8de149-64e1-4961-a6cf-6aeb02daef68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c593e40-7ac9-4fe8-9fcc-882272fa9ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ce2984-b1d9-43c2-9843-4f9c4afd7895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb70b26-0b5e-40df-a731-afbbada0a641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c98a88d4-e2a5-4d7d-bfc9-40a5bd69c410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987a34e4-c69f-4ac7-9492-9765b86ee826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af6051f-e726-4dce-ad34-0a9f460dfa75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c98e352-ee10-47a3-a9df-ffce3bb7d54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35a8330-d466-4254-a8fb-20ca46a3cbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987084bd-2f3d-4a60-9eec-44df774b3741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc656a7-413e-4c00-a4a8-e34265169aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df11001-afc2-4d2e-92c3-d3a968ef48aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be94d319-5952-40f2-b4fa-a93efdcf79b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a58281-2ab8-4d1b-964e-39fbece56995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db4783c-3382-47ad-8ab7-d564cd75b259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0a3eb09-1048-497a-9f7b-7c894b99d06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e325ddf-cb3d-4a7b-8cd5-0254687d4976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2cb411-cad0-4631-8ce1-87f89f614366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a245e9c6-e956-4ef3-ae79-a88add697084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec7906fb-660a-4682-b71f-1e538239aaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ae4531-8693-417a-a709-055e215e882d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec16a6e-e61f-4d48-86b4-84c9f821467b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e3e83a-e000-4a97-80da-270392ee827b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ffdb2a-c6cd-466d-857d-f226ce0b8c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0b3720-3847-4b3d-8d4b-64ec649d79fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af09dce2-45fa-4cfe-809f-ed43299b290d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcee924-477f-4a91-b490-01eee91de83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75754af9-8dfb-4398-9998-a2c5845868f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23b4df9-d25d-4665-8fea-4e3ea0d1d0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f48476f-ec20-47a3-b297-006cd6e415a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b21afc-b5ee-4bff-a73a-f44859af5494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b496486-c78e-40d9-9518-0364867a5fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79a896a-8c98-411b-8022-50feaa691fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36a9ec9-6f78-4b99-b560-bd0f94d7adbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438124ec-403a-4a03-a2fc-137e0af5eb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 756f45d6-736e-4955-acc9-5abefebf9dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c890c6-3b04-4e2d-a8ea-758ae3811d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a88735d4-91b1-4102-8e1c-d756eb482982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe2bf90-0449-4b8c-99d9-5f024efd7cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17f1d43-2956-41fd-ba9c-2bfe2af23085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07a485ca-4bec-47c2-b006-f9a9c2a41f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c79d5ccb-415a-4162-913f-02c55ff54cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bde8aa1-7520-4b38-b597-c5c802a63083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a9260bd-25b1-4ab6-97b6-fdce0ed19632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c8af7d-1884-4a82-bc16-b1099a970481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee3d017b-ae18-431c-8a31-ea13e2edbbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349c8f76-382c-4e4d-8122-1f64c1761d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bbe78f1-8136-4c45-a47a-e64f1ca01bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f68e4e-570f-4aa4-ba0c-920fe0885f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f1896a-c0be-4de3-a4f6-8be90db00581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41d2c42-143d-49ee-bae7-6050042e15c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8d6f1a-685e-4f03-808c-ffe03f71f229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dcfafa-d02f-4887-9e41-2fb7a0e2e09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b7be6c-ce5d-4400-9bb7-9a696d36aeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48b8570-b530-478e-91c1-3c79014cf423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22a57a9-dcc2-4faa-b4fe-9f9eb5d9999a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433e2515-d764-4c4c-91d5-81fdce3b609f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06fc78a-0f0b-4074-a2fb-81760d94542e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e7002b-c3ef-4c4f-93c8-aac295791b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c575af0-602c-436f-be7c-2a2581ec3f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a551f821-8fd2-4a92-b88c-f82af0a0f01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07460a7-5fe4-44fb-b854-f6dce2710a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e21e3d8-3da5-43d0-ac43-170769843846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5397e4a1-ddaf-45f7-bbc1-656b7b6ff1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e188e88d-6272-41d7-b73f-aa73c2e25d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c44c42-d745-4264-8f03-8d17417cb875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c807a3ae-39fa-4323-ae85-6e0046f08e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a986d4-3975-489a-87d3-c414511b2616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2cb8f4-3fde-4c58-9d44-c895982e8402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7758bbb8-ad7c-4d2c-81a6-409ba6be2e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a719268-c5ab-44ab-bcd7-3b9ba0b1e862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a07808-67ea-4487-acf1-e5c49ecb2912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa6892b-49ff-4eea-af6c-26549dad7df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff8d0bff-28ff-48ff-bc5b-0c31dd35f728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0904daee-f711-4380-b3f0-7023ef372f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af02475-3bd0-4506-b727-b9375db6a094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431dc462-ebc7-4dab-b217-a16018342d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09d4b77-7b7f-45df-a40c-438786eaab8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 178c2e4b-6b3d-4c23-9038-2751fea33e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 021495b2-80df-4837-9216-da743fcc8239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377f211b-7b5b-4868-94b0-f6fc3982285d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874cbe78-9b59-4212-97f0-1e5ff3d32f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d8eb3f-9fbd-4e28-8916-a021391150c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4eee533-014c-4e91-957a-a1a13b9b4068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07414cb6-5452-4b7e-9dbc-c9a1f245c599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 091a77c7-78b6-4a25-bd8d-1c9ce348dc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc124612-d9d7-4990-8e75-1707daf41b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3cee1e-5ff2-4d6d-83f0-25c3a163b48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe2808d-6788-430e-ac6a-63295163c723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198a4565-267f-4716-a945-c4e2960f7cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6199c9-f5a3-4e16-9905-403b3b7ae048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec45a1e7-b2e5-49b6-8881-017647815152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ecef031-c67e-4408-9c8c-0d133775523e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4aa60e5-133c-48c1-a344-95a8ff3ce571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0fe17c-3fdf-433b-8ae6-d083bb97cd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861468c1-e4f4-4fc5-b1da-adf1a0376a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3914a984-c6d5-4c82-ae68-b758e63d993c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d00e10c-9922-47aa-acce-5b628a24bf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e1e44af-1aa5-4f83-b67c-6185ebc78a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec7a5c6-70fe-4031-9791-34daed9f76b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14971fb0-0887-4ab1-8a1d-388500a140d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1496e5cb-473a-49ee-bf21-670cf764e832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49484282-b425-472e-bc59-5e19a8048025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61951e16-51fe-4469-aff1-e05078d5f9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a11ec5-f882-49c2-81c1-f49296a7e770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc032f5d-9efd-4d2a-ad74-50288190a8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7bece22-4aae-452c-9e22-2b27102e0b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302d8f96-e734-4d49-8056-52a6d8419c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c63c562-1de3-4d64-9d17-d66c4db4e36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26813a21-eb70-4526-896d-7b7dc272f586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2abe9289-a2ab-48af-9698-e764620abb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a025bcea-3cf0-49a3-8996-45a74652530b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02fabf2-9fb9-4cb7-82f8-757756c298c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f8d246-9933-4712-a03a-6abc90f8d968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83853210-0d2e-4c2a-95ae-8d0198beddae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4dc822c-9774-431a-8a05-9967e3cbe5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01849308-205e-4cc1-a73e-123612ff596e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a138b596-5581-4b50-9208-816d85b91757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11fb8254-9cb2-4ef6-bf06-2c0291f0c056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd530f4-781f-4347-9bd5-fa9b8ff5a608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa8dad51-3911-4b57-9b5e-1c928d1949f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feee4866-1a82-426f-afe4-4545685d6cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42472fa0-a654-4362-8666-b64417004a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643b6ab3-d296-48fb-91b3-70ea4947625b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ec4410-bb5d-4bde-994e-8a25f412f0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28672ce5-9ed7-4af0-bf14-9da0d3aad29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9354e0d3-eaf3-4c06-9703-3a944ed2fd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a101bc-c2f4-4e36-a0a2-13218d02b6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77db3719-0dff-43a3-b15e-060fce562e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c83da3be-b716-4ea1-beeb-1c1abff7a598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea07b62-28ef-469c-802d-2c814e3a312b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe44a8f-d18f-455a-8d8f-2d446ba4d914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8007cfe9-eaf4-40a6-8560-75574cc08bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45782d64-2a84-4671-be39-081f1e35e2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fbd38e-713c-4a9b-9a65-3680449e7dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eafb9648-baa8-4082-8f5c-bdab1a7b31b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851848e1-aa4c-4fff-9f31-c80e58395476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62fe354-f6e5-4d03-9086-b56e7eecb197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 284b419b-7b02-4431-a0c9-372ece19492e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8761de-fc9c-4b9e-a1db-df3e4d47acb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29458150-bb48-4a11-a1aa-96d36a21c18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc3f4c4-abd8-4dda-b888-868e7c8aedb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3580e137-0455-43bf-9dc8-992ad0085d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5c1a0c-200c-4751-a3b8-2ef498a963a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e540eb24-3215-4945-9e6b-587deba03b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b78f27a-6eec-4439-bcba-2afe9116ae33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aed727-745a-44e9-aedf-5d5cb951b135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71999c1b-0b73-4655-b3a7-83599338944c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5df471d-3047-48f8-aadf-a82e76d11267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b247afc-bec0-4aa5-99f4-2d14b658dcfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22d874a-aa33-454e-9701-2068eb235054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3614b56-2370-4ef7-823b-27fa1c2e3f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e8f4f5-1f91-44a0-a79f-1300733e55d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b21fea-77fb-4909-9220-e80585ab36d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae124c8c-dbb5-47da-a8b1-4e4334b1947c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2036ba4e-182a-400c-a1d9-2bd7b9fd899e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4470ea-f1ff-47c2-9bd7-1ca1bbb967f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc74ca0-f3fd-48f5-a014-14fe1eb3b029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2401bcb-e630-4b70-aea7-7221f46a696e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8c10ff-be3d-4e6b-a118-e6e80fd41cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179ff3ea-3847-4698-a69c-913e8850cbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a0647e-bdd1-4c4b-9204-bf8cdf083d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327256f7-cc4d-4e11-b1c9-c5e7d48bb844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6859aaa7-cb6f-4cb4-8539-4a21bfaf94bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0166a1e-898c-4ba8-92cf-a3f9eb6b205f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317bd77c-e091-4662-845d-799ae1385ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb1fb17-2fc0-42ed-827c-7bb98a16371c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ab2752-c6cf-4ed6-817c-bfcba057d462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce0ab8c-77af-403b-adb3-ccfcbca721bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6742b959-40b5-446c-a45a-1cf0e6424e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8152f17-8483-4a46-b84e-a895681f023a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8cb379-92e4-4750-a74f-73bd86313ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66232ab5-a409-4a23-8800-fd5f84545376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d326a4ea-d169-4a9c-8821-c1f84647ac10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a379ea7a-6bf2-4bd9-8941-a2634923e633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3096348-f20c-4c60-9b69-1c866d78b3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37229d96-b052-4b41-ab83-bbe7eecfe0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c5d6e8-1dd0-4c7a-b802-94307ba8abd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ce92f5-09d1-4d81-ab5c-8d415fff6ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655d183a-48a7-4491-9913-2aea104c5990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c0d61b-78f8-4d9a-9000-6d804dc79642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf45034-04fb-41c6-a878-2a5d2f6cc84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e432a7e-e8e2-4624-b1c5-1b39fbbefe00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed5c6c6-431f-4f0a-a3c7-a8001181e561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7330a03-8284-4135-a087-69ece44a19cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c134e4c7-5e59-4757-ac51-a66f7006fd8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1072a88-97e6-4055-b904-55390018e0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b174e14c-bc14-4591-b9d3-d1b419d91615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc7c2e8-e491-46f1-830c-7938a5d52450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1941a1d8-69b7-434e-ba55-1bd4c7c5363d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8c9c98-458e-4702-adf2-bd12d6efc3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6151d16-451e-4c7d-810d-99a7b4969809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6592327f-a455-4914-adf0-9275d27dbd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22052f2-d868-4e1f-92f6-1ccdd7e35f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec3538a-7cea-4873-9f23-ddc5c69682a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4306efe8-5cec-4e88-aa56-330cf5b5e5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5966f0b-92ca-4809-82d5-f3d2967c2273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0168753-71a4-4749-9eae-5c13bd6149fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37aaddc0-fd0f-419f-aad0-fdb4c218124a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f576407-a431-4933-987c-71e83c855da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0ba4ef-fcef-4b35-a404-82d55ead1150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bec502-8bfb-4bcb-b4bc-983f6e940a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8f9ccf-defc-4c37-8f88-65f84c448fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de79d00-11c9-4274-bd8e-1af56c4c7f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f998a53-5929-4d2e-be3a-7ded047bf29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af39eefe-46f8-48a8-aef3-2456dcfde7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e51723-9851-43d1-907d-10916ccd0b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a06dfb1-ca3f-4877-8800-3c1c5170cbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6e12cf-7b3b-4390-a076-ba00320e72e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f34c6a6-8181-49e6-a332-619dd469884b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7f69a3-08a1-45d5-b2c1-8848ef623d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee6d85a-83b5-4c50-9e4a-dfa3c8767338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca1fe358-a931-470b-9baf-23e09f484811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507433d0-7083-4722-8790-457478e39afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bf0585-9532-4b5a-8387-271e0f59a9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e84e4b-b7d3-4b29-9131-431177299441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0685bfa8-19a6-4302-92fc-9396d0ac7d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4d8a21-ce56-4cd0-ad54-fea0d65f920d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39827760-5a6f-49b2-98c4-a4eb23821c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd39e20-3230-4953-a9cf-27fcdcbf7b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb51bef-2cab-4acc-bcd5-d7964b794aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25e8e30-b01b-4b66-9ecb-3eb9b948a7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ec49c8-16f0-41cd-8a5b-96c36c70e448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a1a3b7-158e-448e-8649-fb6208f1149b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a5e356-b6f5-4dc6-9638-14f7032c3e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d78d4d-c7ac-4737-b752-9da808c69a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe60425-35c8-4147-9133-ab95ca10dc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef319ba-aa04-4864-aedc-2854dc053003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa5e8ac-f99d-4181-aa10-c18e055e4bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6453a9-38fa-4c97-809a-b865941524a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc57e551-387f-427d-8cdf-0f041ae6d9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740307db-2f3e-4818-8504-800dfc216c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c3d676-42bd-4340-9c46-de987496df44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47b220d-d40e-4538-8364-908cc99115e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f47c7c-2c3b-4a6a-be3e-3d3e88a2495e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b91adf2-353b-4e83-8d97-f7bee3d3e05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b45ec1-f7eb-4122-ba83-f9f41826667e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc2b5c7-8975-4da8-9676-78171b4141e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b30a296d-f1bf-4832-ac71-ed9e77405679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e77b0c-3bc7-4377-93c5-ef557b21ef93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fef437-1d95-4b45-afd5-cb6702479f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc2cc913-ee41-47bd-a1fe-73c1affba758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3466228-5eb2-41b6-92f1-6e75a07161e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c2fbe7-33df-42e7-b995-f7543aab0a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28ca035-0dc3-4ad3-9c43-2303a68da4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87a5bde-75eb-4bb5-a76b-167c7c913c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb3ffed-50ed-4dfe-8e95-dd1147917d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c0c495-70d2-4e1f-8d47-f0367d4f32f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf1bfc3-ede5-4615-baf1-4eb73d7fc149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d991802-a487-4dce-ad0a-19c8f2ae4290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afecbf6b-2fab-4612-b001-36854eb530ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e69a8ad-1b30-4d8d-8312-bb7dc696c774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a578b57c-fdc1-413b-ad8e-8180fac8c002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba8c95f-ad4f-401d-9a91-3b68d6f1572a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c85a6a-5d33-4df2-8a9a-4118c049ed13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abeccf41-5201-4d04-8397-03071c9f563e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc75b37d-52cb-419f-a784-18a6eb1ebddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a74d2e-b40d-4ab8-a858-0444ea74b259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ece11b-56bb-40da-afb0-33e36df889a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a372fd-4373-4dbe-bc85-eeb04fa6988c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a91589-61cf-4aa5-8b0d-42b84633c186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208cb4c5-7a78-48f2-a41b-9bfff2758e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6fed02b-16cc-49d3-b580-bb73609fde8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00eb0a7-254b-4c94-b9d0-3dc4af53edd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6775b1-56e3-4b55-9bab-f909c496698f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e24c70-2997-42ad-b046-6de43d3b2a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feef77f4-75a3-4326-81b5-fca0c63764e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bbeb44a-609b-474f-957d-c3fb31c97ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0290c137-5903-45e8-a0f5-f9ff5fdc4ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c2fdcf-e7f9-489e-91c9-575da6be0475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b81903-c742-4aba-ba3d-f529a2581833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56367ed1-707f-44d3-8000-04ac78658b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd26d4c0-783c-4ac2-8df6-0b0c46b83023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4176cb-149c-4617-a3c6-840c1b4afa4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebe21c9-4a48-4cb8-8438-e46e8378697a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6041e13a-5aee-4713-8ea2-31d4973aab6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461b86dc-f93e-4184-aa5b-5b4c30fb1511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7086d933-8f52-444f-ba10-2eef5f28e3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb40f788-bb7c-4ce8-8d71-a9f4d304f1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be20081-380f-41e8-a753-044e6b7a5740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10517566-4729-44df-a2a7-a0b3c2c58578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3dce83-53fd-4fda-ab69-0aa8c2b521ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27707fb3-31f3-4eb5-9678-947df85f0362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db477b9-735a-4af9-8c93-0115ea10e363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a421e85-ef15-4a69-a855-7241a89a3dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17539e19-deca-40cf-8805-a431f12368a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af550e4-ec1c-4012-b18e-9e4941eec525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4474b1-99c2-492e-b0e4-167bf14c8970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789f923a-1e40-4dbb-86e6-c57af8b6ab19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88dfab18-813e-4f39-911c-2913d39f4adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537500de-27ff-4bf1-866a-f386c2895353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e49c55-136c-413d-be1b-19809bd6c1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c108553e-b030-4bdd-a9b6-8602917b9a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c00523-3b36-44ce-b75a-f76ee16d7d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539edb33-661e-4ff2-b692-8c3d1343aec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9a309c-9463-425d-bb3e-b9e9bef3c235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf20aba2-9ba4-402e-a7e1-2c96b41bdcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196b8574-43ea-4cc7-822d-d9668e792308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e59516-9a76-4f7e-856e-dbd5bc22d638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe854e1-7541-48ea-848c-475817c98070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57d61a8-feab-4bbf-bd48-d526ca9fec30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecef0e2-74dd-4383-8b03-322b9610e766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2216871-28ec-4821-8d06-ce314b395ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8b3ee9-cef6-4009-aa16-348590c93301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b2de71-63a8-4be4-bad0-e6a3b408ec72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75cb3d70-a519-42a3-82df-86f123ea6e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ddcfb0-c23f-47bc-be29-f0d4ece0ba6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae65f12e-8f76-4643-97a0-a65f1db5b393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15485eed-9543-410a-8532-1ae79162e609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257fcae0-c590-4345-9f0b-e86a24e63dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1957e2-e48e-4db0-952d-3edda4bfa29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feaba47f-f558-47fb-81bd-0c0bfc1cc6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4fc405-eb4b-4cd6-abc2-8541586a8c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b154829-7269-4e1d-9c69-b22f8e2ae599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063e619c-0d5b-4521-a461-900c1a43e64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e7b1c9-83dd-4884-a1d6-aac0a6a453c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb66dd3-fd2d-4d2b-8edf-c4e784771046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a4e2ad-dde4-429d-80d3-95815c7a8e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce98ce8-be25-4f17-87f2-e849d41de85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec3e237-c92a-4d3d-82fb-395cedbdf5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c02c1d-2c9e-4bb6-a44f-d625118308ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff148ee-7a5f-41ee-ba3c-df40b35dde02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60917cac-063a-441c-95e7-31c57a919b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a49e8e9-2de2-42ec-b3db-68d5d2952b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e188a48-d6e6-45a3-8780-147f15fc55f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e7b391-bd53-4fe0-bba2-1e39463a6fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700847a5-843f-497b-be73-fbd306e99338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f76b365-df3a-4a7d-bb2a-0bfc74987cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182ca6e3-e453-441d-8815-52cdda1108a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c937285-38d1-4d43-b8cd-cd207681e15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71157c9e-cbc0-4a23-bc5a-f12ddfe85a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85b38a6-3bea-4896-a8ee-9406b64bd9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f91aca3-3a1b-409d-b181-53800734c440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201e90e2-3e3f-41c0-a864-689796bc5865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6baa1de-1f2c-42ac-a6b4-e8bc7dc841f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bc43bd-b284-4049-9a3f-a35b993e4704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e9ab0c-1191-4302-997c-1509ec133bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2462911c-6fe0-4674-b96a-960c0f6423ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4302af8c-322d-40a5-977d-8af823c83ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6280202-a17e-4438-85ff-fbbae5b1b081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255f329b-bc99-403c-8693-1daa942b107c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6431a914-e7a9-402d-92d9-892eefa3c1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5abd1a7f-aa2e-4c30-b1d7-656914f38e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1f0b33-0eed-46ca-821f-9511b63dffdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2ebbf0-8e50-4ed3-82ca-75d14f33b44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5b0ab5-35a7-4774-b2e0-217a32d7e164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076648e3-6295-47d1-be49-5752fe8ceafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944ac8f3-489a-400b-bcb5-34e8bc35bd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0fd4db-1212-4fd9-99c9-aec6cb4b00d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f55fa7fc-74ae-4bca-be33-43d5194288f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e705212-cc2e-45f6-83dc-6b4fc67019de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0312cb49-3e75-46f5-93e6-1222e0d9d85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4869125e-04d4-46a3-a37a-0317aa4e2c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e907a51-8076-4c49-9380-86208c64fd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36aed854-7cdc-4524-9746-9bffd57a3e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb9b8f1-6b21-42af-b743-b95c710d7184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd83d923-a1d3-4df4-a39c-1fdd10ab6681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7552725-1645-4eb4-9f3c-3b7b49fd2541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ba5826-2db0-47ea-8cf9-6ffd2a059b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc5fde0-b558-4f19-98cc-7b4edbaac239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d828e7-ba73-4a86-8cc8-2f79576813a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9160b34-f01d-4090-9fc2-1c94b90fbbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46238d1-706d-49b4-ac34-719a46cc187b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417f9879-85e3-491e-aba0-43165a6de811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b8bd214-de89-4271-af03-eafba2445f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9ea37b-5d35-458b-a44b-747125b8ecb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac4843e-0c13-48f1-aae8-488b33ff6a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9435232-1f55-4e28-8b9e-71cbff351791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acce0231-2123-4be9-8458-70e491a1e36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1716d6bb-fbd7-4099-b0c0-0dee2b338064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636d2b19-429c-4ded-887f-e6e444e2243d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8877f60a-98ec-476f-9813-121e56f8c46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2621032-f384-43df-8886-50f491683b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea9733c-e1e8-4dc4-a6dd-c46f37a7db4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78d9a4e-b03c-4672-bc23-dd193d1442b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44e5089-6dca-4b64-875f-910e7fb7e83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4b8ace-11bf-417b-bea3-ddc850afc992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4da59f2-471c-4ce5-adfc-df73c1d97dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471a0c7c-6b5f-4d89-b626-7079400c6bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd034645-a44c-4f8a-bac8-1fe2c84891ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb432227-dc72-4def-ac3c-525d90ff3d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cc9861-0d61-4dd6-bca0-0bc02b91a7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a1a031-f232-4443-be3f-148c0b96a5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b5798e-91ea-4665-b195-19341930a07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c40a18-39c6-4066-a982-06795d8831d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874fb399-9104-4443-a1d7-70c1c23c2837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2d66b3-2f82-4cdc-9b5f-4055c3bf70af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fc4ab6-8a6a-438b-be88-fa670d4d7d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f279e94-38a1-41b0-aa23-e879a0e76de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855e1837-c572-489b-b2b4-eebb8c0941a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee16b4e3-12c6-4586-96e7-174a9562c71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ba116f-ef85-41f7-8d2a-3b297027bbc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef28233-6c09-4e67-8bef-88a0aabe97c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d36138-5cc0-45bf-b5a6-37f267814973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfeb8280-f75b-4d59-a9c1-e5e974c8835d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8a0af8-ab1b-4f3b-b4fb-72c35ca91daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fd67f0-225e-48c9-888b-56ea07f9d5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3598ef45-229c-475d-8343-4db0784c2515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb3ca3e-e05b-40aa-ac0d-f8a9debd5b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c381cb23-78d7-4753-9472-15ac9c3c5625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a345208-1206-48b9-a2cf-5a6b037b8899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e00633-85f6-44f9-a18f-05a519b9b75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402a4286-2e42-42c2-9dbd-de7170da15ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e73d443-fd20-4698-9dba-647fb184846c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a169c669-b769-4dd9-89fc-3ad98ff0e1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5652e0b2-d473-4926-813d-d38b64f953fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c441c3-4a1e-4598-b52a-f9319e827026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011511ad-8a58-4874-867e-8612499924d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2633c253-8586-465b-ab49-352ec4e72463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00af2fab-6ed9-4ed0-b1a8-64352f0bfd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087bb65f-41c3-4fa7-97de-d9b4faee80ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82508e5d-88b4-437a-9a89-63d21159f7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7144ce5-fc8a-44b5-a8ca-7607256fc64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fca0353-98f5-4211-9a02-31c21d89229d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe0baf2-d5a0-4bfb-9350-244dd20c43a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e01066-e399-4c62-8d63-769caaeee1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6eaa5c-d1fc-431e-bb37-810d089cd901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c7c364-f0fd-4cd5-8828-f7b303061af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167048b7-7cfe-410c-8aff-68f314f29e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0216c854-7fd5-44ed-9a6c-8dfcf59fbdf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce466b40-53c0-4d12-b4d6-0d53b9ebda60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d686a004-bacd-4542-ade6-61bb4ad18565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd265b14-a9f2-4d3b-9bcd-5b3445576ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b613285f-09ca-42d8-9cdc-e1ad323213bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33c12c4-c3aa-4683-bc14-010653646874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19016f7a-b28b-45c7-a414-43d4424ea11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a69e1ff-3ad0-47f6-9d7a-ee4d661740c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 398593e9-2ac7-47b6-8fef-f74e6fae7562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4721867-567c-4d18-9a59-5a0f14700364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9354f8f0-f8f3-43a5-a86d-b92669e85ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719d71b2-0a95-4ee9-a9a8-22eeeb20fb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8650a5f3-77c4-404c-b535-3339f1e43d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de1a5e1-83a6-4170-bea0-40317b52df3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eeee8a1-ddda-4aac-96cc-488b1f9e48ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29b845fd-0d10-4c51-b99d-807adce203cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff451ce9-607a-4f2f-9a1d-f62d97bea4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6718e214-6b2a-417d-b7ce-f358ba4d753c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd014a9-0888-406e-81e3-f0a1d3158b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc1e595-7e10-4f85-bc3d-e4f1fddc67f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d61f67-bc02-4b66-82b4-1d5e258aff83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9eba6ff-7e05-45d7-9521-c05088c2cb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650c0003-ea5f-4685-a68a-bd74313fcd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c0ddbc-1c5a-4696-9195-fd7aadba3c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a9abce-e88c-4b3b-a9e4-3a476014c855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f6ddf8-c075-4a00-a8b1-c2439b896c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e3e0d5-9a10-475f-89e6-60f979a06b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b2a8256-57f7-4387-aadc-8969401e7549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc0d5cf-1562-409e-98a9-f6002506170c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ea6864-b078-439e-934c-bcdb04b90091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492244c4-3035-41a0-bf89-89a005a4ef35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3284aa8b-d8b8-4fe0-a04a-87bfac6979c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f4d9611-1baa-4764-b217-2050ae55358d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc6c835-a780-4d0c-9d9c-74793821e959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17122ef-e4da-4be0-ba63-69b163b32d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b314f2e-c573-4b50-9e02-7325a2cd3c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a59451c6-827b-4797-a39f-0c907892232d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f3ad0b-4955-44d0-a82b-ac250e84c12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a080ab-6fbd-445d-926d-2f72f76a6a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a23d11-98f0-4ac2-b56b-62564e0498d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14e47e4-a7e5-4bc6-ab1c-a66f9eb8c3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025fd92a-ed78-4ffe-b5bd-6c5def65de1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4754d4-ef90-44ab-919b-a1e17d74e14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb5bdeb-98ea-47c5-bd1c-33a42ad377cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51556cf9-646e-49a3-872c-4663e962d928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88406f4a-0393-4ecb-8a98-2f23c143c17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc898376-bcff-4bb2-8ce2-70ecb6114622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686f2fed-07eb-4e34-8a10-d247e5ddf6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 799b3a49-50a7-4f41-9113-353ed54a6604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c885f676-707f-4efe-88f9-c47901579225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2442f3de-3f26-4ff1-8cf4-0a9721b13056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237e2086-4c43-4c00-8ec6-5656b9b9865e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9198310-60ba-4a25-95c4-2f099fa76b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562ce712-4a95-4ef8-b27e-844a40327e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f8e518-8479-4691-b1aa-ce2646cbca6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009a338a-45f7-4ef6-a3c1-574e09d15c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d026f0-32c9-4d78-895c-1ba041df41a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0cf3754-a3e8-47b7-8f2c-4152732fc58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa8e842-dcfc-4c47-8eef-2b5fe7a7f26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a42da68-8767-4b67-b466-0d3c013ed1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0239c08-9c38-4279-a868-02cf6ea8c381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f30760-e4d3-4ff9-9872-ac4e1df15e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2718c1c-de7a-4259-a218-e0f11dbf0054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acafef5f-bd52-41d1-bbc0-54df41de9844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36646add-6890-43fd-8426-4b51c90f0713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe540b0-6c11-468e-b7d9-744989ee512b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcb47f4-040d-4ead-8d76-14145294b049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51d8fbd-a046-42f2-b8b4-2983d552af0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5040928-6e57-4fc8-ad62-2ae294e665c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc0c258-273c-4f27-976e-a9924e545226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b21f5a6-c028-4e29-aadb-aed9ef901b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8fba51-52ac-4e56-a192-e3a7b499632f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6faac6d-0d9b-4159-b7dc-73bedced00bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67504d55-acb4-4648-b785-fbf94378d0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0bcc414-d479-402e-8a84-0d391e493763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eec9953-b075-4f2f-8e7b-ccb923bb6a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c661e982-c1eb-4c49-a8d7-0824fd346086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25863b9d-7fb3-48fa-95c5-e2ec0fa6669b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aefa1c9-cdca-45a0-b553-1082a3b3718b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef265c86-3f6f-47b1-b64c-ef81aa63bd6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a8b4cd-aaef-4f96-bdfb-482afe4fa1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbaa16d-8ec1-4d63-a927-26dc33fefbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b3d0cd-4ca4-46ec-ab03-81edde7c4507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd92b944-9634-4835-bbca-d8ae2f8dfd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1ffb76-7a0d-43fb-ba16-99deceb81e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d67a457a-da40-4900-a80f-c1a82dc286f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44fdef49-00ce-4edf-948e-744ef774fd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75c235f-d4c4-4672-8284-964b8c233224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940c076a-4474-4122-b260-5a759094d59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f05b6ee-102a-4cb6-a8cb-817d57969a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7026075d-2da3-41a4-b3fd-f1a09a7a4234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11527b82-1f83-46e2-a427-397e74c679fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99863d6f-ba8d-4d9e-9921-d9f027f92ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd34f0c-dfca-479f-b359-2ae714610662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec03e31a-d6ec-4b30-b5e4-6aa8f682a4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb3a5e6c-7663-4c51-9067-7f3d083e64af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7654b438-62b6-4ae3-8808-30bd5c6a9aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd017fa-d56e-4f50-926b-5b0267f3b5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2298b6dc-d459-4721-a032-6ddfc85bc80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6646fe0-188b-4f8e-9ea6-909a3940c949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b32172d-69eb-4849-98ff-a1d1c0ed2071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4e3f0e-1936-4c60-9331-995b53e7779c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ff14c0-5b1e-468c-a439-3b29961d332e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2adabbb-9b9a-4e40-9f59-d64b1e0935ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2435036d-1302-4a2f-9ca8-5cab434df1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c7578e-3e5b-49d0-ac2e-894b819f6664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7414d6d9-146f-4269-9c49-fd505bbf37cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 313dcb6f-381c-446c-b8f6-60b7f5c8e500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d031b14a-81e7-4529-b6ba-7bb4c96eca60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a92fd5-5b99-4730-8c36-8b2116306408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd463758-81a5-42ea-9ce8-d623f40d4c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab93fd6-3061-496f-85ca-ba792b82623a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a04169-7652-4811-a5c4-133f8c24445c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf736f8-38f3-446a-aff0-c9e6aed7f714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4ddd34-568c-4de2-a2cb-b7ee8e6fad6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ce30fd-2abc-4d65-b0d9-d92b36269f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530aadf2-5241-4540-9c00-4e2f1a45c654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598046a4-57f3-4044-b13e-42542ce0791b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e1507a-be57-4b2b-9878-1b354323ff5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aef39d2-e290-4313-bdbc-4753e84f1f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d38dd59-ae67-4bd1-83fb-297b7458b527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8768f676-def1-44fc-80d8-50bd07539edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2097f1b-413c-43cf-a589-99898c390026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc734cb1-0f59-42a2-9cd6-7a9b12ee45db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7edceb71-d02e-4f63-9f7a-8be007357468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663d0385-2fcc-476e-ba7b-de4f042381b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7500a9c-e744-4abf-8e02-66f9af0dba1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0640838-770f-4234-9682-dd7b6c547347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123f1b2c-5e51-4e22-8536-16988398b1ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e7ebe5-783c-4b3a-bddf-e8409d315381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56da3eea-be7a-48e9-a367-ee268d374871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94af30b-ba37-4bb4-9474-d68bcbd3bc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042c8230-fbad-4059-9e19-1fe52c63afcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44138bf4-5af3-4e9e-960d-46981104f433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e23bc0-78bb-485c-b626-f49d170f871c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf05d52-b4f8-4cb0-8e52-3a58ea849387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7492a81c-9709-4b73-8449-52666ab8497f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b85657-cb83-4e33-8ab2-54bb156cb0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676690fe-9dfc-4208-959a-e7396c815852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47962b6b-ea36-43de-b5c7-c217b928a5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0873888-3465-400b-8056-1f0b1bf5b761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8aa30c4-612b-4531-ad43-14c92c6fd3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48796b5-4032-4d95-af21-7d1ae9567f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041a7cfc-65de-4878-b3a7-0824d7e01dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82573d0c-90f8-4e08-ae94-624c5f5a7de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b9cb10-822f-4123-ab4d-5d77da9ffdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365becb7-d1e1-4bf2-98a0-689746867a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c35db5b-0c0a-4406-a356-f529d520dbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 165025cf-2222-4c60-901a-f501d32eaebb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(6065, 24), y=(6065,)
   Test:  X=(1517, 24), y=(1517,)

⚠️  Limiting training data: 6065 → 800 samples
⚠️  Limiting test data: 1517 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3699, val=0.1426 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1070, val=0.0855 (↓), lr=0.001000
   • Epoch   3/100: train=0.0886, val=0.0850, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0848, val=0.0825 (↓), lr=0.001000
   • Epoch   5/100: train=0.0853, val=0.0825, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0848, val=0.0815, patience=3/15, lr=0.001000
   • Epoch  21/100: train=0.0840, val=0.0810, patience=8/15, lr=0.001000
   • Epoch  31/100: train=0.0825, val=0.0807, patience=6/15, lr=0.001000
   📉 Epoch 41: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0784, val=0.0793, patience=6/15, lr=0.000500
   📉 Epoch 49: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 2 Summary - Client client_1
   Epochs: 50/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0608
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0442
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.5203, RMSE: 0.7214, MAE: 0.6628, R²: -5.4283

📊 Round 2 Test Metrics:
   Loss: 0.5100, RMSE: 0.7142, MAE: 0.6550, R²: -5.3010

============================================================
🔄 Round 9 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3924, val=0.3226 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2125, val=0.1032 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0920, val=0.0773 (↓), lr=0.000250
   • Epoch   4/100: train=0.0868, val=0.0783, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0867, val=0.0771, patience=2/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0861, val=0.0775, patience=8/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 9 Summary - Client client_1
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0339
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0168
============================================================


============================================================
🔄 Round 10 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.4213, val=0.3718 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.3519, val=0.3281 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3067, val=0.2799 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.2534, val=0.2217 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.1921, val=0.1602 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0843, val=0.0853, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 10 Summary - Client client_1
   Epochs: 24/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0004
============================================================


============================================================
🔄 Round 11 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.4440, val=0.4303 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4336, val=0.4233 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4268, val=0.4170 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4206, val=0.4112 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4149, val=0.4059 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.3896, val=0.3827 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.3732, val=0.3672 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.3667, val=0.3610 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3625, val=0.3569 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3584, val=0.3529 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3544, val=0.3490 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3505, val=0.3452 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3467, val=0.3414 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3429, val=0.3376 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.3383, RMSE=0.5816, R²=-3.0330
   Val:   Loss=0.3342, RMSE=0.5781, R²=-2.8167
============================================================


============================================================
🔄 Round 12 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4359, val=0.4411 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4353, val=0.4405 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4347, val=0.4399 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4342, val=0.4394 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4337, val=0.4389 (↓), lr=0.000001
   • Epoch  11/100: train=0.4309, val=0.4360, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.4268, val=0.4318, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4230, val=0.4279, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4194, val=0.4242, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4158, val=0.4205, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4122, val=0.4168, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4087, val=0.4131, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4051, val=0.4094, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4015, val=0.4057, patience=1/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3986, RMSE=0.6314, R²=-3.5306
   Val:   Loss=0.4023, RMSE=0.6343, R²=-4.6718
============================================================


============================================================
🔄 Round 13 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4177, val=0.4209 (↓), lr=0.000001
   • Epoch   2/100: train=0.4174, val=0.4205, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4169, val=0.4201 (↓), lr=0.000001
   • Epoch   4/100: train=0.4165, val=0.4197, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4161, val=0.4193 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4137, val=0.4169 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4098, val=0.4130 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4058, val=0.4090 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4019, val=0.4051 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3979, val=0.4011 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3939, val=0.3971 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3899, val=0.3931 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3858, val=0.3890 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3816, val=0.3848 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3777, RMSE=0.6146, R²=-3.5065
   Val:   Loss=0.3810, RMSE=0.6173, R²=-3.3360
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.4162, RMSE: 0.6452, MAE: 0.5790, R²: -4.1422

============================================================
🔄 Round 14 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3911, val=0.4457 (↓), lr=0.000001
   • Epoch   2/100: train=0.3907, val=0.4453, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3903, val=0.4449 (↓), lr=0.000001
   • Epoch   4/100: train=0.3899, val=0.4445, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3895, val=0.4440 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3872, val=0.4416 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3833, val=0.4374 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3793, val=0.4332 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3753, val=0.4289 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3713, val=0.4246 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3672, val=0.4202 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3630, val=0.4158 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3588, val=0.4112 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3545, val=0.4067 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3502, RMSE=0.5918, R²=-3.2563
   Val:   Loss=0.4025, RMSE=0.6344, R²=-3.3340
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3879, RMSE: 0.6229, MAE: 0.5540, R²: -3.7926

📊 Round 14 Test Metrics:
   Loss: 0.3318, RMSE: 0.5760, MAE: 0.5008, R²: -3.0990

============================================================
🔄 Round 18 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2949, val=0.3179 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2942, val=0.3171 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2934, val=0.3164 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2927, val=0.3157 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2920, val=0.3149 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2879, val=0.3107 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2813, val=0.3039 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2749, val=0.2972 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2685, val=0.2905 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2621, val=0.2838 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2556, val=0.2771 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2491, val=0.2702 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2426, val=0.2634 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2360, val=0.2564 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2298, RMSE=0.4794, R²=-1.7229
   Val:   Loss=0.2501, RMSE=0.5001, R²=-1.9350
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2832, RMSE: 0.5322, MAE: 0.4523, R²: -2.4985

📊 Round 18 Test Metrics:
   Loss: 0.1783, RMSE: 0.4223, MAE: 0.3456, R²: -1.2028

============================================================
🔄 Round 22 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1743, val=0.1603 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1735, val=0.1596 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1727, val=0.1588 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1719, val=0.1581 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1712, val=0.1574 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1666, val=0.1531 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1594, val=0.1463 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1526, val=0.1400 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1462, val=0.1340 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1402, val=0.1284 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1345, val=0.1231 (↓), lr=0.000001
   • Epoch  71/100: train=0.1291, val=0.1182, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1241, val=0.1136, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1195, val=0.1094, patience=1/15, lr=0.000001

============================================================
📊 Round 22 Summary - Client client_1
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1155, RMSE=0.3398, R²=-0.3518
   Val:   Loss=0.1058, RMSE=0.3253, R²=-0.3021
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2460, R²: -0.0287

============================================================
🔄 Round 27 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 27 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0084
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0511
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2456, R²: -0.0236

📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2449, R²: -0.0159

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0009
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0329
============================================================


============================================================
🔄 Round 34 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 34 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0033
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0012
============================================================


============================================================
🔄 Round 35 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 35 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0031
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0052
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0097

📊 Round 35 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2443, R²: -0.0093

============================================================
🔄 Round 41 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 41 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0061
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0035
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2442, R²: -0.0086

============================================================
🔄 Round 45 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 45 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0124
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2441, R²: -0.0069

============================================================
🔄 Round 47 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 47 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0046
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0076
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2441, R²: -0.0066

============================================================
🔄 Round 49 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 49 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0035
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0031
============================================================


============================================================
🔄 Round 50 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 50 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0003
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0107
============================================================


============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0041
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0204
============================================================


============================================================
🔄 Round 52 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 52 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0030
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0049
============================================================


============================================================
🔄 Round 54 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 54 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0016
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0016
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2439, R²: -0.0047

============================================================
🔄 Round 57 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 57 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0005
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0091
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2438, R²: -0.0041

============================================================
🔄 Round 58 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 58 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0020
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0024
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2438, R²: -0.0040

============================================================
🔄 Round 61 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 61 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0142
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0030

============================================================
🔄 Round 67 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 67 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0019
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0113
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0030

============================================================
🔄 Round 68 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 68 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0033
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0155
============================================================


============================================================
🔄 Round 69 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 69 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0012
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0007
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

📊 Round 69 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

============================================================
🔄 Round 72 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 72 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0019
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0015
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0030

============================================================
🔄 Round 75 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 75 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0023
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

============================================================
🔄 Round 76 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 76 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0016
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0000
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

============================================================
🔄 Round 77 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 77 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0018
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0023
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0032

============================================================
🔄 Round 79 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 79 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0036
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0193
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2437, R²: -0.0031

📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0031

📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0031

============================================================
🔄 Round 83 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 83 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0019
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0009
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0030

📊 Round 83 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0028

============================================================
🔄 Round 86 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 86 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0023
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0028

============================================================
🔄 Round 88 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 88 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0029
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0035
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0031

📊 Round 88 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

📊 Round 88 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0032

============================================================
🔄 Round 91 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 91 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0004
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0058
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0032

📊 Round 91 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0031

📊 Round 91 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0031

============================================================
🔄 Round 95 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 95 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0028
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0309
============================================================


============================================================
🔄 Round 97 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 97 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0017
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0031

============================================================
🔄 Round 98 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 98 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0012
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0008
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

============================================================
🔄 Round 99 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 99 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0035
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0031
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0037

============================================================
🔄 Round 101 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 101 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0039
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0100
============================================================


============================================================
🔄 Round 103 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 103 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0066
============================================================


============================================================
🔄 Round 104 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 104 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0024
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0045
============================================================


============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0038
   Val:   Loss=0.0957, RMSE=0.3093, R²=0.0000
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2439, R²: -0.0043

📊 Round 105 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2439, R²: -0.0043

============================================================
🔄 Round 108 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 108 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0054
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2438, R²: -0.0039

📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2438, R²: -0.0038

📊 Round 108 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0034

📊 Round 108 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0033

============================================================
🔄 Round 114 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 114 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0007
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0122
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

============================================================
🔄 Round 120 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 120 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0020
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0026
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0029

============================================================
🔄 Round 121 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 121 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0008
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0036
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0028

============================================================
🔄 Round 125 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 125 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0010
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0027

📊 Round 125 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 128 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 128 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0019
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0034
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 131 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 131 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0001
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0050
============================================================


============================================================
🔄 Round 133 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 133 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0019
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0025
============================================================


============================================================
🔄 Round 134 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 134 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0000
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0054
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

📊 Round 134 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 137 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 137 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0018
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0018
============================================================


============================================================
🔄 Round 139 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 139 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0012
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0069
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 140 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 140 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0048
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0140
============================================================


============================================================
🔄 Round 142 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 142 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0053
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0132
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 142 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 145 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 145 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0016
   Val:   Loss=0.0724, RMSE=0.2692, R²=-0.0017
============================================================


============================================================
🔄 Round 146 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 146 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0018
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0026
============================================================


============================================================
🔄 Round 147 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 147 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0031
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 148 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 148 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0007
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0062
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0024

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 155 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 155 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0005
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0059
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

============================================================
🔄 Round 158 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 158 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0004
============================================================


============================================================
🔄 Round 159 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 159 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0018
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0137
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0028

============================================================
🔄 Round 160 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 160 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0033
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0033
============================================================


============================================================
🔄 Round 161 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 161 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0005
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0072
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0030

============================================================
🔄 Round 164 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 164 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0027
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0068
============================================================


============================================================
🔄 Round 165 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 165 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0154
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0027

📊 Round 165 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0026

============================================================
🔄 Round 168 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 168 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0035
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0025
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

📊 Round 168 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 168 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0026

============================================================
🔄 Round 177 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 177 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0040
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0667
============================================================


============================================================
🔄 Round 178 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 178 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0027
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0354
============================================================


============================================================
🔄 Round 181 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 181 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0005
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0007
============================================================


============================================================
🔄 Round 182 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 182 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0021
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 182 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 186 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 186 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0030
============================================================


============================================================
🔄 Round 187 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 187 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0024
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0049
============================================================


============================================================
🔄 Round 189 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 189 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0011
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0075
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 192 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 192 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0013
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0052
============================================================


============================================================
🔄 Round 193 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 193 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0036
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 194 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 194 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0018
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0064
============================================================


============================================================
🔄 Round 197 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 197 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0013
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0132
============================================================


============================================================
🔄 Round 199 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 199 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0028
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0063
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 205 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 205 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0007
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0005
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0028

============================================================
🔄 Round 206 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 206 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0021
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

📊 Round 206 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 210 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 210 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0007
============================================================


============================================================
🔄 Round 211 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 211 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0008
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0002
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0027

📊 Round 211 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0029

============================================================
🔄 Round 217 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 217 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0008
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0003
============================================================


============================================================
🔄 Round 218 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 218 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0000
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0063
============================================================


============================================================
🔄 Round 220 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 220 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0985, RMSE=0.3138, R²=-0.0121
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0030

============================================================
🔄 Round 224 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 224 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0012
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0108
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

📊 Round 224 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

📊 Round 224 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0027

============================================================
🔄 Round 229 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 229 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0012
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0047
============================================================


============================================================
🔄 Round 230 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 230 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0017
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0200
============================================================


============================================================
🔄 Round 231 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 231 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0007
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0045
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 231 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 235 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 235 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0025
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 237 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 237 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0023
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0077
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 237 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 240 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 240 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0020
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0030
============================================================


============================================================
🔄 Round 241 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 241 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0006
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0053
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 242 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 242 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0009
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0005
============================================================


============================================================
🔄 Round 244 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 244 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0020
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0003
============================================================


============================================================
🔄 Round 245 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 245 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0013
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 247 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 247 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0016
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0037
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 247 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 247 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 254 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 254 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0001
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0016
============================================================


============================================================
🔄 Round 256 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 256 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0010
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0113
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0026

📊 Round 256 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0026

📊 Round 256 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

============================================================
🔄 Round 260 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 260 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0031
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0122
============================================================


============================================================
🔄 Round 262 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 262 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0017
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0059
============================================================


============================================================
🔄 Round 263 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 263 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0027
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0068
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 266 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 266 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0074
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0026

📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

📊 Round 266 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

============================================================
🔄 Round 272 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 272 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0008
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0013
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

📊 Round 272 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 275 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 275 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0000
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0016
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

📊 Round 275 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 278 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 278 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0000
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0209
============================================================


============================================================
🔄 Round 279 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 279 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0105
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 281 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 281 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0002
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0035
============================================================


============================================================
🔄 Round 282 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 282 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0007
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0021
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

📊 Round 282 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 289 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 289 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0005
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0094
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

📊 Round 289 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2436, R²: -0.0015

📊 Round 289 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2436, R²: -0.0015

📊 Round 289 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2436, R²: -0.0013

============================================================
🔄 Round 294 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 294 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0020
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0051
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2436, R²: -0.0012

============================================================
🔄 Round 296 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 296 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0012
============================================================


============================================================
🔄 Round 297 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 297 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0146
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 300 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 300 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0008
============================================================


============================================================
🔄 Round 301 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 301 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0019
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0034
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 301 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 301 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 307 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 307 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0005
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0006
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 307 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 307 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 307 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 313 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 313 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0023
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0102
============================================================


============================================================
🔄 Round 314 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 314 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0102
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 317 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 317 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0002
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0129
============================================================


============================================================
🔄 Round 318 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 318 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0061
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 318 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0017

📊 Round 318 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 322 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 322 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0008
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0019
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 322 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 325 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 325 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0020
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0017

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0017

📊 Round 325 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2436, R²: -0.0013

============================================================
🔄 Round 338 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 338 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0027
============================================================


============================================================
🔄 Round 340 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 340 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0023
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0126
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 342 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 342 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0007
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0125
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 344 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 344 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0004
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0017
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 345 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 345 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0109
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 345 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 349 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 349 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0027
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0540
============================================================


============================================================
🔄 Round 351 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 351 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0024
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0098
============================================================


============================================================
🔄 Round 352 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 352 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0042
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 354 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 354 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0003
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0002
============================================================


============================================================
🔄 Round 355 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 355 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0014
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0044
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 355 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 357 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 357 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0004
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0000
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 359 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 359 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0001
============================================================


============================================================
🔄 Round 363 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 363 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0005
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0002
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0026

============================================================
🔄 Round 369 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 369 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0876, RMSE=0.2961, R²=-0.0092
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 372 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 372 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0012
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0101
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0027

📊 Round 372 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0030

📊 Round 372 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0029

============================================================
🔄 Round 380 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 380 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0000
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0066
============================================================


============================================================
🔄 Round 381 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 381 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0005
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0006
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0026

============================================================
🔄 Round 382 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 382 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0009
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0039
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0027

============================================================
🔄 Round 383 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 383 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0004
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0050
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0026

============================================================
🔄 Round 384 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 384 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0017
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0071
============================================================


============================================================
🔄 Round 385 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 385 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0023
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0055
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0028

============================================================
🔄 Round 387 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 387 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0011
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0036
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2438, R²: -0.0031

📊 Round 387 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 390 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 390 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0010
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 392 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 392 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0424
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0029

============================================================
🔄 Round 395 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 395 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0000
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0047
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0029

============================================================
🔄 Round 396 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 396 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0002
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0025

📊 Round 396 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0025

============================================================
🔄 Round 398 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 398 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0001
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0055
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0025

============================================================
🔄 Round 399 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 399 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0002
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0070
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2438, R²: -0.0025

============================================================
🔄 Round 404 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 404 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0007
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0062
============================================================


============================================================
🔄 Round 406 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 406 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0006
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0041
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 408 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 408 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0018
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0026
============================================================


============================================================
🔄 Round 409 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 409 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0012
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0022
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 413 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 413 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0002
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0133
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 417 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 417 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0011
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 417 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 420 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 420 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0012
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0092
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 424 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 424 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0044
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 426 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 426 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0001
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0043
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 426 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

📊 Round 426 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 426 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 426 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 437 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 437 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0076
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 438 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 438 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0005
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0062
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 440 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 440 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0008
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0041
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 440 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 442 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 442 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0002
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0006
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 442 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 448 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 448 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0012
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0025
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 457 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 457 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0010
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0024
============================================================


============================================================
🔄 Round 459 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 459 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0012
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0021
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 459 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 459 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 459 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 459 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 466 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 466 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0010
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0035
============================================================


============================================================
🔄 Round 467 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 467 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0006
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0031
============================================================


============================================================
🔄 Round 469 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 469 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0004
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0036
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 471 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 471 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0016
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0038
============================================================


============================================================
🔄 Round 472 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 472 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0057
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 472 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 484 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 484 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0014
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0094
============================================================


============================================================
🔄 Round 485 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 485 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0002
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0017
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 486 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 486 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0007
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0021
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 488 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 488 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0010
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0037
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 488 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 488 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 493 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 493 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0007
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0067
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 496 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 496 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0266
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 496 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 499 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 499 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0043
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0667
============================================================


============================================================
🔄 Round 500 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 500 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0001
   Val:   Loss=0.0813, RMSE=0.2850, R²=-0.0123
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 500 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 500 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 500 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 507 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 507 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0011
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0061
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 507 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 510 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 510 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0012
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0043
============================================================


============================================================
🔄 Round 511 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 511 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0016
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0082
============================================================


============================================================
🔄 Round 515 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 515 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0004
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0069
============================================================


============================================================
🔄 Round 517 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 517 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0011
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0083
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 519 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 519 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0011
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0254
============================================================


============================================================
🔄 Round 521 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 521 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0001
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0003
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 522 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 522 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0018
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0087
============================================================


============================================================
🔄 Round 523 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 523 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0010
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0050
============================================================


============================================================
🔄 Round 525 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 525 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0029
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0056
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 527 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 527 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0019
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 528 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 528 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0002
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0055
============================================================


============================================================
🔄 Round 530 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 530 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0007
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0127
============================================================


============================================================
🔄 Round 531 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 531 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0022
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0026
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 534 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 534 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0007
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0101
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0024

============================================================
🔄 Round 536 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 536 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0009
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0047
============================================================


============================================================
🔄 Round 539 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 539 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0006
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0002
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 543 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 543 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0011
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0061
============================================================


============================================================
🔄 Round 546 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 546 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0005
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0028
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 551 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 551 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0011
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0069
============================================================


============================================================
🔄 Round 552 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 552 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0005
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0025
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 553 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 553 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0006
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0012
============================================================


============================================================
🔄 Round 554 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 554 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0001
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0134
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 556 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 556 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0045
============================================================


============================================================
🔄 Round 557 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 557 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0006
============================================================


============================================================
🔄 Round 558 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 558 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0046
============================================================


============================================================
🔄 Round 559 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 559 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0004
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0019
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 559 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 559 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

📊 Round 559 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 564 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 564 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0003
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0004
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 567 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 567 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0009
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0056
============================================================


============================================================
🔄 Round 568 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 568 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0009
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0067
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 568 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 568 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 568 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 574 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 574 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0021
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 574 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 574 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 574 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 582 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 582 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0002
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0078
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 584 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 584 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0008
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0031
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

📊 Round 584 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 586 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 586 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0025
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 589 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 589 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0004
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0001
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

📊 Round 589 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0014

📊 Round 589 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0014

📊 Round 589 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0014

============================================================
🔄 Round 594 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 594 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0002
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0021
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0014

============================================================
🔄 Round 600 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 600 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0007
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0050
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 600 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 603 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 603 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0000
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0006
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 604 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 604 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0002
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0036
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 606 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 606 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0009
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0028
============================================================


============================================================
🔄 Round 607 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 607 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0023
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0086
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 608 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 608 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0005
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0031
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0014

============================================================
🔄 Round 610 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 610 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0026
============================================================


============================================================
🔄 Round 613 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 613 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0003
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0020
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0017

📊 Round 613 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 617 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 617 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0011
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0048
============================================================


============================================================
🔄 Round 618 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 618 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0004
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0030
============================================================


============================================================
🔄 Round 619 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 619 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0009
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0028
============================================================


============================================================
🔄 Round 620 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 620 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0005
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0006
============================================================


============================================================
🔄 Round 621 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 621 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0017
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 621 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 628 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 628 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0003
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0211
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 630 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 630 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0100
============================================================


============================================================
🔄 Round 632 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 632 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0007
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0019
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 634 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 634 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0000
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0043
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 635 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 635 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0015
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 636 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 636 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0001
============================================================


============================================================
🔄 Round 638 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 638 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0004
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0004
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 643 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 643 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0009
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0038
============================================================


============================================================
🔄 Round 644 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 644 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0006
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0031
============================================================


============================================================
🔄 Round 647 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 647 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0005
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0001
============================================================


============================================================
🔄 Round 648 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 648 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0000
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0101
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 650 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 650 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0001
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0176
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 651 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 651 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0001
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0019
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 653 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 653 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0000
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0083
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

============================================================
🔄 Round 655 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 655 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0102
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 656 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 656 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0014
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0099
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 656 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 659 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 659 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0049
============================================================


============================================================
🔄 Round 660 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 660 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0008
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0042
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 662 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 662 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0013
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0090
============================================================


============================================================
🔄 Round 663 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 663 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0022
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0056
============================================================


============================================================
🔄 Round 664 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 664 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0001
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0017
============================================================


============================================================
🔄 Round 665 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 665 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0021
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0083
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 665 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 668 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 668 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0009
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0046
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 668 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 674 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 674 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0038
============================================================


============================================================
🔄 Round 675 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 675 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0004
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0005
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

📊 Round 675 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

============================================================
🔄 Round 678 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 678 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0011
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0098
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

📊 Round 678 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 680 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 680 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0002
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0066
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

📊 Round 680 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

📊 Round 680 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 684 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 684 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0008
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0094
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 685 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 685 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0012
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0039
============================================================


============================================================
🔄 Round 686 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 686 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0004
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0070
============================================================


============================================================
🔄 Round 687 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 687 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0011
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0042
============================================================


============================================================
🔄 Round 688 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 688 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0008
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0038
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0016

============================================================
🔄 Round 690 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 690 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0014
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0043
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

============================================================
🔄 Round 691 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 691 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0002
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0006
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

📊 Round 691 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 696 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 696 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0001
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0139
============================================================


============================================================
🔄 Round 698 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 698 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0010
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0036
============================================================


============================================================
🔄 Round 699 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 699 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0057
============================================================


============================================================
🔄 Round 700 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 700 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0013
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0103
============================================================


============================================================
🔄 Round 701 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 701 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0071
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 702 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 702 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0013
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0001
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 703 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 703 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0009
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0117
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 703 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 703 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 709 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 709 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0008
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0043
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 711 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 711 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0005
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0003
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 712 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 712 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0006
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0012
============================================================


============================================================
🔄 Round 714 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 714 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0008
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

📊 Round 714 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 716 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 716 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0012
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0034
============================================================


============================================================
🔄 Round 717 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 717 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0005
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0034
============================================================


============================================================
🔄 Round 722 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 722 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0003
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0001
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0019

============================================================
🔄 Round 725 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 725 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0018
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0314
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 728 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 728 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0011
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0121
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

📊 Round 728 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0018

============================================================
🔄 Round 731 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 731 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0009
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0048
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 732 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 732 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0007
============================================================


============================================================
🔄 Round 733 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 733 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0002
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0006
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

📊 Round 733 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

📊 Round 733 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

============================================================
🔄 Round 739 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 739 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0008
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0030
============================================================


============================================================
🔄 Round 740 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 740 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0004
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0021
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0015

============================================================
🔄 Round 746 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 746 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0002
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0007
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2437, R²: -0.0012

📊 Round 746 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2436, R²: -0.0010

📊 Round 746 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2436, R²: -0.0011

📊 Round 746 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2436, R²: -0.0011

📊 Round 746 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2437, R²: -0.0013

============================================================
🔄 Round 752 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 752 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0003
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0059
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 754 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 754 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0000
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0158
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

📊 Round 754 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

📊 Round 754 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

============================================================
🔄 Round 761 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 761 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0003
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0024
============================================================


============================================================
🔄 Round 763 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 763 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0005
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0022

============================================================
🔄 Round 766 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 766 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0046
============================================================


============================================================
🔄 Round 767 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 767 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0005
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0011
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0021

============================================================
🔄 Round 769 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 769 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0007
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0142
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0023

📊 Round 769 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

📊 Round 769 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0020

============================================================
🔄 Round 772 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 772 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0113
============================================================


============================================================
🔄 Round 773 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 773 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0006
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0004
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2437, R²: -0.0017

============================================================
🔄 Round 776 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 776 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0003
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0031
============================================================


============================================================
🔄 Round 777 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 777 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0021
============================================================


============================================================
🔄 Round 779 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 779 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0006
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0038
============================================================


============================================================
🔄 Round 781 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 781 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0012
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0109
============================================================


============================================================
🔄 Round 782 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 782 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0031
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0212
============================================================


============================================================
🔄 Round 783 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 783 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0007
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0020
============================================================


============================================================
🔄 Round 784 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 784 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0002
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0028
============================================================


❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
