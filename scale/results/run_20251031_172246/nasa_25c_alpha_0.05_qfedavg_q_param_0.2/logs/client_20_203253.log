[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51dae295-7e88-4b9e-8158-18b56bbdeca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36b768a-5f4c-4407-b30b-36141b9271a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b502ac-c9d4-43dd-a766-e4718a0fbf36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0ca2c9-1026-44f6-a840-ed23b3303c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec460ceb-ee24-4668-8efa-00747b80ac43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c1bbcd9-db3c-4949-bf50-f620abf02884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac048b77-d3b3-49f5-b49e-4f8fcd08c570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0dbad97-4570-443d-809b-4842ca2262eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bef9a4a-305c-45cc-8816-7361f50cd21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09116cb7-7541-4449-b037-ffaf9af7ce08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810075b5-5a26-4be9-8fb2-4127348dc405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19715cda-77c1-490b-9a3d-c072809a287c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63015bf-b3c3-4817-ba8b-dd2b6e421557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c37bcb96-38d2-41e3-ba4c-3ceeca1e5333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2257d94-1076-4248-a635-4eff3a0376b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972123ae-dc86-454d-804b-7810ab5608f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20089b87-704a-4967-abc5-6ca5828f21b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719a1839-2431-4f1e-821c-b59e514fd9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28806857-461d-4742-b250-02cb399b6e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d08b37-0ac0-4bc2-984c-ea478c415c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd41f12-4e27-4d75-a3b8-7bade4eef182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda9ed86-e0f2-4dfc-a78a-7d2ff8644200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 337f133d-ff54-4f47-bcd7-3f9f09a500a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680a92b5-8c5b-4192-a2c6-463efa512ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f53add0-870d-4229-9e99-88ea11b5b891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a11bfa-acee-4555-87e0-f2ee142f250b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5da3d1d-134e-4a11-a0a1-761bae4d97ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24b715c1-b724-43da-8b15-bc4143a11585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec400ce-c5bc-4ccb-9a38-4623f5f80d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e8d009-f08f-4bfb-85b2-dba6cbb4533f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395678b0-9713-46ef-be7e-0087b0b18bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b81268-b822-4416-876b-662242ace3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db0ace65-a406-432f-8ef3-489dca807ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ca1a5d-ab31-4881-ae88-c280dfaa7c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b013f4a-13e3-4467-9f54-d5f2a320652e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96476c4-51a0-4cda-adee-cf53feca119c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed135393-206e-4c3d-a939-36b3e1a54bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbde42b-394a-4a65-b2c6-3ecf04e3359c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd932e6-de1c-4d31-9f0f-10d8f14297ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8339a6-0d26-4916-8d0d-66d29e472249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d5678b-3a53-409c-8ecb-3b02f36f3ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 654a013f-ee9b-4696-9fd1-652c24aeb7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f59438-5589-4635-9e87-a79b181d84ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c32af549-db63-4ac7-8ed3-d6506c4f2f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567da596-8625-47ab-b1a5-06a4432e2b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8764e852-6a79-4281-a4b9-500c12872f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cdfcfde-a391-4099-816a-30d69ed47b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb5126a-8f1d-46c3-b28d-d624847edf32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8724015b-47da-4657-bc7a-3c24a1b42b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cad6f49-7454-4726-a809-1cca058e7b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d328bb-b58c-4fe1-8c88-73bc8c099d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe66f67e-8c21-4b54-ba34-213f185ea0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d20a22-b580-4bcb-ab65-4b18feeebdc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12951c34-fe96-4271-a9fd-637821e57ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93cd3e2-3c0a-4743-aabe-17ef0ceaaa6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e2789d-c7ff-42d4-8d23-9702ce5d39bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5762ba4c-aa87-4a17-8371-becb5257bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8aec461-fbb0-4a0c-ae38-c7c1269b1c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e9377c-fa40-4063-9bc2-0e02ace56108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffdfe311-a1c4-44dc-a099-24d661fa306c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d6b144-20a2-48a7-9cf1-54135d11da4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40aeb79-81f7-4ff1-ad6b-e4aa37c99cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65316f9e-7ace-4c2f-bf88-959c73d8a888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9393966-1462-4ce2-acdf-74a79b8a6c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701e6020-5937-4c5d-8e6f-94bf968f1ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326e6fb9-bf39-4b63-817e-f233396bbb35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7073650-327d-4fa0-97d6-d3bf78f1d111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35698911-b957-4123-a8e0-38cb4c61e868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae7b212-0df6-4715-bd21-ff34e386530a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aea4f7-df6d-47e9-9340-f72632ea4fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad78829-d4d9-4976-aba1-d2fe8a3e1777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fefce1-a5f2-4ab1-a6c5-238a49889f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e114bdbc-9ab5-44ee-b7d8-2ff7ef3c2812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cdc06d-5a63-42f7-a937-f0c9b0a28b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b63497-a903-450c-8505-a58b4e7712c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec70b5d-717f-454e-9b6b-37b6186e17d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0db013-863f-4f1b-90e8-5b5f5ac28320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504f8eeb-b37b-4f4e-99ba-af1cc3eff6b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b74a33a9-fbd8-49d1-a89a-e0a08a2d92a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7300bef4-62ca-4f60-8f02-ba94a9e57971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5fd335f-4d27-4ca6-becb-17447d69135a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4902cc3-c4c7-40e0-9ab1-03be54db17f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0bd5b6-0b12-40f0-aebd-f3ee9efdc580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43598de-1b0d-49b4-b70e-46caf9ea37de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d5249d-c060-4f3e-893a-b1534ffad43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee02433-fd60-4767-a9a4-911aa89f1de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f665bcb-df2d-496c-9b56-b16be25bf51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5349df-d7ea-490b-87d3-ebb694f20549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ef7f3d-073e-4acc-8893-353469f6ba29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90226c8b-1f01-4b76-9e66-b5d99125cd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbc14b5-d7b9-474a-8a3e-b3301a9eda25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c9960b-e588-443c-858a-eb17834fdeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cec982d-3a8a-49c6-866e-4066be5f403d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92208e1a-922d-42ac-95c2-dcc3e11eb4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31878f1d-713f-4368-89bd-37b6c8973b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b9a66f-ffe7-48d7-a31d-4dd6981a947a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa07917-fc03-4d8e-960f-c82dda6ab3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78e33df-837c-4d21-930f-627ae1c71208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5d3a2c-6170-4eea-8b11-95b0a7dc0daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ae23bb-5a3c-4ca7-b76b-111139775855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b6a8e0-ec88-4ffd-bdd9-9dae276189c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2fd45ca-0287-46c6-b4d0-3753c79ff2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a865dd7-2b37-47d2-9f42-b854872917cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6921531d-e0be-4b99-8a05-178e1cdc4936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3008767-6663-48dc-9878-4eac323d4793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6d3d50-09ed-4ecc-b62f-c40d1e0b876c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c938245b-1d96-4d94-b3a7-87eaf87115af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197e9bab-7bc2-4bfa-ad16-b580f9c3cf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9881c534-3530-48b5-ba73-3755be9cda94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a90502-370d-4088-ab40-0db9eea9818a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e987100-6c7c-447b-817c-1a2719223ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247a5ff4-ecfa-416d-a8d1-19e99a6564b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1b8396d-82b7-4837-9952-4550ec4f140e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d319ed5a-35d2-4907-a63c-e4247a1e3b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413419c2-9218-428a-aad8-19a0b7719fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafc14be-7d94-4c4e-8da4-cc9f73359bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0008a47-ccca-4492-b0be-3c3273ddae1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393d3ee0-7063-415e-83ed-ebe2a059f587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533f12c4-f2c4-4746-a2cb-ec05a5ea9ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd223b95-4aee-42ca-9b19-96564a555484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b552308-3e3b-4ed2-b737-c1b72154bafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f39662-0dd1-4a6e-b98d-46b42c2a39ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de01b80b-fcfb-4fef-989b-421b73bb6b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de463e7-33ee-4092-8802-495fd13cc239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e901b48-de2c-4f44-a173-df9233e748c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe62a8ed-554b-4bf8-850c-e6ad1e9871c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb337667-75de-435d-82ed-a22a39897131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 703be44c-2c8c-4138-b833-9cd7f43a5759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8186f6d-a67b-4987-ab0e-a4d206426ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2675e2-ebf7-45e3-8923-bd02fdaed3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097f8776-07d1-4480-b74c-1291576c9242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934c4d42-3f1b-4cff-82d1-1c8da7e50c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7727b775-e9f2-49e2-8ab8-4db83af18fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239f1392-e724-40ec-ac6d-4b6264340487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b5a335-8c09-4bbf-85ed-36e11f406099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe46f782-5525-4e99-85b3-9ed69416fb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b80449-062f-42af-8b9f-24cbde697214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40458fd9-4957-410a-bba9-de2d5c3969f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a5345a-e6f3-4d4c-bac7-c1802da0d25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7fccf54-0d17-4dd0-9b4f-71c6cb7458f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42e72ea-424a-48dc-92ab-a2488b0e0072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 312b34c6-4caa-428d-9174-45dd6ebef30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36c0370-766f-44b5-b24e-de65145b72d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779773a4-8e02-43c0-a976-10d176a296f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 211f8ed2-c50f-4c7a-bf21-2c9de83f780b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d9d90d-0a4b-4a98-b2dc-131fe29cb3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a356ad72-baa5-4199-bcd8-eebd5141fbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59bf58a-a5f8-4b94-932d-e34f19a0c0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ca9432-bfaa-49f8-88e6-7c129296612a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75bd4f2e-39ea-4253-b138-b8785f6a36fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71be10a8-bbba-4470-abf2-36d196c7a808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80ae872-3172-4c56-9e78-15d56b055726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b8862fc-2345-46c4-8950-db64aa30a69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f098b7-2820-4a04-a1ac-4a7af51c26cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7df5ba-a7b0-414c-a715-cb1f8ef0d8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a78502-3207-4152-99a8-3077e8337caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f279bd-2833-4f62-a0f6-d9d85ae6a080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005c1a83-e62f-417f-9bfe-4bd06e2778ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766ebf80-93e5-4d08-bd59-87dc3b3c0651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebdf48a6-173a-4663-8126-d682d1d3527e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3393591e-b5a7-403c-80f2-b9e4c58f83c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5473cd2f-5ce6-4465-94f4-873ca49cf092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5566184a-c761-48bc-8f3a-1bc0e52ec69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dffadd5-6306-4ca5-bbba-8257cce0fd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa74952e-6c8a-4a05-af2d-b7fb84147ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbbde658-3f8a-497d-92be-bb55be4cd059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 300ebf79-31c8-4d66-8706-5b6a0c741fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1621d1-4d74-403a-ad6a-19b5ae6bd764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f97d806-bdc7-49ba-a791-cba477623223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e1af3eb-89bd-4ee4-a0c6-a22fe18b8e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c3261d-6579-4317-bdea-72aff115dd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7935d770-7ee2-4fcc-814e-c33c4c9ec36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212d953a-abec-4b05-9b83-884b71651379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871c30d3-5dd6-4432-8912-096ccf6117a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc82032-175d-45eb-bad4-05736bafb022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0131ec1d-72ad-43f2-b777-da0ce2c42786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff95344f-59a9-49f0-9c52-8f4348e7f7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1831a192-3759-408e-9fe6-784e78faa1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e859d50-497d-413e-930f-a8ff73414fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc8465e-92a9-450a-a221-22cbf8246f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb952ac-6a8b-4f0a-baf1-f5c9fd4e8fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354e9b74-1de6-4db1-9a24-699979927012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90ccd55-7d8b-4e55-a8a9-d20bb22406c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d2a344-965f-4455-93e8-153799bdc0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4451689-159b-4ed6-bbd8-0b0e25e8a97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f85340-324b-4b1c-9bc2-f17d112800bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f6ca55-9f1e-4ac3-8ace-2ea5690ea033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5807fa-0fde-4e32-a353-440de165ef66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89e7917-a845-408d-b759-665282264eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c7664e-ded4-42c8-970b-467a89415c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2901d1-42be-4d5a-840c-f8a185a7eb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1080a9ea-3673-46be-9334-7277fc940c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ff5a4e-464e-4041-a7b3-41bdc756019a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922fd8be-877f-4699-81c1-0d0a13b0219e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fdf1c4-4da7-40e6-93a2-3eb302a3bc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69cd58c8-a4b4-439b-8e64-95a21f98f52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e941cae4-dc71-4982-a543-762560afc032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13f5a7ef-448a-4b1f-8558-95d8fd751b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33f92e0d-d074-4ec0-b1e8-ba6f16e78a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4696a7be-eded-45df-8e41-548eb2af8a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98d67a4-a6c7-4a4c-85f2-d88577361af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ff8d68-b658-4275-9da5-9dd38e2a316e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e29bd6-ad1d-4322-8e3e-05e2c131612f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1564affb-94eb-45c3-8684-7e90ccd4a957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a653eab5-f72a-44cb-9134-505633c881a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a882f8-ffee-4b24-b419-67c704964d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb85be1-3b5e-426f-a82f-bf5a2168718a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73dffc4d-a64b-434b-8199-ae3e73f841c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9accd95b-67ad-49e7-ab5c-69da8367a656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d15454-1f4b-4818-ad04-49150095b8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44be4c7e-57d5-4594-b87d-21f9a14be276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c151ee0d-0e99-4694-a3ef-812908e6c4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee643c5e-b3f4-4445-bd59-d937c487e37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca61c8fd-40e6-45b2-acc9-6d71697ed150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0feced3c-b09e-49f0-968e-497035897edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ee0bb3-4ee7-4a10-8d20-394ae22ea888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8087e220-cc39-4fe1-aa3d-74fd54866684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffa0851-3242-4b7d-8a5b-6b1891d7fc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e37303-7441-4be9-9137-2e60e7f0e50f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2bfa41-e5b0-41a1-a8f7-3036524d4f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1235a86b-1b91-4f66-a7f2-d8b288767981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f699773-f002-49bc-a210-a66001233514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461f6e11-39db-46a0-b5e9-328601c9315e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31387e52-afd1-4f22-bf20-1cf438070066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d886cede-5118-4522-b1a7-1dd9c83d7422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb5184d-368b-498e-bcfb-e5b772c2cca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d681d4cb-14fc-49bf-852b-df1144ffb286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e493712-1aad-43df-a8c5-06d6f0a855ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08903106-2d4b-446e-965d-8e9760116a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b994ab9-5551-4a66-aae6-11f779dfbe62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f976fa70-4cc9-4635-9023-da4f9ddfd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ccbbe4e-58ae-4335-a341-0003aa3439a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9ed9ed-e8e4-49d1-8be6-7a3ab716831e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf51b8cd-9ae8-42f1-ae55-c84f6d6fdfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f3fa92-f255-4355-b202-493d3fa50e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d2cc70-e4f7-4c74-9b71-65701257a0ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ac68a2-f8a1-430a-bba5-9651fcc98466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68587d8d-c696-4c20-bc94-e96e9ec20226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad61e5e7-c277-41ae-a532-b490720f3013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a17d36c-579b-4423-8a68-45f50bf6c523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65125b34-a028-48c2-a91f-b777fabc2b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ed8720-0e80-4bdf-a96b-bb447d3d7464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626b036b-a834-422d-a0dd-14bde3c4d6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8aa510b-c6c2-4470-a486-f0be71ed6870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9e30b0-81f9-4bb3-bde3-f90bd8d0b7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf3848e-c456-44b5-b9bb-e6d432ed0a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f168631-576a-4e2a-b6d0-7859a581cad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9aeb86-17fe-4ec5-8335-4283f0db8dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb101ba-265d-4456-841e-c716df66269d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd643ca-cf62-4ceb-b4bf-c182f25e6865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8acd87-734b-4a63-b0a1-e6d45be55458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e7b348f-6e66-4180-93b9-414522a83c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226bb036-4d7e-4891-bb1f-57678a75b3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1baed04f-ea46-41ff-85e4-39faa4946287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4af01c1-dc62-4636-8681-05f23904e734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d594a8c3-5aca-4446-8220-12577b341550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3d8c4d-b32a-43df-b594-d0214a5306ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef98ca4-5a31-4fd0-a2e4-b4141f69d4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f20ba1c-d61d-4493-b504-6b036d1f8e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dbcad0e-6da1-46d1-95b0-637c46876981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1883008a-5852-46a9-bc91-02dd23d4de29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d710f5-6153-4399-89f4-42a85f2847d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b205ce89-b0b7-4930-be56-4884041ccb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9688849-0ed2-4e10-8540-9cd3932f2676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51857014-c016-4583-9b8a-7dbc1479e805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2610bc-834e-4ca4-871b-794a6aad003d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31238065-6954-42f2-acbc-67a33b9b3b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423f751b-0d9e-4902-b72c-0e5478771e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9905cce6-d7ff-48a3-b4bb-985c5e014511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a5377d-039b-41da-9fd6-fdb982928f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a2aa0e-db9b-4189-b430-735d56ff5341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9450a205-115c-4e7e-b65b-eaf8c4f5f7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e0a06a2-3b2b-4984-935c-112d0ea53a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab14d27-7947-4b97-ba99-ea3a6f077328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070f576e-e4d6-4d35-9404-9a4dce19d0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce265d13-26f2-48b5-ba18-e4389933c1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39fd9b95-c98d-4463-b792-44df07c0336e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1890e39-dcff-4a25-ad42-e7a640794c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65087557-6fc9-43cc-9e51-4b3caa16a846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3cae564-775a-471b-af3f-14c521052ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c51ff6-dea6-4f82-bdc9-1d6116b86306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bd7165-a8ca-4b1d-984a-743d98e33381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047a9c4e-dc16-4b58-9dca-0fa4670a90ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d77577-6d78-42f4-85ad-40f6afd14d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28581be6-76bf-41a2-beba-0bc1cc7a7eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7be906f-6e03-4ed4-90f7-b487d259022b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe2e879-0af7-41dd-b52e-99228601fc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cb86fe-8a0b-41f2-9c64-2f30b31f470b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674a3984-d2ba-445c-9170-678291e009db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4500318-33d7-46f5-9d7e-1b8a568c79e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150ef2fd-b244-4d13-8b00-3698ef552a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f096a44e-0113-4cb9-9f62-f4a07e108970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bffcce0-6387-4409-b729-61823d819eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725d43b9-3dfb-4ed8-b4d1-b32d62ed49c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb16ebe7-27b6-44ef-aab7-f9c1cf9abce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bbcad0-feef-4072-9cac-a5c4021e59f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0698574a-58fb-4759-9efb-230e86378abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed5c588-d0df-4e82-ad51-a76bb5f71a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfb4c80-4608-4703-ab5b-cd1917f3ed46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1224243-bb44-4367-8fe9-07ccfa9bde12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97c8195-cefe-43d5-8009-54fb95ba7ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c519b542-a1b7-457b-8d13-c9dbc8c840b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2499e4-6399-4b12-80cd-f0ccfa662f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bd1d79-2e19-427b-bd92-e27da84711dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb91d3c-c14a-409c-aa28-623f5408c8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efb6977-8f25-42d4-a283-bb8aec22f799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e3fef6f-f6c5-4d44-829a-a94b513369fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777bc6e7-f5fd-4473-bcb0-2f8612470df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1480cf68-934a-4027-a6e6-fb5b4739e82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7ba95c-ffa5-4385-9146-081d77aedf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d19252-d0ff-4105-b8ce-5fc436d2a8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929251cc-bdee-4eee-8bc8-1e5fe7db3669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1672ca-521f-4f0f-a23c-2f5d67516016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e1519a-cb0f-4088-8968-09c38f91e854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5778b590-b237-4d1e-bc65-3651a405172f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5b05cb-00f0-48b9-a631-165ba749158a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1a2ce2-1b0e-4a99-a8fc-869680351110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0402e406-0b78-4c07-9f9e-b1e93fd8ec18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f3d638-6613-46c2-887a-d1a4880d6f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c79bd3b-0ad8-45f8-bc8a-581aeebe819b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aeb257f-a919-4ba2-acf3-dfa2ee45ba84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca803be-9e7d-48b6-bc4a-b3b2a4ded65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b57609-d7f9-4632-ac91-60391f448ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6727d334-10b8-48bb-bcea-7ddd5c9320a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c9c9c4-3849-48bb-b394-2e286ab01034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb9241f-3158-409b-9b7f-dfb47048f5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60556505-5072-49a0-836c-baf28b0e36f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdd69ea-05c4-40d9-8a50-be6cfb095237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8608b50c-b90d-4f0a-8ea3-899b8886fde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62465c29-343f-4498-b811-f0fb3b668aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294cf7cb-2f6e-4916-a4ef-0abcbfa18046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ba6bda-ae1a-4c86-bc14-70020915e334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4a671b-70fa-4c4f-800a-c2016d22a4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b31643a-aaa0-4eec-9489-9816d9ef6230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfac5cf-ddfe-4e27-b567-1ea4d1ea061a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bd7014-6eb5-4bff-bc88-b996963a11b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d26042-4184-430a-b34d-b7c7210a21db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779dcd76-3d06-47a3-b3f3-ea8a3fb5258d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af726890-6d2e-4197-9fee-1cfd9f38ed23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f65909b-c963-4b0c-a44f-24c0e699eb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7d9ced-b1b4-4878-808b-fc86a239c16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5af69fd-f12f-40d7-bec2-28d9a133745c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1affc61e-5738-4937-ab91-9e704f6605e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d30d860-f94c-460a-9614-43a74228ef37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040bef0c-6469-4ff1-9b83-5fb83c805ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f611699f-6a32-4339-b2e1-fab8d5f9b315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bba19e8-6727-4a95-b5eb-a0fdfb0ba30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d0fa5d-67e8-4497-be64-90891228a57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a51e0e0-d4c5-45d6-83a7-c0d2b8f1b95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704f6bb4-a1e5-4ce0-89d2-f71c48a7b486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ac57f9-989b-4984-b3fc-cafa1a488d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b415fc8-806c-498e-8a62-ad441ecda7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c86f4db-5088-4379-a407-79824e298552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789818d7-83d9-420c-bb6f-80b1618b1919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dffa543-d9c4-4f8f-a39e-086cf70f7ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32974d1e-443e-4fa7-8323-00cf3314e8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34a6160-60d0-4f5e-bd09-edc050c13ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3ce2d4-c664-4cfe-a023-78fa75cc48d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2ca725-aa13-4477-a42c-9000db0dde51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45575510-29b7-41ee-986b-c2ac43b384ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8186dd3b-9af6-4f3a-b2a4-50beb306baea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973f611e-445e-4f5b-be44-64eccad0bc22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8723686a-7cca-43c0-8975-d25711ffa857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b1ff4b-6060-4580-bc80-76dcf311b7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bb5f4d-075f-4e9f-8a8d-f0bea48da8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50dddfc4-40ad-4a21-9b27-1eb2cfa3929b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d91cb5c-fb70-4dc0-81dd-e6f9580b22cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f13195-d963-424d-933f-9aa3418e4850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1684bf38-1be8-4ee8-8c61-6f4566f4621b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198c4ddc-081b-4a1d-abe2-f53e712ae644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4634c087-9a4f-4e29-b6a2-5b1d535ad678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa13c74-cada-451a-9c5b-725e632b8082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2c5afb-9b7a-42f8-99b0-066a3cfaa9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e0db1f-9c1e-4a27-87a0-859381746db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6334204-7cb1-4d5e-ba65-8c3a66004d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fa374d-631a-4730-9f81-822e993c0295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8516e183-e6c3-4886-8aa3-6a76600d6ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29fd15f-dd8a-4836-b3c2-c021fae2e670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ee4703-db55-45d8-a8ca-99c9b1ab98a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2237371-8d8b-4ae9-905c-69a00fb066c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e7cef1-4c09-4a70-9dbc-7416eec1738c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd2378c-6ab6-4f54-ad85-aab26d949c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860b6bb6-7d42-4ddf-8360-e8125f53fd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf0bddc-22d4-45aa-b922-f813c21972fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac85efb-e266-407f-ac77-95246f362160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58bb871a-88f1-4ccd-a382-aba9e4a5afcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e004fa86-1b0e-4735-8f07-db11a2e5b7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f391747d-bff4-4cec-ac28-01bd6f24b0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38fbb1fa-c748-4eec-bf53-df537e787516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f63a79-7d64-4d29-a843-d7cbd00c4843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422f2fe2-9cac-4922-8ea0-cd43da0e93f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f534965-eceb-4430-974d-9f2ef4ebd874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac78396-90ad-4623-8135-08b87a3347ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116df55c-7c4d-470f-819e-9857f0005f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32dcd135-8ad1-495d-bdd8-a89ee0db0345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd463af-fba2-407e-9382-9a3ba894cd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00468e61-c5c4-4d7c-8a1b-30e795530dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8830659-a6ae-4481-8696-499819adfe4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184d23bc-12a6-4891-b587-e50a77389e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20c8b35-daff-446b-ab20-8840ebebbab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed7af83-ef2c-4eba-87c5-9843c5b9e7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196ed860-4225-4c20-8bba-d34a4f00b365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce36da9-493e-449c-b9e9-34e181c1471d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bdaccdc-e85e-42d2-a3d5-f61ce9701cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0286988-f86a-41a6-848a-50dfa80f36bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab875e7-965b-4292-8008-6e4d00925dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85922ba5-0917-43e1-a8e3-5d708c606bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b861dc32-3bef-4353-aa67-7a4c79c09171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bdc2b2f-7e72-4300-b198-28de01e025c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e151af4-af16-40d7-917a-169e927ce856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc25399-bd16-41d5-a1cb-0e03c70a5867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57071d06-380d-4750-9596-add9a7b452d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d22aff1-3c41-47a0-a48f-95693046e7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d372a70-3849-4d23-88d1-d0ae704a28d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80663f3b-f3ae-4074-9461-345188c04c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e956447-8d12-45e5-b5f5-199d65274c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c719fc6-5efd-4756-9f5a-f071f803bda0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4156d69d-d63c-44f7-b192-e09245d278e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec71468-f354-4786-bc96-d1b6484951b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdcd506-cd3d-404b-a4bf-2bb6c0c1e762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a375bdd-5041-4848-89f4-f6acd48d6609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020f8780-a552-4f5c-b8d3-2df97d89a2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d668c4b-dc91-43e5-aee5-9e54bf28ca1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36576bbe-e346-4420-ab56-49398ed4bc22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b336eb-06c7-49e2-a9e4-7c184790f55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6030dd-2ff8-47f1-9410-a354ab66db2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36276924-f67c-4c21-84fe-c0b556f4e1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e96899e-02f1-46ba-be8f-0e3fa9830001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9812f42-af2b-4127-b071-ddd6cf93097a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cfed4d-020d-4531-9ef7-2e5337d24705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85082e11-6866-4eea-abe7-e77d86b90ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0b397e-a707-48e3-9eb8-98c10731f96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dec2f66-eda8-4419-9e98-1bb91be8fad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd50ca4-ca72-44b5-b7f3-e744835f9b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d8b872-e1c1-400d-aa31-ed755a689e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7097f1-b27c-4e24-be08-a75ad6794c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6bb8c6-7b8b-4c28-8d4a-5305f2ee5cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83356708-361c-482b-a949-d177aa3b47d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b34578-8123-46d6-8250-0fe2c586936b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751e264a-70c8-4f70-a189-7a59d76bec8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c29df9-077c-4bff-b08e-4c0479d7868d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438bcfa7-39fb-44bc-a106-b296c9bc5ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8a21a2-6c81-42c9-97a9-15a5e01a534d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8cd6786-82b1-426b-843f-911cf2777a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebed75bb-93a3-4910-8b18-f718269ebe6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2688a09-d76f-4ee9-90f2-1f5bdaf950a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d1bf3c-f8b5-4512-9924-9bc3b15c2ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b04bd23c-be76-4021-a120-715905e65a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b168e6-cb4e-44d0-a1bd-4ebf22e39882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0ea8b9-4b41-4e7a-88f0-cf44fbe23d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77baf5f1-e767-40f3-a907-4e5c0a4ee4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0854bf0-ce7c-4627-be8b-b136ec969611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e5e24c-1d05-4f61-88ca-ced1d0789390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9dd870b-4903-43ab-a10d-10907a484028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235c45fd-22a6-41b6-b00e-da229e5e1f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab17574d-e5a7-4d53-917a-baf1c819d261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f086c91-b935-45ea-9562-803a42800e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5598f095-38a3-4683-950f-d421aa3da8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b78dba7-d86a-47bf-b6ba-f24123f02177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b83a2b8-d144-45dc-ae48-abcaa1779570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a947913-7006-4ae3-84aa-dc47d1c272e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfcafffa-e6e9-41d3-b94a-bb7920cd97b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f4b0d42-624d-4792-83fe-be86d819bc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a197c08e-d5fe-4004-8b8b-c2b0a07493a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbc9a2d-c9ad-4b62-8a33-b1be99c150c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4396de90-48ea-4931-8f0a-46e2de23ed9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d97d6e3-67ab-429a-b590-92741496c90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f388b1-2c62-4a9e-96d3-cfb90964ef04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d83b0933-38c9-4963-be62-c32f509f94cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95058a97-0a18-4c97-b426-b1d863699a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac367857-a113-42bc-9d72-5b40b86ee532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eccc021-3057-49c5-89ce-3ff122af5687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb051e0c-d95e-40c1-b1ec-04a60d7a27c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34b7531-7c31-4b93-90aa-b538a4134453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726496e0-c792-44a2-bf33-4bab09cea13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef864367-1adb-423b-a6b2-5bdb700c4a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b144ad38-818c-407a-9dc2-a4cbe604c050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643df85d-255d-4b42-9e45-b8322fbf2297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487c959c-05ca-4e15-82bd-e7bcd55caa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c145791-caa4-4991-95b0-d9d78fd4f9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16290bd-c8b5-4fc0-977f-941289457adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b298c1c3-7b27-406d-8f78-6490b2cc615e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38f2beb-a06d-4d3b-aa1f-c52399fa0717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8f4d0b-1e40-4926-bd5c-6be476c76e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c485eda-d4bb-4d81-ad01-a7bef0e10e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b42fb60-4a38-448a-9702-e82423f92078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b9b878-2567-4e51-ac7c-c66b6aaf3fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a6b1a9-aa01-42fa-a007-88ac7bd01973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445227f5-1c39-4913-b955-a3d60b7fe968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8e0db7-86bb-4fb3-a904-ef5cfd5ecb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 004531f9-2b1f-4d85-85d6-ca2f344907bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4e7c9a-051a-4261-bc07-b95f05ac7301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131f5b4f-b586-41fc-8a65-1b827584dcdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da6754d7-d6e5-4bde-bcb4-0fc3520a556a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e167a63e-cbb3-42c5-9d8b-1bc4fe81a030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7cb96d-27d9-46b6-9cf1-bcc4f09d8a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2181d293-f091-4e2a-8aaf-74c52fe61386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef2d3521-348b-4e77-9614-d549deafa5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e1d50c-5d40-49f8-adb0-45ad8140e339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c317c6-6ccf-45ae-a1ae-e90a2419ea79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da76ee4-fa27-44a4-9d92-099a7bad0a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cffd3de6-f330-48ff-b72d-7a9b18a0d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7a1de2-961d-417a-ab07-37cce56e8822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d0e5e8-fff2-40e9-950a-e7c48ca1aef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020f3f87-5156-44d3-953a-fce879065e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ecaf7b-55c1-4da6-b23a-7a954020de18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56542c7a-eb1f-46aa-9cdf-9b84ed1b70e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112f6ab3-cc72-42fa-b918-f67edab4b1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6eecba6-afa8-44e8-ab7b-61b443a14f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b21770e-b9b5-4570-a1b6-415ba553b5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78930888-2680-48da-99d5-100a4bd94dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38aad108-680f-4066-ac87-bdc2c20c82ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e40e0d-2bf1-44e5-bde4-bd58387f6ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94293db9-ab0a-4217-9bf4-eb501c9c67a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37a92e5-74fc-4dc9-8593-00c4f65f327d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667b52b9-c01c-4367-b495-560ec4c9438d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7e83bb-47b3-46fb-bf12-3118e17f518a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ad38e0-3fac-46af-a9de-8c8db8f8af57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff978d8d-4708-4cb5-9723-5b2031595941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843b3c07-2d0f-420c-95f6-f805a9327e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c317f2-fc1e-44e1-b959-be3e42b1b875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d26e43a-2ff4-47ef-b667-75aebf5a78bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f273b6c-59eb-4e36-989b-832faa8b7b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8e152a-7b8f-4eaa-998a-8f69ac8766c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32475aa0-cf90-4ac9-9992-b1b3984f0ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d040fde9-fc5d-408f-875a-c2c3641b39b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e9ee20-5e66-4e37-9849-6377ae0f086a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53154f6-475c-4993-a9df-04189279f32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e99cbf5a-cfff-4b9f-8d37-8a51af3be71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32d4820-2c81-4ffa-891b-4a77487a89de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd138a06-8b9b-4cb4-835e-7b5812b7b3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3931df17-960e-41ea-9e1e-35561b05238a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6a11fb-5031-4d12-930d-b2aeb69a08a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c37143a-50ce-43fe-a906-338bda68d5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0b94920-f995-4ca5-b722-02b07991e429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e88053-f020-4aec-a4f6-e16fca13f7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4d651e-75c9-4c7a-ad51-12e5adba055d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d78d375-3342-4154-9a0e-59f7c25fbe61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107d6671-7511-488a-a528-17363002d8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c2432e-f3c7-4b37-a3b2-bd3a4ff30646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f364237-8de8-4696-83f5-2aba2f8b741a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc5cbdd-d276-4e55-b05c-c5030de421fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea5ff68-a2af-4c11-91f2-5bbf79990661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b34dd78-b4e2-44fd-b181-6f29dbc389ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8966c035-f4c4-4239-bcf2-a8380ce1e748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e09a40f-5dc5-4ffb-9593-58b7188d0070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e5dad6-1354-482a-af63-1eae77c0aa88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011931e1-f583-46ef-bd20-bd198af1a00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3feddcdd-e5a6-4224-ad35-7e3a864e15f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf1a6482-649f-472f-acfa-b293e57af4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67b5044-3527-4550-bad5-0ea9b34c8bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8f7c80-6e79-4648-815f-c5b9f1bf0db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f336d9-7a60-4b00-ab56-b8545f74454b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6b7fde-0371-4d5e-a528-4974417090e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6782b5-db2c-4a23-bf40-5edbaa44bfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480bb175-f8de-420a-9587-6e9ac182548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3a8ef8-8701-4c35-98cf-3c7ce099f85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06fdcc6a-37e6-4399-8be0-553560a8f046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc516c1-f8e2-4581-81ee-208164a8f228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d186d6bd-8846-4886-a99b-ae0edb098d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad1caaa3-1347-4020-9e75-dd53685e560c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ad0322-ca26-4ed5-bbd4-f43750e9abfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39202419-f580-4170-b7c5-f5b35f1fc818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85eae2d3-0768-43b5-9902-4c6d7d928c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88c33f8-bde8-4867-a0d8-533fcd646c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89e6dcb-43eb-4dfe-b0d8-1f95d9a175a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4014735-4f4b-4f75-ac87-9aca85cfba6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01495fa6-8c2c-4ceb-981e-c287e020cc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c578566f-9d60-461b-8e2f-ba0973a2f951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246e6c00-74a3-4cb4-bb23-a464eb828da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45173ee3-c620-4fca-83f6-f76ed6b82022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e34540c-8713-4de9-a9b0-e2e90dc84290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc00f70-f820-4ebb-8fa5-13111652f762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61876194-ca47-4b39-bf3b-096c64fb9c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0eb4f3f-444d-4032-b3ad-bc3f81daf8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6547754e-6ac8-41e9-ac76-31ac08cc1278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f339d8a1-22a9-4e54-857b-37727c8673f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df735d30-4eb3-4964-bc2f-957ebf8bed3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f47be22-3acb-4c67-acaa-0fdb7378412f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c18a5-b437-48b6-a381-3ca7baa96f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c97c17b7-6e8b-470d-af07-d77588a9fe60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72064392-6111-4f86-9b94-93ae1a304995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ff321e-afeb-4ed7-a865-68df1e7857b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67efb96-9a00-4ba3-a34f-a5225646837b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00eef4b8-b885-4f90-b820-100331f40eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81921dca-7824-426f-8e51-a7fcec8c7034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de1649e-5747-484c-97ac-f879b0a79ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1498a770-c274-4bd4-8485-5c62bff11783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71b64ab6-5115-488f-9c3f-93b11dd1d24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322e939a-bdab-4d37-ba27-abc0ab454d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206269b6-2f64-43b1-976f-7ef6876938fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1615e57d-8ca3-45ec-b594-823e6fc019ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dffbc1f-9d11-48e2-a187-0548e6c4b64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1994d5-7336-4bb2-bf30-9196fbb6fd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be14aa8-e4f2-46fa-bda4-5eae3067ca89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ee47cd-7d4d-42c3-b642-6eb89f819fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55394524-3b61-4167-bbdf-b12aae148b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb57b00-9d0d-45e3-b8d6-30ae2354ad97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a68957-d885-4532-8e03-16641f3fb2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a91983-c880-4964-be77-c9be68439ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6c5093-103d-4d99-881d-ef8d0e02fd64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25565ee5-358b-465b-82c1-eee503070664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2e1efe-ba00-4570-9468-473cb5e7c9f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af41d9e-1505-441d-8182-147236850635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23037030-3bbb-45ad-9427-9383401e351d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d32d58-d6b7-4177-a449-0c8182c3a2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d67962a-2f2f-48c3-ba49-5a757553d963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e20f6da-9cc1-4984-aaa3-9741c177cd9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d543728b-5b70-412c-b65e-6be2f58e6914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d735355-9cdb-4194-9c82-0a869441d08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc1e5f8-5146-4f9a-b7b7-8949aa024759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8443a7ba-9560-4e8c-92b5-296b4e780d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d565fcb0-e286-4db4-8020-204f5d7cb83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79048188-76bc-48af-9b4c-bb8fdc52bd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5015b81-be98-454e-b248-b7bc743b4161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239f4e8d-9990-4c3d-8368-a9e1688a8dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2dd44b-b1a8-4c6f-b64d-df05416c7994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e480473e-3402-4410-85f0-b075509b2abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbaffaf-5f4f-4d3b-b6d2-6dab9fccdd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd653602-2f8a-46c5-be42-9775742477a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8823fc6a-abab-482a-a8b8-61d4cdf208e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f982f9de-c3e6-40b8-841b-bdc628780889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4923269-1de7-466a-802c-0ff0264c03e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8911db18-044b-4151-b105-278f0fbc6391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2e30d2-98bf-4ec1-93a4-61340584f44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 567591bf-905d-488a-822c-2c3163595e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14ff18a-ef5a-4c15-8a1f-3d7239b3356d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a2ff36-a5ea-4fde-a9fa-ec7e7c74c795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ea1235-d695-4793-8960-dc1436ddce25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea3604d-4e16-451d-bca4-069a81808432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d41563-cd2e-4ef0-8e31-32388f492a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da7aa1df-e912-42ca-9e24-70ce8e9a6f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b109c874-ad40-412e-bcd4-a15a6a95981d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aab6d70-399c-4f50-b3c9-5a520cd7f074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c1eee4-2878-42ec-976a-44110c276710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7e87e6-60a2-44df-b8ca-12efa70071a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9b164c-9ce7-4e18-a1c3-edc746713563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f5f714-2d7e-4e93-b66e-a21be7b958ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122140d8-9e1b-4840-8958-5a908a88a9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c844d8cf-ed06-4aae-9d07-a369fd939f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7733fad-8025-4981-bff2-f6455003b3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2ee23d-a771-4bbe-959c-b0c41b784892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c719cb7-2a23-4fcc-a163-aaf157bde670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edef2e68-7c14-4163-af18-c677c390785a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac63f9b4-7178-4b98-80b7-348d85852d30
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(6680, 24), y=(6680,)
   Test:  X=(1670, 24), y=(1670,)

⚠️  Limiting training data: 6680 → 800 samples
⚠️  Limiting test data: 1670 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3702, val=0.1575 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1054, val=0.0879 (↓), lr=0.001000
   • Epoch   3/100: train=0.0869, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0876, val=0.0875, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0871, val=0.0876, patience=3/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0861, val=0.0881, patience=9/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 2 Summary - Client client_20
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0157
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0192
============================================================


============================================================
🔄 Round 3 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.4351, val=0.3512 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3028, val=0.2370 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1635, val=0.0861 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0926, val=0.0786 (↓), lr=0.000250
   • Epoch   5/100: train=0.0882, val=0.0794, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0883, val=0.0789, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 3 Summary - Client client_20
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0080
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0032
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4836, RMSE: 0.6954, MAE: 0.6334, R²: -4.8724

============================================================
🔄 Round 5 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.5018, val=0.4118 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4597, val=0.3780 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.4259, val=0.3512 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3970, val=0.3263 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3692, val=0.3019 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1946, val=0.1547 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0874, val=0.0929, patience=1/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0847, val=0.0949, patience=11/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 5 Summary - Client client_20
   Epochs: 35/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0407
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0017
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4674, RMSE: 0.6837, MAE: 0.6205, R²: -4.6757

============================================================
🔄 Round 10 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4731, val=0.4371 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.4701, val=0.4340 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.4669, val=0.4311 (↓), lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   ✓ Epoch   4/100: train=0.4640, val=0.4285 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.4620, val=0.4272 (↓), lr=0.000002
   ✓ Epoch  11/100: train=0.4552, val=0.4209 (↓), lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.4497, val=0.4159, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4455, val=0.4119, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4416, val=0.4081, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4378, val=0.4045, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4341, val=0.4010, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4305, val=0.3975, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4269, val=0.3940, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4232, val=0.3906, patience=1/15, lr=0.000001

============================================================
📊 Round 10 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.4195, RMSE=0.6477, R²=-3.8133
   Val:   Loss=0.3875, RMSE=0.6225, R²=-3.6122
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4334, RMSE: 0.6583, MAE: 0.5924, R²: -4.2627

📊 Round 10 Test Metrics:
   Loss: 0.4248, RMSE: 0.6518, MAE: 0.5851, R²: -4.1584

============================================================
🔄 Round 12 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4489, val=0.4355 (↓), lr=0.000001
   • Epoch   2/100: train=0.4484, val=0.4351, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4480, val=0.4347 (↓), lr=0.000001
   • Epoch   4/100: train=0.4476, val=0.4343, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4472, val=0.4339 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4447, val=0.4315 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4408, val=0.4276 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4369, val=0.4238 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4331, val=0.4201 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4293, val=0.4164 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4255, val=0.4127 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4217, val=0.4089 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4178, val=0.4051 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4139, val=0.4013 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4113, RMSE=0.6413, R²=-3.7683
   Val:   Loss=0.3978, RMSE=0.6307, R²=-3.5194
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4061, RMSE: 0.6373, MAE: 0.5690, R²: -3.9317

============================================================
🔄 Round 13 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4273, val=0.4266 (↓), lr=0.000001
   • Epoch   2/100: train=0.4269, val=0.4262, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4266, val=0.4258 (↓), lr=0.000001
   • Epoch   4/100: train=0.4262, val=0.4254, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4258, val=0.4250 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4234, val=0.4227 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4195, val=0.4189 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4156, val=0.4150 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4117, val=0.4111 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4077, val=0.4071 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4036, val=0.4031 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3995, val=0.3991 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3954, val=0.3950 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3912, val=0.3908 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3882, RMSE=0.6231, R²=-3.5041
   Val:   Loss=0.3870, RMSE=0.6221, R²=-3.3759
============================================================


============================================================
🔄 Round 14 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4222, val=0.3723 (↓), lr=0.000001
   • Epoch   2/100: train=0.4218, val=0.3719, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4214, val=0.3716 (↓), lr=0.000001
   • Epoch   4/100: train=0.4210, val=0.3712, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4206, val=0.3708 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4181, val=0.3685 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4140, val=0.3647 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4098, val=0.3608 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4056, val=0.3569 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4013, val=0.3529 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3970, val=0.3489 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3926, val=0.3449 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3882, val=0.3407 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3836, val=0.3366 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3783, RMSE=0.6150, R²=-3.3359
   Val:   Loss=0.3328, RMSE=0.5769, R²=-3.0092
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3626, RMSE: 0.6022, MAE: 0.5294, R²: -3.4035

============================================================
🔄 Round 16 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3481, val=0.3901 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3476, val=0.3896 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3471, val=0.3891 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3467, val=0.3886 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3462, val=0.3881 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3434, val=0.3850 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3387, val=0.3799 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3339, val=0.3747 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3291, val=0.3694 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3242, val=0.3641 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3193, val=0.3588 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3143, val=0.3533 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3093, val=0.3478 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3041, val=0.3422 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2998, RMSE=0.5476, R²=-2.4165
   Val:   Loss=0.3371, RMSE=0.5806, R²=-3.1849
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.2894, RMSE: 0.5380, MAE: 0.4556, R²: -2.5149

============================================================
🔄 Round 19 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2812, val=0.2756 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2806, val=0.2749 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2798, val=0.2742 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2791, val=0.2735 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2784, val=0.2729 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2742, val=0.2688 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2673, val=0.2622 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2603, val=0.2555 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2534, val=0.2489 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2464, val=0.2422 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2394, val=0.2355 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2324, val=0.2288 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2253, val=0.2221 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2183, val=0.2154 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2117, RMSE=0.4601, R²=-1.4903
   Val:   Loss=0.2094, RMSE=0.4576, R²=-1.2536
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.2282, RMSE: 0.4777, MAE: 0.3920, R²: -1.7717

============================================================
🔄 Round 20 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2364, val=0.2735 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2358, val=0.2729 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2353, val=0.2722 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2347, val=0.2716 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2341, val=0.2709 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2305, val=0.2670 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2245, val=0.2603 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2184, val=0.2534 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2122, val=0.2464 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2059, val=0.2394 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1995, val=0.2322 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1931, val=0.2250 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1867, val=0.2178 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1804, val=0.2105 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1749, RMSE=0.4183, R²=-1.0412
   Val:   Loss=0.2041, RMSE=0.4517, R²=-1.2916
============================================================


============================================================
🔄 Round 23 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1494, val=0.1384 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1487, val=0.1378 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1481, val=0.1372 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1475, val=0.1367 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1469, val=0.1361 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1433, val=0.1328 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1375, val=0.1276 (↓), lr=0.000001
   • Epoch  31/100: train=0.1321, val=0.1228, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1270, val=0.1182, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1222, val=0.1140, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1178, val=0.1101, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1137, val=0.1065, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1100, val=0.1033, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1066, val=0.1004, patience=1/15, lr=0.000001

============================================================
📊 Round 23 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1037, RMSE=0.3221, R²=-0.1931
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.1529
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.1103, RMSE: 0.3320, MAE: 0.2749, R²: -0.3388

============================================================
🔄 Round 24 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1157, val=0.1360 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1152, val=0.1354 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1148, val=0.1349 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1143, val=0.1344 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1139, val=0.1339 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1114, val=0.1309 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1075, val=0.1264 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1040, val=0.1222 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1010, val=0.1184 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0982, val=0.1151 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0958, val=0.1120 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0937, val=0.1094 (↓), lr=0.000001
   • Epoch  81/100: train=0.0920, val=0.1070, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0904, val=0.1049, patience=2/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_20
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0573
   Val:   Loss=0.1033, RMSE=0.3214, R²=-0.1028
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2488, R²: -0.0053

============================================================
🔄 Round 27 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0850, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0882, val=0.0846, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0880, val=0.0843, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0878, val=0.0840, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 27 Summary - Client client_20
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0081
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0202
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: -0.0031

============================================================
🔄 Round 28 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0914, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0863, val=0.0912, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 28 Summary - Client client_20
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0088
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0111
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2485, R²: -0.0003

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: 0.0006

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: 0.0008

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: 0.0010

============================================================
🔄 Round 34 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 34 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0080
   Val:   Loss=0.1010, RMSE=0.3178, R²=-0.0009
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: 0.0011

============================================================
🔄 Round 39 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 39 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0022
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0191
============================================================


============================================================
🔄 Round 40 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 40 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0035
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0120
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: 0.0012

============================================================
🔄 Round 46 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 46 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0013
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0350
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: 0.0011

📊 Round 46 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 52 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 52 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0020
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0077
============================================================


============================================================
🔄 Round 53 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 53 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0026
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0105
============================================================


============================================================
🔄 Round 54 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 54 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0016
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0092
============================================================


============================================================
🔄 Round 55 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 55 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0034
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0008
============================================================


============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0023
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0117
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 59 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 59 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0051
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0020
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 59 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 66 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 66 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0010
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0054
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 71 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 71 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0033
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0065
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 73 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 73 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0000
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0096
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 74 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 74 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0026
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0006
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 78 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 78 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0016
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0166
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 80 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 80 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0033
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0147
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 80 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 83 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 83 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0003
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0107
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 83 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 89 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 89 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0041
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0046
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 90 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 90 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0037
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0041
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 90 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 93 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 93 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0009
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0061
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 95 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 95 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0024
   Val:   Loss=0.0990, RMSE=0.3146, R²=-0.0120
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 97 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 97 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0013
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0052
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 97 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 104 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 104 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0024
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0008
============================================================


============================================================
🔄 Round 105 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 105 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0010
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0085
============================================================


============================================================
🔄 Round 106 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 106 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0144
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 109 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 109 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0010
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0140
============================================================


============================================================
🔄 Round 111 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 111 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0002
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0135
============================================================


============================================================
🔄 Round 112 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 112 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0056
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0003
============================================================


============================================================
🔄 Round 113 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 113 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0028
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0232
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 113 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 115 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 115 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0023
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0088
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 116 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 116 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0035
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0242
============================================================


============================================================
🔄 Round 117 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 117 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0017
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0127
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 119 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 119 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0030
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0218
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 122 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 122 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0006
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0299
============================================================


============================================================
🔄 Round 123 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 123 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0013
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0070
============================================================


============================================================
🔄 Round 126 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 126 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0017
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0034
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0001

📊 Round 126 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 133 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 133 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0006
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0127
============================================================


============================================================
🔄 Round 134 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 134 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0028
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0016
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 135 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 135 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0014
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0278
============================================================


============================================================
🔄 Round 136 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 136 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0023
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0008
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 136 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 136 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0001

============================================================
🔄 Round 141 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 141 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0012
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0028
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0001

============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0075
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 144 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 144 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0009
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0045
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2487, R²: 0.0000

📊 Round 144 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2487, R²: 0.0000

============================================================
🔄 Round 146 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 146 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0006
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0181
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2487, R²: 0.0000

📊 Round 146 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2487, R²: 0.0001

============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0042
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0088
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2487, R²: 0.0001

============================================================
🔄 Round 149 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 149 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0012
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0036
============================================================


============================================================
🔄 Round 150 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 150 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0043
============================================================


============================================================
🔄 Round 151 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 151 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0006
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0261
============================================================


============================================================
🔄 Round 155 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 155 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0020
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0059
============================================================


============================================================
🔄 Round 157 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 157 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0001
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0099
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 160 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 160 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0051
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0056
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 162 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 162 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0018
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0047
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 162 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0019
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0139
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 165 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 170 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 170 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0016
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0018
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0000
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0081
============================================================


============================================================
🔄 Round 174 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 174 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0008
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0058
============================================================


============================================================
🔄 Round 175 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 175 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0023
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0049
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 175 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0026
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0018
============================================================


============================================================
🔄 Round 180 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 180 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0050
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0343
============================================================


============================================================
🔄 Round 181 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 181 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0029
   Val:   Loss=0.0921, RMSE=0.3036, R²=-0.0076
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 181 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0022
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0003
============================================================


============================================================
🔄 Round 188 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 188 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0029
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0018
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 190 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 190 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0008
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0115
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 192 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 192 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0024
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0091
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 194 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 194 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0010
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0034
============================================================


============================================================
🔄 Round 195 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 195 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0000
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0124
============================================================


============================================================
🔄 Round 196 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 196 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0005
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0058
============================================================


============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0004
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0100
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 199 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 202 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 202 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0017
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0037
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 204 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 204 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0025
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0001
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 205 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 205 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0026
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0139
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 207 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 207 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0001
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0178
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 209 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 209 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0054
============================================================


============================================================
🔄 Round 211 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 211 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0013
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0040
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 213 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 213 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0034
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0047
============================================================


============================================================
🔄 Round 217 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 217 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0015
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0031
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 217 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 219 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 219 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0007
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0176
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 220 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 220 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0035
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0016
============================================================


============================================================
🔄 Round 221 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 221 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0045
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0083
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 221 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 221 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 230 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 230 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0048
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0132
============================================================


============================================================
🔄 Round 231 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 231 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0029
   Val:   Loss=0.0940, RMSE=0.3065, R²=0.0012
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 234 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 234 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0008
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0096
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 238 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 238 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0007
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0059
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 239 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 239 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0063
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0367
============================================================


============================================================
🔄 Round 242 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 242 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0020
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0003
============================================================


============================================================
🔄 Round 244 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 244 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0002
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0171
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 248 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 248 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0013
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0108
============================================================


============================================================
🔄 Round 249 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 249 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0045
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0038
============================================================


============================================================
🔄 Round 251 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 251 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0024
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0055
============================================================


============================================================
🔄 Round 254 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 254 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0012
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0039
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 258 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 258 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0036
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0013
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 261 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 261 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0003
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0115
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 262 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 262 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0033
   Val:   Loss=0.0977, RMSE=0.3126, R²=0.0012
============================================================


============================================================
🔄 Round 264 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 264 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0028
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0138
============================================================


============================================================
🔄 Round 265 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 265 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0135
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 265 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 265 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

📊 Round 265 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 271 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 271 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0021
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0088
============================================================


============================================================
🔄 Round 272 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 272 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0043
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0024
============================================================


============================================================
🔄 Round 273 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 273 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0023
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0020
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 275 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 275 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0028
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0005
============================================================


============================================================
🔄 Round 277 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 277 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0053
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0111
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 277 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 277 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 277 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 277 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 284 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 284 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0032
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0035
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 284 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 284 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 284 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 290 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 290 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0018
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0002
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2488, R²: -0.0000

📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2488, R²: -0.0000

============================================================
🔄 Round 296 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 296 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0036
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.1006
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2488, R²: -0.0000

📊 Round 296 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0003

============================================================
🔄 Round 303 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 303 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0028
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0021
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 305 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 305 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0001
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0104
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 306 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 306 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0002
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0101
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 311 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 311 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0004
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0329
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 314 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 314 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0057
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0038
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 315 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 315 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0004
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0083
============================================================


============================================================
🔄 Round 317 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 317 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0049
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0089
============================================================


============================================================
🔄 Round 318 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 318 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0026
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0028
============================================================


============================================================
🔄 Round 319 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 319 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0010
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0107
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 319 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 319 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 323 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 323 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0018
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0011
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 328 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 328 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0018
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0017
============================================================


============================================================
🔄 Round 330 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 330 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0037
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0085
============================================================


============================================================
🔄 Round 331 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 331 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0006
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0234
============================================================


============================================================
🔄 Round 332 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 332 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0001
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0104
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

============================================================
🔄 Round 334 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 334 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0026
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0250
============================================================


============================================================
🔄 Round 335 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 335 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0022
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0005
============================================================


============================================================
🔄 Round 336 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 336 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0001
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0146
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0002

============================================================
🔄 Round 339 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 339 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0008
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0125
============================================================


============================================================
🔄 Round 341 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 341 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0007
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0155
============================================================


============================================================
🔄 Round 342 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 342 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0013
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0110
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 342 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 342 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 348 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 348 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0015
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0020
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 350 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 350 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0002
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0083
============================================================


============================================================
🔄 Round 351 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 351 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0007
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0130
============================================================


============================================================
🔄 Round 356 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 356 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0004
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0078
============================================================


============================================================
🔄 Round 357 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 357 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0021
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0006
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 358 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 358 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0032
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0046
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 360 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 360 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0016
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0018
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0007

📊 Round 360 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 362 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 362 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0031
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0014
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

📊 Round 362 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

📊 Round 362 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 368 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 368 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0031
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0061
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

📊 Round 368 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 371 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 371 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0029
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 372 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 372 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0147
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

📊 Round 372 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2486, R²: 0.0013

============================================================
🔄 Round 375 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 375 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0050
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0018
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2486, R²: 0.0013

============================================================
🔄 Round 376 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 376 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0010
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0099
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 377 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 377 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0060
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0068
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 378 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 378 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0029
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0064
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 379 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 379 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0023
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0034
============================================================


============================================================
🔄 Round 382 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 382 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0139
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 383 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 383 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0030
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0018
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 385 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 385 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0013
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0199
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 389 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 389 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0008
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0078
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 392 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 392 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0013
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0112
============================================================


============================================================
🔄 Round 393 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 393 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0041
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0011
============================================================


============================================================
🔄 Round 394 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 394 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0039
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0065
============================================================


============================================================
🔄 Round 401 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 401 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0005
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0082
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 402 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 402 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0042
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0156
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 402 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 406 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 406 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0029
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0042
============================================================


============================================================
🔄 Round 408 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 408 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0007
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0065
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 408 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 411 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 411 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0024
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0008
============================================================


============================================================
🔄 Round 412 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 412 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0000
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0095
============================================================


============================================================
🔄 Round 415 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 415 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0031
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0047
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 417 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 417 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0015
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0089
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 418 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 418 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0007
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 423 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 423 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0002
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0135
============================================================


============================================================
🔄 Round 424 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 424 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0040
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0038
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 426 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 426 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0012
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0086
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 430 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 430 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0002
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0289
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 431 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 431 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0102
============================================================


============================================================
🔄 Round 432 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 432 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0024
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0015
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 432 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 434 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 434 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0030
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0080
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 437 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 437 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0018
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0020
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 438 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 438 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0003
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0103
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 439 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 439 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0009
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0291
============================================================


============================================================
🔄 Round 440 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 440 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0019
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0016
============================================================


============================================================
🔄 Round 442 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 442 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0013
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0035
============================================================


============================================================
🔄 Round 443 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 443 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0001
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0130
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 445 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 445 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0048
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0083
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

📊 Round 445 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 451 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 451 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0004
============================================================


============================================================
🔄 Round 453 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 453 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0024
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0006
============================================================


============================================================
🔄 Round 454 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 454 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0030
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0013
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 457 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 457 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0024
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0041
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 458 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 458 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0027
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0024
============================================================


============================================================
🔄 Round 459 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 459 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0011
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0043
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 459 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 461 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 461 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0040
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0078
============================================================


============================================================
🔄 Round 464 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 464 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0018
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0044
============================================================


============================================================
🔄 Round 466 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 466 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0028
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0170
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 467 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 467 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0024
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0006
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 467 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 470 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 470 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0019
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0189
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 472 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 472 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0018
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0016
============================================================


============================================================
🔄 Round 473 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 473 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0025
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0064
============================================================


============================================================
🔄 Round 474 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 474 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0020
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0005
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 477 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 477 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0026
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0125
============================================================


============================================================
🔄 Round 478 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 478 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0002
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0255
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 479 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 479 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0029
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0012
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 480 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 480 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0001
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0227
============================================================


============================================================
🔄 Round 481 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 481 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0024
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0014
============================================================


============================================================
🔄 Round 482 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 482 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0031
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0012
============================================================


============================================================
🔄 Round 484 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 484 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0040
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0052
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 484 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 490 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 490 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0007
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0054
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 490 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 490 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 495 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 495 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0027
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0103
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 496 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 496 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0034
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0028
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 497 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 497 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0030
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0013
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 498 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 498 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0047
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0064
============================================================


============================================================
🔄 Round 500 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 500 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0006
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0237
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 500 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 500 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 505 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 505 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0020
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0011
============================================================


============================================================
🔄 Round 508 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 508 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0015
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0105
============================================================


============================================================
🔄 Round 509 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 509 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0027
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0022
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 510 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 510 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0018
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0177
============================================================


============================================================
🔄 Round 512 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 512 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0021
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0083
============================================================


============================================================
🔄 Round 514 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 514 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0131
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 514 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 516 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 516 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0034
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0192
============================================================


============================================================
🔄 Round 518 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 518 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0024
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0021
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 518 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 520 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 520 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0015
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0065
============================================================


============================================================
🔄 Round 521 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 521 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0016
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0015
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 521 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 521 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 524 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 524 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0049
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0068
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 524 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 526 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 526 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0010
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0033
============================================================


============================================================
🔄 Round 528 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 528 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0005
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0059
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 528 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 535 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 535 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0036
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0013
============================================================


============================================================
🔄 Round 536 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 536 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0015
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0072
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 537 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 537 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0034
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0012
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 539 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 539 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0021
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0018
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 540 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 540 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0011
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0040
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 541 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 541 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0013
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0036
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 541 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 546 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 546 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0015
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0040
============================================================


============================================================
🔄 Round 549 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 549 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0024
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0006
============================================================


============================================================
🔄 Round 551 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 551 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0014
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0099
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 551 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 557 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 557 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0007
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0067
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 558 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 558 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0007
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0231
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 558 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 558 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 565 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 565 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0071
============================================================


============================================================
🔄 Round 566 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 566 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0004
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0222
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 566 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 566 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 566 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 575 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 575 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0048
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0051
============================================================


============================================================
🔄 Round 577 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 577 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0016
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0028
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 577 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 577 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 580 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 580 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0003
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0072
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 580 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 583 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 583 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0018
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0022
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 584 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 584 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0011
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0050
============================================================


============================================================
🔄 Round 586 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 586 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0033
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0040
============================================================


============================================================
🔄 Round 587 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 587 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0033
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0013
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 588 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 588 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0016
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0019
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 589 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 589 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0028
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0047
============================================================


============================================================
🔄 Round 590 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 590 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0031
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0050
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 590 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 590 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

============================================================
🔄 Round 595 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 595 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0001
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0201
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 599 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 599 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0015
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0012
============================================================


============================================================
🔄 Round 600 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 600 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0029
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0104
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 600 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 603 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 603 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0041
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0009
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 605 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 605 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0178
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 606 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 606 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0036
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0028
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 606 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 613 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 613 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0003
   Val:   Loss=0.0972, RMSE=0.3117, R²=-0.0164
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 614 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 614 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0001
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

📊 Round 614 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 617 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 617 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0024
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0009
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 617 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 617 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 617 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 622 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 622 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0011
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0075
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 623 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 623 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0077
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 623 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 625 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 625 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0022
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0049
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 626 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 626 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0027
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0029
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 626 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 628 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 628 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0050
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0053
============================================================


============================================================
🔄 Round 629 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 629 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0024
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0078
============================================================


============================================================
🔄 Round 630 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 630 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0009
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0065
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 633 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 633 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0009
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.0055
============================================================


============================================================
🔄 Round 634 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 634 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0024
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0018
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 634 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

📊 Round 634 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 637 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 637 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0011
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0085
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 637 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 640 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 640 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0004
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0064
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 641 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 641 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0032
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0033
============================================================


============================================================
🔄 Round 643 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 643 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0039
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0085
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 645 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 645 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0024
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0008
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 645 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 648 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 648 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0027
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0003
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 651 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 651 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0009
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0255
============================================================


============================================================
🔄 Round 652 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 652 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0028
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0006
============================================================


============================================================
🔄 Round 653 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 653 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0016
   Val:   Loss=0.1010, RMSE=0.3177, R²=-0.0043
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 653 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 656 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 656 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0003
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0126
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 656 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 662 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 662 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0024
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0003
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 662 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 662 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

📊 Round 662 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 668 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 668 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0042
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0113
============================================================


============================================================
🔄 Round 669 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 669 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0035
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0049
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 669 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 669 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 675 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 675 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0028
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0038
============================================================


============================================================
🔄 Round 678 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 678 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0015
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0022
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 678 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 682 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 682 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0004
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0061
============================================================


============================================================
🔄 Round 684 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 684 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0023
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0023
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 685 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 685 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0015
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0021
============================================================


============================================================
🔄 Round 686 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 686 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0018
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0387
============================================================


============================================================
🔄 Round 687 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 687 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0063
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0523
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 687 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0006

📊 Round 687 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 692 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 692 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0035
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0161
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 692 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 692 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 696 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 696 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0019
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0074
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 696 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 698 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 698 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0020
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0054
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 699 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 699 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0022
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0024
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 701 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 701 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0024
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0002
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 702 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 702 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0011
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0167
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 702 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 708 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 708 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0011
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0044
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 709 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 709 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0035
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0042
============================================================


============================================================
🔄 Round 710 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 710 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0014
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0031
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 714 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 714 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0019
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0028
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 717 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 717 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0002
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0128
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 718 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 718 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0016
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0035
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0010

============================================================
🔄 Round 722 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 722 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0022
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0023
============================================================


============================================================
🔄 Round 724 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 724 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0007
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0143
============================================================


============================================================
🔄 Round 725 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 725 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0007
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0116
============================================================


============================================================
🔄 Round 726 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 726 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0009
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0053
============================================================


============================================================
🔄 Round 729 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 729 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0016
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0022
============================================================


============================================================
🔄 Round 730 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 730 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0015
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0024
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 731 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 731 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0011
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0107
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 731 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 733 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 733 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0060
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 735 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 735 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0023
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0014
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

📊 Round 735 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0005

============================================================
🔄 Round 738 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 738 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0222
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

============================================================
🔄 Round 741 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 741 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0024
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0011
============================================================


============================================================
🔄 Round 744 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 744 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.0137
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 745 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 745 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0045
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0007
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 746 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 746 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0242
============================================================


============================================================
🔄 Round 748 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 748 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0029
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0007
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2487, R²: 0.0004

📊 Round 748 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 752 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 752 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0007
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0342
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0007

📊 Round 752 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 755 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 755 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0009
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0405
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 757 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 757 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0010
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0056
============================================================


============================================================
🔄 Round 758 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 758 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0048
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0111
============================================================


============================================================
🔄 Round 760 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 760 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0020
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0012
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 762 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 762 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0019
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0317
============================================================


============================================================
🔄 Round 765 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 765 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0020
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0019
============================================================


============================================================
🔄 Round 767 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 767 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0013
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0140
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0011

============================================================
🔄 Round 770 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 770 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0020
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0040
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0009

📊 Round 770 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0008

============================================================
🔄 Round 778 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 778 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0051
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0246
============================================================


============================================================
🔄 Round 779 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 779 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0009
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0195
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 782 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 782 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0013
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0052
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

📊 Round 782 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2486, R²: 0.0008

📊 Round 782 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 785 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 785 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0012
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0043
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
