[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792b4668-7ee4-4de5-91e2-467bc8a6af1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a497fc80-8389-464e-8690-343810c5b839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe55d51a-7b41-490c-84ab-1cffc29be3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4b6802-2164-439b-b679-d02665fa3006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0048fa53-608d-4c21-8a3d-3b7960f7c1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12323953-a22e-47a7-944f-1ca21e61859e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23bd0e5-8b77-45b0-b60d-773c58d90007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d580c716-61e5-4965-a722-440741c3052d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9980e9c0-de0d-4586-a362-afe751193417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa2cbb60-0271-43c9-a89c-9edcba954dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4405a8a4-1f3d-4b43-8173-4f190e07aa77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a916f65-05e7-4e39-9b70-b083fd63e76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cfb19b-f831-4041-99f7-50f9f3808b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c74b62-43f8-419e-ac5d-4a1fc6b823fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a9d3be-0d2c-4b0b-b791-39f68c3756ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ac5ba8-d21f-4658-b983-8e9a79897152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7238fb5-103b-421c-ab6c-8820efdab1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cf0ee1-6bc3-46c3-84c0-a34c3ff4e60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44e3c1d-622e-4cef-81ea-b181bd20638f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf15119-1fd9-4eed-bcdb-2a9288b40bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d07773-133f-49d1-916f-8488e42439d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc5347d-7da8-4492-81ab-60f6db994424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456952c2-1040-4ee8-8b3b-c26c6810bb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240d003b-aaff-476f-8c2e-0f2f6ddfde67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d97c376-9279-49c3-81be-db889f2d9165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7d7223-56d2-465e-b4f5-c3567c1352ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e675580-f4a4-409b-81a8-da030a876707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efc4d83-94ea-41d3-9778-847c62122754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be909fbb-016d-4ded-ab06-c444a9a49bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f08ae33-60c2-4314-9d1a-a9f4669f78b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11e12771-59d7-4a2d-a903-f028f6d1543d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95bf6a77-0362-4fe0-b22b-2a9ecc44fc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af32d19f-5e22-437e-85c2-9dbf8e5ac368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14e838c-bdf8-4a17-890e-bb908486e6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e05d4e8f-8f68-4224-bc1d-da5e4fde5b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78cbb08a-d20c-4333-935e-b4c5ee054bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74876866-efc5-42f0-bae6-06ee7b476e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4aedf3-b9db-4b87-a3df-00b22c77025c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad83dd6-0df7-4503-a879-5591bc4c7a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc7fb0c5-a4ee-4ce5-a608-46bcd6189703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fb7384-7ae9-4ef8-87a1-66a2ac55c7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316079ff-03a6-414d-afaf-321ef99bf256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432e40f3-f76c-436c-b7e5-3b43d7a47a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d3561b-fb41-466c-aeb3-bcc2e9d85260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025a325b-82f6-41b9-9920-8302a8d451da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf643c88-1307-456e-ac08-eca08f6095a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1ff05d-2dd9-4bff-b548-6f9f18f04640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4bc8a94-36c6-4c27-8dcf-870d3cd396fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc7543d-6152-411b-88ea-5afa3df1ee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ec6427-9e90-462b-84f2-041b7c9e1a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8795cb34-02cc-48fc-b82b-d7a6b4d6bbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe54212d-70dd-4655-8d6e-dbe0297d9347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c00ab26-23b0-4fd0-aee6-c4d8108a3948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279fc453-1146-43da-ba34-91b7e76f5ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4ca4b3-99a6-4d16-b6ca-c27746872377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47f55cf-ab6b-4452-9a70-4f828eb83779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7fa58b-e94a-435f-9f60-d52b4c6b418a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00fd7a7-1097-45ca-86d5-694420007c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04bc8a66-1762-4811-bab5-b6ba23e58bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4346d1-71b3-40d8-af9f-a519948aa2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047788c0-8491-4429-9d5e-53700766747b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed390f79-cf18-420a-bd4e-ba8af80e0254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613557ca-9d16-452f-aa2b-c2618a57ad20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404907bb-f7b2-490e-84c2-1a18b1a88f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1dccdd8-c35a-4fcb-b4aa-85ae9f554d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b95374d-02b6-4f96-839d-629aa7261bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8f4deaf-2184-4f5d-81e7-e37722ee9521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52233695-04a3-4d82-94cd-9e269752a2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040ff2f5-13dc-4408-a915-6637a51f52de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcb7935-4548-48bc-9452-bfd6878c67a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a795091-c320-4908-bf90-4a9d64b2ca8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa46643-b412-43e0-8927-9a30e3ea7804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff9804c-8ddc-4579-8356-01d1a1ab6061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f49ae0-f987-4e4e-9b78-44e18d6ac17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9569cc75-e1e4-49b2-80d8-3650d0bbe7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2fdc1a-dc15-4739-a116-c2ae61dc8aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db1979a4-2667-4d82-901b-45e1cbec171b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf030f97-a799-41b6-b589-c45bfd1d2d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318f5116-9b7d-4abe-b53a-9750f51a9eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3598d2c-0603-4034-8df6-01d8c21cd90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc6754c-c9f7-4b01-b6ef-e8d2ad19a4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c59a986-d766-4aeb-b436-4a0836d7b2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610e8a38-119d-4f67-85ff-2e2e5155ffb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9072f7d1-3ef6-4083-92b1-ca1ca5a03cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9a43ec-2ccc-46b7-b748-284899b6e58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1190b1a0-1619-45c1-87c0-3db15ae09cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec913a3-5c12-439e-a164-c2213e3c7541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a1352e-cdcd-4f17-a533-2809db0afc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed85004c-6c6e-44e9-a7ad-7f57ecfbe250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d46d67-7c85-4551-a990-4097eb9795e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb3ffc1-4708-4770-b3d4-ee565cfce2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787e0b15-1d46-4c9e-b496-0986b3f04b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ce0fee-0053-4f8b-b9e7-cdb22c783a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e49630-88b5-4c5d-90a8-5d8a12f7b8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ce13ac-de95-40df-91de-5675064d01f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8071d4-7dd5-47c8-a222-dd78aea3df65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51894bad-95f4-41b4-b113-b24660b8865c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e17e89-18a8-40e1-b6cf-071d305d7bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5873e1-f760-45c1-b582-4808397417e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40b1248-eb3b-4026-b54f-ca04699f11da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50922bfc-f193-424d-a0af-0121ef056c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e67321a-4a14-408f-824a-876354b37ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4d4873-248b-4f11-861f-cb71f3ca184a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290d1bc2-d179-437d-bbd2-f7dca0dc1592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7221c92-1890-4b98-9253-218921ded6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ea9c8f-f028-4f12-b885-90cc917de139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3ac1f7-4651-4a49-98a8-cac67fed86c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947b2018-b89f-4b6c-aa6a-a8f6c8325d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b147f48-cae0-41a7-a5c5-5ea26c3646b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eadc269c-ab62-4229-95b9-43e29acb1232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088287c5-4aff-4e26-80ef-03d9c48bd20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53bfddc8-f06b-4438-b1ac-fa0e1cce60e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9144f8-1078-43ba-a99d-bf3b31ad32a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d81e3b2-07da-4055-8fa8-433c5ae487a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6a7cc7-0303-4c8c-918c-4e4a18d7e21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c9c1072-f07b-417f-8835-895af945c05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f561fe8d-4fce-44ec-bbae-70ab29b764e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d80d10-cef3-4a83-a02a-3694587ad3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a26b3766-260f-438e-bcf2-1345586bdc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d101ffa-69ef-4c09-8fb0-4523e682b182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02ffa35-7c1c-4753-8a8b-8590734f0852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2d7d4a-7705-4cfb-83aa-9161ddc3b20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d0bc27-cce0-49e4-9224-c593f6576ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6d69e5-e5c3-4548-aca8-24976b25dd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7390410-90c1-4093-924b-c8892fcb1088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e51794-f8e4-457b-b5a2-2adacb2ececb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d96610-635e-4b3b-9974-aa1d8d031d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077dfe9f-82c7-4652-9005-f8ecbfea2dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999b3bbc-d6ac-408e-9f59-72744736e6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015a79e1-fc34-4a81-8c39-78357e40e9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03cfb55b-0d3d-48ac-90be-2b3ec081d596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 856bf25c-a288-4613-a7e5-2d44aa59c361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270dc9aa-3ec8-4ada-8390-d21a9a11c99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e99eb86a-08f6-4ea7-88a9-8783fec8c389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750ba563-b00b-4c8f-8efa-a64a755bb29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee7679a-a677-4c4b-9c88-78a82da99218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c9e254-6db3-42f7-baf4-333cbda4b696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59196e43-ec2f-47e7-8b9c-0052ac3335b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2b3347-4285-4517-9edc-5f5efc10737b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01006fa-0d8e-49a2-b770-e81466b7c440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b496f510-4ea0-4544-8e46-fe58c8874d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce34818f-c441-4b37-a331-db369bdcbbfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d921a44f-c3b4-4fcf-b75f-1862b5d92f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f8669d-8043-45b6-a27c-45614597ac46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ed00ad-d5f5-4f8e-aa42-c9edfe930d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8e0aa5-9547-4607-8439-b899165a8776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d574db2-94e0-4d0b-b7d7-31a2d5a2376a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06777cd9-6f6e-4dcd-ade9-5d708bc040e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e24f73-3ba8-43e9-8f10-e79c7fb71cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f963131-f9cc-40f5-9305-d88ad6a675b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec911a0-3412-4994-9e9d-19e78540007d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3961174e-3d58-43e7-8995-58cd4e574888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d81ff84-0fa5-4894-abb6-c5a04150cc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86b5809-1de0-4e97-8ce5-35a0fc04c1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0f47c39-1acf-4c5a-9d22-df045bb8c5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a321a7-9a55-427f-800a-6c1f3d893bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 477ded6e-939f-43f9-8e72-32e4a87858b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e149f806-c099-4f15-b0b7-1cf2d15a29d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3894ea7d-f2cb-4685-b72b-cbd412fdb9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8188a9f0-8d6d-42e6-97c7-eabd9ea97327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0059495-baca-4831-b32e-074cc9a045b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7634fe2f-295a-445d-b64b-1e4ad1af0d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153e454d-a676-475a-9b3e-b4c207483ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c79dd5-ce62-4317-940b-db39ffc5e4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5fc3567-9f99-41de-9def-bb5ade7a5353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d499b89c-6a5d-43fe-9248-e2851db38fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b0a347-eee7-479f-890c-2981e2c4abcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdea7b0-7c5c-4839-a7fe-3546758fd744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d849613-363d-4649-aa6f-21ab2c812dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bcc1d24-5f8a-487c-8284-c200146c86ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6d29aa-d5a2-4647-b8c5-5bf4f5d55e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dacddeb-9494-41fc-87c6-a2fc81b93959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b74e04cd-4dae-489f-9276-f7703c1fd7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23591514-fafb-49c2-a448-ca05738feff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045dec01-6fd1-4bf2-9928-312aff7b93c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c36e5b5-491d-4844-a884-8b6dba87d3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df886248-8b85-4c7f-9061-cfd811b53f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523b34d0-c389-4e43-b7fe-f31a9ca60b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c04086c-ad6c-442a-be65-a82091ce67a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 627b867e-8668-4b5a-b6bd-f38501036d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66655cd7-9e8b-46fe-94a7-524af9ecc0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd347947-5537-4335-9c64-2f973b447c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f339d2b9-e805-44f9-84b4-b1a3f1da9c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b6a6f2-0c2d-4751-9f0d-1af9f51c4408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3d0ace-5086-4725-8161-a0bc2c5262e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51cf1c1-9338-4e85-8026-fed295df9566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb49abf5-c7aa-413e-9159-68a63526fb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea2224f-0059-435f-8aa6-859f26cb9379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b90a72de-a222-4930-b036-ee7894c336ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6891f308-945f-44c1-8ddd-61c856f4a38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b59f9bb-ba21-457d-baae-27b601bed51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02a4d13-ec04-4ae0-9baa-904ec82a2872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87c2dc5-c3ae-42ee-939f-da66b69dce85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde5dd48-2ab6-42d5-967e-55ffb093a636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da591272-4b5e-4c17-8121-5909f6bc316f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94fc3b8-310e-4634-954a-3b870b117b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173e1da2-24b0-4fcb-affa-f36c264681c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b616b9-f5e6-42ea-9e08-ae4e27fcab49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9e49ce-6e89-4b0a-9fe5-44bc1058172a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 914f4cd1-5966-4946-8eb6-dc51f826cd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bcecd0-7ace-42c4-8820-35637ec7d42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae6e99a-15b4-41c6-9788-48dce23e896b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94b7c4d-9310-4aa7-94aa-de1b65e69afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84cea2bf-d936-41ad-9e32-f829e3c7b336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e995486b-ee88-4d13-bc37-2513a61db240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 190364d2-be63-407e-82cb-f5d097d04667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b991ecaa-a42c-4bd2-b622-9013d256a8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c9ef60-14ba-46e2-a2f9-ae2aa6aa16e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43ac26f-6ea1-40a7-87d5-cb88bf442bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21da4c53-0940-47c5-b622-885b6ba6df90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fbc63e8-5431-4190-8221-e7263bde3243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1df447-df44-43cf-8166-dacbe6e51d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2228ac6-0d54-48de-986e-2a6a46e63d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bf13f6-907b-4b4c-9803-84792e69cdc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e345910-408a-4570-8067-5f2be5c3d356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b92e092-fbc4-48d0-b56b-46abe6eb66c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869513d6-d1eb-4b7f-81f1-2bc96ffec538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c02c736-1ca4-4fb9-bcf1-a851f413070b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4754341-fc91-41d8-a42c-ca8ab19e157f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1477e13f-a25d-4f29-8502-5b2a069f158f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a123a7-509f-4b03-a16e-25418de45819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc35b77-071a-4709-befc-f8388d6ca3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f888e1e8-8a9e-4787-bc50-85d1c78439f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2c5a3e-57bb-46a1-a4f9-bd6fcc97e3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d58c0a1-1f82-47d3-b330-c4f65e7252d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d664cdf5-18d4-4202-bc66-d9503515572b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4acd5ca8-0d31-408c-8673-6cf6fcae4c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e5a4f1-f676-4465-8a96-0b3dc65b3e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b61bbbd-43b7-41e5-9d1b-e34235b6396e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495a83cc-c9ff-437a-a5f4-a8571b4c4af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc54925-6ce7-40bb-91a4-2a35f4c8a42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c252e7de-d837-41d1-9739-415090521e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7917cb10-ca66-44a1-9a5a-f10e84978462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7520a728-50a6-4f71-bc5e-abe85442e5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f87d0fc-1125-42dc-b83f-2d3c72f40cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b05495a-33c5-4c47-bf60-6517f655f0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1286807d-516c-4e0f-bf94-b6c1213fb2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ae7e2c-e72b-40e3-89db-d3224a7e5e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a354e4-82b7-4283-b8cc-6247b46c1efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d255d57-a7c6-4c47-b4d1-e31281674534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcecef98-9d1b-4dc7-9ccd-3e6a2a729580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd92f72a-3133-4293-a5d1-38e3a21d12ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be64310-4946-4a3c-879e-e7a1ccff5c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fdaf42-8e71-411b-94b1-b597b6d5f5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab895a5-1965-4d25-96ef-57890863eea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea8ec1f-df94-4d8c-9fd2-35c7ad712d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8dd4544-5e33-4179-8431-157c98c2a7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e437fd-c164-46f5-98fc-418a81a44f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d02e72f-a616-4bf9-ad17-c359bab5948b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612a6897-75a2-4119-9816-4a3d8077e6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cec3463-2a77-4639-8956-e29481e45d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42d5b3e-60ac-4a01-95c3-6fcc96f68a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16687c97-c22a-45f8-8d70-e5df3a7bcfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b73002-a788-470b-9264-b88f158f9b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222b22a9-473f-4b33-a25f-d262cb4746a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7299f37-b5a8-4145-9efa-a1071def9504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7822e0ed-c8fa-48d6-a144-d6c2c3879149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c084c9-45af-4d79-aafb-ce4ad5c7f8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80e6cec-eddf-4621-8b2e-df217479497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419e3675-93f8-46b9-a097-af6d56427ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd68a40-95b5-4446-81e2-d4b15a623474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed01b774-a38f-47aa-af31-b8bbca63cebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7d573b-92a7-4b7d-bd9d-15d5fe8c0b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b9def2-835e-4662-a01a-1f63b7356915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd82bd4-6c00-4c59-971d-10c567207cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfada00-a614-4ea7-8f12-7cdb0a83b939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400262ce-1cd5-47ae-af43-d12edc3fcc0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce03242a-369b-4134-a302-e7cd08a3d54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab60e0a2-2621-47ff-9016-63e25e7b7670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce83def-a569-4d3c-bff9-ae1aee007b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac304d0-2eb4-475a-aee5-68dd4995e491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c37092-c2f4-448a-bd69-0d5fee41142c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3810c8b-8c44-4f55-928b-12a877e49da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a3c776e-45a2-4615-a21b-8857659e1e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c53b0a-20eb-40f1-a6df-5d875099c4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8f148b-9ba4-4dd4-8419-ef1f976fd883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc959aed-4eeb-4034-b438-42413df60f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8701252-9284-4a05-96a0-6ed009b22fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af469f79-2f73-4411-98fd-ec667b74c017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297d01a9-c46e-49f5-a101-3f6dde3f7d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4517acb8-3bca-4af6-adeb-5cf0e44b66bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c76fcf-50d5-4f49-bf40-913e3727c2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356f332e-c96b-4fbf-b87b-3bf78620104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81821516-9fc3-42cc-93ad-02a11c5104be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb6bacb-b280-4cc5-88e2-7fccce6fd2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e1a3c8-b99b-4930-96fb-74ea337ca63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13cb8117-f0a2-48f3-a4ea-4b68d99077be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e4fce9-afbc-43b7-b114-769d9447c724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0bd772f-62d4-45fa-9f15-3fb1f4d3f26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12804ca4-249c-4762-a68a-f710d6ea8a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45c59af-477a-4284-b6d8-c20853e7f6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbecad3f-a94c-4fa8-a95b-e1b7e61a1460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15392b48-49db-4d30-a62c-2888b904a471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca57eaa9-c945-442c-878f-436d166b38ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c695942-0036-48b0-8cb7-3ae61343e8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ecbf730-4208-41b7-9b78-da8cc7859a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5075a2-7f35-4b25-afec-a527e164afb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc37d152-172f-4b8a-b4d6-1c0dc409fa4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed831f75-4736-45a6-b0bb-b6204e1381f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86b2e8a-3af3-4157-bb17-be7e2816026b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf0c115-8751-4fc6-846a-3938c2732480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4499d74-68d0-476b-999c-587e4141521f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0a496e-ae19-4fe3-8498-a1c9506ba0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9226bf0-8007-4483-8d79-f4a2d9155f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c0a82e-69a5-43aa-b774-018718b96c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759d25d9-6122-4be8-80d9-db6891abe741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfd64cc-7d83-493d-beae-4241e303da53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c11c20b-9ca1-4410-ae79-76c5868947bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17252fd2-f267-4605-8aa6-8fb611ba6ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eea8ffc0-0b32-4518-bd36-46109dd53f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c2adec-1e01-4dfe-ac92-56a8c9327292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec9ef7c-3a87-4d85-baa4-138bfbe284ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871ed84d-d6da-4b80-82db-b9bcecba2193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbf440b-7ddf-4f53-b1f2-f13652047556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f44f9e-2486-4a5c-888e-9734555d72a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d226e14d-1c37-4910-9391-cf05b2d37e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3920af20-15bc-480e-92f7-614fc09414d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7bfbad2-f14c-4b9a-8fa4-2d8f5123b974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6d3d0f-87a3-4a24-9034-9b45efff0243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c0224e-62ef-4d35-8270-f68bd50e83ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe601029-3aa9-402e-87e4-449379906d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e818870-ba7e-4cc2-930b-531a00d19780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cd56c2-75da-4e59-bfdd-a2a464a444ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c3c526-78f0-4de1-89fe-81c0d0228d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba356853-0b2c-4dfb-aea6-a30b8af0eeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85616db-9b18-4d8a-9154-bb32096e21b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc8f19b-4179-4ab9-8506-6fe4ebeee97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfd621e-4c2d-46d9-84b6-73a6f58b058a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc847b14-3571-4393-a50b-02ed0e32477d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b742ad-6c45-48c1-a1ad-55284ffe5fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01027b7b-b044-4484-bf93-b8b0f4e5b8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e93be3f-a331-4da4-ab12-55d8b6bb82f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d101beff-7346-416c-beb0-c59194310cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a85339b-031b-45ed-8bb2-daa8f19bb110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bee91d-9c8a-4026-9de9-954d6bfe85bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b6f027-d6ac-4604-bb37-dc9093a0f9b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f650eeeb-4e01-43b2-9b96-6257d8edcd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4464d69-6ef8-4b2b-a5a4-5d06af7ccefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48d5bca-f5bb-4cbb-82f4-34e00f55443d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ba4144-f1fd-4f72-a263-d3559492f4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba494c64-d336-4c83-840c-f942bca5bc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75948ccb-4f94-43dd-bc6b-5e9883002b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a4a657-9440-4c2d-920b-bc52e1678c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f606b3e1-df08-42b3-82dd-4f5702d7f702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057844bd-bb73-49fd-8fe0-ece499a8db7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1661b0d5-b2b5-45d9-a5c3-be8e0c41e183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692048e4-46ec-4bfa-99ba-9753c348141a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e03a2c0b-1d3b-4313-984c-0159e0abcf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c7cd494-17ac-4fb7-ba69-9697eeeca25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fabd8cf0-8bbd-4920-96ac-50c551cab289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d3867f-d015-4ee7-8a68-37b4fc0464f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a83c54-a5f7-4d1d-9693-b9b326687525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8052a5e1-8b10-4961-83da-6702263a491f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d30bd4-b57c-4770-8a11-e482fe55e046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac025d3f-d569-49b0-a016-11e627023db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a936dc9-55cc-45e3-9d9d-a53948a61a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548dc7d1-1e91-4b55-93fb-8ba5ea5d9b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0f7afe-aa69-431d-9abc-1b8b0f5f973f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662775b7-4e66-4d2f-bf05-67f07ac737fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137c30cc-df41-46db-87bf-5f0838debf54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cddee22-2715-4ca1-bc8d-3b288b1cbcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31fe13e-1891-41f7-8b96-0d1eeffd4624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1149b333-4ff3-4dac-a674-d2097a63dbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a927994-8e9a-4b39-9138-19bf0fda82ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de808fe2-a4c1-4dd1-982a-faac9250f5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868d3ac4-728f-4ea6-8101-a04ef0c88332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f906c69d-1df7-4072-a4a6-34113a118055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b22480e-321e-42cf-aede-2e81b1ad5627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cace025a-a9a6-411e-bfa7-64c42276a5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69c6e6d-7620-4704-8050-38cebd1ad4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211e36f9-22b6-417e-acd5-feb7e68c71c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ef32e7-a953-4834-a62d-d72f9e6e9913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4938321f-17b8-471c-bcc6-dfc3f72c70e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f23e3e2-f1ee-4638-89ff-3da5c6679fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6893147c-bd75-49be-8db2-5982683d5356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582f296b-73dd-4141-bad5-a0ace2a86b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd1df0a-af38-4427-a32e-71d10dcf7de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909844a6-7a39-46c1-9bce-51126bcc8189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907666ca-7149-413c-a056-8fb9bafcb7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c51175c-6111-4e3b-98a8-359449d9f9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa8d511-94f2-41ba-a011-112d7558371c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1afb83-d7cf-4bfd-ac05-c6500c080380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090d5340-0634-4fcb-a69d-e9bd1fe3a5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aefeb03-6b36-4d72-8386-987a2801f9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fdd0bcd-ef4c-4fc1-b889-92ea70148c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8fb8db-46ae-4538-89a5-c6061d742ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6f4094-7285-4891-a52d-bce9e047eca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b02cc8-5e78-47d3-b99a-c81916601a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a9177d-d071-4d43-ba6b-0d00060c73ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca432ec-332f-41ba-b4b5-627cdc46c763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c12e2f2-9796-49a0-809c-e77a3002b651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b760a61-249b-45bf-8f95-94210ba5db99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da5eb32-5689-4409-bda2-26f7b66d2748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73d4bf6-2316-49b9-b664-0810dc10e811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2e7161-9311-470c-b949-69d17e2a969c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dac9405-bfe6-4eed-84e2-f8629379ab41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1930ef8b-677a-4fe9-9e15-fec07fe8799e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b37312-00f0-4d36-a2ad-b8d4cd955532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a50f9bf-48eb-4804-9e37-75f63e00892a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea68ed1-3a97-4eec-9391-88f91d624484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22507360-09ee-4e7f-acdc-c78a9f3836d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ad8d0a-4105-4309-a2df-8298f0d35270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7916e372-64a1-498b-a611-da0ce905737e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dbc0c1-b348-4185-a9cc-89b07049d6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b5ff2a-28d2-4e5a-b751-719a48ea01cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4904e9c-b4c6-4066-b6aa-bffe68eb3bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ac9f50-107f-4a43-9392-bc8f722d26ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 567f0269-fa74-41ff-90f7-9824f5ac0e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b327d479-0a4e-4791-b33a-f1b7b16cdb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43089b16-b2d1-4021-bf82-7befeb1dba5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ff34e6-760e-45ee-a1d3-6ef6c3ff324a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62deae5d-819f-4ef2-b2be-5645a973fcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6efcd7-79a7-40fe-ba18-cda73f4ef7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c932f59-3e75-4d01-a261-95988250b516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77cd6124-6936-46c2-8019-c9b3d0a50770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab74142c-f621-490e-91f3-d71fe50f09d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b53899-0103-470e-bc68-a159f512166b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d74741ba-3bde-4530-b113-7b2b7415d3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520428f4-9a7f-48df-8cca-157ba89f5417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf44f9cd-fd69-4b41-aa1b-bcff2a3ca461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10987420-9aa3-41ec-8a0e-d03e98552eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba1b841c-4733-47e6-8239-815edac5ce67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81a6738-29d1-41e7-94e8-f25f48fd3b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd1f3b5-7400-472d-852b-1707d32221fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417c3b37-bbf5-483b-a096-5b63943bb955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c667824f-1470-478b-9e5f-fa4a33d47df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db67df7-6377-4f69-af5d-9320f34035eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4459352c-304b-4c05-a465-09ba80450364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cafc5b6b-0f28-48d1-842d-a13ad610dc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a0cc20-6ddf-473a-b759-412b5bf88204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a60ee5f-13d3-4729-8b33-e49a7bb412ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5828661-82b9-4168-bd58-6e0ff87d2000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15cea602-9a89-4495-86c1-e096864eeba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d98d61-c50b-4ab3-b896-f34b4494111f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09e7d6c-c53a-460b-a2de-fa9f099bf730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e48126-d90b-48c8-9eaa-90a7616f059d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033dbd95-cd3a-4bd6-bb1a-342f17854fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd2046e-bc45-46d4-bb21-711d5a781238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e495c542-d860-4b20-88dd-1d3d80d01992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d734383e-f25f-4823-af53-7bd32e15b5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c0c194-7e8b-478b-8f2e-01613efcd621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a5346c-f4f8-4524-b3a0-77a37a537061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d681ec-d7e3-47aa-9854-667059eca21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fba271-c16b-4448-9f62-3b4b5f2495d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12e976d-81f7-4d2e-8a9d-a75c1568256a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ea2060-a6d3-4086-90bd-92241ab76cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9208254-45f9-468a-ad50-e0a1070e105d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ed0002-fe59-4f44-8a0b-ac3cd11f71d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d077b2b-e520-4faf-96f2-8d3ae27ac211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd04514-afbc-4119-8566-c09b3f58b071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408611b7-adf4-4996-acc2-d1036748ea2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a00df2-e775-47aa-ac45-5b79fd058c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb95b1e1-7e76-4113-ad4b-02a9e9b02974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961730d3-611c-4a2f-9a33-8ca3f6e64fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80815a78-b49d-4be2-b7b4-36bcfc406345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2a93a6-2b8e-45f6-b633-50b854004d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1bda182-a79c-4f66-b93a-d6bf1a624aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb0b626-6370-456a-a810-b16f4f16e614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6feb2c5-4ef9-490d-a922-98a6c324d871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f57fbf-8b6e-4cf6-83bc-d69dfd8c154f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da300fd-3e2b-411c-8b65-ace0d08959d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8754b2c9-65ab-433d-a979-1470234efda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2933a385-e8d3-4b88-bd26-d80fbbd05d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42eae33-871f-4813-9214-b13a05ffe80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7e41ff-e063-4157-9bb5-519eddd79d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd0866c-bcb0-45f7-8c88-1c5a1718bd40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b3269f-5659-4ff2-9075-9484a18642f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5690afd5-40ca-4b49-bcde-61a571c039aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e375d45d-2845-43be-ae71-74abee5211b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493b48e5-0597-44ce-9498-cd250a31b14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6abbc5e4-415e-4e18-9a51-0dfd26da2602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8e4ebd-cad6-4e92-8ad4-1b17eda2ee74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b8424e9-0220-465a-a78b-4fdaef3b9a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60663a5c-0a79-4312-8a4d-e3e58ebeeb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f371b9f-534a-49d4-867a-9b693c09900a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde25ad9-4ac8-4409-a197-01eb56cc0d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd960175-c146-492e-b8be-ca98d9b28541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa0af52-bddb-4d96-b39a-af69913ef3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422c2d46-9984-4063-bf10-9ead0cc175c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50aa9be-be30-4d25-8ce0-e14605d2aa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda80791-ae27-4529-9380-4b36e1f99f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc97e53-7a78-4a30-bfb4-98de0eefa6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c982b2f-cf24-4615-a149-b79c391ad852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2d29c9-a90f-4886-abd8-24f7cd640ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f08c13a-09c3-4160-8c13-01a0972078a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe1f609-e326-43be-bc94-887ae95367cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ea73bb-3320-4f31-a83e-941fba2d567d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138380ab-efc3-4db6-b43a-73fc481394b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1632318b-d82f-418a-b2a8-4cb186a7997a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e2be17-dae6-4634-8485-582923eb5234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cbfb78b-4e5c-44ee-bb1c-4a935c29977a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e895c956-3d9f-4ae6-8994-abcbec821e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c2ae31-1657-4491-b816-00d0c3a6497c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7aac405-a0f2-41dd-b404-88ce0e8a3eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007d2ca1-82f7-45cf-b6af-28f91b5c3224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003cfc74-c1a1-4cd8-b8ce-b0ef4d01a4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4790b847-3a2f-4e8d-a3ef-cec3c9b1c1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411a2aa1-1c55-4234-a3d0-e23fb7ca7df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e2bf14-0d5a-4d31-8fa8-35931ccf2907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb28c6ea-49e6-460f-8231-adf3bed3d142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd9fa30-52f9-4ca7-a35d-60322f090cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1861ab-0fff-4f61-9c59-7496ab1f7127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d40c66-276f-472d-aa8a-eb6ae5256650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8f2fce-e951-4090-8f9b-a22f48b040a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21f32acc-02f9-48a3-9723-394309ec1a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9b88ff-f13a-4baa-9a53-83742c1c54e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130ff0e9-c5c3-4dd6-829a-887438475e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011392d1-826e-4d5e-970c-93d6293d0776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28dd5bf-9ad8-45bc-a328-74683c1f713a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba569a0-2b4f-4be4-9a54-1beeb96600e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae84838-432b-47cf-a4c9-fdccfd405cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4a23a2-ed66-4950-83e1-8a46092f2952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60790fb1-ef68-44bc-bbae-ca243f87f563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9edd49a2-6d47-443e-af8a-1471ade697a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6824402f-8550-48b6-a9e2-6f66408bf614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7a0252-41d5-4d99-9e8b-8ff247dc07cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb59437-ee35-472e-acee-be3ceea82018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28ed5e84-640e-439a-a20b-ab7b2834b425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445f80bf-5751-49a0-b255-03d5037f03dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ec8c77-e8fa-4313-a4bd-426728e3a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fef3b46-b40f-4b9c-a4ab-ab6e7b2a1857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8f813e-45fe-4170-8ccc-7f2a46c2c37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b759ff0-65e6-43a2-9af1-1907a71d3408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8c165c-6cff-4298-bcf3-1f0e377bddb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86019d4b-4818-42aa-8f1e-26540038e690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485a7aff-115b-46e5-b292-f175e79ba207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a6b834-2f7d-4ac3-ba1e-1fd938454895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1039195b-7c14-4ea2-97f9-ab7e36db9c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2359f3bd-b2d3-4776-bfba-3dd8cb53272a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0ef381-b18f-4b9a-ae67-71ec910e70fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41632691-1f91-4d31-ba61-34ea977c9ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6f3809-5046-49a2-9f4c-9a82d7f5f1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c241c668-d1d7-4739-9025-dfe30fc36c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be39bf9d-83cf-497e-83d9-88bba6837858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194f3720-485f-4a6d-909d-a95846d34dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4caef6-a450-40c1-9221-62137f16f716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6229b711-72ba-4724-a38f-2787a85d5bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1996ce-8e8a-40e0-9767-988323dcca96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5b327e-ab17-47f2-b979-215544393b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2ee08d-c908-427b-b5f6-0ec312e3fd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb34091-ebb5-498f-9fce-1d23055edb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d721b254-e7b6-4364-a7d8-961811366006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccf662a-6782-4e1d-87e6-6d3719f3f8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b1ef31-9bfc-4cfa-9b31-bc902d13072f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185093b4-c579-4e14-9548-96bd02bbd5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94847c52-8cab-4df7-a995-ebee04a99a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f849976-12ed-47b6-9674-b9c172553616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adc029bb-a9af-4a0f-8553-1fddc27b2096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8bae39-7dc5-4c4d-b9cb-3f5081a16fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9feff0-efea-4ee5-9051-4be11d6a339e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421332f4-a4fa-4b55-b807-904370f83807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5447b7f-0f9a-4f52-a9fd-03b507dc3eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc7d13f-63cf-4df4-9712-5b044b0c4b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36f3d7d-1914-4804-85ee-d27d0bab6296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca6281c-122b-457f-b0db-f092604cfd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b4836b-81b7-4fe8-a602-c72f1162785a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e5ab0e-82a0-492b-af62-209e5437815f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c9b2d6-1476-42c5-9339-713e77bb8a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10590b1b-c9fc-4d04-997f-27de72a89238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f9fdd1-fe1d-4a8b-9247-70c0e0400232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ce03ff-d998-4214-85f1-ca35e2f007db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bec85e2-07da-48cf-b2ab-365eebdafe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a137bc3-e314-4a83-9b68-e009c9f21455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c32ecf-cc2a-4b43-9d84-797f8380e4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d748c11-f8fe-4656-9011-01af0257ef52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40329520-bd05-4e0a-839e-51d94686e8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a77dfd-678c-48b4-86b9-25c2bd9d61f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df067f39-b867-413a-9848-66d59350bd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cc36ae-f61d-4f4f-96b2-dd418508bd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c662c78-0e9d-41d3-adec-7b65467559e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e13d3fbd-ffe3-4408-857c-014e52eee0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faaeb5c8-7f77-4402-83a4-2f2c1fb05025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9747b78f-54cc-4791-b3cb-4e7ca4ec4497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c89eeeb-64d6-487b-92df-045c6c909e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0737ac9b-efbe-44b1-ae69-8b4fd35426f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b336fc3-1990-4c76-bb12-a137a94cd14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd176d19-5ba7-43dd-8114-55a622bca0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e3389a-506b-4e32-b21f-7ca9cd9852f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936ebae5-3026-4498-b1bf-ae6c12e68327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b881c1f8-77ce-4910-ad73-87a4e763defb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ece3aed-e907-40db-8de1-29f27823e7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229b6b1a-db8c-404f-844b-2f51041a8a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe516554-1019-4df6-9b3a-c7e07af91662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd08dca-19a3-4e10-99d7-3e74b9222d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f2e2b9-d9e6-4c9d-ac5c-f5c10cbf3fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4530b3-70d0-4c48-a081-be60f357f3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9434bbf5-e219-42c0-84b1-644f6f47a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5719a653-7854-4937-8866-fe2256fe3324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09fe6e4e-f33f-4dde-86fc-6c28cb6d11cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bc59f8-2042-48ed-8575-10958acdf38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e228300e-9e00-4582-8e64-601b6947b8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca22f7ed-a859-4292-8852-a6139f29f233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9064808b-304d-4a68-819e-165a52aad43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f9dae40-818e-4e29-aa74-adb0b621ca3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec759dcf-7f0e-4101-b452-bec40aeee4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 914806fd-e13f-41da-ae33-381732fe82ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9ba4c7-8799-4cf0-b798-e3f90a6bc32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd3699c-ff3a-48ee-9714-d8c38c365116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d85a2b1-c74d-4dfe-8be1-0af0e94c69d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca109d2b-0be7-4980-bd9b-0cfafb5043b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bf3ca1-f3e4-47ff-91cc-a211b7741bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d484815-2e1d-4860-a535-fa959a5ba438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ab368b-1917-4f5b-b87d-9abe8ade0ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9afb107-25a9-4797-9aea-ccf1f67ac4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a56383-2fd4-493a-991b-8c335db41f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2bdc9bb-bffb-443a-b9f3-c0aac3a092dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08012627-d1f2-4239-b2ff-609ee3891ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23e3676-135f-417d-9dc3-17402f9d811d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb178810-3b18-4dcf-83bb-47d5c847b5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df23433-39f7-417c-90cf-9ff584d87bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867889c0-3529-43c2-b5e2-b09d07941851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116f6389-7f6f-4cf7-aba3-7809a97a3127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba406df4-dbe8-42e4-8ef2-bb31b7499537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dfa048f-ecbb-4f03-8f91-9ead2c07f538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8976a7-74c5-4f44-80de-0bcb0a021928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8398b2dd-d74a-4975-af00-09d1bbba027e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88a4d8c-a70c-4eec-b2be-8d5e670a39b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee29578e-57b5-4d2a-abb2-9d843c7bf352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a83c3c4-aeae-4918-be1b-dc50bd2aba2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5f7d6d-6d27-4d3a-8b72-61524bf76dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae4d1d7-1c2d-45fe-905b-b04806ca6546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca36b7a-d59f-4352-a93e-e71bfa61a688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4553b992-efc7-4d84-88dd-b4e360746bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32424711-e178-4ea6-994e-c01d9abe4b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3d784f-9118-4946-85e7-4e241af2fcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023afd13-898a-4bfc-ab22-3a4f8197e0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c907b4da-f57a-4b1e-b294-8c1fbe8f2002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbad8e28-dbea-424e-b63f-51e25cd1494e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5872722c-2265-4122-9714-8896e8c64eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e8e1b9-ad2d-486e-b217-1c0192edce28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e80e87-dc15-483b-920a-fced4dace878
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(4800, 24), y=(4800,)
   Test:  X=(1200, 24), y=(1200,)

⚠️  Limiting training data: 4800 → 800 samples
⚠️  Limiting test data: 1200 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3524, val=0.1535 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0864, val=0.0884 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0794, val=0.0853 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0761, val=0.0837 (↓), lr=0.001000
   • Epoch   5/100: train=0.0753, val=0.0840, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0743, val=0.0849, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 2 Summary - Client client_21
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0095
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0162
============================================================


============================================================
🔄 Round 3 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4357, val=0.4358 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3391, val=0.3372 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2228, val=0.1666 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0915, val=0.0830 (↓), lr=0.000250
   • Epoch   5/100: train=0.0768, val=0.0851, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0747, val=0.0847, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 3 Summary - Client client_21
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0345
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0025
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4791, RMSE: 0.6921, MAE: 0.6326, R²: -5.0685

📊 Round 3 Test Metrics:
   Loss: 0.4723, RMSE: 0.6873, MAE: 0.6272, R²: -4.9833

============================================================
🔄 Round 7 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4639, val=0.4150 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4208, val=0.3766 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3839, val=0.3442 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3505, val=0.3132 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3160, val=0.2778 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1012, val=0.0947 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0755, val=0.0838, patience=7/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 7 Summary - Client client_21
   Epochs: 29/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0198
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0073
============================================================


============================================================
🔄 Round 8 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4724, val=0.4464 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   ✓ Epoch   2/100: train=0.4663, val=0.4402 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.4615, val=0.4375 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.4587, val=0.4349 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.4561, val=0.4326 (↓), lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.4439, val=0.4216 (↓), lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.4363, val=0.4147, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4324, val=0.4109, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4288, val=0.4075, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4253, val=0.4041, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4219, val=0.4008, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4185, val=0.3976, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4151, val=0.3943, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4117, val=0.3911, patience=1/15, lr=0.000001

============================================================
📊 Round 8 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.4077, RMSE=0.6385, R²=-4.3814
   Val:   Loss=0.3882, RMSE=0.6231, R²=-3.8190
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4515, RMSE: 0.6720, MAE: 0.6104, R²: -4.7198

📊 Round 8 Test Metrics:
   Loss: 0.4428, RMSE: 0.6655, MAE: 0.6032, R²: -4.6095

📊 Round 8 Test Metrics:
   Loss: 0.4324, RMSE: 0.6575, MAE: 0.5945, R²: -4.4770

============================================================
🔄 Round 11 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4487, val=0.4071 (↓), lr=0.000001
   • Epoch   2/100: train=0.4482, val=0.4067, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4477, val=0.4063 (↓), lr=0.000001
   • Epoch   4/100: train=0.4473, val=0.4058, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4468, val=0.4054 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4442, val=0.4030 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4400, val=0.3991 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4361, val=0.3954 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4322, val=0.3918 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4283, val=0.3882 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4245, val=0.3846 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4206, val=0.3809 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4167, val=0.3773 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4128, val=0.3737 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4089, RMSE=0.6395, R²=-4.3347
   Val:   Loss=0.3704, RMSE=0.6086, R²=-3.8451
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.4051, RMSE: 0.6364, MAE: 0.5711, R²: -4.1311

📊 Round 11 Test Metrics:
   Loss: 0.3612, RMSE: 0.6010, MAE: 0.5313, R²: -3.5759

============================================================
🔄 Round 18 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3017, val=0.2549 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3008, val=0.2540 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2998, val=0.2532 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2988, val=0.2523 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2979, val=0.2515 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2928, val=0.2469 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2850, val=0.2400 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2776, val=0.2334 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2704, val=0.2270 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2633, val=0.2207 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2562, val=0.2144 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2492, val=0.2082 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2421, val=0.2019 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2350, val=0.1957 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2279, RMSE=0.4774, R²=-1.9561
   Val:   Loss=0.1900, RMSE=0.4359, R²=-1.5748
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2254, RMSE: 0.4748, MAE: 0.3930, R²: -1.8551

============================================================
🔄 Round 20 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2294, val=0.2339 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2288, val=0.2332 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2281, val=0.2326 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2275, val=0.2319 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2268, val=0.2313 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2229, val=0.2274 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2163, val=0.2208 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2096, val=0.2141 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2029, val=0.2074 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1962, val=0.2007 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1895, val=0.1940 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1828, val=0.1873 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1761, val=0.1807 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1695, val=0.1741 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1621, RMSE=0.4027, R²=-1.1448
   Val:   Loss=0.1683, RMSE=0.4102, R²=-1.0622
============================================================


============================================================
🔄 Round 22 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1643, val=0.1598 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1636, val=0.1592 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1630, val=0.1586 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1623, val=0.1580 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1617, val=0.1574 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1578, val=0.1536 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1514, val=0.1476 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1453, val=0.1417 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1393, val=0.1360 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1335, val=0.1305 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1280, val=0.1253 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1227, val=0.1203 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1177, val=0.1156 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1130, val=0.1112 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1089, RMSE=0.3301, R²=-0.4271
   Val:   Loss=0.1075, RMSE=0.3279, R²=-0.3675
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.1319, RMSE: 0.3631, MAE: 0.2967, R²: -0.6703

============================================================
🔄 Round 23 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1400, val=0.1075 (↓), lr=0.000001
   • Epoch   2/100: train=0.1393, val=0.1070, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1387, val=0.1066 (↓), lr=0.000001
   • Epoch   4/100: train=0.1380, val=0.1061, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1374, val=0.1057 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1335, val=0.1030 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1275, val=0.0989 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1219, val=0.0952 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1167, val=0.0919 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1119, val=0.0889 (↓), lr=0.000001
   • Epoch  61/100: train=0.1075, val=0.0863, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1034, val=0.0840 (↓), lr=0.000001
   • Epoch  81/100: train=0.0997, val=0.0821, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0964, val=0.0804, patience=1/15, lr=0.000001

============================================================
📊 Round 23 Summary - Client client_21
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0933, RMSE=0.3054, R²=-0.2255
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0512
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: -0.0071

📊 Round 23 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2419, R²: -0.0049

============================================================
🔄 Round 28 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 28 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0119
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0141
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 31 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 31 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=-0.0070
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0096
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: -0.0014

============================================================
🔄 Round 33 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 33 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=-0.0036
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0192
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0013

📊 Round 33 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0013

============================================================
🔄 Round 35 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 35 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0042
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0223
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0012

============================================================
🔄 Round 36 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 36 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0037
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0144
============================================================


============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0043
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0163
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0012

============================================================
🔄 Round 39 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 39 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=-0.0058
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0049
============================================================


============================================================
🔄 Round 40 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 40 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=-0.0094
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0065
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0012

📊 Round 40 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0012

============================================================
🔄 Round 43 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 43 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0039
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0112
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2415, R²: -0.0013

============================================================
🔄 Round 44 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 44 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=-0.0048
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0104
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2415, R²: -0.0013

============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0041
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0346
============================================================


============================================================
🔄 Round 47 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 47 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0065
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.0014
============================================================


============================================================
🔄 Round 48 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 48 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0043
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0081
============================================================


============================================================
🔄 Round 49 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 49 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0069
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0022
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: -0.0015

============================================================
🔄 Round 51 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 51 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0049
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0048
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: -0.0016

📊 Round 51 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: -0.0016

============================================================
🔄 Round 53 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 53 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0053
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0053
============================================================


============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0046
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0072
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

============================================================
🔄 Round 56 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 56 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0058
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0012
============================================================


============================================================
🔄 Round 64 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 64 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=-0.0069
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0025
============================================================


============================================================
🔄 Round 65 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 65 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=-0.0091
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0049
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: -0.0028

📊 Round 65 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 72 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 72 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0050
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0228
============================================================


============================================================
🔄 Round 73 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 73 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=-0.0049
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0178
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 76 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 76 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0063
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0006
============================================================


============================================================
🔄 Round 78 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 78 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=-0.0044
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0054
============================================================


============================================================
🔄 Round 79 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 79 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=-0.0033
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0094
============================================================


============================================================
🔄 Round 80 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 80 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0046
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0066
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0026

============================================================
🔄 Round 84 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 84 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=-0.0066
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0034
============================================================


============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=-0.0036
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0112
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 90 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 90 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=-0.0031
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0150
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

📊 Round 90 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

📊 Round 90 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

📊 Round 90 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 96 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 96 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0036
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0082
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 98 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 98 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0027
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0148
============================================================


============================================================
🔄 Round 99 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 99 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=-0.0049
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0034
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 101 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 101 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0022
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0130
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0019

============================================================
🔄 Round 109 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 109 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0040
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0064
============================================================


============================================================
🔄 Round 110 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 110 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0058
   Val:   Loss=0.0679, RMSE=0.2606, R²=-0.0017
============================================================


============================================================
🔄 Round 113 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 113 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0036
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0167
============================================================


============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=-0.0045
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0207
============================================================


============================================================
🔄 Round 117 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 117 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0054
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0021
============================================================


============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=-0.0039
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0058
============================================================


============================================================
🔄 Round 120 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 120 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0038
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0115
============================================================


============================================================
🔄 Round 121 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 121 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0039
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0067
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: -0.0027

📊 Round 121 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 125 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 125 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=-0.0031
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0100
============================================================


============================================================
🔄 Round 126 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 126 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0043
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0191
============================================================


============================================================
🔄 Round 127 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 127 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=-0.0033
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0087
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0030

============================================================
🔄 Round 134 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 134 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0031
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0101
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 135 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 135 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=-0.0040
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0094
============================================================


============================================================
🔄 Round 136 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 136 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=-0.0035
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0079
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2416, R²: -0.0027

📊 Round 136 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0041
   Val:   Loss=0.0688, RMSE=0.2623, R²=-0.0091
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0032
   Val:   Loss=0.0658, RMSE=0.2564, R²=-0.0106
============================================================


============================================================
🔄 Round 143 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 143 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0051
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0010
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

📊 Round 143 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0030

📊 Round 143 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0030

============================================================
🔄 Round 146 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 146 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0049
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0316
============================================================


============================================================
🔄 Round 147 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 147 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0061
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0050
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0029

📊 Round 147 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0029

============================================================
🔄 Round 149 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 149 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=-0.0073
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0044
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2416, R²: -0.0027

============================================================
🔄 Round 152 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 152 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0039
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0083
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2416, R²: -0.0026

📊 Round 152 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0026

============================================================
🔄 Round 156 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 156 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0053
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0083
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 157 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 157 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0040
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0052
============================================================


============================================================
🔄 Round 160 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 160 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=-0.0068
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0107
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0060
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0047
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

📊 Round 162 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0040
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0047
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 168 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 168 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0037
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0043
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0048
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0011
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

📊 Round 169 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 173 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 173 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=-0.0042
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0044
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 177 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 177 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0042
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0094
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

📊 Round 177 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

============================================================
🔄 Round 180 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 180 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0048
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0002
============================================================


============================================================
🔄 Round 182 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 182 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0049
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0015
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

📊 Round 182 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

============================================================
🔄 Round 184 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 184 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0049
   Val:   Loss=0.0721, RMSE=0.2684, R²=-0.0097
============================================================


============================================================
🔄 Round 185 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 185 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0018
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0113
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 187 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 187 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0036
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0072
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 188 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 188 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=-0.0042
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0113
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

📊 Round 188 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

📊 Round 188 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

============================================================
🔄 Round 192 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 192 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0009
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0172
============================================================


============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2738, R²=-0.0014
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0230
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

============================================================
🔄 Round 194 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 194 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0044
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0127
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0027

============================================================
🔄 Round 198 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 198 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=-0.0042
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0014
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 200 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 200 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=-0.0033
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0068
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 201 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 201 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0151
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 202 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 202 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=-0.0031
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0056
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 205 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 205 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0038
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0239
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 215 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 215 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=-0.0033
   Val:   Loss=0.0707, RMSE=0.2658, R²=-0.0171
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 216 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 216 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0040
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0045
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 217 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 217 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0043
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0004
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

📊 Round 217 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0019

📊 Round 217 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0019

============================================================
🔄 Round 222 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 222 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0036
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0021
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0019

============================================================
🔄 Round 223 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 223 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0045
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0016
============================================================


============================================================
🔄 Round 225 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 225 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0024
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0082
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 226 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 226 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0043
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0003
============================================================


============================================================
🔄 Round 228 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 228 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=-0.0032
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0049
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

📊 Round 228 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

============================================================
🔄 Round 232 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 232 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0027
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0162
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

============================================================
🔄 Round 233 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 233 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0026
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0070
============================================================


============================================================
🔄 Round 234 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 234 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0050
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0021
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

============================================================
🔄 Round 236 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 236 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0058
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0128
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

📊 Round 236 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

============================================================
🔄 Round 238 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 238 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=-0.0022
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0241
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0027

📊 Round 238 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

============================================================
🔄 Round 242 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 242 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=-0.0026
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0165
============================================================


============================================================
🔄 Round 243 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 243 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0023
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0133
============================================================


============================================================
🔄 Round 245 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 245 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0031
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0052
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

============================================================
🔄 Round 246 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 246 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0050
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0128
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

============================================================
🔄 Round 249 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 249 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0022
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0176
============================================================


============================================================
🔄 Round 250 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 250 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0036
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0174
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 250 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 250 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 250 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0024

============================================================
🔄 Round 255 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 255 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0037
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0020
============================================================


============================================================
🔄 Round 256 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 256 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0033
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0061
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 261 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 261 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=-0.0037
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0079
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 263 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 263 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0043
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0230
============================================================


============================================================
🔄 Round 264 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 264 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=-0.0004
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0214
============================================================


============================================================
🔄 Round 265 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 265 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0031
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0122
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 267 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 267 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0038
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0109
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 269 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 269 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0061
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0347
============================================================


============================================================
🔄 Round 270 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 270 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0022
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0071
============================================================


============================================================
🔄 Round 271 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 271 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0035
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0050
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 273 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 273 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0013
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0122
============================================================


============================================================
🔄 Round 275 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 275 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0016
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0153
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

📊 Round 275 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 278 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 278 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=-0.0065
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0010
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 279 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 279 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=-0.0033
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0041
============================================================


============================================================
🔄 Round 281 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 281 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0049
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0030
============================================================


============================================================
🔄 Round 282 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 282 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0029
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0074
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 282 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 282 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0027

📊 Round 282 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

📊 Round 282 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0029

📊 Round 282 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0031

📊 Round 282 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0032

============================================================
🔄 Round 300 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 300 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=-0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0084
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 302 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 302 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=-0.0035
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0054
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 304 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 304 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=-0.0035
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0123
============================================================


============================================================
🔄 Round 305 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 305 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0033
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0017
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 306 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 306 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0021
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0113
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 309 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 309 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0038
   Val:   Loss=0.0683, RMSE=0.2613, R²=-0.0029
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

📊 Round 309 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 311 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 311 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0019
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0151
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 314 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 314 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0033
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0089
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

============================================================
🔄 Round 322 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 322 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=-0.0018
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0088
============================================================


============================================================
🔄 Round 323 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 323 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0029
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0148
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0023

============================================================
🔄 Round 327 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 327 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0031
   Val:   Loss=0.0689, RMSE=0.2624, R²=-0.0034
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

📊 Round 327 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

============================================================
🔄 Round 330 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 330 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0041
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0013
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

============================================================
🔄 Round 332 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 332 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0030
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0049
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0026

============================================================
🔄 Round 333 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 333 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=-0.0017
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0069
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 337 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 337 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=-0.0046
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0351
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0029

============================================================
🔄 Round 340 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 340 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0046
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0032
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 342 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 342 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0039
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0002
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

📊 Round 342 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

📊 Round 342 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 346 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 346 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=-0.0037
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0004
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 347 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 347 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=-0.0023
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0113
============================================================


============================================================
🔄 Round 348 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 348 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0045
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0045
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

============================================================
🔄 Round 350 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 350 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0008
   Val:   Loss=0.0690, RMSE=0.2626, R²=-0.0296
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

============================================================
🔄 Round 351 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 351 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0049
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0065
============================================================


============================================================
🔄 Round 352 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 352 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0016
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0138
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

============================================================
🔄 Round 353 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 353 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=-0.0034
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0023
============================================================


============================================================
🔄 Round 356 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 356 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0013
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0158
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0025

📊 Round 356 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0024

============================================================
🔄 Round 361 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 361 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=-0.0048
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0052
============================================================


============================================================
🔄 Round 362 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 362 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0038
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0408
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

📊 Round 362 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 366 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 366 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0034
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0016
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 367 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 367 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0043
   Val:   Loss=0.0669, RMSE=0.2587, R²=0.0026
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

📊 Round 367 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 370 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 370 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0033
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0036
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

============================================================
🔄 Round 373 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 373 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=-0.0035
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0018
============================================================


============================================================
🔄 Round 374 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 374 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0009
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0169
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0014

============================================================
🔄 Round 376 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 376 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0031
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0065
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

============================================================
🔄 Round 380 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 380 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=-0.0010
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0079
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 382 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 382 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0032
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0022
============================================================


============================================================
🔄 Round 383 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 383 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0031
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0001
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

============================================================
🔄 Round 385 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 385 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0036
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0010
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

📊 Round 385 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

============================================================
🔄 Round 388 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 388 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0019
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0088
============================================================


============================================================
🔄 Round 389 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 389 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0030
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0070
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

📊 Round 389 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

📊 Round 389 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0014

============================================================
🔄 Round 393 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 393 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0025
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0156
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 397 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 397 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0030
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0011
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 398 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 398 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=-0.0031
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0034
============================================================


============================================================
🔄 Round 399 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 399 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0036
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0081
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 400 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 400 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0017
   Val:   Loss=0.0698, RMSE=0.2641, R²=-0.0057
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 401 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 401 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0011
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0074
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 402 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 402 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=-0.0039
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0021
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 404 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0641, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0641, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 404 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0023
   Val:   Loss=0.0640, RMSE=0.2530, R²=-0.0186
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 404 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 406 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 406 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=-0.0021
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0038
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

📊 Round 406 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 411 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 411 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0027
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0006
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0020

📊 Round 411 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

📊 Round 411 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 414 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 414 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=-0.0028
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0079
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 416 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 416 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0309
============================================================


============================================================
🔄 Round 418 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 418 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0030
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0216
============================================================


============================================================
🔄 Round 419 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 419 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0017
   Val:   Loss=0.0686, RMSE=0.2620, R²=-0.0149
============================================================


============================================================
🔄 Round 420 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 420 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0031
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0017
============================================================


============================================================
🔄 Round 421 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 421 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0198
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 430 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 430 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0048
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0115
============================================================


============================================================
🔄 Round 433 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 433 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0021
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0032
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 434 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 434 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0015
   Val:   Loss=0.0672, RMSE=0.2592, R²=-0.0067
============================================================


============================================================
🔄 Round 437 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 437 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=-0.0022
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0022
============================================================


============================================================
🔄 Round 438 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 438 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0023
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0065
============================================================


============================================================
🔄 Round 440 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 440 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=-0.0014
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0056
============================================================


============================================================
🔄 Round 441 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 441 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0033
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0022
============================================================


============================================================
🔄 Round 442 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 442 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0021
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0092
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

============================================================
🔄 Round 443 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 443 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=-0.0022
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0020
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0018

📊 Round 443 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 447 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 447 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0016
   Val:   Loss=0.0693, RMSE=0.2632, R²=-0.0054
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 448 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 448 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=-0.0011
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0090
============================================================


============================================================
🔄 Round 449 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 449 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=-0.0014
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0046
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

📊 Round 449 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 452 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 452 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=-0.0021
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0120
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

📊 Round 452 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 459 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 459 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0077
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 461 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 461 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0039
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0142
============================================================


============================================================
🔄 Round 462 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 462 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0014
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0264
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 462 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 462 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 462 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 468 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 468 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0018
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0034
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

📊 Round 468 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0016

============================================================
🔄 Round 477 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 477 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=-0.0019
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0108
============================================================


============================================================
🔄 Round 479 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 479 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=-0.0024
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0051
============================================================


============================================================
🔄 Round 480 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 480 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=-0.0019
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0021
============================================================


============================================================
🔄 Round 481 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 481 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0025
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0087
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 483 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 483 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=-0.0016
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0034
============================================================


============================================================
🔄 Round 484 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 484 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0005
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0082
============================================================


============================================================
🔄 Round 485 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 485 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0035
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0189
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 487 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 487 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0028
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0055
============================================================


============================================================
🔄 Round 488 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 488 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0017
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0035
============================================================


============================================================
🔄 Round 491 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 491 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=-0.0024
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0021
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 491 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 496 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 496 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=-0.0025
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0070
============================================================


============================================================
🔄 Round 497 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 497 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0033
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0310
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 498 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 498 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0020
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0095
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 499 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 499 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=-0.0025
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0135
============================================================


============================================================
🔄 Round 500 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 500 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=-0.0026
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0001
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

📊 Round 500 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 502 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 502 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0021
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0013
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 504 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 504 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0101
============================================================


============================================================
🔄 Round 505 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 505 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=-0.0016
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0071
============================================================


============================================================
🔄 Round 506 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 506 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0034
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0002
============================================================


============================================================
🔄 Round 507 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 507 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0023
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0012
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 507 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 507 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 507 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 517 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 517 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0049
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0116
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 517 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 517 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 524 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 524 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0034
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0056
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 525 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 525 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0020
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0195
============================================================


============================================================
🔄 Round 526 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 526 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0029
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0018
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

📊 Round 526 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

============================================================
🔄 Round 528 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 528 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0027
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0006
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

📊 Round 528 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0017

============================================================
🔄 Round 534 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 534 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=-0.0007
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0058
============================================================


============================================================
🔄 Round 535 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 535 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2738, R²=-0.0015
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0154
============================================================


============================================================
🔄 Round 537 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 537 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0002
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0118
============================================================


============================================================
🔄 Round 538 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 538 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0063
   Val:   Loss=0.0688, RMSE=0.2624, R²=-0.0295
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 541 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 541 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=-0.0023
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0009
============================================================


============================================================
🔄 Round 542 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 542 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0026
   Val:   Loss=0.0674, RMSE=0.2597, R²=-0.0023
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 543 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 543 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=-0.0044
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0052
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 543 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 547 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 547 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0019
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0044
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

📊 Round 547 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 549 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 549 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=-0.0039
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0002
============================================================


============================================================
🔄 Round 554 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 554 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0008
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0073
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 555 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 555 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0005
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0129
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 557 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 557 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0011
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0052
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 557 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 559 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 559 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=-0.0017
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0132
============================================================


============================================================
🔄 Round 560 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 560 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=-0.0028
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0031
============================================================


============================================================
🔄 Round 563 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 563 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=-0.0027
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0020
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

============================================================
🔄 Round 567 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 567 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0001
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0085
============================================================


============================================================
🔄 Round 568 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 568 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0015
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0209
============================================================


============================================================
🔄 Round 569 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 569 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0011
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0142
============================================================


============================================================
🔄 Round 571 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 571 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0015
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0051
============================================================


============================================================
🔄 Round 575 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 575 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0007
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0111
============================================================


============================================================
🔄 Round 576 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 576 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0018
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0020
============================================================


============================================================
🔄 Round 577 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 577 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0030
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0011
============================================================


============================================================
🔄 Round 578 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 578 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=-0.0018
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0172
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 580 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 580 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0023
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0218
============================================================


============================================================
🔄 Round 581 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 581 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0018
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0164
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 581 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 585 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 585 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0038
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0223
============================================================


============================================================
🔄 Round 589 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 589 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=-0.0025
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0007
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

📊 Round 589 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

📊 Round 589 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

📊 Round 589 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

============================================================
🔄 Round 594 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 594 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=-0.0022
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0085
============================================================


============================================================
🔄 Round 595 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 595 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0009
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0180
============================================================


============================================================
🔄 Round 596 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 596 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0018
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0119
============================================================


============================================================
🔄 Round 597 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 597 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0017
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0019
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0022

============================================================
🔄 Round 598 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 598 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0011
   Val:   Loss=0.0672, RMSE=0.2592, R²=-0.0050
============================================================


============================================================
🔄 Round 600 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 600 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0022
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0005
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 600 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

📊 Round 600 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 607 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 607 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0006
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0196
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 609 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 609 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=-0.0023
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0061
============================================================


============================================================
🔄 Round 612 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 612 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0026
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0021
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 613 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 613 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0052
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0031
============================================================


============================================================
🔄 Round 614 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 614 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0019
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0081
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

📊 Round 614 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2416, R²: -0.0015

============================================================
🔄 Round 617 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 617 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0018
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0007
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 619 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 619 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0018
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0018
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 621 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 621 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=-0.0019
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0019
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 621 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 621 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 624 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 624 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=-0.0017
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0081
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 626 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 626 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=-0.0006
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0069
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 627 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 627 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0012
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0030
============================================================


============================================================
🔄 Round 629 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 629 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0020
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0004
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 633 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 633 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0019
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0062
============================================================


============================================================
🔄 Round 634 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 634 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=-0.0017
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0030
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 640 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 640 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0020
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0006
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 640 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 644 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 644 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=-0.0022
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0136
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 644 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 646 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 646 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0014
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0043
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 649 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 649 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0001
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0110
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 649 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 649 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0021

============================================================
🔄 Round 654 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 654 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0012
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0038
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0022

📊 Round 654 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

📊 Round 654 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 658 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 658 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0012
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0128
============================================================


============================================================
🔄 Round 659 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 659 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0023
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0129
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 659 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

============================================================
🔄 Round 664 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 664 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=-0.0046
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0532
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

📊 Round 664 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

============================================================
🔄 Round 667 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 667 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0015
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0094
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

============================================================
🔄 Round 668 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 668 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=-0.0006
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0041
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

📊 Round 668 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

📊 Round 668 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

============================================================
🔄 Round 674 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0624 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0624, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0624, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0624, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0624, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0624, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0624)

============================================================
📊 Round 674 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0013
   Val:   Loss=0.0624, RMSE=0.2499, R²=-0.0027
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 674 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0020

📊 Round 674 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 674 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 680 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 680 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=-0.0002
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0092
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 680 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 683 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0629 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0629, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0629, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0629, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0629, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0630, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0629)

============================================================
📊 Round 683 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0016
   Val:   Loss=0.0629, RMSE=0.2508, R²=-0.0170
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 683 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 686 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 686 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0004
============================================================


============================================================
🔄 Round 688 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 688 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=-0.0011
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0110
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 692 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 692 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0026
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0028
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

📊 Round 692 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 695 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 695 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=-0.0016
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0005
============================================================


============================================================
🔄 Round 696 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 696 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0008
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0177
============================================================


============================================================
🔄 Round 698 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 698 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0012
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0025
============================================================


============================================================
🔄 Round 699 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 699 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0013
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0023
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 701 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 701 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=-0.0007
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0034
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

📊 Round 701 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 703 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 703 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=-0.0019
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0010
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 704 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 704 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=-0.0024
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0187
============================================================


============================================================
🔄 Round 705 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 705 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=-0.0018
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0007
============================================================


============================================================
🔄 Round 706 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 706 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0017
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0101
============================================================


============================================================
🔄 Round 707 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 707 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0006
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0125
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

📊 Round 707 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0012

📊 Round 707 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

============================================================
🔄 Round 713 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 713 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0002
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0140
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 714 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 714 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0086
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 716 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 716 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=-0.0007
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0038
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0013

============================================================
🔄 Round 718 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 718 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=-0.0013
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0415
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

📊 Round 718 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

📊 Round 718 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

📊 Round 718 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 726 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 726 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0021
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0025
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 727 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 727 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=-0.0024
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0009
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

📊 Round 727 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 730 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 730 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0008
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0033
============================================================


============================================================
🔄 Round 732 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 732 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=-0.0021
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0018
============================================================


============================================================
🔄 Round 733 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 733 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=-0.0017
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0059
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0019

============================================================
🔄 Round 735 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 735 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=-0.0017
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0002
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 737 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 737 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0004
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0051
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0017

============================================================
🔄 Round 738 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 738 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=-0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0024
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 739 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 739 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0021
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0010
============================================================


============================================================
🔄 Round 742 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 742 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=-0.0012
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0062
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 743 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 743 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0001
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0097
============================================================


============================================================
🔄 Round 744 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 744 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0015
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0344
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0020

============================================================
🔄 Round 750 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 750 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0013
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0014
============================================================


============================================================
🔄 Round 751 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 751 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=-0.0048
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0181
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

📊 Round 751 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

📊 Round 751 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

============================================================
🔄 Round 758 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 758 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0022
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0068
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0013

============================================================
🔄 Round 766 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 766 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=-0.0030
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0295
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0012

📊 Round 766 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0011

📊 Round 766 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2417, R²: -0.0014

📊 Round 766 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

📊 Round 766 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0015

📊 Round 766 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0016

============================================================
🔄 Round 778 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 778 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0028
   Val:   Loss=0.0681, RMSE=0.2610, R²=-0.0224
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

📊 Round 778 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0018

============================================================
🔄 Round 782 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 782 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=-0.0010
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0043
============================================================


============================================================
🔄 Round 784 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 784 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0009
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0159
============================================================


❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
